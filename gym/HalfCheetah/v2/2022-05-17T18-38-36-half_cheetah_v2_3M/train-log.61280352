Initialising...
Changed directory to /rds/user/ajc348/hpc-work/softlearning.

JobID: 61280352
======
Time: Tue 17 May 18:36:28 BST 2022
Running on master node: cpu-q-259
Current directory: /rds/user/ajc348/hpc-work/softlearning

Nodes allocated:
================
cpu-q-259

numtasks=1, numnodes=1, mpi_tasks_per_node=1 (OMP_NUM_THREADS=1)

Executing command:
==================
softlearning run_example_local examples.development --cpus 1 --trial-cpus 1 --local-dir . --algorithm SAC --universe gym --domain HalfCheetah --task v2 --exp-name half_cheetah_v2_3M --checkpoint-frequency 10

Warning: robosuite package not found. Run `pip install robosuite` to use robosuite environments.
== Status ==
Memory usage on this node: 17.8/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+-------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+
| Trial name               | status   | loc   |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |
|--------------------------+----------+-------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------|
| id=31acc_00000-seed=9479 | RUNNING  |       |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |
+--------------------------+----------+-------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+


[2m[36m(pid=283289)[0m Warning: robosuite package not found. Run `pip install robosuite` to use robosuite environments.
[2m[36m(pid=283289)[0m Using seed 9479
Result for id=31acc_00000-seed=9479:
  alpha: 0.022199438884854317
  date: 2022-05-17_18-45-31
  done: false
  epoch: 0
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.0733493447303772
      reward_ctrl-last-mean: -0.24177770614624025
      reward_ctrl-mean-mean: -0.40566818028092383
      reward_ctrl-median-mean: -0.4013489961624146
      reward_ctrl-range-mean: 0.5176917433738708
      reward_run-first-mean: -0.15881838137952534
      reward_run-last-mean: 3.043933509962642
      reward_run-mean-mean: 2.489522605371327
      reward_run-median-mean: 2.5072648085321703
      reward_run-range-mean: 4.9004801345415085
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 2083.8544921875
    episode-reward-mean: 2083.8544921875
    episode-reward-min: 2083.8544921875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 1
  node_ip: 10.43.77.35
  num_train_steps: 25000
  pid: 283289
  policy:
    actions-max: 0.9999919533729553
    actions-mean: 0.062251586467027664
    actions-min: -0.9999655485153198
    actions-std: 0.7550143003463745
    entropy-mean: -5.925097465515137
    entropy-std: 5.327149391174316
    scales-max: 0.850675642490387
    scales-mean: 0.4585624933242798
    scales-min: 0.05785929784178734
    scales-std: 0.13413293659687042
    shifts-max: 6.150871276855469
    shifts-mean: 0.15410666167736053
    shifts-min: -5.133410453796387
    shifts-std: 1.5152584314346313
  sampler:
    episodes: 35
    last-path-return: 2192.6137649875004
    max-path-return: 2192.6137649875004
    pool-size: 35000
    total-samples: 35000
  time_since_restore: 395.0176303386688
  time_this_iter_s: 395.0176303386688
  time_total_s: 395.0176303386688
  times:
    epoch_after_hook: 5.029025487601757e-06
    epoch_before_hook: 6.268199649639428e-05
    evaluation_metrics: 0.0005245979991741478
    evaluation_paths: 0.628755097015528
    sample: 30.426710831641685
    timestep_after_hook: 0.07371451702783816
    timestep_before_hook: 0.15682598284911364
    train: 354.45912373505416
    training_metrics: 0.0024790540046524256
    training_paths: 0.1164847589971032
  timestamp: 1652809531
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 25000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.21595763325691225
      reward_ctrl-last-mean: -0.36651077270507815
      reward_ctrl-mean-mean: -0.3503599696847796
      reward_ctrl-median-mean: -0.35137261390686036
      reward_ctrl-range-mean: 0.5083147391676903
      reward_run-first-mean: -0.11756213770337857
      reward_run-last-mean: 1.2229291202939976
      reward_run-mean-mean: 1.5735910558948452
      reward_run-median-mean: 1.5497981126034228
      reward_run-range-mean: 5.370052736386373
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 2192.613764987499
    episode-reward-mean: 1223.2310862100655
    episode-reward-min: 341.20224356278743
    episode-reward-std: 666.3774889400128
  training_iteration: 1
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 0.8549200892448425
    Q_value-mean: 31.682151794433594
    alpha: 0.16832508146762848
    alpha_loss-mean: 1.4849790334701538
    policy_loss-mean: -32.87811279296875
  
== Status ==
Memory usage on this node: 18.1/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      1 |          395.018 |       0 |      25000 |            25000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.05950060859322548
  date: 2022-05-17_18-51-55
  done: false
  epoch: 1
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.17286659479141236
      reward_ctrl-last-mean: -0.3042518138885498
      reward_ctrl-mean-mean: -0.40505981182456013
      reward_ctrl-median-mean: -0.41622602939605713
      reward_ctrl-range-mean: 0.5346337914466859
      reward_run-first-mean: 0.21844404751881624
      reward_run-last-mean: 3.343079540268832
      reward_run-mean-mean: 4.499761381835619
      reward_run-median-mean: 4.546663723275799
      reward_run-range-mean: 7.736369048701644
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 4094.70166015625
    episode-reward-mean: 4094.70166015625
    episode-reward-min: 4094.70166015625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 2
  node_ip: 10.43.77.35
  num_train_steps: 50000
  pid: 283289
  policy:
    actions-max: 0.9998502731323242
    actions-mean: -0.10309091210365295
    actions-min: -0.9998109340667725
    actions-std: 0.7640261650085449
    entropy-mean: -5.80190896987915
    entropy-std: 4.736921787261963
    scales-max: 0.8492934703826904
    scales-mean: 0.45082521438598633
    scales-min: 0.11528021097183228
    scales-std: 0.12832054495811462
    shifts-max: 4.100767612457275
    shifts-mean: -0.18694020807743073
    shifts-min: -4.588189125061035
    shifts-std: 1.505892038345337
  sampler:
    episodes: 60
    last-path-return: 3999.383280721255
    max-path-return: 3999.383280721255
    pool-size: 60000
    total-samples: 60000
  time_since_restore: 779.1070659160614
  time_this_iter_s: 384.0894355773926
  time_total_s: 779.1070659160614
  times:
    epoch_after_hook: 5.651003448292613e-06
    epoch_before_hook: 5.1144015742465854e-05
    evaluation_metrics: 0.0005151730147190392
    evaluation_paths: 0.6532335710071493
    sample: 30.08659325444023
    timestep_after_hook: 0.07314514962490648
    timestep_before_hook: 0.15804931175080128
    train: 351.9322879568499
    training_metrics: 0.0022374410182237625
    training_paths: 0.14995126097346656
  timestamp: 1652809915
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 50000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.13933264911174775
      reward_ctrl-last-mean: -0.4188309216499329
      reward_ctrl-mean-mean: -0.3991427777892351
      reward_ctrl-median-mean: -0.40815962672233586
      reward_ctrl-range-mean: 0.5119784712791444
      reward_run-first-mean: -0.02403387039441019
      reward_run-last-mean: 3.9548878424637053
      reward_run-mean-mean: 3.95635086619721
      reward_run-median-mean: 4.0815336445482675
      reward_run-range-mean: 7.244057052967378
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 3999.383280721253
    episode-reward-mean: 3557.2080884079755
    episode-reward-min: 2087.0890662988045
    episode-reward-std: 513.4161246000078
  training_iteration: 2
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 3.01059627532959
    Q_value-mean: 86.8278579711914
    alpha: 0.04310385137796402
    alpha_loss-mean: -0.001724769244901836
    policy_loss-mean: -88.13670349121094
  
== Status ==
Memory usage on this node: 18.1/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      2 |          779.107 |       1 |      25000 |            50000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.08804360777139664
  date: 2022-05-17_18-58-19
  done: false
  epoch: 2
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.21874232292175294
      reward_ctrl-last-mean: -0.5243102073669433
      reward_ctrl-mean-mean: -0.3992183406889439
      reward_ctrl-median-mean: -0.4058669567108154
      reward_ctrl-range-mean: 0.526886111497879
      reward_run-first-mean: -0.133546697744103
      reward_run-last-mean: 6.416320448184933
      reward_run-mean-mean: 5.180508922117181
      reward_run-median-mean: 5.248296437416968
      reward_run-range-mean: 8.614834599173358
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 4781.29052734375
    episode-reward-mean: 4781.29052734375
    episode-reward-min: 4781.29052734375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 3
  node_ip: 10.43.77.35
  num_train_steps: 75000
  pid: 283289
  policy:
    actions-max: 0.9996910691261292
    actions-mean: -0.12800033390522003
    actions-min: -0.9992426633834839
    actions-std: 0.7713759541511536
    entropy-mean: -5.94718599319458
    entropy-std: 4.554985046386719
    scales-max: 1.1031697988510132
    scales-mean: 0.4709673225879669
    scales-min: 0.12076408416032791
    scales-std: 0.12476688623428345
    shifts-max: 4.336303234100342
    shifts-mean: -0.19690358638763428
    shifts-min: -3.5031967163085938
    shifts-std: 1.498092770576477
  sampler:
    episodes: 85
    last-path-return: 4919.544245501507
    max-path-return: 4919.544245501507
    pool-size: 85000
    total-samples: 85000
  time_since_restore: 1163.1314043998718
  time_this_iter_s: 384.0243384838104
  time_total_s: 1163.1314043998718
  times:
    epoch_after_hook: 1.8520222511142492e-06
    epoch_before_hook: 4.820601316168904e-05
    evaluation_metrics: 0.0004970039881300181
    evaluation_paths: 0.63337003000197
    sample: 30.174345034756698
    timestep_after_hook: 0.07491712420596741
    timestep_before_hook: 0.15820196745335124
    train: 351.82655100073316
    training_metrics: 0.002001996006583795
    training_paths: 0.11609811100061052
  timestamp: 1652810299
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 75000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.19464985251426697
      reward_ctrl-last-mean: -0.38328874111175537
      reward_ctrl-mean-mean: -0.3998568422701955
      reward_ctrl-median-mean: -0.40519793868064885
      reward_ctrl-range-mean: 0.4941297772526741
      reward_run-first-mean: -0.1371819524852076
      reward_run-last-mean: 4.691249035474016
      reward_run-mean-mean: 4.815453765154021
      reward_run-median-mean: 4.913175667319123
      reward_run-range-mean: 8.182498679555511
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 4919.544245501505
    episode-reward-mean: 4415.596922883826
    episode-reward-min: 3270.943760394851
    episode-reward-std: 452.12730783276925
  training_iteration: 3
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 5.122433185577393
    Q_value-mean: 185.26608276367188
    alpha: 0.07621338218450546
    alpha_loss-mean: -0.0012231569271534681
    policy_loss-mean: -186.63748168945312
  
== Status ==
Memory usage on this node: 18.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      3 |          1163.13 |       2 |      25000 |            75000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.10586971044540405
  date: 2022-05-17_19-04-43
  done: false
  epoch: 3
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.12877511978149414
      reward_ctrl-last-mean: -0.3860980033874512
      reward_ctrl-mean-mean: -0.4145326640963555
      reward_ctrl-median-mean: -0.4224157571792603
      reward_ctrl-range-mean: 0.4787153363227844
      reward_run-first-mean: -0.08454814080399622
      reward_run-last-mean: 6.305442817318863
      reward_run-mean-mean: 6.078497783938641
      reward_run-median-mean: 6.130801802543715
      reward_run-range-mean: 9.204205547122587
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 5663.96533203125
    episode-reward-mean: 5663.96533203125
    episode-reward-min: 5663.96533203125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 4
  node_ip: 10.43.77.35
  num_train_steps: 100000
  pid: 283289
  policy:
    actions-max: 0.9997616410255432
    actions-mean: -0.17577631771564484
    actions-min: -0.9994962811470032
    actions-std: 0.7696006298065186
    entropy-mean: -6.087279319763184
    entropy-std: 4.239784240722656
    scales-max: 1.2242717742919922
    scales-mean: 0.46625956892967224
    scales-min: 0.0866270437836647
    scales-std: 0.13416379690170288
    shifts-max: 4.7216339111328125
    shifts-mean: -0.3315093517303467
    shifts-min: -4.00874662399292
    shifts-std: 1.4689444303512573
  sampler:
    episodes: 110
    last-path-return: 5515.9880157819025
    max-path-return: 5698.879639230722
    pool-size: 110000
    total-samples: 110000
  time_since_restore: 1547.5981991291046
  time_this_iter_s: 384.4667947292328
  time_total_s: 1547.5981991291046
  times:
    epoch_after_hook: 1.9849976524710655e-06
    epoch_before_hook: 5.325101665221155e-05
    evaluation_metrics: 0.0004990160232409835
    evaluation_paths: 0.6407989700092003
    sample: 30.357837532937992
    timestep_after_hook: 0.076373110874556
    timestep_before_hook: 0.15901179786305875
    train: 351.89774048147956
    training_metrics: 0.00190917297732085
    training_paths: 0.2933255600219127
  timestamp: 1652810683
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 100000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.24554731726646425
      reward_ctrl-last-mean: -0.47550985574722293
      reward_ctrl-mean-mean: -0.4141742261713744
      reward_ctrl-median-mean: -0.418761329650879
      reward_ctrl-range-mean: 0.4746575117111206
      reward_run-first-mean: -0.2657656228646282
      reward_run-last-mean: 6.321624985130711
      reward_run-mean-mean: 5.932543589788773
      reward_run-median-mean: 5.974386806282929
      reward_run-range-mean: 9.13139855156181
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 5698.879639230726
    episode-reward-mean: 5518.3693636173975
    episode-reward-min: 5414.461818996722
    episode-reward-std: 71.44848658524484
  training_iteration: 4
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.602622032165527
    Q_value-mean: 257.36065673828125
    alpha: 0.09585023671388626
    alpha_loss-mean: -0.0007824900094419718
    policy_loss-mean: -258.64471435546875
  
== Status ==
Memory usage on this node: 18.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      4 |           1547.6 |       3 |      25000 |           100000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.12576137483119965
  date: 2022-05-17_19-11-08
  done: false
  epoch: 4
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2382814407348633
      reward_ctrl-last-mean: -0.26884377002716064
      reward_ctrl-mean-mean: -0.393830669093132
      reward_ctrl-median-mean: -0.3935290813446045
      reward_ctrl-range-mean: 0.40230846405029297
      reward_run-first-mean: -0.23332484954471966
      reward_run-last-mean: 5.808750079604579
      reward_run-mean-mean: 6.569378963136845
      reward_run-median-mean: 6.5785892037416716
      reward_run-range-mean: 9.284014124074632
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 6175.54833984375
    episode-reward-mean: 6175.54833984375
    episode-reward-min: 6175.54833984375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 5
  node_ip: 10.43.77.35
  num_train_steps: 125000
  pid: 283289
  policy:
    actions-max: 0.9990144968032837
    actions-mean: -0.11459016054868698
    actions-min: -0.9995713233947754
    actions-std: 0.7749812602996826
    entropy-mean: -5.979002952575684
    entropy-std: 4.756860256195068
    scales-max: 1.0569173097610474
    scales-mean: 0.466850608587265
    scales-min: 0.10452701151371002
    scales-std: 0.12897659838199615
    shifts-max: 3.19850754737854
    shifts-mean: -0.17720605432987213
    shifts-min: -4.07259464263916
    shifts-std: 1.483383297920227
  sampler:
    episodes: 135
    last-path-return: 6136.796107375714
    max-path-return: 6276.437446710968
    pool-size: 135000
    total-samples: 135000
  time_since_restore: 1931.673800945282
  time_this_iter_s: 384.07560181617737
  time_total_s: 1931.673800945282
  times:
    epoch_after_hook: 2.3139873519539833e-06
    epoch_before_hook: 5.897998926229775e-05
    evaluation_metrics: 0.0005242119950708002
    evaluation_paths: 0.633554470987292
    sample: 30.14139546651859
    timestep_after_hook: 0.07498146485886537
    timestep_before_hook: 0.1553615087759681
    train: 351.91378094328684
    training_metrics: 0.0020585019956342876
    training_paths: 0.11725906800711527
  timestamp: 1652811068
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 125000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2809224009513855
      reward_ctrl-last-mean: -0.36444481849670407
      reward_ctrl-mean-mean: -0.4051958435285091
      reward_ctrl-median-mean: -0.40764671087265014
      reward_ctrl-range-mean: 0.43352537870407104
      reward_run-first-mean: -0.2500533081154015
      reward_run-last-mean: 6.621606572392807
      reward_run-mean-mean: 6.504391351882555
      reward_run-median-mean: 6.55734539181821
      reward_run-range-mean: 9.64075932787944
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 6276.437446710966
    episode-reward-mean: 6099.195508354045
    episode-reward-min: 5960.523460057004
    episode-reward-std: 88.24782759974259
  training_iteration: 5
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.689094543457031
    Q_value-mean: 318.1428527832031
    alpha: 0.1183723658323288
    alpha_loss-mean: -0.0008293612045235932
    policy_loss-mean: -319.31683349609375
  
== Status ==
Memory usage on this node: 18.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      5 |          1931.67 |       4 |      25000 |           125000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.13825488090515137
  date: 2022-05-17_19-17-28
  done: false
  epoch: 5
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.22699494361877443
      reward_ctrl-last-mean: -0.2764929294586182
      reward_ctrl-mean-mean: -0.3854455160617829
      reward_ctrl-median-mean: -0.38868653774261475
      reward_ctrl-range-mean: 0.46709496974945064
      reward_run-first-mean: -0.6129854944426161
      reward_run-last-mean: 6.025211695069856
      reward_run-mean-mean: 6.835883897672385
      reward_run-median-mean: 6.8805960592787585
      reward_run-range-mean: 10.198089603559472
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 6450.4384765625
    episode-reward-mean: 6450.4384765625
    episode-reward-min: 6450.4384765625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 6
  node_ip: 10.43.77.35
  num_train_steps: 150000
  pid: 283289
  policy:
    actions-max: 0.9995456337928772
    actions-mean: -0.1547747105360031
    actions-min: -0.9990962147712708
    actions-std: 0.7782714366912842
    entropy-mean: -6.341861724853516
    entropy-std: 4.311136722564697
    scales-max: 0.9331845641136169
    scales-mean: 0.44614076614379883
    scales-min: 0.08529362082481384
    scales-std: 0.12976311147212982
    shifts-max: 3.2490952014923096
    shifts-mean: -0.23601919412612915
    shifts-min: -3.040971279144287
    shifts-std: 1.4854445457458496
  sampler:
    episodes: 160
    last-path-return: 6590.85037719583
    max-path-return: 6748.168533022316
    pool-size: 160000
    total-samples: 160000
  time_since_restore: 2312.3728227615356
  time_this_iter_s: 380.69902181625366
  time_total_s: 2312.3728227615356
  times:
    epoch_after_hook: 1.9060098566114902e-06
    epoch_before_hook: 5.3902011131867766e-05
    evaluation_metrics: 0.0005069820035714656
    evaluation_paths: 0.6062202480097767
    sample: 29.71880228992086
    timestep_after_hook: 0.07408364658476785
    timestep_before_hook: 0.1533803231723141
    train: 349.0041448142438
    training_metrics: 0.002478976995917037
    training_paths: 0.11343850701814517
  timestamp: 1652811448
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 150000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.25133527636528014
      reward_ctrl-last-mean: -0.3993199849128723
      reward_ctrl-mean-mean: -0.3924522911423445
      reward_ctrl-median-mean: -0.3940505838394165
      reward_ctrl-range-mean: 0.46188883125782015
      reward_run-first-mean: -0.17919234157122285
      reward_run-last-mean: 7.455479578135055
      reward_run-mean-mean: 6.956333715410901
      reward_run-median-mean: 7.013914596229753
      reward_run-range-mean: 10.062320992843121
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 6748.168533022307
    episode-reward-mean: 6563.881424268557
    episode-reward-min: 6316.148971800387
    episode-reward-std: 104.07723348390378
  training_iteration: 6
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.398662567138672
    Q_value-mean: 370.4268798828125
    alpha: 0.132320836186409
    alpha_loss-mean: -0.0005224936176091433
    policy_loss-mean: -371.5450439453125
  
== Status ==
Memory usage on this node: 18.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      6 |          2312.37 |       5 |      25000 |           150000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.14737991988658905
  date: 2022-05-17_19-23-43
  done: false
  epoch: 6
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2564684867858887
      reward_ctrl-last-mean: -0.4311888694763184
      reward_ctrl-mean-mean: -0.3974410125076771
      reward_ctrl-median-mean: -0.39893273115158084
      reward_ctrl-range-mean: 0.4928339779376984
      reward_run-first-mean: -0.4883629255495579
      reward_run-last-mean: 7.639927486735587
      reward_run-mean-mean: 7.428468752317396
      reward_run-median-mean: 7.492623277191228
      reward_run-range-mean: 10.74805598182042
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7031.02734375
    episode-reward-mean: 7031.02734375
    episode-reward-min: 7031.02734375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 7
  node_ip: 10.43.77.35
  num_train_steps: 175000
  pid: 283289
  policy:
    actions-max: 0.9993131756782532
    actions-mean: -0.1666199117898941
    actions-min: -0.9984803795814514
    actions-std: 0.7622854113578796
    entropy-mean: -5.8431549072265625
    entropy-std: 4.350927829742432
    scales-max: 0.9479813575744629
    scales-mean: 0.45058849453926086
    scales-min: 0.09716526418924332
    scales-std: 0.14292488992214203
    shifts-max: 3.7480130195617676
    shifts-mean: -0.28102126717567444
    shifts-min: -3.9125936031341553
    shifts-std: 1.4166382551193237
  sampler:
    episodes: 185
    last-path-return: 7048.158218490495
    max-path-return: 7106.066316327309
    pool-size: 185000
    total-samples: 185000
  time_since_restore: 2686.9365944862366
  time_this_iter_s: 374.5637717247009
  time_total_s: 2686.9365944862366
  times:
    epoch_after_hook: 2.0980078261345625e-06
    epoch_before_hook: 4.3517007725313306e-05
    evaluation_metrics: 0.0005096509994473308
    evaluation_paths: 0.6063655909965746
    sample: 28.87445648838184
    timestep_after_hook: 0.07336725891218521
    timestep_before_hook: 0.15441229072166607
    train: 343.5311189080239
    training_metrics: 0.0019193600164726377
    training_paths: 0.3051337110227905
  timestamp: 1652811823
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 175000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.27026398777961735
      reward_ctrl-last-mean: -0.41234587192535405
      reward_ctrl-mean-mean: -0.3888325124561788
      reward_ctrl-median-mean: -0.3905576419830322
      reward_ctrl-range-mean: 0.44535244107246397
      reward_run-first-mean: -0.15491474351528584
      reward_run-last-mean: 7.552071977222795
      reward_run-mean-mean: 7.347904797905097
      reward_run-median-mean: 7.445379864146743
      reward_run-range-mean: 10.485342092847736
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7106.066316327311
    episode-reward-mean: 6959.0722854489195
    episode-reward-min: 6836.191928459975
    episode-reward-std: 83.96861055506122
  training_iteration: 7
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.320980072021484
    Q_value-mean: 418.4893493652344
    alpha: 0.14320896565914154
    alpha_loss-mean: -0.0003357154782861471
    policy_loss-mean: -419.5848693847656
  
== Status ==
Memory usage on this node: 18.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      7 |          2686.94 |       6 |      25000 |           175000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.1538650542497635
  date: 2022-05-17_19-29-57
  done: false
  epoch: 7
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2332152843475342
      reward_ctrl-last-mean: -0.35339667797088625
      reward_ctrl-mean-mean: -0.3868049441277981
      reward_ctrl-median-mean: -0.38536490201950074
      reward_ctrl-range-mean: 0.5229190170764922
      reward_run-first-mean: -0.28451071554156965
      reward_run-last-mean: 6.646038139998609
      reward_run-mean-mean: 7.745381375502073
      reward_run-median-mean: 7.93147307236886
      reward_run-range-mean: 10.774814565107693
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7358.576171875
    episode-reward-mean: 7358.576171875
    episode-reward-min: 7358.576171875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 8
  node_ip: 10.43.77.35
  num_train_steps: 200000
  pid: 283289
  policy:
    actions-max: 0.9992172718048096
    actions-mean: -0.15381880104541779
    actions-min: -0.9998754262924194
    actions-std: 0.7622804045677185
    entropy-mean: -6.056148052215576
    entropy-std: 4.136134147644043
    scales-max: 0.9226990342140198
    scales-mean: 0.4359166622161865
    scales-min: 0.0831800177693367
    scales-std: 0.142588809132576
    shifts-max: 3.797487735748291
    shifts-mean: -0.2500855624675751
    shifts-min: -3.7064762115478516
    shifts-std: 1.4224984645843506
  sampler:
    episodes: 210
    last-path-return: 7345.283383977722
    max-path-return: 7379.784041072397
    pool-size: 210000
    total-samples: 210000
  time_since_restore: 3060.79731297493
  time_this_iter_s: 373.86071848869324
  time_total_s: 3060.79731297493
  times:
    epoch_after_hook: 2.176006091758609e-06
    epoch_before_hook: 4.7442008508369327e-05
    evaluation_metrics: 0.0004886790120508522
    evaluation_paths: 0.6068036879878491
    sample: 29.11167699145153
    timestep_after_hook: 0.07246786207542755
    timestep_before_hook: 0.15574367792578414
    train: 342.7856098851771
    training_metrics: 0.0018773539923131466
    training_paths: 0.11537874600617215
  timestamp: 1652812197
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 200000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2691700279712677
      reward_ctrl-last-mean: -0.39747816801071173
      reward_ctrl-mean-mean: -0.3864935921216011
      reward_ctrl-median-mean: -0.3896478939056397
      reward_ctrl-range-mean: 0.4654908829927445
      reward_run-first-mean: -0.10126282332809544
      reward_run-last-mean: 7.236132627684128
      reward_run-mean-mean: 7.564487176227819
      reward_run-median-mean: 7.692618685990361
      reward_run-range-mean: 10.742294066995441
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7379.784041072393
    episode-reward-mean: 7177.993584106216
    episode-reward-min: 6938.351649182236
    episode-reward-std: 132.1363972094192
  training_iteration: 8
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.587486267089844
    Q_value-mean: 455.5530090332031
    alpha: 0.15088807046413422
    alpha_loss-mean: -0.00023792854335624725
    policy_loss-mean: -456.5584411621094
  
== Status ==
Memory usage on this node: 18.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      8 |           3060.8 |       7 |      25000 |           200000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.15855103731155396
  date: 2022-05-17_19-36-11
  done: false
  epoch: 8
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.24404044151306153
      reward_ctrl-last-mean: -0.4029249668121338
      reward_ctrl-mean-mean: -0.38402650730609894
      reward_ctrl-median-mean: -0.38991277217864995
      reward_ctrl-range-mean: 0.4323052048683167
      reward_run-first-mean: -0.1441812394409646
      reward_run-last-mean: 8.602109895720105
      reward_run-mean-mean: 8.111557226988145
      reward_run-median-mean: 8.290388124232209
      reward_run-range-mean: 11.108913888378662
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7727.53076171875
    episode-reward-mean: 7727.53076171875
    episode-reward-min: 7727.53076171875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 9
  node_ip: 10.43.77.35
  num_train_steps: 225000
  pid: 283289
  policy:
    actions-max: 0.9987526535987854
    actions-mean: -0.13072136044502258
    actions-min: -0.9988478422164917
    actions-std: 0.7632993459701538
    entropy-mean: -5.69830322265625
    entropy-std: 3.630026340484619
    scales-max: 0.9194713234901428
    scales-mean: 0.43496665358543396
    scales-min: 0.09539686888456345
    scales-std: 0.13836978375911713
    shifts-max: 3.5545153617858887
    shifts-mean: -0.2139015942811966
    shifts-min: -3.4061851501464844
    shifts-std: 1.4103283882141113
  sampler:
    episodes: 235
    last-path-return: 7367.702090199405
    max-path-return: 7535.438333392048
    pool-size: 235000
    total-samples: 235000
  time_since_restore: 3434.7166113853455
  time_this_iter_s: 373.91929841041565
  time_total_s: 3434.7166113853455
  times:
    epoch_after_hook: 2.0190200302749872e-06
    epoch_before_hook: 5.5182987125590444e-05
    evaluation_metrics: 0.0005000380042474717
    evaluation_paths: 0.6485956189862918
    sample: 28.828204164048657
    timestep_after_hook: 0.07206356682581827
    timestep_before_hook: 0.1543758574698586
    train: 343.0869865528657
    training_metrics: 0.0020256400166545063
    training_paths: 0.1139674220175948
  timestamp: 1652812571
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 225000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.19537485539913177
      reward_ctrl-last-mean: -0.40385856389999386
      reward_ctrl-mean-mean: -0.3848960700541735
      reward_ctrl-median-mean: -0.38719590783119207
      reward_ctrl-range-mean: 0.46856584787368777
      reward_run-first-mean: 0.013798574176090119
      reward_run-last-mean: 7.990005202598127
      reward_run-mean-mean: 7.823996860555904
      reward_run-median-mean: 7.9647462603650325
      reward_run-range-mean: 10.880188859195425
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7535.438333392038
    episode-reward-mean: 7439.100790501732
    episode-reward-min: 7318.2109377034485
    episode-reward-std: 67.26922951034913
  training_iteration: 9
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.35822868347168
    Q_value-mean: 484.3205871582031
    alpha: 0.1573621779680252
    alpha_loss-mean: -0.00017020420636981726
    policy_loss-mean: -485.22369384765625
  
== Status ==
Memory usage on this node: 18.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |      9 |          3434.72 |       8 |      25000 |           225000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.16426204144954681
  date: 2022-05-17_19-42-07
  done: false
  epoch: 9
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.11770148277282716
      reward_ctrl-last-mean: -0.449742603302002
      reward_ctrl-mean-mean: -0.38596135292053224
      reward_ctrl-median-mean: -0.38988579511642457
      reward_ctrl-range-mean: 0.4642479658126831
      reward_run-first-mean: 0.029629990988093158
      reward_run-last-mean: 8.657359147215402
      reward_run-mean-mean: 8.059597226695688
      reward_run-median-mean: 8.252104657610104
      reward_run-range-mean: 11.200969344577503
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7673.63623046875
    episode-reward-mean: 7673.63623046875
    episode-reward-min: 7673.63623046875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 10
  node_ip: 10.43.77.35
  num_train_steps: 250000
  pid: 283289
  policy:
    actions-max: 0.9990720748901367
    actions-mean: -0.14319442212581635
    actions-min: -0.9998288154602051
    actions-std: 0.7676969766616821
    entropy-mean: -5.8750834465026855
    entropy-std: 4.09315299987793
    scales-max: 1.0722196102142334
    scales-mean: 0.447147935628891
    scales-min: 0.08774545788764954
    scales-std: 0.14893895387649536
    shifts-max: 3.4297001361846924
    shifts-mean: -0.23680800199508667
    shifts-min: -3.502443552017212
    shifts-std: 1.412227749824524
  sampler:
    episodes: 260
    last-path-return: 7663.894859981359
    max-path-return: 7775.492026741209
    pool-size: 260000
    total-samples: 260000
  time_since_restore: 3790.630986213684
  time_this_iter_s: 355.9143748283386
  time_total_s: 3790.630986213684
  times:
    epoch_after_hook: 1.7569982446730137e-06
    epoch_before_hook: 4.884498775936663e-05
    evaluation_metrics: 0.000439864001236856
    evaluation_paths: 0.5374928429955617
    sample: 28.145745327026816
    timestep_after_hook: 0.07007743953727186
    timestep_before_hook: 0.14802815768052824
    train: 325.94021937812795
    training_metrics: 0.0017546750023029745
    training_paths: 0.10165360500104725
  timestamp: 1652812927
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 250000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.23098433256149292
      reward_ctrl-last-mean: -0.3887218570709229
      reward_ctrl-mean-mean: -0.38856865696787835
      reward_ctrl-median-mean: -0.3919589996337891
      reward_ctrl-range-mean: 0.45378440558910366
      reward_run-first-mean: 0.20858969159600482
      reward_run-last-mean: 8.232899310575817
      reward_run-mean-mean: 8.051196861956829
      reward_run-median-mean: 8.225594151696232
      reward_run-range-mean: 11.169873841430036
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7775.492026741203
    episode-reward-mean: 7662.628204988949
    episode-reward-min: 7385.885952774295
    episode-reward-std: 101.68503405410121
  training_iteration: 10
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.280170440673828
    Q_value-mean: 509.4193115234375
    alpha: 0.16337798535823822
    alpha_loss-mean: -0.00021158660820219666
    policy_loss-mean: -510.26458740234375
  
== Status ==
Memory usage on this node: 17.9/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     10 |          3790.63 |       9 |      25000 |           250000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.17014767229557037
  date: 2022-05-17_19-46-44
  done: false
  epoch: 10
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.22323129177093506
      reward_ctrl-last-mean: -0.43580679893493657
      reward_ctrl-mean-mean: -0.3913436512589455
      reward_ctrl-median-mean: -0.3981058597564697
      reward_ctrl-range-mean: 0.4581918954849244
      reward_run-first-mean: -0.19933023059930527
      reward_run-last-mean: 6.939778872161924
      reward_run-mean-mean: 8.232079346609831
      reward_run-median-mean: 8.447625966563237
      reward_run-range-mean: 10.944192855362001
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7840.73583984375
    episode-reward-mean: 7840.73583984375
    episode-reward-min: 7840.73583984375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 11
  node_ip: 10.43.77.35
  num_train_steps: 275000
  pid: 283289
  policy:
    actions-max: 0.9990971684455872
    actions-mean: -0.11648019403219223
    actions-min: -0.9985833764076233
    actions-std: 0.7616689205169678
    entropy-mean: -5.580212593078613
    entropy-std: 3.9826407432556152
    scales-max: 0.9322066307067871
    scales-mean: 0.43696093559265137
    scales-min: 0.06484885513782501
    scales-std: 0.1454901248216629
    shifts-max: 2.8674583435058594
    shifts-mean: -0.17284707725048065
    shifts-min: -3.1955575942993164
    shifts-std: 1.4259865283966064
  sampler:
    episodes: 285
    last-path-return: 7831.251356882679
    max-path-return: 7976.782187135611
    pool-size: 285000
    total-samples: 285000
  time_since_restore: 4067.5865910053253
  time_this_iter_s: 276.95560479164124
  time_total_s: 4067.5865910053253
  times:
    epoch_after_hook: 2.6459747459739447e-06
    epoch_before_hook: 4.404099308885634e-05
    evaluation_metrics: 0.030158020003000274
    evaluation_paths: 0.5020069669990335
    sample: 22.683870938868495
    timestep_after_hook: 0.059631644311593845
    timestep_before_hook: 0.1288354483549483
    train: 251.5882202112407
    training_metrics: 0.038442552991909906
    training_paths: 1.1518343269999605
  timestamp: 1652813204
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 275000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.25024118423461916
      reward_ctrl-last-mean: -0.46485960006713867
      reward_ctrl-mean-mean: -0.38488989987283945
      reward_ctrl-median-mean: -0.38948403477668764
      reward_ctrl-range-mean: 0.4366928800940514
      reward_run-first-mean: 0.1811959698150796
      reward_run-last-mean: 8.594659340700218
      reward_run-mean-mean: 8.202667703771422
      reward_run-median-mean: 8.394054706241164
      reward_run-range-mean: 11.398065415014656
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 7976.782187135611
    episode-reward-mean: 7817.7778038985825
    episode-reward-min: 7652.004967557186
    episode-reward-std: 93.16875273285211
  training_iteration: 11
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.193983554840088
    Q_value-mean: 532.2579345703125
    alpha: 0.16678601503372192
    alpha_loss-mean: -0.00020492363546509296
    policy_loss-mean: -533.0496826171875
  
== Status ==
Memory usage on this node: 17.0/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     11 |          4067.59 |      10 |      25000 |           275000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.1715940237045288
  date: 2022-05-17_19-50-17
  done: false
  epoch: 11
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.16089640855789186
      reward_ctrl-last-mean: -0.263336706161499
      reward_ctrl-mean-mean: -0.37975963143706326
      reward_ctrl-median-mean: -0.38584184646606445
      reward_ctrl-range-mean: 0.47085950970649726
      reward_run-first-mean: -0.22561150739145885
      reward_run-last-mean: 9.56939884479766
      reward_run-mean-mean: 8.433165983077737
      reward_run-median-mean: 8.61746464432457
      reward_run-range-mean: 11.423775858365776
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8053.40625
    episode-reward-mean: 8053.40625
    episode-reward-min: 8053.40625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 12
  node_ip: 10.43.77.35
  num_train_steps: 300000
  pid: 283289
  policy:
    actions-max: 0.9990127086639404
    actions-mean: -0.14487159252166748
    actions-min: -0.9992715716362
    actions-std: 0.7582166194915771
    entropy-mean: -5.467388153076172
    entropy-std: 3.9786133766174316
    scales-max: 0.9946785569190979
    scales-mean: 0.4348708391189575
    scales-min: 0.0750543400645256
    scales-std: 0.14293380081653595
    shifts-max: 2.9764225482940674
    shifts-mean: -0.2413676232099533
    shifts-min: -3.187659978866577
    shifts-std: 1.3849608898162842
  sampler:
    episodes: 310
    last-path-return: 8154.127828408835
    max-path-return: 8154.127828408835
    pool-size: 310000
    total-samples: 310000
  time_since_restore: 4279.829387426376
  time_this_iter_s: 212.24279642105103
  time_total_s: 4279.829387426376
  times:
    epoch_after_hook: 1.9650033209472895e-06
    epoch_before_hook: 4.502700176090002e-05
    evaluation_metrics: 0.0004140559758525342
    evaluation_paths: 0.5021230700076558
    sample: 14.022959271358559
    timestep_after_hook: 0.035824968304950744
    timestep_before_hook: 0.0814449125318788
    train: 197.1123740222829
    training_metrics: 0.001574572001118213
    training_paths: 0.07329044400830753
  timestamp: 1652813417
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 300000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.24018869280815122
      reward_ctrl-last-mean: -0.37701159477233886
      reward_ctrl-mean-mean: -0.38427267388880254
      reward_ctrl-median-mean: -0.3905615162849426
      reward_ctrl-range-mean: 0.44070518136024467
      reward_run-first-mean: -0.1651066896620088
      reward_run-last-mean: 9.086210496936474
      reward_run-mean-mean: 8.390534960313902
      reward_run-median-mean: 8.593037831667147
      reward_run-range-mean: 11.269861086556412
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8154.127828408833
    episode-reward-mean: 8006.2622864251
    episode-reward-min: 7836.707405433795
    episode-reward-std: 90.08414479576612
  training_iteration: 12
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.132842540740967
    Q_value-mean: 552.2485961914062
    alpha: 0.17115327715873718
    alpha_loss-mean: -3.414420280023478e-05
    policy_loss-mean: -552.9794311523438
  
== Status ==
Memory usage on this node: 16.8/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     12 |          4279.83 |      11 |      25000 |           300000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.17634464800357819
  date: 2022-05-17_19-53-45
  done: false
  epoch: 12
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.39329190254211427
      reward_ctrl-last-mean: -0.35212125778198244
      reward_ctrl-mean-mean: -0.38259007334709166
      reward_ctrl-median-mean: -0.38728121519088743
      reward_ctrl-range-mean: 0.4295280337333679
      reward_run-first-mean: -0.08015821401420153
      reward_run-last-mean: 8.205923811458433
      reward_run-mean-mean: 8.620768589321893
      reward_run-median-mean: 8.830489421359964
      reward_run-range-mean: 11.416878332327105
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8238.1787109375
    episode-reward-mean: 8238.1787109375
    episode-reward-min: 8238.1787109375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 13
  node_ip: 10.43.77.35
  num_train_steps: 325000
  pid: 283289
  policy:
    actions-max: 0.999991238117218
    actions-mean: -0.14112721383571625
    actions-min: -0.9996902346611023
    actions-std: 0.7740066647529602
    entropy-mean: -6.0131988525390625
    entropy-std: 3.89868426322937
    scales-max: 0.960061252117157
    scales-mean: 0.4384712874889374
    scales-min: 0.07630438357591629
    scales-std: 0.14377500116825104
    shifts-max: 4.120570659637451
    shifts-mean: -0.23076288402080536
    shifts-min: -3.2267956733703613
    shifts-std: 1.4253995418548584
  sampler:
    episodes: 335
    last-path-return: 7917.475664257921
    max-path-return: 8327.255006802705
    pool-size: 335000
    total-samples: 335000
  time_since_restore: 4487.216903209686
  time_this_iter_s: 207.38751578330994
  time_total_s: 4487.216903209686
  times:
    epoch_after_hook: 1.8769933376461267e-06
    epoch_before_hook: 2.434599446132779e-05
    evaluation_metrics: 0.00041456500184722245
    evaluation_paths: 0.4863445730006788
    sample: 13.406050615711138
    timestep_after_hook: 0.03284886144683696
    timestep_before_hook: 0.07656831666827202
    train: 192.9286053305259
    training_metrics: 0.0016295900277327746
    training_paths: 0.07325029600178823
  timestamp: 1652813625
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 325000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.28419150173664093
      reward_ctrl-last-mean: -0.3653200387954712
      reward_ctrl-mean-mean: -0.3798160950013995
      reward_ctrl-median-mean: -0.3869995391368866
      reward_ctrl-range-mean: 0.44533455699682245
      reward_run-first-mean: -0.027110781593184002
      reward_run-last-mean: 8.849652074645974
      reward_run-mean-mean: 8.531221213557455
      reward_run-median-mean: 8.788306472709262
      reward_run-range-mean: 11.422231237422466
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8327.25500680272
    episode-reward-mean: 8151.405118556055
    episode-reward-min: 7917.475664257929
    episode-reward-std: 115.5668086746575
  training_iteration: 13
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.099319934844971
    Q_value-mean: 569.4923095703125
    alpha: 0.17363274097442627
    alpha_loss-mean: -0.00018397091480437666
    policy_loss-mean: -570.1720581054688
  
== Status ==
Memory usage on this node: 16.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     13 |          4487.22 |      12 |      25000 |           325000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.1800745129585266
  date: 2022-05-17_19-57-12
  done: false
  epoch: 13
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2538149118423462
      reward_ctrl-last-mean: -0.42257242202758794
      reward_ctrl-mean-mean: -0.3797027329325676
      reward_ctrl-median-mean: -0.38221943378448486
      reward_ctrl-range-mean: 0.47124456167221074
      reward_run-first-mean: -0.04361951666329619
      reward_run-last-mean: 9.339915936703846
      reward_run-mean-mean: 8.620294854844175
      reward_run-median-mean: 8.844619480225049
      reward_run-range-mean: 11.183331855065047
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8240.591796875
    episode-reward-mean: 8240.591796875
    episode-reward-min: 8240.591796875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 14
  node_ip: 10.43.77.35
  num_train_steps: 350000
  pid: 283289
  policy:
    actions-max: 0.9997829794883728
    actions-mean: -0.11144986748695374
    actions-min: -0.9992490410804749
    actions-std: 0.7807572484016418
    entropy-mean: -6.280763149261475
    entropy-std: 3.824463367462158
    scales-max: 0.9330440163612366
    scales-mean: 0.436251163482666
    scales-min: 0.0779397264122963
    scales-std: 0.14019076526165009
    shifts-max: 3.3692595958709717
    shifts-mean: -0.18429672718048096
    shifts-min: -3.236908435821533
    shifts-std: 1.4959131479263306
  sampler:
    episodes: 360
    last-path-return: 8189.271720085203
    max-path-return: 8444.2553735818
    pool-size: 360000
    total-samples: 360000
  time_since_restore: 4694.6050045490265
  time_this_iter_s: 207.3881013393402
  time_total_s: 4694.6050045490265
  times:
    epoch_after_hook: 1.7569982446730137e-06
    epoch_before_hook: 2.453001798130572e-05
    evaluation_metrics: 0.00041390801197849214
    evaluation_paths: 0.4918866240186617
    sample: 13.33903772366466
    timestep_after_hook: 0.03271629009395838
    timestep_before_hook: 0.0755467286799103
    train: 192.9049502419366
    training_metrics: 0.0015760809765197337
    training_paths: 0.1613353920110967
  timestamp: 1652813832
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 350000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.28898084759712217
      reward_ctrl-last-mean: -0.4020692849159241
      reward_ctrl-mean-mean: -0.37962925004065035
      reward_ctrl-median-mean: -0.3862716460227966
      reward_ctrl-range-mean: 0.45322274506092075
      reward_run-first-mean: -0.5036783320783399
      reward_run-last-mean: 9.199947024606558
      reward_run-mean-mean: 8.663594908633291
      reward_run-median-mean: 8.908003865391137
      reward_run-range-mean: 11.765804874396961
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8380.768080978996
    episode-reward-mean: 8283.965658592642
    episode-reward-min: 8169.181249426027
    episode-reward-std: 78.67007750928845
  training_iteration: 14
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.161900520324707
    Q_value-mean: 586.2257690429688
    alpha: 0.17807595431804657
    alpha_loss-mean: -0.00012478740245569497
    policy_loss-mean: -586.8655395507812
  
== Status ==
Memory usage on this node: 16.0/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     14 |          4694.61 |      13 |      25000 |           350000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.17960378527641296
  date: 2022-05-17_20-00-39
  done: false
  epoch: 14
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.30068678855895997
      reward_ctrl-last-mean: -0.36339540481567384
      reward_ctrl-mean-mean: -0.37029694576263433
      reward_ctrl-median-mean: -0.37875548601150516
      reward_ctrl-range-mean: 0.414596951007843
      reward_run-first-mean: -0.43062615588052866
      reward_run-last-mean: 8.020703657767854
      reward_run-mean-mean: 9.160549616806692
      reward_run-median-mean: 9.40642591026041
      reward_run-range-mean: 11.946878692618567
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8790.2529296875
    episode-reward-mean: 8790.2529296875
    episode-reward-min: 8790.2529296875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 15
  node_ip: 10.43.77.35
  num_train_steps: 375000
  pid: 283289
  policy:
    actions-max: 0.9998376369476318
    actions-mean: -0.12415393441915512
    actions-min: -0.998360276222229
    actions-std: 0.7669513821601868
    entropy-mean: -5.722756862640381
    entropy-std: 4.0544633865356445
    scales-max: 0.9938739538192749
    scales-mean: 0.4364370107650757
    scales-min: 0.06526491045951843
    scales-std: 0.14843012392520905
    shifts-max: 3.211284875869751
    shifts-mean: -0.1960337907075882
    shifts-min: -3.7163562774658203
    shifts-std: 1.4366191625595093
  sampler:
    episodes: 385
    last-path-return: 8441.149319688837
    max-path-return: 8641.20502061841
    pool-size: 385000
    total-samples: 385000
  time_since_restore: 4901.780586481094
  time_this_iter_s: 207.17558193206787
  time_total_s: 4901.780586481094
  times:
    epoch_after_hook: 1.8049904610961676e-06
    epoch_before_hook: 2.474401844665408e-05
    evaluation_metrics: 0.00040902799810282886
    evaluation_paths: 0.4860083909879904
    sample: 13.456194112921366
    timestep_after_hook: 0.032763558643637225
    timestep_before_hook: 0.07636822701897472
    train: 192.66636286510038
    training_metrics: 0.0015601209888700396
    training_paths: 0.07449432701105252
  timestamp: 1652814039
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 375000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3155976629257203
      reward_ctrl-last-mean: -0.38928194999694826
      reward_ctrl-mean-mean: -0.37478455940812827
      reward_ctrl-median-mean: -0.38131594061851504
      reward_ctrl-range-mean: 0.4804996100068092
      reward_run-first-mean: -0.5855414387567297
      reward_run-last-mean: 9.018776916505203
      reward_run-mean-mean: 8.890533869204765
      reward_run-median-mean: 9.148147743175329
      reward_run-range-mean: 12.049084021174043
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8641.205020618418
    episode-reward-mean: 8515.749309796634
    episode-reward-min: 8434.296166098336
    episode-reward-std: 75.5273471727419
  training_iteration: 15
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.057456970214844
    Q_value-mean: 601.7694702148438
    alpha: 0.18082556128501892
    alpha_loss-mean: 5.456874714582227e-05
    policy_loss-mean: -602.3811645507812
  
== Status ==
Memory usage on this node: 15.4/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     15 |          4901.78 |      14 |      25000 |           375000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.18656688928604126
  date: 2022-05-17_20-04-06
  done: false
  epoch: 15
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3263342142105103
      reward_ctrl-last-mean: -0.23515636920928956
      reward_ctrl-mean-mean: -0.3710511719346047
      reward_ctrl-median-mean: -0.37626605033874516
      reward_ctrl-range-mean: 0.42381219863891606
      reward_run-first-mean: -0.7375750985927474
      reward_run-last-mean: 9.979274873995791
      reward_run-mean-mean: 9.221625811541239
      reward_run-median-mean: 9.529665586875424
      reward_run-range-mean: 13.168638335520605
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8850.57421875
    episode-reward-mean: 8850.57421875
    episode-reward-min: 8850.57421875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 16
  node_ip: 10.43.77.35
  num_train_steps: 400000
  pid: 283289
  policy:
    actions-max: 0.998942494392395
    actions-mean: -0.11212112754583359
    actions-min: -0.9996487498283386
    actions-std: 0.771454393863678
    entropy-mean: -6.2167205810546875
    entropy-std: 3.947084665298462
    scales-max: 0.8623189330101013
    scales-mean: 0.43463611602783203
    scales-min: 0.061941735446453094
    scales-std: 0.1383054554462433
    shifts-max: 3.0489490032196045
    shifts-mean: -0.1481311172246933
    shifts-min: -3.324122428894043
    shifts-std: 1.4521740674972534
  sampler:
    episodes: 410
    last-path-return: 8786.63024960607
    max-path-return: 8894.569437595545
    pool-size: 410000
    total-samples: 410000
  time_since_restore: 5108.734667062759
  time_this_iter_s: 206.95408058166504
  time_total_s: 5108.734667062759
  times:
    epoch_after_hook: 1.9060098566114902e-06
    epoch_before_hook: 2.7180009055882692e-05
    evaluation_metrics: 0.0004121529927942902
    evaluation_paths: 0.48905716501758434
    sample: 13.253857195435558
    timestep_after_hook: 0.032593511044979095
    timestep_before_hook: 0.0754139490891248
    train: 192.6198833992239
    training_metrics: 0.0016812369867693633
    training_paths: 0.10115849200519733
  timestamp: 1652814246
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 400000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2945772159099579
      reward_ctrl-last-mean: -0.42460518836975103
      reward_ctrl-mean-mean: -0.3698709503149986
      reward_ctrl-median-mean: -0.3783485078811646
      reward_ctrl-range-mean: 0.4643571442365647
      reward_run-first-mean: -0.4554418066525131
      reward_run-last-mean: 9.622161887739594
      reward_run-mean-mean: 9.031980143166964
      reward_run-median-mean: 9.311391806755317
      reward_run-range-mean: 12.040939227533183
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8894.569437595554
    episode-reward-mean: 8662.109192851965
    episode-reward-min: 8381.578138586721
    episode-reward-std: 146.22401104752535
  training_iteration: 16
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.101614475250244
    Q_value-mean: 618.4446411132812
    alpha: 0.18275819718837738
    alpha_loss-mean: -0.00025435234420001507
    policy_loss-mean: -619.0615844726562
  
== Status ==
Memory usage on this node: 15.1/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     16 |          5108.73 |      15 |      25000 |           400000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.19194556772708893
  date: 2022-05-17_20-07-33
  done: false
  epoch: 16
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.27661919593811035
      reward_ctrl-last-mean: -0.48337779045104984
      reward_ctrl-mean-mean: -0.3691492931306362
      reward_ctrl-median-mean: -0.37629014253616333
      reward_ctrl-range-mean: 0.5256632566452026
      reward_run-first-mean: -0.3266015303978617
      reward_run-last-mean: 8.991679113526061
      reward_run-mean-mean: 9.45943003829528
      reward_run-median-mean: 9.797222645294994
      reward_run-range-mean: 12.954787230964369
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9090.2802734375
    episode-reward-mean: 9090.2802734375
    episode-reward-min: 9090.2802734375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 17
  node_ip: 10.43.77.35
  num_train_steps: 425000
  pid: 283289
  policy:
    actions-max: 0.9994295835494995
    actions-mean: -0.16210885345935822
    actions-min: -0.9987203478813171
    actions-std: 0.7632049918174744
    entropy-mean: -6.026243686676025
    entropy-std: 4.162206172943115
    scales-max: 1.0253366231918335
    scales-mean: 0.43986329436302185
    scales-min: 0.06410588324069977
    scales-std: 0.14576344192028046
    shifts-max: 4.069427013397217
    shifts-mean: -0.25816312432289124
    shifts-min: -3.3402957916259766
    shifts-std: 1.42946457862854
  sampler:
    episodes: 435
    last-path-return: 8778.6573722687
    max-path-return: 9170.274406984156
    pool-size: 435000
    total-samples: 435000
  time_since_restore: 5315.591091871262
  time_this_iter_s: 206.8564248085022
  time_total_s: 5315.591091871262
  times:
    epoch_after_hook: 1.5179975889623165e-06
    epoch_before_hook: 2.6563997380435467e-05
    evaluation_metrics: 0.0004248830082360655
    evaluation_paths: 0.4868807519960683
    sample: 13.202611212065676
    timestep_after_hook: 0.032465127762407064
    timestep_before_hook: 0.07505231307004578
    train: 192.48533973511076
    training_metrics: 0.0014913759951014072
    training_paths: 0.19348011899273843
  timestamp: 1652814453
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 425000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.31370993375778206
      reward_ctrl-last-mean: -0.37842417120933536
      reward_ctrl-mean-mean: -0.36662542334198955
      reward_ctrl-median-mean: -0.37294523119926454
      reward_ctrl-range-mean: 0.4813334882259369
      reward_run-first-mean: -0.4192854729498987
      reward_run-last-mean: 9.635833294894269
      reward_run-mean-mean: 9.316984512953711
      reward_run-median-mean: 9.618822723390835
      reward_run-range-mean: 12.583333343072267
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9170.27440698415
    episode-reward-mean: 8950.35908961172
    episode-reward-min: 8725.747468666774
    episode-reward-std: 148.40007530428213
  training_iteration: 17
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.334258556365967
    Q_value-mean: 635.3953857421875
    alpha: 0.1894715428352356
    alpha_loss-mean: -0.000200844879145734
    policy_loss-mean: -636.0131225585938
  
== Status ==
Memory usage on this node: 15.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     17 |          5315.59 |      16 |      25000 |           425000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.1985863298177719
  date: 2022-05-17_20-11-00
  done: false
  epoch: 17
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.25436518192291263
      reward_ctrl-last-mean: -0.3780505180358887
      reward_ctrl-mean-mean: -0.37008528006672864
      reward_ctrl-median-mean: -0.37875238656997684
      reward_ctrl-range-mean: 0.4771505773067474
      reward_run-first-mean: -0.3852341877903914
      reward_run-last-mean: 8.852573934948396
      reward_run-mean-mean: 9.249958247984395
      reward_run-median-mean: 9.537027838584358
      reward_run-range-mean: 12.368128913609205
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 8879.873046875
    episode-reward-mean: 8879.873046875
    episode-reward-min: 8879.873046875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 18
  node_ip: 10.43.77.35
  num_train_steps: 450000
  pid: 283289
  policy:
    actions-max: 0.9981767535209656
    actions-mean: -0.12675423920154572
    actions-min: -0.9990057945251465
    actions-std: 0.7703405022621155
    entropy-mean: -6.021575450897217
    entropy-std: 4.0538835525512695
    scales-max: 1.0896445512771606
    scales-mean: 0.43954452872276306
    scales-min: 0.07006161659955978
    scales-std: 0.14463815093040466
    shifts-max: 2.978785276412964
    shifts-mean: -0.20472539961338043
    shifts-min: -3.3222532272338867
    shifts-std: 1.4394266605377197
  sampler:
    episodes: 460
    last-path-return: 8946.537504171774
    max-path-return: 9224.631452485475
    pool-size: 460000
    total-samples: 460000
  time_since_restore: 5522.256312608719
  time_this_iter_s: 206.66522073745728
  time_total_s: 5522.256312608719
  times:
    epoch_after_hook: 1.5060068108141422e-06
    epoch_before_hook: 2.7083995519205928e-05
    evaluation_metrics: 0.0004052520089317113
    evaluation_paths: 0.5152799100033008
    sample: 13.193161250761477
    timestep_after_hook: 0.03252857970073819
    timestep_before_hook: 0.07559798035072163
    train: 192.39490208844654
    training_metrics: 0.0015520440065301955
    training_paths: 0.07269395602634177
  timestamp: 1652814660
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 450000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3324544680118561
      reward_ctrl-last-mean: -0.38614112854003907
      reward_ctrl-mean-mean: -0.36418490780055524
      reward_ctrl-median-mean: -0.3677844762802124
      reward_ctrl-range-mean: 0.48202312767505645
      reward_run-first-mean: -0.6786767350052745
      reward_run-last-mean: 9.683882189138899
      reward_run-mean-mean: 9.275956703008235
      reward_run-median-mean: 9.594802325256481
      reward_run-range-mean: 12.66257742839672
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9055.727804848
    episode-reward-mean: 8911.771795207678
    episode-reward-min: 8769.790885695482
    episode-reward-std: 79.7603718610456
  training_iteration: 18
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.601991653442383
    Q_value-mean: 651.9114990234375
    alpha: 0.19493678212165833
    alpha_loss-mean: -0.00022254833311308175
    policy_loss-mean: -652.5408935546875
  
== Status ==
Memory usage on this node: 15.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     18 |          5522.26 |      17 |      25000 |           450000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.20211979746818542
  date: 2022-05-17_20-14-27
  done: false
  epoch: 18
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.5075154304504395
      reward_ctrl-last-mean: -0.49445562362670903
      reward_ctrl-mean-mean: -0.36818571976423264
      reward_ctrl-median-mean: -0.3699858903884888
      reward_ctrl-range-mean: 0.5106927394866944
      reward_run-first-mean: -1.0152784955476943
      reward_run-last-mean: 10.63513480803067
      reward_run-mean-mean: 9.452100678311437
      reward_run-median-mean: 9.766199634539703
      reward_run-range-mean: 13.234940343576785
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9083.9150390625
    episode-reward-mean: 9083.9150390625
    episode-reward-min: 9083.9150390625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 19
  node_ip: 10.43.77.35
  num_train_steps: 475000
  pid: 283289
  policy:
    actions-max: 0.9998683929443359
    actions-mean: -0.09828416258096695
    actions-min: -0.9994451999664307
    actions-std: 0.7820942997932434
    entropy-mean: -6.42937707901001
    entropy-std: 4.0117950439453125
    scales-max: 1.2126268148422241
    scales-mean: 0.44326353073120117
    scales-min: 0.06772424280643463
    scales-std: 0.143283873796463
    shifts-max: 3.3745994567871094
    shifts-mean: -0.15107125043869019
    shifts-min: -3.415684700012207
    shifts-std: 1.4874882698059082
  sampler:
    episodes: 485
    last-path-return: 9050.419671416452
    max-path-return: 9264.145581690485
    pool-size: 485000
    total-samples: 485000
  time_since_restore: 5728.839034318924
  time_this_iter_s: 206.58272171020508
  time_total_s: 5728.839034318924
  times:
    epoch_after_hook: 1.52099528349936e-06
    epoch_before_hook: 2.717200550250709e-05
    evaluation_metrics: 0.00041076098568737507
    evaluation_paths: 0.517671280016657
    sample: 13.250174311280716
    timestep_after_hook: 0.03265566861955449
    timestep_before_hook: 0.0757474213896785
    train: 192.2517053630727
    training_metrics: 0.001561048993607983
    training_paths: 0.07349621399771422
  timestamp: 1652814867
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 475000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3266850638389588
      reward_ctrl-last-mean: -0.38412961602211004
      reward_ctrl-mean-mean: -0.3660183530110121
      reward_ctrl-median-mean: -0.3696352851390839
      reward_ctrl-range-mean: 0.49851809620857235
      reward_run-first-mean: -0.6299985580386482
      reward_run-last-mean: 9.972923367561634
      reward_run-mean-mean: 9.445023030926233
      reward_run-median-mean: 9.761215054782937
      reward_run-range-mean: 12.847311019444822
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9264.145581690487
    episode-reward-mean: 9079.004677915222
    episode-reward-min: 8809.451901403972
    episode-reward-std: 145.97645144420184
  training_iteration: 19
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 6.874915599822998
    Q_value-mean: 665.6677856445312
    alpha: 0.2002570927143097
    alpha_loss-mean: -0.00012009830243187025
    policy_loss-mean: -666.2684936523438
  
== Status ==
Memory usage on this node: 15.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     19 |          5728.84 |      18 |      25000 |           475000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.20519877970218658
  date: 2022-05-17_20-17-59
  done: false
  epoch: 19
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.30381422042846684
      reward_ctrl-last-mean: -0.3281955480575562
      reward_ctrl-mean-mean: -0.3746675509929657
      reward_ctrl-median-mean: -0.37742985486984254
      reward_ctrl-range-mean: 0.44344543218612664
      reward_run-first-mean: 0.010572843448042636
      reward_run-last-mean: 11.074829629449141
      reward_run-mean-mean: 9.969975956866321
      reward_run-median-mean: 10.338555976152861
      reward_run-range-mean: 12.498815057850054
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9595.30859375
    episode-reward-mean: 9595.30859375
    episode-reward-min: 9595.30859375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 20
  node_ip: 10.43.77.35
  num_train_steps: 500000
  pid: 283289
  policy:
    actions-max: 0.9994984865188599
    actions-mean: -0.04280361533164978
    actions-min: -0.9989880919456482
    actions-std: 0.763923168182373
    entropy-mean: -5.663161277770996
    entropy-std: 3.8161888122558594
    scales-max: 0.9312865138053894
    scales-mean: 0.4266093671321869
    scales-min: 0.0634421780705452
    scales-std: 0.14707651734352112
    shifts-max: 2.938211441040039
    shifts-mean: -0.053522396832704544
    shifts-min: -3.188901901245117
    shifts-std: 1.4197922945022583
  sampler:
    episodes: 510
    last-path-return: 9254.89455065543
    max-path-return: 9583.54944848131
    pool-size: 510000
    total-samples: 510000
  time_since_restore: 5940.769365787506
  time_this_iter_s: 211.93033146858215
  time_total_s: 5940.769365787506
  times:
    epoch_after_hook: 1.6570265870541334e-06
    epoch_before_hook: 2.7147005312144756e-05
    evaluation_metrics: 0.0004433470021467656
    evaluation_paths: 0.494941444019787
    sample: 14.190206117229536
    timestep_after_hook: 0.03460895494208671
    timestep_before_hook: 0.07893207939923741
    train: 196.55231632792857
    training_metrics: 0.0015365110011771321
    training_paths: 0.18745632498757914
  timestamp: 1652815079
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 500000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.343131639957428
      reward_ctrl-last-mean: -0.3638856196403504
      reward_ctrl-mean-mean: -0.3684758928984404
      reward_ctrl-median-mean: -0.3705809545516968
      reward_ctrl-range-mean: 0.4792059850692749
      reward_run-first-mean: -0.7114882714382957
      reward_run-last-mean: 9.164647719819754
      reward_run-mean-mean: 9.692056986925033
      reward_run-median-mean: 10.064243691027713
      reward_run-range-mean: 13.190480884365012
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9583.549448481299
    episode-reward-mean: 9323.581094026591
    episode-reward-min: 9008.884512433466
    episode-reward-std: 180.40926328380888
  training_iteration: 20
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 7.075190544128418
    Q_value-mean: 677.7772216796875
    alpha: 0.20344185829162598
    alpha_loss-mean: -9.982415940612555e-05
    policy_loss-mean: -678.3653564453125
  
== Status ==
Memory usage on this node: 52.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     20 |          5940.77 |      19 |      25000 |           500000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2070680856704712
  date: 2022-05-17_20-21-33
  done: false
  epoch: 20
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3247278928756714
      reward_ctrl-last-mean: -0.4918840885162354
      reward_ctrl-mean-mean: -0.36504954804182055
      reward_ctrl-median-mean: -0.36878899335861204
      reward_ctrl-range-mean: 0.4786068737506867
      reward_run-first-mean: -0.7859432104961966
      reward_run-last-mean: 10.585856228044577
      reward_run-mean-mean: 9.657313408601729
      reward_run-median-mean: 9.992486252514254
      reward_run-range-mean: 12.956945010610905
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9292.263671875
    episode-reward-mean: 9292.263671875
    episode-reward-min: 9292.263671875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 21
  node_ip: 10.43.77.35
  num_train_steps: 525000
  pid: 283289
  policy:
    actions-max: 0.9987780451774597
    actions-mean: -0.10784301161766052
    actions-min: -0.9989715814590454
    actions-std: 0.7714298367500305
    entropy-mean: -6.256186485290527
    entropy-std: 3.70078706741333
    scales-max: 1.2539410591125488
    scales-mean: 0.42382264137268066
    scales-min: 0.06569813191890717
    scales-std: 0.14622822403907776
    shifts-max: 3.3914999961853027
    shifts-mean: -0.14928176999092102
    shifts-min: -3.1685476303100586
    shifts-std: 1.4296417236328125
  sampler:
    episodes: 535
    last-path-return: 9172.111007197718
    max-path-return: 9583.54944848131
    pool-size: 535000
    total-samples: 535000
  time_since_restore: 6155.1140677928925
  time_this_iter_s: 214.34470200538635
  time_total_s: 6155.1140677928925
  times:
    epoch_after_hook: 1.6239937394857407e-06
    epoch_before_hook: 3.857002593576908e-05
    evaluation_metrics: 0.00041174099897034466
    evaluation_paths: 0.5002899240062106
    sample: 14.558669978374382
    timestep_after_hook: 0.03557510345126502
    timestep_before_hook: 0.08054292015731335
    train: 198.59686460485682
    training_metrics: 0.0015258780040312558
    training_paths: 0.17495884699746966
  timestamp: 1652815293
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 525000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3139385151863098
      reward_ctrl-last-mean: -0.37689418673515324
      reward_ctrl-mean-mean: -0.3695125780898333
      reward_ctrl-median-mean: -0.37489542961120603
      reward_ctrl-range-mean: 0.48591185986995705
      reward_run-first-mean: -0.394973951166082
      reward_run-last-mean: 10.297325198076578
      reward_run-mean-mean: 9.561369649364746
      reward_run-median-mean: 9.944468397126663
      reward_run-range-mean: 13.064398789902336
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9439.827419560577
    episode-reward-mean: 9191.857071274913
    episode-reward-min: 8940.523708080633
    episode-reward-std: 138.37835889251784
  training_iteration: 21
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 7.485815525054932
    Q_value-mean: 688.8213500976562
    alpha: 0.20695260167121887
    alpha_loss-mean: -5.69316471228376e-05
    policy_loss-mean: -689.3802490234375
  
== Status ==
Memory usage on this node: 52.8/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     21 |          6155.11 |      20 |      25000 |           525000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.20830832421779633
  date: 2022-05-17_20-25-07
  done: false
  epoch: 21
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4113960266113281
      reward_ctrl-last-mean: -0.26768102645874026
      reward_ctrl-mean-mean: -0.3777929647564888
      reward_ctrl-median-mean: -0.38059581518173224
      reward_ctrl-range-mean: 0.4597880005836487
      reward_run-first-mean: -0.663890673372974
      reward_run-last-mean: 11.376478429286863
      reward_run-mean-mean: 9.974222568258439
      reward_run-median-mean: 10.383178155636301
      reward_run-range-mean: 13.473929367686791
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9596.4296875
    episode-reward-mean: 9596.4296875
    episode-reward-min: 9596.4296875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 22
  node_ip: 10.43.77.35
  num_train_steps: 550000
  pid: 283289
  policy:
    actions-max: 0.9993911385536194
    actions-mean: -0.08460863679647446
    actions-min: -0.9995993375778198
    actions-std: 0.7734015583992004
    entropy-mean: -6.171405792236328
    entropy-std: 3.6697561740875244
    scales-max: 0.9944995045661926
    scales-mean: 0.42393890023231506
    scales-min: 0.06440271437168121
    scales-std: 0.13837957382202148
    shifts-max: 3.339726209640503
    shifts-mean: -0.11121112108230591
    shifts-min: -3.7519822120666504
    shifts-std: 1.4396229982376099
  sampler:
    episodes: 560
    last-path-return: 9442.534333633714
    max-path-return: 9827.576183382564
    pool-size: 560000
    total-samples: 560000
  time_since_restore: 6369.096915006638
  time_this_iter_s: 213.98284721374512
  time_total_s: 6369.096915006638
  times:
    epoch_after_hook: 1.6700068954378366e-06
    epoch_before_hook: 3.569797263480723e-05
    evaluation_metrics: 0.00040863099275156856
    evaluation_paths: 0.4971586080209818
    sample: 14.551519198488677
    timestep_after_hook: 0.03533424672787078
    timestep_before_hook: 0.0792300928151235
    train: 198.24206301104277
    training_metrics: 0.0015222559741232544
    training_paths: 0.1824773330008611
  timestamp: 1652815507
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 550000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.32960883855819706
      reward_ctrl-last-mean: -0.4603061866760254
      reward_ctrl-mean-mean: -0.3715389427030087
      reward_ctrl-median-mean: -0.3748792731761933
      reward_ctrl-range-mean: 0.4906802392005921
      reward_run-first-mean: -0.5732634744857813
      reward_run-last-mean: 10.310655445557359
      reward_run-mean-mean: 9.889047110859545
      reward_run-median-mean: 10.2628897578047
      reward_run-range-mean: 13.387586277228767
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9783.369526629238
    episode-reward-mean: 9517.508168156533
    episode-reward-min: 9303.264945873281
    episode-reward-std: 168.6012367413888
  training_iteration: 22
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 7.795734882354736
    Q_value-mean: 698.1612548828125
    alpha: 0.21068669855594635
    alpha_loss-mean: -3.756444129976444e-05
    policy_loss-mean: -698.701171875
  
== Status ==
Memory usage on this node: 52.8/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     22 |           6369.1 |      21 |      25000 |           550000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.21391192078590393
  date: 2022-05-17_20-28-41
  done: false
  epoch: 22
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.22416086196899415
      reward_ctrl-last-mean: -0.28350205421447755
      reward_ctrl-mean-mean: -0.37171459473371504
      reward_ctrl-median-mean: -0.37336794137954715
      reward_ctrl-range-mean: 0.4805238366127014
      reward_run-first-mean: -0.44960613538075106
      reward_run-last-mean: 11.858336846678412
      reward_run-mean-mean: 10.176414361096358
      reward_run-median-mean: 10.58286291973019
      reward_run-range-mean: 13.631292621478755
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9804.69921875
    episode-reward-mean: 9804.69921875
    episode-reward-min: 9804.69921875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 23
  node_ip: 10.43.77.35
  num_train_steps: 575000
  pid: 283289
  policy:
    actions-max: 0.9989908337593079
    actions-mean: -0.09542643278837204
    actions-min: -0.9970395565032959
    actions-std: 0.7689362168312073
    entropy-mean: -5.807882785797119
    entropy-std: 3.615964651107788
    scales-max: 0.955313503742218
    scales-mean: 0.42434433102607727
    scales-min: 0.06262825429439545
    scales-std: 0.13897864520549774
    shifts-max: 2.890838861465454
    shifts-mean: -0.11894648522138596
    shifts-min: -3.302110195159912
    shifts-std: 1.4287667274475098
  sampler:
    episodes: 585
    last-path-return: 9517.53449369178
    max-path-return: 9942.240415492639
    pool-size: 585000
    total-samples: 585000
  time_since_restore: 6582.97092962265
  time_this_iter_s: 213.87401461601257
  time_total_s: 6582.97092962265
  times:
    epoch_after_hook: 1.4849938452243805e-06
    epoch_before_hook: 2.891398617066443e-05
    evaluation_metrics: 0.0004153389891143888
    evaluation_paths: 0.4955292159866076
    sample: 14.46490708499914
    timestep_after_hook: 0.035151341173332185
    timestep_before_hook: 0.08046778856078163
    train: 198.32342052203603
    training_metrics: 0.001510093017714098
    training_paths: 0.07955651500378735
  timestamp: 1652815721
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 575000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3200820159912109
      reward_ctrl-last-mean: -0.39529653072357174
      reward_ctrl-mean-mean: -0.3728160247582198
      reward_ctrl-median-mean: -0.37416175246238703
      reward_ctrl-range-mean: 0.4700557440519333
      reward_run-first-mean: -0.5845643427325936
      reward_run-last-mean: 10.734314488027053
      reward_run-mean-mean: 9.971947862375979
      reward_run-median-mean: 10.359570547939754
      reward_run-range-mean: 13.529778048553101
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9811.465845082868
    episode-reward-mean: 9599.131837617759
    episode-reward-min: 9452.842471687538
    episode-reward-std: 94.45578541926116
  training_iteration: 23
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 7.7927656173706055
    Q_value-mean: 708.3607177734375
    alpha: 0.21180851757526398
    alpha_loss-mean: -0.00018708044080995023
    policy_loss-mean: -708.8908081054688
  
== Status ==
Memory usage on this node: 51.9/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     23 |          6582.97 |      22 |      25000 |           575000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.21545752882957458
  date: 2022-05-17_20-32-15
  done: false
  epoch: 23
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.45618996620178226
      reward_ctrl-last-mean: -0.48038873672485355
      reward_ctrl-mean-mean: -0.3768953010737896
      reward_ctrl-median-mean: -0.3764021635055542
      reward_ctrl-range-mean: 0.4900616824626923
      reward_run-first-mean: -0.8450773723466005
      reward_run-last-mean: 10.33124044368492
      reward_run-mean-mean: 10.235179394174736
      reward_run-median-mean: 10.571147579688045
      reward_run-range-mean: 13.863623393702234
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9858.2841796875
    episode-reward-mean: 9858.2841796875
    episode-reward-min: 9858.2841796875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 24
  node_ip: 10.43.77.35
  num_train_steps: 600000
  pid: 283289
  policy:
    actions-max: 0.9993731379508972
    actions-mean: -0.08399218320846558
    actions-min: -0.9991336464881897
    actions-std: 0.7847181558609009
    entropy-mean: -6.648721694946289
    entropy-std: 3.7376930713653564
    scales-max: 0.9973981380462646
    scales-mean: 0.429428368806839
    scales-min: 0.05386018753051758
    scales-std: 0.145354762673378
    shifts-max: 4.014768600463867
    shifts-mean: -0.12870998680591583
    shifts-min: -3.1550703048706055
    shifts-std: 1.481703758239746
  sampler:
    episodes: 610
    last-path-return: 9723.794064350053
    max-path-return: 9972.99534809325
    pool-size: 610000
    total-samples: 610000
  time_since_restore: 6797.113585948944
  time_this_iter_s: 214.14265632629395
  time_total_s: 6797.113585948944
  times:
    epoch_after_hook: 1.7529819160699844e-06
    epoch_before_hook: 3.557800664566457e-05
    evaluation_metrics: 0.0006471830129157752
    evaluation_paths: 0.4947425360151101
    sample: 14.611621058691526
    timestep_after_hook: 0.035230373847298324
    timestep_before_hook: 0.08054555166745558
    train: 198.44844957237365
    training_metrics: 0.0015822030254639685
    training_paths: 0.07687485098722391
  timestamp: 1652815935
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 600000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3595812797546387
      reward_ctrl-last-mean: -0.41625100612640387
      reward_ctrl-mean-mean: -0.374224909491837
      reward_ctrl-median-mean: -0.3748960065841675
      reward_ctrl-range-mean: 0.49465169519186025
      reward_run-first-mean: -0.632017555623488
      reward_run-last-mean: 10.689197795935456
      reward_run-mean-mean: 10.128417437126943
      reward_run-median-mean: 10.550024349832562
      reward_run-range-mean: 13.61851288461565
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9875.512522576762
    episode-reward-mean: 9754.192527635107
    episode-reward-min: 9634.459973419856
    episode-reward-std: 77.54461424525644
  training_iteration: 24
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 7.920141220092773
    Q_value-mean: 717.689697265625
    alpha: 0.21466875076293945
    alpha_loss-mean: -4.095870826859027e-05
    policy_loss-mean: -718.1973876953125
  
== Status ==
Memory usage on this node: 51.9/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     24 |          6797.11 |      23 |      25000 |           600000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.22047783434391022
  date: 2022-05-17_20-35-50
  done: false
  epoch: 24
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2193955421447754
      reward_ctrl-last-mean: -0.4340414524078369
      reward_ctrl-mean-mean: -0.37975101002454753
      reward_ctrl-median-mean: -0.3792962670326233
      reward_ctrl-range-mean: 0.47290302515029903
      reward_run-first-mean: 0.17253331333940441
      reward_run-last-mean: 12.520893317773698
      reward_run-mean-mean: 10.44820881952248
      reward_run-median-mean: 10.909156212253208
      reward_run-range-mean: 13.506323760843829
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10068.45703125
    episode-reward-mean: 10068.45703125
    episode-reward-min: 10068.45703125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 25
  node_ip: 10.43.77.35
  num_train_steps: 625000
  pid: 283289
  policy:
    actions-max: 0.9996539950370789
    actions-mean: -0.10312121361494064
    actions-min: -0.9990745186805725
    actions-std: 0.782640278339386
    entropy-mean: -6.6494574546813965
    entropy-std: 3.452357530593872
    scales-max: 0.9265667796134949
    scales-mean: 0.43185853958129883
    scales-min: 0.05852280184626579
    scales-std: 0.1375516653060913
    shifts-max: 4.231002330780029
    shifts-mean: -0.15500514209270477
    shifts-min: -3.129948139190674
    shifts-std: 1.4682743549346924
  sampler:
    episodes: 635
    last-path-return: 9985.114978155798
    max-path-return: 9997.46138734755
    pool-size: 635000
    total-samples: 635000
  time_since_restore: 7011.2159512043
  time_this_iter_s: 214.10236525535583
  time_total_s: 7011.2159512043
  times:
    epoch_after_hook: 1.5370023902505636e-06
    epoch_before_hook: 2.9326998628675938e-05
    evaluation_metrics: 0.0004065389803145081
    evaluation_paths: 0.4981380040117074
    sample: 14.541744689515326
    timestep_after_hook: 0.03522800831706263
    timestep_before_hook: 0.08033760730177164
    train: 198.47428720307653
    training_metrics: 0.001580471987836063
    training_paths: 0.07826231099897996
  timestamp: 1652816150
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 625000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2759537869691848
      reward_ctrl-last-mean: -0.35455268144607544
      reward_ctrl-mean-mean: -0.37570267927587037
      reward_ctrl-median-mean: -0.3777788579463959
      reward_ctrl-range-mean: 0.47887151479721063
      reward_run-first-mean: -0.42520302836723733
      reward_run-last-mean: 10.862288314281955
      reward_run-mean-mean: 10.301794296724063
      reward_run-median-mean: 10.707302046308612
      reward_run-range-mean: 13.704727891408831
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9997.461387347552
    episode-reward-mean: 9926.091617448192
    episode-reward-min: 9843.253718555126
    episode-reward-std: 50.82465877528603
  training_iteration: 25
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 7.9952392578125
    Q_value-mean: 726.6056518554688
    alpha: 0.21541376411914825
    alpha_loss-mean: -0.00016935326857492328
    policy_loss-mean: -727.0946655273438
  
== Status ==
Memory usage on this node: 51.9/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     25 |          7011.22 |      24 |      25000 |           625000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.21626222133636475
  date: 2022-05-17_20-39-24
  done: false
  epoch: 25
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.41588468551635743
      reward_ctrl-last-mean: -0.16373128890991212
      reward_ctrl-mean-mean: -0.3676847068548203
      reward_ctrl-median-mean: -0.36139286756515504
      reward_ctrl-range-mean: 0.47756249904632564
      reward_run-first-mean: -0.7164582019599259
      reward_run-last-mean: 11.763193094291182
      reward_run-mean-mean: 10.208970062428838
      reward_run-median-mean: 10.653985022257615
      reward_run-range-mean: 14.449774851700953
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 9841.28515625
    episode-reward-mean: 9841.28515625
    episode-reward-min: 9841.28515625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 26
  node_ip: 10.43.77.35
  num_train_steps: 650000
  pid: 283289
  policy:
    actions-max: 0.9991702437400818
    actions-mean: -0.0720660611987114
    actions-min: -0.9996245503425598
    actions-std: 0.7694460153579712
    entropy-mean: -5.693262100219727
    entropy-std: 4.138848304748535
    scales-max: 0.9847413301467896
    scales-mean: 0.43443727493286133
    scales-min: 0.05683721974492073
    scales-std: 0.15185488760471344
    shifts-max: 2.8243625164031982
    shifts-mean: -0.08884397894144058
    shifts-min: -2.793408155441284
    shifts-std: 1.4211183786392212
  sampler:
    episodes: 660
    last-path-return: 10013.565680822327
    max-path-return: 10163.049975990216
    pool-size: 660000
    total-samples: 660000
  time_since_restore: 7225.294563531876
  time_this_iter_s: 214.07861232757568
  time_total_s: 7225.294563531876
  times:
    epoch_after_hook: 1.6039994079619646e-06
    epoch_before_hook: 4.250500933267176e-05
    evaluation_metrics: 0.00041339200106449425
    evaluation_paths: 0.49908746700384654
    sample: 14.599624333786778
    timestep_after_hook: 0.03522091658669524
    timestep_before_hook: 0.0807713138347026
    train: 198.3905243750196
    training_metrics: 0.001534224982606247
    training_paths: 0.07784820400411263
  timestamp: 1652816364
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 650000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2911977076530457
      reward_ctrl-last-mean: -0.396417191028595
      reward_ctrl-mean-mean: -0.3740879622554779
      reward_ctrl-median-mean: -0.37294321298599253
      reward_ctrl-range-mean: 0.46522812128067026
      reward_run-first-mean: -0.532053905112555
      reward_run-last-mean: 10.953066734760341
      reward_run-mean-mean: 10.320248718841302
      reward_run-median-mean: 10.749974257184604
      reward_run-range-mean: 13.826814646916437
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10163.049975990216
    episode-reward-mean: 9946.160756585825
    episode-reward-min: 9737.167145508201
    episode-reward-std: 141.36283313678751
  training_iteration: 26
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 8.062649726867676
    Q_value-mean: 734.7139892578125
    alpha: 0.21862204372882843
    alpha_loss-mean: 0.00017225071496795863
    policy_loss-mean: -735.1763305664062
  
== Status ==
Memory usage on this node: 82.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     26 |          7225.29 |      25 |      25000 |           650000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.22058004140853882
  date: 2022-05-17_20-42-58
  done: false
  epoch: 26
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.36053071022033695
      reward_ctrl-last-mean: -0.45627608299255373
      reward_ctrl-mean-mean: -0.37496709249615673
      reward_ctrl-median-mean: -0.37532297372817996
      reward_ctrl-range-mean: 0.48329866528511045
      reward_run-first-mean: -0.6874413857666752
      reward_run-last-mean: 10.564931283759051
      reward_run-mean-mean: 10.611679590291592
      reward_run-median-mean: 11.169215470521863
      reward_run-range-mean: 13.909370762171335
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10236.712890625
    episode-reward-mean: 10236.712890625
    episode-reward-min: 10236.712890625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 27
  node_ip: 10.43.77.35
  num_train_steps: 675000
  pid: 283289
  policy:
    actions-max: 0.9990674257278442
    actions-mean: -0.10263055562973022
    actions-min: -0.9994863867759705
    actions-std: 0.7652143239974976
    entropy-mean: -5.731443881988525
    entropy-std: 3.644120454788208
    scales-max: 1.0330450534820557
    scales-mean: 0.4325588047504425
    scales-min: 0.05706328526139259
    scales-std: 0.14112289249897003
    shifts-max: 3.1845641136169434
    shifts-mean: -0.15593086183071136
    shifts-min: -3.0355026721954346
    shifts-std: 1.4358278512954712
  sampler:
    episodes: 685
    last-path-return: 10023.114404307746
    max-path-return: 10351.271564919205
    pool-size: 685000
    total-samples: 685000
  time_since_restore: 7439.326560974121
  time_this_iter_s: 214.03199744224548
  time_total_s: 7439.326560974121
  times:
    epoch_after_hook: 1.61500065587461e-06
    epoch_before_hook: 3.156901220791042e-05
    evaluation_metrics: 0.0004135899944230914
    evaluation_paths: 0.49814786299248226
    sample: 14.500772280793171
    timestep_after_hook: 0.03515296205296181
    timestep_before_hook: 0.08042862021829933
    train: 198.44739016448148
    training_metrics: 0.001586794009199366
    training_paths: 0.07507536601042375
  timestamp: 1652816578
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 675000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.28775376558303833
      reward_ctrl-last-mean: -0.40025014162063605
      reward_ctrl-mean-mean: -0.3734093213027716
      reward_ctrl-median-mean: -0.3726298904418946
      reward_ctrl-range-mean: 0.4724470460414887
      reward_run-first-mean: -0.5335880352839035
      reward_run-last-mean: 10.766035343382555
      reward_run-mean-mean: 10.475107221334081
      reward_run-median-mean: 10.91659483661823
      reward_run-range-mean: 14.107416873360027
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10351.271564919207
    episode-reward-mean: 10101.697900031311
    episode-reward-min: 9973.008926192835
    episode-reward-std: 131.17086240689105
  training_iteration: 27
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 8.036458015441895
    Q_value-mean: 742.43896484375
    alpha: 0.21979400515556335
    alpha_loss-mean: -0.0001570351014379412
    policy_loss-mean: -742.8759765625
  
== Status ==
Memory usage on this node: 82.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     27 |          7439.33 |      26 |      25000 |           675000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.22118625044822693
  date: 2022-05-17_20-46-34
  done: false
  epoch: 27
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.24490463733673096
      reward_ctrl-last-mean: -0.4462133407592774
      reward_ctrl-mean-mean: -0.37270910162925724
      reward_ctrl-median-mean: -0.37027213573455814
      reward_ctrl-range-mean: 0.4482995986938476
      reward_run-first-mean: -0.07247964939169904
      reward_run-last-mean: 11.859761509626878
      reward_run-mean-mean: 10.657164863104757
      reward_run-median-mean: 11.053378841703818
      reward_run-range-mean: 13.299181180386359
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10284.4560546875
    episode-reward-mean: 10284.4560546875
    episode-reward-min: 10284.4560546875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 28
  node_ip: 10.43.77.35
  num_train_steps: 700000
  pid: 283289
  policy:
    actions-max: 0.9989731907844543
    actions-mean: -0.09664701670408249
    actions-min: -0.9984558820724487
    actions-std: 0.77621990442276
    entropy-mean: -6.2462053298950195
    entropy-std: 3.841710329055786
    scales-max: 0.8827002644538879
    scales-mean: 0.43790724873542786
    scales-min: 0.050462570041418076
    scales-std: 0.14109395444393158
    shifts-max: 2.9815196990966797
    shifts-mean: -0.1236756220459938
    shifts-min: -2.994767665863037
    shifts-std: 1.4618637561798096
  sampler:
    episodes: 710
    last-path-return: 10017.536177006457
    max-path-return: 10351.271564919205
    pool-size: 710000
    total-samples: 710000
  time_since_restore: 7655.603112220764
  time_this_iter_s: 216.27655124664307
  time_total_s: 7655.603112220764
  times:
    epoch_after_hook: 1.6550184227526188e-06
    epoch_before_hook: 3.6013982025906444e-05
    evaluation_metrics: 0.0004009900148957968
    evaluation_paths: 0.49486668000463396
    sample: 14.608903863816522
    timestep_after_hook: 0.035166515241144225
    timestep_before_hook: 0.08052795586991124
    train: 200.55444278850337
    training_metrics: 0.001572219975059852
    training_paths: 0.07778868000605144
  timestamp: 1652816794
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 700000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3701643705368043
      reward_ctrl-last-mean: -0.37209525823593137
      reward_ctrl-mean-mean: -0.3739278529047966
      reward_ctrl-median-mean: -0.3723168849945069
      reward_ctrl-range-mean: 0.4623452746868134
      reward_run-first-mean: -0.641128294220476
      reward_run-last-mean: 11.092120304919035
      reward_run-mean-mean: 10.432535700832997
      reward_run-median-mean: 10.869454767303111
      reward_run-range-mean: 14.152707240089416
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10346.480478147401
    episode-reward-mean: 10058.607847928202
    episode-reward-min: 9796.806160239834
    episode-reward-std: 171.73223892495164
  training_iteration: 28
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 8.20634651184082
    Q_value-mean: 750.4161376953125
    alpha: 0.22262878715991974
    alpha_loss-mean: -2.413029142189771e-05
    policy_loss-mean: -750.8372802734375
  
== Status ==
Memory usage on this node: 82.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     28 |           7655.6 |      27 |      25000 |           700000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.22764183580875397
  date: 2022-05-17_20-50-09
  done: false
  epoch: 28
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.31693382263183595
      reward_ctrl-last-mean: -0.4045753002166748
      reward_ctrl-mean-mean: -0.375328019297123
      reward_ctrl-median-mean: -0.37313988208770754
      reward_ctrl-range-mean: 0.4548880815505981
      reward_run-first-mean: -0.2953032640914914
      reward_run-last-mean: 12.247513188688117
      reward_run-mean-mean: 10.617164374671647
      reward_run-median-mean: 11.044529272885555
      reward_run-range-mean: 14.300396831321205
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10241.8359375
    episode-reward-mean: 10241.8359375
    episode-reward-min: 10241.8359375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 29
  node_ip: 10.43.77.35
  num_train_steps: 725000
  pid: 283289
  policy:
    actions-max: 0.9993669986724854
    actions-mean: -0.09828000515699387
    actions-min: -0.9999127984046936
    actions-std: 0.7667789459228516
    entropy-mean: -5.963622093200684
    entropy-std: 3.761500120162964
    scales-max: 0.922058641910553
    scales-mean: 0.43496379256248474
    scales-min: 0.04980037733912468
    scales-std: 0.1447347104549408
    shifts-max: 4.486889839172363
    shifts-mean: -0.12962345778942108
    shifts-min: -3.2043466567993164
    shifts-std: 1.4151209592819214
  sampler:
    episodes: 735
    last-path-return: 10195.212242754533
    max-path-return: 10543.95424223624
    pool-size: 735000
    total-samples: 735000
  time_since_restore: 7870.513875246048
  time_this_iter_s: 214.9107630252838
  time_total_s: 7870.513875246048
  times:
    epoch_after_hook: 1.8069986253976822e-06
    epoch_before_hook: 3.086499054916203e-05
    evaluation_metrics: 0.00041423700167797506
    evaluation_paths: 0.49945243599358946
    sample: 14.594614888628712
    timestep_after_hook: 0.03523824276635423
    timestep_before_hook: 0.08118328233831562
    train: 199.22425850041327
    training_metrics: 0.0016173830081243068
    training_paths: 0.07928456898662262
  timestamp: 1652817009
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 725000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.23877874970436097
      reward_ctrl-last-mean: -0.41840535402297974
      reward_ctrl-mean-mean: -0.3724941733253002
      reward_ctrl-median-mean: -0.3712957417964936
      reward_ctrl-range-mean: 0.4715501081943511
      reward_run-first-mean: -0.48779893821293785
      reward_run-last-mean: 10.941962615358307
      reward_run-mean-mean: 10.577533731784067
      reward_run-median-mean: 11.036182587708268
      reward_run-range-mean: 14.103520400311151
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10423.463011901289
    episode-reward-mean: 10205.039558458764
    episode-reward-min: 9990.099102775472
    episode-reward-std: 128.36315802967752
  training_iteration: 29
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 8.267685890197754
    Q_value-mean: 758.4332885742188
    alpha: 0.22484664618968964
    alpha_loss-mean: -0.00020917929941788316
    policy_loss-mean: -758.8411865234375
  
== Status ==
Memory usage on this node: 82.4/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     29 |          7870.51 |      28 |      25000 |           725000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.22420375049114227
  date: 2022-05-17_20-53-43
  done: false
  epoch: 29
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.14807716608047486
      reward_ctrl-last-mean: -0.4068220138549805
      reward_ctrl-mean-mean: -0.3768781112670898
      reward_ctrl-median-mean: -0.3769716858863831
      reward_ctrl-range-mean: 0.45588719844818115
      reward_run-first-mean: -0.6053459133766067
      reward_run-last-mean: 9.977111175874143
      reward_run-mean-mean: 10.484434990150973
      reward_run-median-mean: 10.942427442548706
      reward_run-range-mean: 14.175228805745835
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10107.556640625
    episode-reward-mean: 10107.556640625
    episode-reward-min: 10107.556640625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 30
  node_ip: 10.43.77.35
  num_train_steps: 750000
  pid: 283289
  policy:
    actions-max: 0.9991532564163208
    actions-mean: -0.08215832710266113
    actions-min: -0.9991846084594727
    actions-std: 0.7693884372711182
    entropy-mean: -5.6912102699279785
    entropy-std: 3.8314335346221924
    scales-max: 1.0669716596603394
    scales-mean: 0.4449883997440338
    scales-min: 0.05242143198847771
    scales-std: 0.15164726972579956
    shifts-max: 2.983494758605957
    shifts-mean: -0.13935332000255585
    shifts-min: -3.3134241104125977
    shifts-std: 1.4262694120407104
  sampler:
    episodes: 760
    last-path-return: 10425.165366373061
    max-path-return: 10545.515978717534
    pool-size: 760000
    total-samples: 760000
  time_since_restore: 8084.844463825226
  time_this_iter_s: 214.33058857917786
  time_total_s: 8084.844463825226
  times:
    epoch_after_hook: 1.5959958545863628e-06
    epoch_before_hook: 3.109898534603417e-05
    evaluation_metrics: 0.00042159599252045155
    evaluation_paths: 0.4948666050040629
    sample: 14.656504859565757
    timestep_after_hook: 0.03539740145788528
    timestep_before_hook: 0.08020865291473456
    train: 198.58987763291225
    training_metrics: 0.0015673179877921939
    training_paths: 0.07803959099692293
  timestamp: 1652817223
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 750000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3289094185829163
      reward_ctrl-last-mean: -0.4028744494915008
      reward_ctrl-mean-mean: -0.3716619035989046
      reward_ctrl-median-mean: -0.3710713028907776
      reward_ctrl-range-mean: 0.46984836876392366
      reward_run-first-mean: -0.6546700620499597
      reward_run-last-mean: 11.488214633063535
      reward_run-mean-mean: 10.672363835081708
      reward_run-median-mean: 11.099817784930387
      reward_run-range-mean: 14.283384547607085
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10545.515978717547
    episode-reward-mean: 10300.701931482803
    episode-reward-min: 10015.965342125412
    episode-reward-std: 144.03098752571705
  training_iteration: 30
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 8.461969375610352
    Q_value-mean: 766.3026123046875
    alpha: 0.227692112326622
    alpha_loss-mean: 0.0001338851870968938
    policy_loss-mean: -766.7036743164062
  
== Status ==
Memory usage on this node: 82.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     30 |          8084.84 |      29 |      25000 |           750000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.23373757302761078
  date: 2022-05-17_20-57-19
  done: false
  epoch: 30
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4168587684631348
      reward_ctrl-last-mean: -0.2742161273956299
      reward_ctrl-mean-mean: -0.3710256901860237
      reward_ctrl-median-mean: -0.3653234720230103
      reward_ctrl-range-mean: 0.4526165723800659
      reward_run-first-mean: -0.5541977461018118
      reward_run-last-mean: 11.068888446270648
      reward_run-mean-mean: 10.980181165417202
      reward_run-median-mean: 11.373827261083704
      reward_run-range-mean: 14.413547842378824
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10609.1552734375
    episode-reward-mean: 10609.1552734375
    episode-reward-min: 10609.1552734375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 31
  node_ip: 10.43.77.35
  num_train_steps: 775000
  pid: 283289
  policy:
    actions-max: 0.9989680647850037
    actions-mean: -0.09319013357162476
    actions-min: -0.9991418719291687
    actions-std: 0.7714420557022095
    entropy-mean: -6.059335231781006
    entropy-std: 3.8833768367767334
    scales-max: 0.9346093535423279
    scales-mean: 0.42884349822998047
    scales-min: 0.04270937293767929
    scales-std: 0.13634367287158966
    shifts-max: 3.528622627258301
    shifts-mean: -0.12968270480632782
    shifts-min: -3.052485227584839
    shifts-std: 1.428821325302124
  sampler:
    episodes: 785
    last-path-return: 10361.400855426496
    max-path-return: 10594.53967858611
    pool-size: 785000
    total-samples: 785000
  time_since_restore: 8299.813329935074
  time_this_iter_s: 214.96886610984802
  time_total_s: 8299.813329935074
  times:
    epoch_after_hook: 1.7709971871227026e-06
    epoch_before_hook: 3.972998820245266e-05
    evaluation_metrics: 0.0004161469987593591
    evaluation_paths: 0.5909811460005585
    sample: 14.468300632957835
    timestep_after_hook: 0.035692301142262295
    timestep_before_hook: 0.08140284309047274
    train: 199.3192898253037
    training_metrics: 0.0015108860097825527
    training_paths: 0.075956413988024
  timestamp: 1652817439
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 775000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3229896378517151
      reward_ctrl-last-mean: -0.37808490037918097
      reward_ctrl-mean-mean: -0.36972413567781454
      reward_ctrl-median-mean: -0.36797704696655276
      reward_ctrl-range-mean: 0.4694858145713807
      reward_run-first-mean: -0.689077709177737
      reward_run-last-mean: 11.737181086246892
      reward_run-mean-mean: 10.736949326717893
      reward_run-median-mean: 11.212401999354235
      reward_run-range-mean: 14.300285502098044
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10594.539678586105
    episode-reward-mean: 10367.225191040077
    episode-reward-min: 10169.07332215055
    episode-reward-std: 144.15264803552225
  training_iteration: 31
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 8.55911922454834
    Q_value-mean: 774.5547485351562
    alpha: 0.22953273355960846
    alpha_loss-mean: -0.00032577887759543955
    policy_loss-mean: -774.9524536132812
  
== Status ==
Memory usage on this node: 82.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     31 |          8299.81 |      30 |      25000 |           775000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.23100532591342926
  date: 2022-05-17_21-00-54
  done: false
  epoch: 31
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.18825278282165528
      reward_ctrl-last-mean: -0.36051459312438966
      reward_ctrl-mean-mean: -0.36919460144042965
      reward_ctrl-median-mean: -0.36564162969589237
      reward_ctrl-range-mean: 0.4307741045951843
      reward_run-first-mean: -0.5658706956063961
      reward_run-last-mean: 12.14314336212965
      reward_run-mean-mean: 10.992160714083967
      reward_run-median-mean: 11.48790135138114
      reward_run-range-mean: 14.740398180776545
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10622.9658203125
    episode-reward-mean: 10622.9658203125
    episode-reward-min: 10622.9658203125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 32
  node_ip: 10.43.77.35
  num_train_steps: 800000
  pid: 283289
  policy:
    actions-max: 0.9995755553245544
    actions-mean: -0.05902663245797157
    actions-min: -0.999609649181366
    actions-std: 0.7784348726272583
    entropy-mean: -6.168814182281494
    entropy-std: 3.5619421005249023
    scales-max: 0.9251584410667419
    scales-mean: 0.43259891867637634
    scales-min: 0.04967077076435089
    scales-std: 0.13792899250984192
    shifts-max: 3.2425661087036133
    shifts-mean: -0.08379346132278442
    shifts-min: -3.0917341709136963
    shifts-std: 1.466059684753418
  sampler:
    episodes: 810
    last-path-return: 10357.317914838788
    max-path-return: 10832.164894348372
    pool-size: 810000
    total-samples: 810000
  time_since_restore: 8514.416004896164
  time_this_iter_s: 214.6026749610901
  time_total_s: 8514.416004896164
  times:
    epoch_after_hook: 1.9909930415451527e-06
    epoch_before_hook: 3.5981007385998964e-05
    evaluation_metrics: 0.001045819983119145
    evaluation_paths: 0.49458545399829745
    sample: 14.462001234351192
    timestep_after_hook: 0.03557267409632914
    timestep_before_hook: 0.08181673087528907
    train: 199.05397455915227
    training_metrics: 0.0015882230072747916
    training_paths: 0.0758309899829328
  timestamp: 1652817654
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 800000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3186478769779205
      reward_ctrl-last-mean: -0.39165405273437504
      reward_ctrl-mean-mean: -0.3693182226449251
      reward_ctrl-median-mean: -0.36771155595779426
      reward_ctrl-range-mean: 0.45975970149040224
      reward_run-first-mean: -0.6497094074374952
      reward_run-last-mean: 11.17603695825619
      reward_run-mean-mean: 10.958941865945857
      reward_run-median-mean: 11.44472230488909
      reward_run-range-mean: 14.429866261114052
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10832.164894348349
    episode-reward-mean: 10589.623643300929
    episode-reward-min: 10357.317914838772
    episode-reward-std: 131.9496548098241
  training_iteration: 32
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 8.694229125976562
    Q_value-mean: 782.1495971679688
    alpha: 0.23141619563102722
    alpha_loss-mean: 0.00010808724618982524
    policy_loss-mean: -782.5379028320312
  
== Status ==
Memory usage on this node: 84.1/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     32 |          8514.42 |      31 |      25000 |           800000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.23506440222263336
  date: 2022-05-17_21-04-28
  done: false
  epoch: 32
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2678675174713135
      reward_ctrl-last-mean: -0.26786131858825685
      reward_ctrl-mean-mean: -0.35973549616336825
      reward_ctrl-median-mean: -0.3593615531921387
      reward_ctrl-range-mean: 0.477510404586792
      reward_run-first-mean: -0.4321892906352415
      reward_run-last-mean: 11.743542249676011
      reward_run-mean-mean: 10.856176950982833
      reward_run-median-mean: 11.332148546587177
      reward_run-range-mean: 14.875254048458588
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10496.44140625
    episode-reward-mean: 10496.44140625
    episode-reward-min: 10496.44140625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 33
  node_ip: 10.43.77.35
  num_train_steps: 825000
  pid: 283289
  policy:
    actions-max: 0.9988577961921692
    actions-mean: -0.044510871171951294
    actions-min: -0.9987500905990601
    actions-std: 0.7880699634552002
    entropy-mean: -6.410278797149658
    entropy-std: 3.6368913650512695
    scales-max: 0.9725854396820068
    scales-mean: 0.4262971580028534
    scales-min: 0.05010303482413292
    scales-std: 0.1378219574689865
    shifts-max: 2.859819173812866
    shifts-mean: -0.03179587796330452
    shifts-min: -3.023688554763794
    shifts-std: 1.465414047241211
  sampler:
    episodes: 835
    last-path-return: 10447.646201431053
    max-path-return: 10832.164894348372
    pool-size: 835000
    total-samples: 835000
  time_since_restore: 8728.846848249435
  time_this_iter_s: 214.43084335327148
  time_total_s: 8728.846848249435
  times:
    epoch_after_hook: 1.5129917301237583e-06
    epoch_before_hook: 2.9031012672930956e-05
    evaluation_metrics: 0.00041042102384380996
    evaluation_paths: 0.4960765169817023
    sample: 14.526553323928965
    timestep_after_hook: 0.03543047225684859
    timestep_before_hook: 0.08220372494542971
    train: 198.81698029951076
    training_metrics: 0.0016275100060738623
    training_paths: 0.07640893501229584
  timestamp: 1652817868
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 825000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.29078837752342224
      reward_ctrl-last-mean: -0.39502674460411075
      reward_ctrl-mean-mean: -0.36970001331508157
      reward_ctrl-median-mean: -0.36683381319046027
      reward_ctrl-range-mean: 0.47429361939430237
      reward_run-first-mean: -0.6981275716775859
      reward_run-last-mean: 11.403305626742394
      reward_run-mean-mean: 10.91094847993898
      reward_run-median-mean: 11.381698890910968
      reward_run-range-mean: 14.506550283160806
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10677.823537621409
    episode-reward-mean: 10541.2484666239
    episode-reward-min: 10340.529361551144
    episode-reward-std: 110.14474223377994
  training_iteration: 33
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 8.890167236328125
    Q_value-mean: 790.0422973632812
    alpha: 0.2337992936372757
    alpha_loss-mean: -0.0001260338758584112
    policy_loss-mean: -790.4196166992188
  
== Status ==
Memory usage on this node: 84.1/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     33 |          8728.85 |      32 |      25000 |           825000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2358207404613495
  date: 2022-05-17_21-08-02
  done: false
  epoch: 33
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.17254900932312012
      reward_ctrl-last-mean: -0.2677313327789307
      reward_ctrl-mean-mean: -0.36275265312194827
      reward_ctrl-median-mean: -0.35739020109176634
      reward_ctrl-range-mean: 0.4476222276687622
      reward_run-first-mean: -0.20015213568867
      reward_run-last-mean: 10.997706475493487
      reward_run-mean-mean: 11.063350311676615
      reward_run-median-mean: 11.506847651600367
      reward_run-range-mean: 14.671352176082511
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10700.59765625
    episode-reward-mean: 10700.59765625
    episode-reward-min: 10700.59765625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 34
  node_ip: 10.43.77.35
  num_train_steps: 850000
  pid: 283289
  policy:
    actions-max: 0.9997778534889221
    actions-mean: -0.061995502561330795
    actions-min: -0.9986793398857117
    actions-std: 0.7759808897972107
    entropy-mean: -6.110387325286865
    entropy-std: 3.8678104877471924
    scales-max: 0.9641332626342773
    scales-mean: 0.42783260345458984
    scales-min: 0.05526283383369446
    scales-std: 0.1426200568675995
    shifts-max: 3.0471792221069336
    shifts-mean: -0.08044420927762985
    shifts-min: -3.2474074363708496
    shifts-std: 1.4411356449127197
  sampler:
    episodes: 860
    last-path-return: 10463.276475265966
    max-path-return: 10850.505922840612
    pool-size: 860000
    total-samples: 860000
  time_since_restore: 8943.228016138077
  time_this_iter_s: 214.38116788864136
  time_total_s: 8943.228016138077
  times:
    epoch_after_hook: 1.614011125639081e-06
    epoch_before_hook: 3.330002073198557e-05
    evaluation_metrics: 0.0004106760025024414
    evaluation_paths: 0.6245816209993791
    sample: 14.615920471202116
    timestep_after_hook: 0.035415967722656205
    timestep_before_hook: 0.08107796829426661
    train: 198.55024570628302
    training_metrics: 0.001506462984252721
    training_paths: 0.07699208499980159
  timestamp: 1652818082
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 850000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.32615658521652224
      reward_ctrl-last-mean: -0.3810520505905151
      reward_ctrl-mean-mean: -0.3692209919095039
      reward_ctrl-median-mean: -0.3662169003486634
      reward_ctrl-range-mean: 0.47773995280265813
      reward_run-first-mean: -0.6755254923459304
      reward_run-last-mean: 11.683935323832657
      reward_run-mean-mean: 10.903047782842783
      reward_run-median-mean: 11.38809212166155
      reward_run-range-mean: 14.843479397785131
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10850.505922840628
    episode-reward-mean: 10533.82679093328
    episode-reward-min: 10386.842856804657
    episode-reward-std: 133.21286514854782
  training_iteration: 34
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 9.106226921081543
    Q_value-mean: 797.1956176757812
    alpha: 0.23767001926898956
    alpha_loss-mean: 1.4613485745940125e-06
    policy_loss-mean: -797.5679321289062
  
== Status ==
Memory usage on this node: 84.1/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     34 |          8943.23 |      33 |      25000 |           850000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.24363870918750763
  date: 2022-05-17_21-11-36
  done: false
  epoch: 34
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.26836981773376467
      reward_ctrl-last-mean: -0.27294416427612306
      reward_ctrl-mean-mean: -0.3646777613759041
      reward_ctrl-median-mean: -0.3584466099739075
      reward_ctrl-range-mean: 0.4640642523765564
      reward_run-first-mean: -0.13632767011546587
      reward_run-last-mean: 13.113230431104057
      reward_run-mean-mean: 11.363487429717575
      reward_run-median-mean: 11.915358560507912
      reward_run-range-mean: 14.512669805921476
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10998.8095703125
    episode-reward-mean: 10998.8095703125
    episode-reward-min: 10998.8095703125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 35
  node_ip: 10.43.77.35
  num_train_steps: 875000
  pid: 283289
  policy:
    actions-max: 0.99925696849823
    actions-mean: -0.0811314657330513
    actions-min: -0.9989785552024841
    actions-std: 0.7617810368537903
    entropy-mean: -5.38877010345459
    entropy-std: 3.8380179405212402
    scales-max: 0.8976392149925232
    scales-mean: 0.43336427211761475
    scales-min: 0.05109822750091553
    scales-std: 0.14064130187034607
    shifts-max: 3.1514627933502197
    shifts-mean: -0.11858821660280228
    shifts-min: -2.9327392578125
    shifts-std: 1.3807440996170044
  sampler:
    episodes: 885
    last-path-return: 10536.018155089523
    max-path-return: 10972.022064365558
    pool-size: 885000
    total-samples: 885000
  time_since_restore: 9157.3267390728
  time_this_iter_s: 214.0987229347229
  time_total_s: 9157.3267390728
  times:
    epoch_after_hook: 1.5289988368749619e-06
    epoch_before_hook: 2.8223992558196187e-05
    evaluation_metrics: 0.00041549900197423995
    evaluation_paths: 0.4932700780045707
    sample: 14.60987968556583
    timestep_after_hook: 0.035304119053762406
    timestep_before_hook: 0.08176374726463109
    train: 198.405185397889
    training_metrics: 0.0015780050016473979
    training_paths: 0.076371912000468
  timestamp: 1652818296
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 875000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.34809854030609133
      reward_ctrl-last-mean: -0.37646020293235777
      reward_ctrl-mean-mean: -0.36875921700119974
      reward_ctrl-median-mean: -0.36570191383361816
      reward_ctrl-range-mean: 0.4716316425800323
      reward_run-first-mean: -0.6748270161937482
      reward_run-last-mean: 11.418455009737727
      reward_run-mean-mean: 11.078125680268906
      reward_run-median-mean: 11.566487770077757
      reward_run-range-mean: 14.71826994893394
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10972.022064365554
    episode-reward-mean: 10709.366463267706
    episode-reward-min: 10311.658099515524
    episode-reward-std: 181.00751697470187
  training_iteration: 35
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 9.144649505615234
    Q_value-mean: 804.306640625
    alpha: 0.23889686167240143
    alpha_loss-mean: -0.0002397926291450858
    policy_loss-mean: -804.6804809570312
  
== Status ==
Memory usage on this node: 84.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     35 |          9157.33 |      34 |      25000 |           875000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.24447020888328552
  date: 2022-05-17_21-15-11
  done: false
  epoch: 35
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.35137851238250734
      reward_ctrl-last-mean: -0.3572823524475098
      reward_ctrl-mean-mean: -0.37570015107393273
      reward_ctrl-median-mean: -0.3744751214981079
      reward_ctrl-range-mean: 0.5151290178298951
      reward_run-first-mean: 0.12717420883170544
      reward_run-last-mean: 11.625651972942705
      reward_run-mean-mean: 11.122812728190521
      reward_run-median-mean: 11.622390826627793
      reward_run-range-mean: 14.383541617543012
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10747.1123046875
    episode-reward-mean: 10747.1123046875
    episode-reward-min: 10747.1123046875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 36
  node_ip: 10.43.77.35
  num_train_steps: 900000
  pid: 283289
  policy:
    actions-max: 0.999148428440094
    actions-mean: -0.07916510105133057
    actions-min: -0.998924195766449
    actions-std: 0.7733889818191528
    entropy-mean: -6.133235454559326
    entropy-std: 3.759840488433838
    scales-max: 0.8594719767570496
    scales-mean: 0.42624759674072266
    scales-min: 0.045811351388692856
    scales-std: 0.13630539178848267
    shifts-max: 3.192656993865967
    shifts-mean: -0.11099348217248917
    shifts-min: -3.368716239929199
    shifts-std: 1.4398596286773682
  sampler:
    episodes: 910
    last-path-return: 10927.69810650494
    max-path-return: 10972.022064365558
    pool-size: 910000
    total-samples: 910000
  time_since_restore: 9371.851147174835
  time_this_iter_s: 214.52440810203552
  time_total_s: 9371.851147174835
  times:
    epoch_after_hook: 1.6960257198661566e-06
    epoch_before_hook: 3.622501390054822e-05
    evaluation_metrics: 0.00041182999848388135
    evaluation_paths: 0.4994757990061771
    sample: 14.545203320623841
    timestep_after_hook: 0.03547453792998567
    timestep_before_hook: 0.08232148876413703
    train: 198.77500804173178
    training_metrics: 0.0015165539807640016
    training_paths: 0.18806325501645915
  timestamp: 1652818511
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 900000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3094231128692627
      reward_ctrl-last-mean: -0.4237137770652771
      reward_ctrl-mean-mean: -0.3680483841365576
      reward_ctrl-median-mean: -0.363323575258255
      reward_ctrl-range-mean: 0.456576698422432
      reward_run-first-mean: -0.5971714024715705
      reward_run-last-mean: 11.606123118666346
      reward_run-mean-mean: 11.160996249501293
      reward_run-median-mean: 11.669501463956259
      reward_run-range-mean: 14.810694311799903
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10948.59890458345
    episode-reward-mean: 10792.947865364737
    episode-reward-min: 10503.621353322971
    episode-reward-std: 135.20021824050124
  training_iteration: 36
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 9.483134269714355
    Q_value-mean: 811.465576171875
    alpha: 0.24278435111045837
    alpha_loss-mean: -2.9022121452726424e-05
    policy_loss-mean: -811.8311767578125
  
== Status ==
Memory usage on this node: 82.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     36 |          9371.85 |      35 |      25000 |           900000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.24347680807113647
  date: 2022-05-17_21-18-45
  done: false
  epoch: 36
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.24886755943298342
      reward_ctrl-last-mean: -0.4851853847503662
      reward_ctrl-mean-mean: -0.3617423885822296
      reward_ctrl-median-mean: -0.35703443288803105
      reward_ctrl-range-mean: 0.4449741959571838
      reward_run-first-mean: -0.4101514084319405
      reward_run-last-mean: 12.01303327247615
      reward_run-mean-mean: 11.37785404672865
      reward_run-median-mean: 11.939471719966122
      reward_run-range-mean: 14.933588528440733
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11016.111328125
    episode-reward-mean: 11016.111328125
    episode-reward-min: 11016.111328125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 37
  node_ip: 10.43.77.35
  num_train_steps: 925000
  pid: 283289
  policy:
    actions-max: 0.9988723993301392
    actions-mean: -0.0532468743622303
    actions-min: -0.9994641542434692
    actions-std: 0.7752664089202881
    entropy-mean: -5.975118160247803
    entropy-std: 3.7147533893585205
    scales-max: 0.963567316532135
    scales-mean: 0.4294358789920807
    scales-min: 0.04067979380488396
    scales-std: 0.14288215339183807
    shifts-max: 3.2487993240356445
    shifts-mean: -0.06495547294616699
    shifts-min: -3.7461490631103516
    shifts-std: 1.442439317703247
  sampler:
    episodes: 935
    last-path-return: 10916.767850322083
    max-path-return: 11097.991387464646
    pool-size: 935000
    total-samples: 935000
  time_since_restore: 9586.117072105408
  time_this_iter_s: 214.2659249305725
  time_total_s: 9586.117072105408
  times:
    epoch_after_hook: 1.828011590987444e-06
    epoch_before_hook: 3.474002005532384e-05
    evaluation_metrics: 0.0004191999905742705
    evaluation_paths: 0.5302393150050193
    sample: 14.72768515982898
    timestep_after_hook: 0.03514720386010595
    timestep_before_hook: 0.08234796795295551
    train: 198.4169849366881
    training_metrics: 0.0015306219866033643
    training_paths: 0.07575659299618565
  timestamp: 1652818725
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 925000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.19334643959999087
      reward_ctrl-last-mean: -0.35892812490463255
      reward_ctrl-mean-mean: -0.3658466787442565
      reward_ctrl-median-mean: -0.3603391778469086
      reward_ctrl-range-mean: 0.4650098457932472
      reward_run-first-mean: -0.49849625792138674
      reward_run-last-mean: 11.99310673975151
      reward_run-mean-mean: 11.244573944656896
      reward_run-median-mean: 11.770345793323955
      reward_run-range-mean: 15.066283274030933
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11074.791762722452
    episode-reward-mean: 10878.727265912637
    episode-reward-min: 10643.185155842686
    episode-reward-std: 140.18507459633975
  training_iteration: 37
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 9.715717315673828
    Q_value-mean: 818.033203125
    alpha: 0.24420295655727386
    alpha_loss-mean: 4.067530608153902e-05
    policy_loss-mean: -818.3966674804688
  
== Status ==
Memory usage on this node: 82.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     37 |          9586.12 |      36 |      25000 |           925000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2462220937013626
  date: 2022-05-17_21-22-19
  done: false
  epoch: 37
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2896549463272095
      reward_ctrl-last-mean: -0.5066148757934571
      reward_ctrl-mean-mean: -0.3634269520044327
      reward_ctrl-median-mean: -0.36336631774902345
      reward_ctrl-range-mean: 0.4419392585754395
      reward_run-first-mean: -0.15524625358781796
      reward_run-last-mean: 11.43903136031895
      reward_run-mean-mean: 11.020066983940339
      reward_run-median-mean: 11.559962429744246
      reward_run-range-mean: 14.135672330566846
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10656.640625
    episode-reward-mean: 10656.640625
    episode-reward-min: 10656.640625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 38
  node_ip: 10.43.77.35
  num_train_steps: 950000
  pid: 283289
  policy:
    actions-max: 0.9995429515838623
    actions-mean: -0.07953902333974838
    actions-min: -0.9990435838699341
    actions-std: 0.7661957740783691
    entropy-mean: -5.580487251281738
    entropy-std: 3.52616024017334
    scales-max: 1.3624540567398071
    scales-mean: 0.4345983564853668
    scales-min: 0.05380996689200401
    scales-std: 0.14694809913635254
    shifts-max: 3.048062801361084
    shifts-mean: -0.12129070609807968
    shifts-min: -2.9604978561401367
    shifts-std: 1.4141793251037598
  sampler:
    episodes: 960
    last-path-return: 10804.358657040408
    max-path-return: 11217.245615713895
    pool-size: 960000
    total-samples: 960000
  time_since_restore: 9800.229227781296
  time_this_iter_s: 214.11215567588806
  time_total_s: 9800.229227781296
  times:
    epoch_after_hook: 1.6539997886866331e-06
    epoch_before_hook: 3.176601603627205e-05
    evaluation_metrics: 0.00041501797386445105
    evaluation_paths: 0.5008854259795044
    sample: 14.521292166697094
    timestep_after_hook: 0.03520705326809548
    timestep_before_hook: 0.08235563029302284
    train: 198.49731090391288
    training_metrics: 0.0015109119995031506
    training_paths: 0.07645015200250782
  timestamp: 1652818939
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 950000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.30783733367919924
      reward_ctrl-last-mean: -0.35941056728363036
      reward_ctrl-mean-mean: -0.3656078345602751
      reward_ctrl-median-mean: -0.3609258663654328
      reward_ctrl-range-mean: 0.46963591277599337
      reward_run-first-mean: -0.6239726913643786
      reward_run-last-mean: 11.79929871343461
      reward_run-mean-mean: 11.317140777104504
      reward_run-median-mean: 11.852906867405501
      reward_run-range-mean: 14.932262074969552
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11217.245615713884
    episode-reward-mean: 10951.532942544229
    episode-reward-min: 10709.376276579129
    episode-reward-std: 148.09016646128987
  training_iteration: 38
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 9.791993141174316
    Q_value-mean: 824.6465454101562
    alpha: 0.2447907030582428
    alpha_loss-mean: -7.026243838481605e-05
    policy_loss-mean: -825.0108642578125
  
== Status ==
Memory usage on this node: 84.1/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     38 |          9800.23 |      37 |      25000 |           950000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2515779435634613
  date: 2022-05-17_21-25-55
  done: false
  epoch: 38
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4664012908935547
      reward_ctrl-last-mean: -0.3558203458786011
      reward_ctrl-mean-mean: -0.37121428261995315
      reward_ctrl-median-mean: -0.3681025505065918
      reward_ctrl-range-mean: 0.4262654781341553
      reward_run-first-mean: -0.6737618893998467
      reward_run-last-mean: 12.170484685320844
      reward_run-mean-mean: 11.433812736888644
      reward_run-median-mean: 11.97329869202349
      reward_run-range-mean: 15.140595053500155
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11062.59765625
    episode-reward-mean: 11062.59765625
    episode-reward-min: 11062.59765625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 39
  node_ip: 10.43.77.35
  num_train_steps: 975000
  pid: 283289
  policy:
    actions-max: 0.998760461807251
    actions-mean: -0.07392752915620804
    actions-min: -0.9984793663024902
    actions-std: 0.7674404978752136
    entropy-mean: -5.540996551513672
    entropy-std: 3.726602792739868
    scales-max: 1.0638550519943237
    scales-mean: 0.4388643205165863
    scales-min: 0.049057357013225555
    scales-std: 0.1473144143819809
    shifts-max: 3.105013847351074
    shifts-mean: -0.11856911331415176
    shifts-min: -3.5182242393493652
    shifts-std: 1.4111080169677734
  sampler:
    episodes: 985
    last-path-return: 10801.786687059453
    max-path-return: 11272.596973592657
    pool-size: 985000
    total-samples: 985000
  time_since_restore: 10015.34341621399
  time_this_iter_s: 215.11418843269348
  time_total_s: 10015.34341621399
  times:
    epoch_after_hook: 2.082000719383359e-06
    epoch_before_hook: 3.607498365454376e-05
    evaluation_metrics: 0.01680995899369009
    evaluation_paths: 0.5066366729734
    sample: 14.960688296501758
    timestep_after_hook: 0.035514359769877046
    timestep_before_hook: 0.08220440457807854
    train: 198.9841622468375
    training_metrics: 0.037797338009113446
    training_paths: 0.07693234700127505
  timestamp: 1652819155
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 975000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2469113087654114
      reward_ctrl-last-mean: -0.37990034341812134
      reward_ctrl-mean-mean: -0.3670772089231015
      reward_ctrl-median-mean: -0.36114337563514715
      reward_ctrl-range-mean: 0.4607484352588653
      reward_run-first-mean: -0.5924616625486212
      reward_run-last-mean: 11.380192341384145
      reward_run-mean-mean: 11.241461693687619
      reward_run-median-mean: 11.801921241588325
      reward_run-range-mean: 14.983067620201535
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11093.737694286585
    episode-reward-mean: 10874.384484764518
    episode-reward-min: 10440.23028902376
    episode-reward-std: 202.941183727537
  training_iteration: 39
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.064395904541016
    Q_value-mean: 831.8666381835938
    alpha: 0.24644501507282257
    alpha_loss-mean: -0.00019184108532499522
    policy_loss-mean: -832.2348022460938
  
== Status ==
Memory usage on this node: 84.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     39 |          10015.3 |      38 |      25000 |           975000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.251133531332016
  date: 2022-05-17_21-29-29
  done: false
  epoch: 39
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.35582942962646485
      reward_ctrl-last-mean: -0.3698967695236206
      reward_ctrl-mean-mean: -0.36483519853353497
      reward_ctrl-median-mean: -0.36213662624359133
      reward_ctrl-range-mean: 0.43124560117721566
      reward_run-first-mean: -0.7710466646344313
      reward_run-last-mean: 13.12763814584514
      reward_run-mean-mean: 11.396053808743957
      reward_run-median-mean: 11.96791658865095
      reward_run-range-mean: 15.328040763829247
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11031.21875
    episode-reward-mean: 11031.21875
    episode-reward-min: 11031.21875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 40
  node_ip: 10.43.77.35
  num_train_steps: 1000000
  pid: 283289
  policy:
    actions-max: 0.9998145699501038
    actions-mean: -0.05816689506173134
    actions-min: -0.9990257620811462
    actions-std: 0.7811248898506165
    entropy-mean: -6.2446818351745605
    entropy-std: 3.8174171447753906
    scales-max: 0.9106974005699158
    scales-mean: 0.43769359588623047
    scales-min: 0.05260581523180008
    scales-std: 0.14468613266944885
    shifts-max: 3.2490298748016357
    shifts-mean: -0.08342579752206802
    shifts-min: -2.9939122200012207
    shifts-std: 1.4630141258239746
  sampler:
    episodes: 1010
    last-path-return: 10823.945224327348
    max-path-return: 11272.596973592657
    pool-size: 1000000
    total-samples: 1010000
  time_since_restore: 10230.058599710464
  time_this_iter_s: 214.71518349647522
  time_total_s: 10230.058599710464
  times:
    epoch_after_hook: 1.5849946066737175e-06
    epoch_before_hook: 4.0277023799717426e-05
    evaluation_metrics: 0.0004027170070912689
    evaluation_paths: 0.4953780459763948
    sample: 14.684458169795107
    timestep_after_hook: 0.035659404122270644
    timestep_before_hook: 0.08286830861470662
    train: 198.93953660337138
    training_metrics: 0.0015663869853597134
    training_paths: 0.07716400400386192
  timestamp: 1652819369
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1000000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2894835090637207
      reward_ctrl-last-mean: -0.36858811378479006
      reward_ctrl-mean-mean: -0.3660955486440659
      reward_ctrl-median-mean: -0.36105984926223755
      reward_ctrl-range-mean: 0.47300282835960383
      reward_run-first-mean: -0.6172515372628095
      reward_run-last-mean: 12.46551357327121
      reward_run-mean-mean: 11.39803044716324
      reward_run-median-mean: 11.906896948195993
      reward_run-range-mean: 14.885436393028135
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11254.42245167281
    episode-reward-mean: 11031.934898519174
    episode-reward-min: 10823.94522432734
    episode-reward-std: 143.9690011547815
  training_iteration: 40
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.493329048156738
    Q_value-mean: 838.1112670898438
    alpha: 0.2497842013835907
    alpha_loss-mean: 2.5532197469146922e-05
    policy_loss-mean: -838.4524536132812
  
== Status ==
Memory usage on this node: 84.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     40 |          10230.1 |      39 |      25000 |          1000000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.26050272583961487
  date: 2022-05-17_21-33-04
  done: false
  epoch: 40
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.330751895904541
      reward_ctrl-last-mean: -0.36380810737609864
      reward_ctrl-mean-mean: -0.3612881629228592
      reward_ctrl-median-mean: -0.356797206401825
      reward_ctrl-range-mean: 0.4712376296520233
      reward_run-first-mean: -0.7325470835603302
      reward_run-last-mean: 11.83079974552129
      reward_run-mean-mean: 11.286204444458528
      reward_run-median-mean: 11.702968657033352
      reward_run-range-mean: 14.58528747051717
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 10924.916015625
    episode-reward-mean: 10924.916015625
    episode-reward-min: 10924.916015625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 41
  node_ip: 10.43.77.35
  num_train_steps: 1025000
  pid: 283289
  policy:
    actions-max: 0.9999292492866516
    actions-mean: -0.0828644335269928
    actions-min: -0.9981891512870789
    actions-std: 0.7651903629302979
    entropy-mean: -5.806929111480713
    entropy-std: 3.5814216136932373
    scales-max: 1.9729077816009521
    scales-mean: 0.43023261427879333
    scales-min: 0.0467737652361393
    scales-std: 0.1469658613204956
    shifts-max: 4.469730377197266
    shifts-mean: -0.12494761496782303
    shifts-min: -2.940481662750244
    shifts-std: 1.4005191326141357
  sampler:
    episodes: 1035
    last-path-return: 11104.493210666657
    max-path-return: 11426.926294659708
    pool-size: 1000000
    total-samples: 1035000
  time_since_restore: 10444.65365076065
  time_this_iter_s: 214.59505105018616
  time_total_s: 10444.65365076065
  times:
    epoch_after_hook: 1.6370031516999006e-06
    epoch_before_hook: 3.958801971748471e-05
    evaluation_metrics: 0.0004098770150449127
    evaluation_paths: 0.4975491270015482
    sample: 14.589814627513988
    timestep_after_hook: 0.03537061286624521
    timestep_before_hook: 0.08292799291666597
    train: 198.91302064058254
    training_metrics: 0.0016206009895540774
    training_paths: 0.07591693801805377
  timestamp: 1652819584
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1025000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3638068318367005
      reward_ctrl-last-mean: -0.3656049823760986
      reward_ctrl-mean-mean: -0.35979086137235167
      reward_ctrl-median-mean: -0.3539651465415955
      reward_ctrl-range-mean: 0.4650131565332414
      reward_run-first-mean: -0.4239444205938086
      reward_run-last-mean: 11.78083910060218
      reward_run-mean-mean: 11.350811888453311
      reward_run-median-mean: 11.91132915168403
      reward_run-range-mean: 14.949155102170343
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11267.99452388977
    episode-reward-mean: 10991.021027080958
    episode-reward-min: 10807.130348468923
    episode-reward-std: 162.75609436048617
  training_iteration: 41
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.709284782409668
    Q_value-mean: 852.5311889648438
    alpha: 0.25445953011512756
    alpha_loss-mean: -0.0002714360598474741
    policy_loss-mean: -852.7494506835938
  
== Status ==
Memory usage on this node: 84.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     41 |          10444.7 |      40 |      25000 |          1025000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2619117200374603
  date: 2022-05-17_21-36-39
  done: false
  epoch: 41
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2792853832244873
      reward_ctrl-last-mean: -0.4546829700469971
      reward_ctrl-mean-mean: -0.35972878439426426
      reward_ctrl-median-mean: -0.35651048421859743
      reward_ctrl-range-mean: 0.4473854064941406
      reward_run-first-mean: -0.6782538302866701
      reward_run-last-mean: 11.865381164086557
      reward_run-mean-mean: 11.923049571532571
      reward_run-median-mean: 12.48442083882594
      reward_run-range-mean: 16.046262958233033
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11563.3203125
    episode-reward-mean: 11563.3203125
    episode-reward-min: 11563.3203125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 42
  node_ip: 10.43.77.35
  num_train_steps: 1050000
  pid: 283289
  policy:
    actions-max: 1.0
    actions-mean: -0.09164601564407349
    actions-min: -0.9999997019767761
    actions-std: 0.7772794961929321
    entropy-mean: -6.201725006103516
    entropy-std: 4.964018821716309
    scales-max: 1.6390721797943115
    scales-mean: 0.4389190673828125
    scales-min: 0.047420985996723175
    scales-std: 0.14613713324069977
    shifts-max: 10.66416072845459
    shifts-mean: -0.12407169491052628
    shifts-min: -7.44043493270874
    shifts-std: 1.479229211807251
  sampler:
    episodes: 1060
    last-path-return: 11175.05912020461
    max-path-return: 11426.926294659708
    pool-size: 1000000
    total-samples: 1060000
  time_since_restore: 10659.102075099945
  time_this_iter_s: 214.44842433929443
  time_total_s: 10659.102075099945
  times:
    epoch_after_hook: 1.8970167730003595e-06
    epoch_before_hook: 3.838801058009267e-05
    evaluation_metrics: 0.0004174379864707589
    evaluation_paths: 0.4948835209943354
    sample: 14.44399985531345
    timestep_after_hook: 0.03533937130123377
    timestep_before_hook: 0.08247052118531428
    train: 198.91763036631164
    training_metrics: 0.001555525988806039
    training_paths: 0.07464291600626893
  timestamp: 1652819799
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1050000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2842336046695709
      reward_ctrl-last-mean: -0.3442195844650269
      reward_ctrl-mean-mean: -0.3621694522196055
      reward_ctrl-median-mean: -0.35622459530830386
      reward_ctrl-range-mean: 0.4622020286321641
      reward_run-first-mean: -0.4463351361372042
      reward_run-last-mean: 12.467533240805551
      reward_run-mean-mean: 11.453571165161748
      reward_run-median-mean: 12.046327452280124
      reward_run-range-mean: 15.162528207039959
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11368.721045081535
    episode-reward-mean: 11091.401712942143
    episode-reward-min: 10545.554609406741
    episode-reward-std: 208.8338004886391
  training_iteration: 42
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.84577751159668
    Q_value-mean: 865.8395385742188
    alpha: 0.2580304741859436
    alpha_loss-mean: -1.9788074496318586e-05
    policy_loss-mean: -865.9443359375
  
== Status ==
Memory usage on this node: 82.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     42 |          10659.1 |      41 |      25000 |          1050000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2580571472644806
  date: 2022-05-17_21-40-13
  done: false
  epoch: 42
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.32400724887847904
      reward_ctrl-last-mean: -0.23276853561401367
      reward_ctrl-mean-mean: -0.35686994541883466
      reward_ctrl-median-mean: -0.3525619983673096
      reward_ctrl-range-mean: 0.43274313211441046
      reward_run-first-mean: -0.6458755057640356
      reward_run-last-mean: 11.785061888535893
      reward_run-mean-mean: 11.73258037887925
      reward_run-median-mean: 12.275958156112665
      reward_run-range-mean: 15.286955482273026
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11375.7109375
    episode-reward-mean: 11375.7109375
    episode-reward-min: 11375.7109375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 43
  node_ip: 10.43.77.35
  num_train_steps: 1075000
  pid: 283289
  policy:
    actions-max: 0.9997113943099976
    actions-mean: -0.07876568287611008
    actions-min: -0.9994966983795166
    actions-std: 0.7762560248374939
    entropy-mean: -6.101694107055664
    entropy-std: 3.5926947593688965
    scales-max: 0.8137083053588867
    scales-mean: 0.4355272948741913
    scales-min: 0.04778505116701126
    scales-std: 0.14095331728458405
    shifts-max: 4.261814117431641
    shifts-mean: -0.12401499599218369
    shifts-min: -4.029851913452148
    shifts-std: 1.45124089717865
  sampler:
    episodes: 1085
    last-path-return: 11246.918272562687
    max-path-return: 11426.926294659708
    pool-size: 1000000
    total-samples: 1085000
  time_since_restore: 10873.90208029747
  time_this_iter_s: 214.80000519752502
  time_total_s: 10873.90208029747
  times:
    epoch_after_hook: 1.581996912136674e-06
    epoch_before_hook: 3.9431004552170634e-05
    evaluation_metrics: 0.00041693600360304117
    evaluation_paths: 0.49606956500792876
    sample: 14.478679844003636
    timestep_after_hook: 0.03540234063984826
    timestep_before_hook: 0.08195838739629835
    train: 199.22974864428397
    training_metrics: 0.001716715982183814
    training_paths: 0.0773651659837924
  timestamp: 1652820013
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1075000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2703273904323578
      reward_ctrl-last-mean: -0.3579831004142761
      reward_ctrl-mean-mean: -0.3604118625992537
      reward_ctrl-median-mean: -0.3562928175926208
      reward_ctrl-range-mean: 0.464864781498909
      reward_run-first-mean: -0.22329953950827192
      reward_run-last-mean: 11.627811636339175
      reward_run-mean-mean: 11.557563798439384
      reward_run-median-mean: 12.106026478775718
      reward_run-range-mean: 15.20942169618328
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11389.67652646822
    episode-reward-mean: 11197.15193584013
    episode-reward-min: 10874.146422097387
    episode-reward-std: 158.87190090206138
  training_iteration: 43
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.723572731018066
    Q_value-mean: 877.8911743164062
    alpha: 0.2588406801223755
    alpha_loss-mean: 0.00011686562356771901
    policy_loss-mean: -877.9135131835938
  
== Status ==
Memory usage on this node: 82.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     43 |          10873.9 |      42 |      25000 |          1075000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2560593783855438
  date: 2022-05-17_21-43-48
  done: false
  epoch: 43
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2810531616210938
      reward_ctrl-last-mean: -0.22416834831237795
      reward_ctrl-mean-mean: -0.3571875686764718
      reward_ctrl-median-mean: -0.3510175943374634
      reward_ctrl-range-mean: 0.47269308567047125
      reward_run-first-mean: -0.9782094215307648
      reward_run-last-mean: 13.482452204177662
      reward_run-mean-mean: 11.59419196857772
      reward_run-median-mean: 12.2468826804932
      reward_run-range-mean: 15.519660680099756
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11237.00390625
    episode-reward-mean: 11237.00390625
    episode-reward-min: 11237.00390625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 44
  node_ip: 10.43.77.35
  num_train_steps: 1100000
  pid: 283289
  policy:
    actions-max: 0.9983646273612976
    actions-mean: -0.0981394350528717
    actions-min: -0.9987055659294128
    actions-std: 0.7637456655502319
    entropy-mean: -5.813079357147217
    entropy-std: 3.431821584701538
    scales-max: 0.8021596670150757
    scales-mean: 0.4308299124240875
    scales-min: 0.04403696581721306
    scales-std: 0.1364137828350067
    shifts-max: 3.0157222747802734
    shifts-mean: -0.15353620052337646
    shifts-min: -2.9515981674194336
    shifts-std: 1.4116756916046143
  sampler:
    episodes: 1110
    last-path-return: 11335.11785022602
    max-path-return: 11707.639923728755
    pool-size: 1000000
    total-samples: 1110000
  time_since_restore: 11088.45644402504
  time_this_iter_s: 214.55436372756958
  time_total_s: 11088.45644402504
  times:
    epoch_after_hook: 1.5079858712852001e-06
    epoch_before_hook: 3.598298644647002e-05
    evaluation_metrics: 0.0004126479907426983
    evaluation_paths: 0.5285582309879828
    sample: 14.52028751114267
    timestep_after_hook: 0.035423308290774
    timestep_before_hook: 0.08230089509743266
    train: 198.91279424892855
    training_metrics: 0.0015667510160710663
    training_paths: 0.07599875400774181
  timestamp: 1652820228
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1100000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.327042920589447
      reward_ctrl-last-mean: -0.35958031415939334
      reward_ctrl-mean-mean: -0.3584278558099269
      reward_ctrl-median-mean: -0.3531257390975952
      reward_ctrl-range-mean: 0.44981249988079075
      reward_run-first-mean: -0.3194885803331333
      reward_run-last-mean: 12.771914700072784
      reward_run-mean-mean: 11.708962270805708
      reward_run-median-mean: 12.242231177999251
      reward_run-range-mean: 15.247866290731935
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11577.355815178675
    episode-reward-mean: 11350.534414995782
    episode-reward-min: 11155.474787149873
    episode-reward-std: 121.70084369720564
  training_iteration: 44
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.43603515625
    Q_value-mean: 890.5699462890625
    alpha: 0.2574262320995331
    alpha_loss-mean: 9.524683264316991e-05
    policy_loss-mean: -890.5308227539062
  
== Status ==
Memory usage on this node: 84.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     44 |          11088.5 |      43 |      25000 |          1100000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2598855197429657
  date: 2022-05-17_21-47-22
  done: false
  epoch: 44
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3605879068374634
      reward_ctrl-last-mean: -0.3274133920669556
      reward_ctrl-mean-mean: -0.36466002917289736
      reward_ctrl-median-mean: -0.36193418502807617
      reward_ctrl-range-mean: 0.49968092441558837
      reward_run-first-mean: -0.6521683020332288
      reward_run-last-mean: 12.825106717878043
      reward_run-mean-mean: 11.781915817861266
      reward_run-median-mean: 12.368356533092424
      reward_run-range-mean: 15.153879129015063
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11417.255859375
    episode-reward-mean: 11417.255859375
    episode-reward-min: 11417.255859375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 45
  node_ip: 10.43.77.35
  num_train_steps: 1125000
  pid: 283289
  policy:
    actions-max: 0.9996485710144043
    actions-mean: -0.07868077605962753
    actions-min: -0.9994017481803894
    actions-std: 0.7795325517654419
    entropy-mean: -6.295383930206299
    entropy-std: 3.5878872871398926
    scales-max: 0.928987979888916
    scales-mean: 0.4347918927669525
    scales-min: 0.041488390415906906
    scales-std: 0.14380638301372528
    shifts-max: 3.2857840061187744
    shifts-mean: -0.1282549351453781
    shifts-min: -3.6810593605041504
    shifts-std: 1.4521684646606445
  sampler:
    episodes: 1135
    last-path-return: 11369.171038539627
    max-path-return: 11707.639923728755
    pool-size: 1000000
    total-samples: 1135000
  time_since_restore: 11302.804967880249
  time_this_iter_s: 214.34852385520935
  time_total_s: 11302.804967880249
  times:
    epoch_after_hook: 1.601001713424921e-06
    epoch_before_hook: 2.794401370920241e-05
    evaluation_metrics: 0.0004030319978483021
    evaluation_paths: 0.49511220600106753
    sample: 14.508713851857465
    timestep_after_hook: 0.03548549785045907
    timestep_before_hook: 0.08173201227327809
    train: 198.75040544601507
    training_metrics: 0.0015670119901187718
    training_paths: 0.07816439200541936
  timestamp: 1652820442
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1125000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3574267745018006
      reward_ctrl-last-mean: -0.4214597010612488
      reward_ctrl-mean-mean: -0.36085663844227794
      reward_ctrl-median-mean: -0.3556941735744477
      reward_ctrl-range-mean: 0.4441366422176361
      reward_run-first-mean: -0.38548117883796257
      reward_run-last-mean: 12.79515655396176
      reward_run-mean-mean: 11.815157729659713
      reward_run-median-mean: 12.398307029465997
      reward_run-range-mean: 15.373412385420215
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11611.016231965015
    episode-reward-mean: 11454.301091217436
    episode-reward-min: 11234.387590325345
    episode-reward-std: 109.50779805040521
  training_iteration: 45
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.438309669494629
    Q_value-mean: 902.6152954101562
    alpha: 0.25836247205734253
    alpha_loss-mean: -0.00012965372297912836
    policy_loss-mean: -902.5401611328125
  
== Status ==
Memory usage on this node: 84.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     45 |          11302.8 |      44 |      25000 |          1125000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2584758698940277
  date: 2022-05-17_21-50-57
  done: false
  epoch: 45
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3112751245498657
      reward_ctrl-last-mean: -0.3570870637893677
      reward_ctrl-mean-mean: -0.35745618914961813
      reward_ctrl-median-mean: -0.3528526544570923
      reward_ctrl-range-mean: 0.47805508375167854
      reward_run-first-mean: -0.24628630578309912
      reward_run-last-mean: 12.702900470037548
      reward_run-mean-mean: 11.800394126498478
      reward_run-median-mean: 12.348647518317648
      reward_run-range-mean: 15.116241873925249
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11442.9384765625
    episode-reward-mean: 11442.9384765625
    episode-reward-min: 11442.9384765625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 46
  node_ip: 10.43.77.35
  num_train_steps: 1150000
  pid: 283289
  policy:
    actions-max: 0.9997419118881226
    actions-mean: -0.03269132599234581
    actions-min: -0.9997230768203735
    actions-std: 0.7689033150672913
    entropy-mean: -5.876923561096191
    entropy-std: 3.485153913497925
    scales-max: 0.8248616456985474
    scales-mean: 0.4274492561817169
    scales-min: 0.04546615108847618
    scales-std: 0.14798317849636078
    shifts-max: 3.584653615951538
    shifts-mean: -0.018140247091650963
    shifts-min: -3.132967948913574
    shifts-std: 1.4138981103897095
  sampler:
    episodes: 1160
    last-path-return: 11558.534363812154
    max-path-return: 11707.639923728755
    pool-size: 1000000
    total-samples: 1160000
  time_since_restore: 11517.399545669556
  time_this_iter_s: 214.59457778930664
  time_total_s: 11517.399545669556
  times:
    epoch_after_hook: 1.6179983504116535e-06
    epoch_before_hook: 3.145600203424692e-05
    evaluation_metrics: 0.00040886399801820517
    evaluation_paths: 0.498657767981058
    sample: 14.602377358154627
    timestep_after_hook: 0.03556027339072898
    timestep_before_hook: 0.08255774242570624
    train: 198.89818573079538
    training_metrics: 0.0015946400235407054
    training_paths: 0.07572941898251884
  timestamp: 1652820657
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1150000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.28551518380641944
      reward_ctrl-last-mean: -0.3757201218605042
      reward_ctrl-mean-mean: -0.35992685914963485
      reward_ctrl-median-mean: -0.355521754026413
      reward_ctrl-range-mean: 0.4746622988581657
      reward_run-first-mean: -0.5955029131581893
      reward_run-last-mean: 12.053454687655858
      reward_run-mean-mean: 11.848478185122843
      reward_run-median-mean: 12.381089473613315
      reward_run-range-mean: 15.368538835804213
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11642.40785952649
    episode-reward-mean: 11488.55132597321
    episode-reward-min: 11329.996237246705
    episode-reward-std: 81.03926905461107
  training_iteration: 46
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.529730796813965
    Q_value-mean: 913.6158447265625
    alpha: 0.2604694068431854
    alpha_loss-mean: 7.467499381164089e-05
    policy_loss-mean: -913.5103149414062
  
== Status ==
Memory usage on this node: 84.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     46 |          11517.4 |      45 |      25000 |          1150000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2606669068336487
  date: 2022-05-17_21-54-31
  done: false
  epoch: 46
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.22514061927795412
      reward_ctrl-last-mean: -0.5462839126586915
      reward_ctrl-mean-mean: -0.36114509158134467
      reward_ctrl-median-mean: -0.35827093124389653
      reward_ctrl-range-mean: 0.43388140201568604
      reward_run-first-mean: -0.5092970153323996
      reward_run-last-mean: 12.53809799014789
      reward_run-mean-mean: 12.14269051565055
      reward_run-median-mean: 12.675602552654368
      reward_run-range-mean: 15.582391713609146
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11781.544921875
    episode-reward-mean: 11781.544921875
    episode-reward-min: 11781.544921875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 47
  node_ip: 10.43.77.35
  num_train_steps: 1175000
  pid: 283289
  policy:
    actions-max: 0.999129593372345
    actions-mean: -0.08361165970563889
    actions-min: -0.9999244213104248
    actions-std: 0.7684648633003235
    entropy-mean: -6.170092582702637
    entropy-std: 3.6956748962402344
    scales-max: 0.8384299278259277
    scales-mean: 0.41968855261802673
    scales-min: 0.04122181609272957
    scales-std: 0.14604225754737854
    shifts-max: 3.210221529006958
    shifts-mean: -0.12191972136497498
    shifts-min: -4.420228958129883
    shifts-std: 1.429007649421692
  sampler:
    episodes: 1185
    last-path-return: 11637.821936706383
    max-path-return: 11786.164717442422
    pool-size: 1000000
    total-samples: 1185000
  time_since_restore: 11731.386862516403
  time_this_iter_s: 213.98731684684753
  time_total_s: 11731.386862516403
  times:
    epoch_after_hook: 1.567997969686985e-06
    epoch_before_hook: 2.987799234688282e-05
    evaluation_metrics: 0.0004193419881630689
    evaluation_paths: 0.5442209760076366
    sample: 14.576982041617157
    timestep_after_hook: 0.03458774447790347
    timestep_before_hook: 0.07951740696444176
    train: 198.27591650540126
    training_metrics: 0.002658381999935955
    training_paths: 0.08061865300987847
  timestamp: 1652820871
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1175000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.26808768868446353
      reward_ctrl-last-mean: -0.3758725929260255
      reward_ctrl-mean-mean: -0.3581005348473788
      reward_ctrl-median-mean: -0.35230754256248475
      reward_ctrl-range-mean: 0.4585535031557083
      reward_run-first-mean: -0.4236012925236915
      reward_run-last-mean: 12.673510755276311
      reward_run-mean-mean: 11.817806027527249
      reward_run-median-mean: 12.36531575388259
      reward_run-range-mean: 15.416282114214065
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11659.00744662021
    episode-reward-mean: 11459.70549267987
    episode-reward-min: 11103.29069809354
    episode-reward-std: 163.09170273828593
  training_iteration: 47
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.657280921936035
    Q_value-mean: 923.4924926757812
    alpha: 0.26222965121269226
    alpha_loss-mean: -7.104608812369406e-05
    policy_loss-mean: -923.3521728515625
  
== Status ==
Memory usage on this node: 83.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     47 |          11731.4 |      46 |      25000 |          1175000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.26624056696891785
  date: 2022-05-17_21-58-04
  done: false
  epoch: 47
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4342045307159424
      reward_ctrl-last-mean: -0.30229732990264896
      reward_ctrl-mean-mean: -0.350179221367836
      reward_ctrl-median-mean: -0.3482341885566712
      reward_ctrl-range-mean: 0.4347417712211609
      reward_run-first-mean: -0.8176227267412342
      reward_run-last-mean: 14.211403589144993
      reward_run-mean-mean: 11.972916660536123
      reward_run-median-mean: 12.701061217572374
      reward_run-range-mean: 16.02706743779632
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11622.7373046875
    episode-reward-mean: 11622.7373046875
    episode-reward-min: 11622.7373046875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 48
  node_ip: 10.43.77.35
  num_train_steps: 1200000
  pid: 283289
  policy:
    actions-max: 0.9988132119178772
    actions-mean: -0.024469083175063133
    actions-min: -0.9991762042045593
    actions-std: 0.7713674902915955
    entropy-mean: -5.854467868804932
    entropy-std: 3.691054344177246
    scales-max: 0.8250442147254944
    scales-mean: 0.427882581949234
    scales-min: 0.041907306760549545
    scales-std: 0.14334635436534882
    shifts-max: 3.589966058731079
    shifts-mean: -0.02820916660130024
    shifts-min: -3.582368850708008
    shifts-std: 1.425144076347351
  sampler:
    episodes: 1210
    last-path-return: 11484.274975566903
    max-path-return: 11903.703240853383
    pool-size: 1000000
    total-samples: 1210000
  time_since_restore: 11944.659952878952
  time_this_iter_s: 213.27309036254883
  time_total_s: 11944.659952878952
  times:
    epoch_after_hook: 1.660024281591177e-06
    epoch_before_hook: 4.425999941304326e-05
    evaluation_metrics: 0.0004092159797437489
    evaluation_paths: 0.4953835370251909
    sample: 14.527276802924462
    timestep_after_hook: 0.03412435558857396
    timestep_before_hook: 0.0786836113256868
    train: 197.6677998159721
    training_metrics: 0.0015489629877265543
    training_paths: 0.07544849999248981
  timestamp: 1652821084
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1200000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3060415756702423
      reward_ctrl-last-mean: -0.3717523193359375
      reward_ctrl-mean-mean: -0.3573401218974591
      reward_ctrl-median-mean: -0.3526280021667481
      reward_ctrl-range-mean: 0.46830217301845545
      reward_run-first-mean: -0.6286954398992268
      reward_run-last-mean: 12.856056633257367
      reward_run-mean-mean: 11.935687699610023
      reward_run-median-mean: 12.537405070301602
      reward_run-range-mean: 15.65942565716125
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11813.324296866704
    episode-reward-mean: 11578.347577712564
    episode-reward-min: 11323.788009122618
    episode-reward-std: 148.46424318541665
  training_iteration: 48
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 10.893781661987305
    Q_value-mean: 933.095703125
    alpha: 0.26353567838668823
    alpha_loss-mean: -0.00018313083273824304
    policy_loss-mean: -932.9309692382812
  
== Status ==
Memory usage on this node: 81.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     48 |          11944.7 |      47 |      25000 |          1200000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.27317944169044495
  date: 2022-05-17_22-01-44
  done: false
  epoch: 48
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2577540874481201
      reward_ctrl-last-mean: -0.32848942279815674
      reward_ctrl-mean-mean: -0.3549160762071609
      reward_ctrl-median-mean: -0.3527495861053467
      reward_ctrl-range-mean: 0.4581409096717835
      reward_run-first-mean: -0.6282547708763759
      reward_run-last-mean: 12.645786434063666
      reward_run-mean-mean: 11.932557968624165
      reward_run-median-mean: 12.430587876371249
      reward_run-range-mean: 15.63982969873414
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11577.6416015625
    episode-reward-mean: 11577.6416015625
    episode-reward-min: 11577.6416015625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 49
  node_ip: 10.43.77.35
  num_train_steps: 1225000
  pid: 283289
  policy:
    actions-max: 0.9992084503173828
    actions-mean: -0.03883789852261543
    actions-min: -0.9981748461723328
    actions-std: 0.7659714818000793
    entropy-mean: -5.766892910003662
    entropy-std: 3.978177070617676
    scales-max: 0.831866443157196
    scales-mean: 0.42695775628089905
    scales-min: 0.03993891179561615
    scales-std: 0.1469372659921646
    shifts-max: 3.249654531478882
    shifts-mean: -0.04947808012366295
    shifts-min: -2.9209208488464355
    shifts-std: 1.4193757772445679
  sampler:
    episodes: 1235
    last-path-return: 11716.627681859942
    max-path-return: 11972.202213876813
    pool-size: 1000000
    total-samples: 1235000
  time_since_restore: 12163.773618221283
  time_this_iter_s: 219.11366534233093
  time_total_s: 12163.773618221283
  times:
    epoch_after_hook: 1.5310070011764765e-06
    epoch_before_hook: 3.313401248306036e-05
    evaluation_metrics: 0.0004122370155528188
    evaluation_paths: 0.49628850098815747
    sample: 15.568220133107388
    timestep_after_hook: 0.03737093915697187
    timestep_before_hook: 0.08512648119358346
    train: 202.07769653576543
    training_metrics: 0.0014834530011285096
    training_paths: 0.42164652998326346
  timestamp: 1652821304
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1225000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3244038093090058
      reward_ctrl-last-mean: -0.3289768600463867
      reward_ctrl-mean-mean: -0.35762900948613885
      reward_ctrl-median-mean: -0.35257291436195376
      reward_ctrl-range-mean: 0.468821448981762
      reward_run-first-mean: -0.6612279012803978
      reward_run-last-mean: 11.310494238144202
      reward_run-mean-mean: 11.551436351802252
      reward_run-median-mean: 12.447593207088069
      reward_run-range-mean: 15.912739879976144
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11883.47165424539
    episode-reward-mean: 11193.807342316111
    episode-reward-min: 7200.711070598743
    episode-reward-std: 1337.817272372112
  training_iteration: 49
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 11.08984661102295
    Q_value-mean: 942.504638671875
    alpha: 0.26520851254463196
    alpha_loss-mean: -0.00023705585044808686
    policy_loss-mean: -942.3178100585938
  
== Status ==
Memory usage on this node: 83.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     49 |          12163.8 |      48 |      25000 |          1225000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2709236443042755
  date: 2022-05-17_22-05-22
  done: false
  epoch: 49
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.20590751171112062
      reward_ctrl-last-mean: -0.3303144931793213
      reward_ctrl-mean-mean: -0.35584098707437517
      reward_ctrl-median-mean: -0.3528442978858948
      reward_ctrl-range-mean: 0.467647385597229
      reward_run-first-mean: -0.6618159878568827
      reward_run-last-mean: 13.484424062658036
      reward_run-mean-mean: 12.347239463156498
      reward_run-median-mean: 12.915594394597747
      reward_run-range-mean: 15.676500943299473
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11991.3984375
    episode-reward-mean: 11991.3984375
    episode-reward-min: 11991.3984375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 50
  node_ip: 10.43.77.35
  num_train_steps: 1250000
  pid: 283289
  policy:
    actions-max: 0.99891597032547
    actions-mean: -0.07612746953964233
    actions-min: -0.9983056783676147
    actions-std: 0.7700865864753723
    entropy-mean: -5.910960674285889
    entropy-std: 3.6348013877868652
    scales-max: 0.84351646900177
    scales-mean: 0.42048513889312744
    scales-min: 0.03960232064127922
    scales-std: 0.15049618482589722
    shifts-max: 3.1609535217285156
    shifts-mean: -0.11364739388227463
    shifts-min: -3.009783983230591
    shifts-std: 1.4071037769317627
  sampler:
    episodes: 1260
    last-path-return: 11928.611965231225
    max-path-return: 12007.175839906591
    pool-size: 1000000
    total-samples: 1260000
  time_since_restore: 12382.079850435257
  time_this_iter_s: 218.306232213974
  time_total_s: 12382.079850435257
  times:
    epoch_after_hook: 1.535983756184578e-06
    epoch_before_hook: 3.1664996640756726e-05
    evaluation_metrics: 0.0004084190004505217
    evaluation_paths: 0.5483353020099457
    sample: 15.136680939001963
    timestep_after_hook: 0.03696463842061348
    timestep_before_hook: 0.08688478960539214
    train: 201.9922413530876
    training_metrics: 0.0015447720070369542
    training_paths: 0.08060101300361566
  timestamp: 1652821522
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1250000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3274515497684479
      reward_ctrl-last-mean: -0.3236855387687683
      reward_ctrl-mean-mean: -0.35451637278437614
      reward_ctrl-median-mean: -0.35045624494552613
      reward_ctrl-range-mean: 0.46421609163284305
      reward_run-first-mean: -0.7391187794688694
      reward_run-last-mean: 12.984461348342847
      reward_run-mean-mean: 12.129829201643883
      reward_run-median-mean: 12.72397601214604
      reward_run-range-mean: 15.827696790741118
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12007.175839906582
    episode-reward-mean: 11775.312828859507
    episode-reward-min: 11419.589918681842
    episode-reward-std: 188.6202397590863
  training_iteration: 50
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 11.501886367797852
    Q_value-mean: 950.0888671875
    alpha: 0.26789671182632446
    alpha_loss-mean: 7.299616117961705e-05
    policy_loss-mean: -949.8733520507812
  
== Status ==
Memory usage on this node: 86.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     50 |          12382.1 |      49 |      25000 |          1250000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.27481427788734436
  date: 2022-05-17_22-08-57
  done: false
  epoch: 50
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.46265783309936526
      reward_ctrl-last-mean: -0.4705066680908203
      reward_ctrl-mean-mean: -0.353449183344841
      reward_ctrl-median-mean: -0.34956836700439453
      reward_ctrl-range-mean: 0.4539222717285157
      reward_run-first-mean: -0.7375856030682071
      reward_run-last-mean: 13.244695454886823
      reward_run-mean-mean: 12.627078624492299
      reward_run-median-mean: 13.174151146529312
      reward_run-range-mean: 16.056401735315756
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12273.62890625
    episode-reward-mean: 12273.62890625
    episode-reward-min: 12273.62890625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 51
  node_ip: 10.43.77.35
  num_train_steps: 1275000
  pid: 283289
  policy:
    actions-max: 0.9999856352806091
    actions-mean: -0.07094067335128784
    actions-min: -0.9985973834991455
    actions-std: 0.7651678919792175
    entropy-mean: -5.772224426269531
    entropy-std: 3.544969320297241
    scales-max: 1.1822975873947144
    scales-mean: 0.42369166016578674
    scales-min: 0.03570735454559326
    scales-std: 0.15135321021080017
    shifts-max: 4.714439868927002
    shifts-mean: -0.1150444746017456
    shifts-min: -3.059542655944824
    shifts-std: 1.4057209491729736
  sampler:
    episodes: 1285
    last-path-return: 11826.1313652641
    max-path-return: 12200.894727507739
    pool-size: 1000000
    total-samples: 1285000
  time_since_restore: 12597.083307743073
  time_this_iter_s: 215.00345730781555
  time_total_s: 12597.083307743073
  times:
    epoch_after_hook: 2.0300212781876326e-06
    epoch_before_hook: 3.710499731823802e-05
    evaluation_metrics: 0.0004045089881401509
    evaluation_paths: 0.5371082649799064
    sample: 14.743276196386432
    timestep_after_hook: 0.03518287921906449
    timestep_before_hook: 0.08200078489608131
    train: 199.12220202031313
    training_metrics: 0.0015194180014077574
    training_paths: 0.07954649897874333
  timestamp: 1652821737
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1275000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.32352456092834475
      reward_ctrl-last-mean: -0.3345052099227905
      reward_ctrl-mean-mean: -0.3546273386323452
      reward_ctrl-median-mean: -0.34954128265380857
      reward_ctrl-range-mean: 0.44629523158073436
      reward_run-first-mean: -0.6162694534408232
      reward_run-last-mean: 12.566015043576499
      reward_run-mean-mean: 12.286305233639109
      reward_run-median-mean: 12.877882651514284
      reward_run-range-mean: 15.867829882255327
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12200.894727507744
    episode-reward-mean: 11931.677895006764
    episode-reward-min: 11764.037333491335
    episode-reward-std: 132.85695156546544
  training_iteration: 51
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 11.585989952087402
    Q_value-mean: 958.2430419921875
    alpha: 0.2705830931663513
    alpha_loss-mean: -9.248081187251955e-05
    policy_loss-mean: -958.019287109375
  
== Status ==
Memory usage on this node: 86.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     51 |          12597.1 |      50 |      25000 |          1275000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.27485063672065735
  date: 2022-05-17_22-12-40
  done: false
  epoch: 51
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.38738431930541994
      reward_ctrl-last-mean: -0.3212159156799317
      reward_ctrl-mean-mean: -0.35660634697079663
      reward_ctrl-median-mean: -0.34891517162323005
      reward_ctrl-range-mean: 0.4948889553546906
      reward_run-first-mean: -0.870434878898137
      reward_run-last-mean: 15.307263203621915
      reward_run-mean-mean: 12.387077606052712
      reward_run-median-mean: 13.259737179189415
      reward_run-range-mean: 16.583823515996684
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12030.470703125
    episode-reward-mean: 12030.470703125
    episode-reward-min: 12030.470703125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 52
  node_ip: 10.43.77.35
  num_train_steps: 1300000
  pid: 283289
  policy:
    actions-max: 0.9991766214370728
    actions-mean: -0.0803183987736702
    actions-min: -0.9991578459739685
    actions-std: 0.7617443799972534
    entropy-mean: -5.923018455505371
    entropy-std: 3.5777430534362793
    scales-max: 1.124097228050232
    scales-mean: 0.4324606955051422
    scales-min: 0.039757903665304184
    scales-std: 0.152299702167511
    shifts-max: 3.6325056552886963
    shifts-mean: -0.1291683167219162
    shifts-min: -3.007375955581665
    shifts-std: 1.4124864339828491
  sampler:
    episodes: 1310
    last-path-return: 11809.014098231011
    max-path-return: 12200.894727507739
    pool-size: 1000000
    total-samples: 1310000
  time_since_restore: 12819.922736406326
  time_this_iter_s: 222.83942866325378
  time_total_s: 12819.922736406326
  times:
    epoch_after_hook: 1.62801006808877e-06
    epoch_before_hook: 4.569700104184449e-05
    evaluation_metrics: 0.00040870998054742813
    evaluation_paths: 0.5266383360140026
    sample: 15.953330796997761
    timestep_after_hook: 0.04055274146958254
    timestep_before_hook: 0.09248479650705121
    train: 205.69603909080615
    training_metrics: 0.0015330349851865321
    training_paths: 0.07856794801773503
  timestamp: 1652821960
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1300000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3347732043266296
      reward_ctrl-last-mean: -0.35554137706756594
      reward_ctrl-mean-mean: -0.359039640647769
      reward_ctrl-median-mean: -0.35304998874664306
      reward_ctrl-range-mean: 0.4636952298879624
      reward_run-first-mean: -0.7207668753053403
      reward_run-last-mean: 12.66400016785019
      reward_run-mean-mean: 12.33209144837932
      reward_run-median-mean: 12.94233284353247
      reward_run-range-mean: 16.109202309217768
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12197.84020855671
    episode-reward-mean: 11973.051807731552
    episode-reward-min: 11749.737899586478
    episode-reward-std: 147.90623505209504
  training_iteration: 52
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 12.109183311462402
    Q_value-mean: 967.3607177734375
    alpha: 0.27432069182395935
    alpha_loss-mean: 3.256248601246625e-05
    policy_loss-mean: -967.1277465820312
  
== Status ==
Memory usage on this node: 83.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     52 |          12819.9 |      51 |      25000 |          1300000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2776820659637451
  date: 2022-05-17_22-16-13
  done: false
  epoch: 52
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.24702656269073486
      reward_ctrl-last-mean: -0.33478469848632814
      reward_ctrl-mean-mean: -0.3599650797843933
      reward_ctrl-median-mean: -0.3561354398727417
      reward_ctrl-range-mean: 0.4725651144981385
      reward_run-first-mean: -0.657468175157801
      reward_run-last-mean: 13.055720149998251
      reward_run-mean-mean: 12.27044165977235
      reward_run-median-mean: 12.842325980374198
      reward_run-range-mean: 16.142426554836295
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 11910.4765625
    episode-reward-mean: 11910.4765625
    episode-reward-min: 11910.4765625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 53
  node_ip: 10.43.77.35
  num_train_steps: 1325000
  pid: 283289
  policy:
    actions-max: 0.999951183795929
    actions-mean: -0.07620077580213547
    actions-min: -0.998537003993988
    actions-std: 0.7630319595336914
    entropy-mean: -5.7967939376831055
    entropy-std: 3.4312596321105957
    scales-max: 0.8786475658416748
    scales-mean: 0.4329237937927246
    scales-min: 0.042810432612895966
    scales-std: 0.14288605749607086
    shifts-max: 3.6664390563964844
    shifts-mean: -0.13428346812725067
    shifts-min: -3.362483263015747
    shifts-std: 1.3853870630264282
  sampler:
    episodes: 1335
    last-path-return: 12260.624527719872
    max-path-return: 12394.13800167813
    pool-size: 1000000
    total-samples: 1335000
  time_since_restore: 13033.245096683502
  time_this_iter_s: 213.3223602771759
  time_total_s: 13033.245096683502
  times:
    epoch_after_hook: 1.6929989214986563e-06
    epoch_before_hook: 2.9943010304123163e-05
    evaluation_metrics: 0.00041627997416071594
    evaluation_paths: 0.4973885379731655
    sample: 14.456829910603119
    timestep_after_hook: 0.03431394218932837
    timestep_before_hook: 0.08038368113921024
    train: 197.77851296402514
    training_metrics: 0.0015940610028337687
    training_paths: 0.07900452398462221
  timestamp: 1652822173
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1325000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3314397954940796
      reward_ctrl-last-mean: -0.2819267821311951
      reward_ctrl-mean-mean: -0.357504754870534
      reward_ctrl-median-mean: -0.35127517104148864
      reward_ctrl-range-mean: 0.4705153280496598
      reward_run-first-mean: -0.5090395471374171
      reward_run-last-mean: 13.422655588859016
      reward_run-mean-mean: 12.400994901309774
      reward_run-median-mean: 13.002012423103736
      reward_run-range-mean: 16.02388249845081
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12263.425351906495
    episode-reward-mean: 12043.49014643924
    episode-reward-min: 11684.978275259713
    episode-reward-std: 185.72536196431042
  training_iteration: 53
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 12.333372116088867
    Q_value-mean: 975.2354125976562
    alpha: 0.27674275636672974
    alpha_loss-mean: -7.308441126951948e-05
    policy_loss-mean: -974.9779052734375
  
== Status ==
Memory usage on this node: 85.4/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     53 |          13033.2 |      52 |      25000 |          1325000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.27221497893333435
  date: 2022-05-17_22-19-57
  done: false
  epoch: 53
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3049151659011841
      reward_ctrl-last-mean: -0.2993788719177246
      reward_ctrl-mean-mean: -0.3582054712951184
      reward_ctrl-median-mean: -0.34797937870025636
      reward_ctrl-range-mean: 0.47663223147392275
      reward_run-first-mean: -0.4655155541748515
      reward_run-last-mean: 13.391873724422112
      reward_run-mean-mean: 12.476201843087042
      reward_run-median-mean: 13.140051806345241
      reward_run-range-mean: 16.494581655987474
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12117.99609375
    episode-reward-mean: 12117.99609375
    episode-reward-min: 12117.99609375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 54
  node_ip: 10.43.77.35
  num_train_steps: 1350000
  pid: 283289
  policy:
    actions-max: 0.9995597004890442
    actions-mean: -0.063435398042202
    actions-min: -0.9989693760871887
    actions-std: 0.7754952907562256
    entropy-mean: -6.336741924285889
    entropy-std: 3.5445828437805176
    scales-max: 0.8422871232032776
    scales-mean: 0.43410900235176086
    scales-min: 0.03461045026779175
    scales-std: 0.1547478288412094
    shifts-max: 4.042789459228516
    shifts-mean: -0.07370505481958389
    shifts-min: -3.4121928215026855
    shifts-std: 1.4574205875396729
  sampler:
    episodes: 1360
    last-path-return: 12194.955280252292
    max-path-return: 12464.617168915753
    pool-size: 1000000
    total-samples: 1360000
  time_since_restore: 13257.005833864212
  time_this_iter_s: 223.76073718070984
  time_total_s: 13257.005833864212
  times:
    epoch_after_hook: 1.5929981600493193e-06
    epoch_before_hook: 3.2912008464336395e-05
    evaluation_metrics: 0.0004147040017414838
    evaluation_paths: 0.4967508619884029
    sample: 16.04566098182113
    timestep_after_hook: 0.040693317248951644
    timestep_before_hook: 0.09371638917946257
    train: 206.55200290534412
    training_metrics: 0.001561638986459002
    training_paths: 0.07692368101561442
  timestamp: 1652822397
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1350000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.32494420051574713
      reward_ctrl-last-mean: -0.3728841400146485
      reward_ctrl-mean-mean: -0.3585730887371302
      reward_ctrl-median-mean: -0.35347861528396607
      reward_ctrl-range-mean: 0.46669010698795327
      reward_run-first-mean: -0.44328107753661977
      reward_run-last-mean: 13.10950639036605
      reward_run-mean-mean: 12.548648537217714
      reward_run-median-mean: 13.145734725428923
      reward_run-range-mean: 16.04294244198977
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12342.617955862166
    episode-reward-mean: 12190.075448480584
    episode-reward-min: 11944.679390549612
    episode-reward-std: 118.40836670986047
  training_iteration: 54
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 12.99065113067627
    Q_value-mean: 982.880859375
    alpha: 0.2784852385520935
    alpha_loss-mean: 0.00018691210425458848
    policy_loss-mean: -982.6187744140625
  
== Status ==
Memory usage on this node: 81.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     54 |            13257 |      53 |      25000 |          1350000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2783542275428772
  date: 2022-05-17_22-23-38
  done: false
  epoch: 54
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.33107273578643803
      reward_ctrl-last-mean: -0.2613349199295044
      reward_ctrl-mean-mean: -0.3486809751927853
      reward_ctrl-median-mean: -0.3424809813499451
      reward_ctrl-range-mean: 0.4853609323501587
      reward_run-first-mean: -0.46176885921727334
      reward_run-last-mean: 14.957842158962649
      reward_run-mean-mean: 12.786218154431346
      reward_run-median-mean: 13.317799696099257
      reward_run-range-mean: 16.110969772097164
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12437.537109375
    episode-reward-mean: 12437.537109375
    episode-reward-min: 12437.537109375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 55
  node_ip: 10.43.77.35
  num_train_steps: 1375000
  pid: 283289
  policy:
    actions-max: 0.9997000098228455
    actions-mean: -0.04821496084332466
    actions-min: -0.9986218810081482
    actions-std: 0.7655888795852661
    entropy-mean: -5.973868370056152
    entropy-std: 3.597461462020874
    scales-max: 0.9488092660903931
    scales-mean: 0.42816033959388733
    scales-min: 0.03534591943025589
    scales-std: 0.15451589226722717
    shifts-max: 3.210162401199341
    shifts-mean: -0.08129341155290604
    shifts-min: -2.7620017528533936
    shifts-std: 1.4043673276901245
  sampler:
    episodes: 1385
    last-path-return: 12299.299105951784
    max-path-return: 12467.030045465342
    pool-size: 1000000
    total-samples: 1385000
  time_since_restore: 13478.35997414589
  time_this_iter_s: 221.35414028167725
  time_total_s: 13478.35997414589
  times:
    epoch_after_hook: 1.9520230125635862e-06
    epoch_before_hook: 3.4554977901279926e-05
    evaluation_metrics: 0.0004168259911239147
    evaluation_paths: 0.5355324760021176
    sample: 15.614330455980962
    timestep_after_hook: 0.038966518332017586
    timestep_before_hook: 0.09020350454375148
    train: 204.5557082989544
    training_metrics: 0.001606254983926192
    training_paths: 0.0792244509793818
  timestamp: 1652822618
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1375000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.33212476968765264
      reward_ctrl-last-mean: -0.34977288007736207
      reward_ctrl-mean-mean: -0.3585351849919558
      reward_ctrl-median-mean: -0.3546365284919739
      reward_ctrl-range-mean: 0.4716478383541108
      reward_run-first-mean: -0.73158533049969
      reward_run-last-mean: 13.525593042766332
      reward_run-mean-mean: 12.602280449675707
      reward_run-median-mean: 13.21097540196412
      reward_run-range-mean: 16.377998725645863
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12334.60185251158
    episode-reward-mean: 12243.74526468375
    episode-reward-min: 12153.034139318966
    episode-reward-std: 69.19665806521273
  training_iteration: 55
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 13.086457252502441
    Q_value-mean: 991.2542114257812
    alpha: 0.28050461411476135
    alpha_loss-mean: -0.00016238422540482134
    policy_loss-mean: -990.9793701171875
  
== Status ==
Memory usage on this node: 86.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     55 |          13478.4 |      54 |      25000 |          1375000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2874715030193329
  date: 2022-05-17_22-27-16
  done: false
  epoch: 55
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3419516563415528
      reward_ctrl-last-mean: -0.19671447277069093
      reward_ctrl-mean-mean: -0.3555660666823387
      reward_ctrl-median-mean: -0.35018031597137456
      reward_ctrl-range-mean: 0.4766652762889862
      reward_run-first-mean: -0.5325904763460154
      reward_run-last-mean: 15.113158908914102
      reward_run-mean-mean: 12.63524751947727
      reward_run-median-mean: 13.39818158567084
      reward_run-range-mean: 16.395450372015592
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12279.681640625
    episode-reward-mean: 12279.681640625
    episode-reward-min: 12279.681640625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 56
  node_ip: 10.43.77.35
  num_train_steps: 1400000
  pid: 283289
  policy:
    actions-max: 0.9983731508255005
    actions-mean: -0.04954390600323677
    actions-min: -0.9979667663574219
    actions-std: 0.7564761638641357
    entropy-mean: -5.651468753814697
    entropy-std: 3.4348745346069336
    scales-max: 0.7749921679496765
    scales-mean: 0.4231839179992676
    scales-min: 0.03320129215717316
    scales-std: 0.15525436401367188
    shifts-max: 2.924830913543701
    shifts-mean: -0.07066772878170013
    shifts-min: -3.0516583919525146
    shifts-std: 1.3710781335830688
  sampler:
    episodes: 1410
    last-path-return: 12213.855267548784
    max-path-return: 12610.002819023193
    pool-size: 1000000
    total-samples: 1410000
  time_since_restore: 13695.736653327942
  time_this_iter_s: 217.3766791820526
  time_total_s: 13695.736653327942
  times:
    epoch_after_hook: 1.5120021998882294e-06
    epoch_before_hook: 3.68300243280828e-05
    evaluation_metrics: 0.00040496099973097444
    evaluation_paths: 0.5021884159941692
    sample: 15.228117129212478
    timestep_after_hook: 0.03690908715361729
    timestep_before_hook: 0.08458585813059472
    train: 201.02640209058882
    training_metrics: 0.00158361200010404
    training_paths: 0.07839915400836617
  timestamp: 1652822836
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1400000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.26608320474624636
      reward_ctrl-last-mean: -0.35679479837417605
      reward_ctrl-mean-mean: -0.35787795332968236
      reward_ctrl-median-mean: -0.35130699872970583
      reward_ctrl-range-mean: 0.4642355495691299
      reward_run-first-mean: -0.5468163847530829
      reward_run-last-mean: 13.933225515412005
      reward_run-mean-mean: 12.720426107209551
      reward_run-median-mean: 13.395781109910866
      reward_run-range-mean: 16.360034832081215
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12610.002819023208
    episode-reward-mean: 12362.548153879869
    episode-reward-min: 11937.068613793697
    episode-reward-std: 186.2891480808798
  training_iteration: 56
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 13.056642532348633
    Q_value-mean: 998.413330078125
    alpha: 0.28478291630744934
    alpha_loss-mean: -0.00026705695199780166
    policy_loss-mean: -998.1133422851562
  
== Status ==
Memory usage on this node: 86.1/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     56 |          13695.7 |      55 |      25000 |          1400000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.29347696900367737
  date: 2022-05-17_22-30-58
  done: false
  epoch: 56
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.263039231300354
      reward_ctrl-last-mean: -0.3775903463363648
      reward_ctrl-mean-mean: -0.3656582300305366
      reward_ctrl-median-mean: -0.3618847131729126
      reward_ctrl-range-mean: 0.4526706337928772
      reward_run-first-mean: -0.6846112071594213
      reward_run-last-mean: 12.937142541918547
      reward_run-mean-mean: 12.56257614034095
      reward_run-median-mean: 13.305479438795373
      reward_run-range-mean: 16.718956119113844
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12196.91796875
    episode-reward-mean: 12196.91796875
    episode-reward-min: 12196.91796875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 57
  node_ip: 10.43.77.35
  num_train_steps: 1425000
  pid: 283289
  policy:
    actions-max: 0.9995096325874329
    actions-mean: -0.09239683300256729
    actions-min: -0.9980716109275818
    actions-std: 0.7576768398284912
    entropy-mean: -5.933408737182617
    entropy-std: 3.4278857707977295
    scales-max: 0.8067720532417297
    scales-mean: 0.4205683767795563
    scales-min: 0.035619478672742844
    scales-std: 0.15038876235485077
    shifts-max: 3.0967276096343994
    shifts-mean: -0.147874116897583
    shifts-min: -3.255584955215454
    shifts-std: 1.3804155588150024
  sampler:
    episodes: 1435
    last-path-return: 12667.829489029167
    max-path-return: 12689.88149806782
    pool-size: 1000000
    total-samples: 1435000
  time_since_restore: 13918.138480901718
  time_this_iter_s: 222.40182757377625
  time_total_s: 13918.138480901718
  times:
    epoch_after_hook: 1.5620025806128979e-06
    epoch_before_hook: 3.710400778800249e-05
    evaluation_metrics: 0.00042685100925154984
    evaluation_paths: 0.4987300119828433
    sample: 15.844102978677256
    timestep_after_hook: 0.04017529706470668
    timestep_before_hook: 0.09072136922623031
    train: 205.40131021421985
    training_metrics: 0.0016377579886466265
    training_paths: 0.07566070900065824
  timestamp: 1652823058
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1425000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.31103978633880613
      reward_ctrl-last-mean: -0.33262213587760925
      reward_ctrl-mean-mean: -0.3621293450683355
      reward_ctrl-median-mean: -0.3573250997066498
      reward_ctrl-range-mean: 0.46935275971889495
      reward_run-first-mean: -0.426029139475149
      reward_run-last-mean: 13.666068562846249
      reward_run-mean-mean: 12.853184137245785
      reward_run-median-mean: 13.494447062137079
      reward_run-range-mean: 16.326630081463442
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12667.829489029162
    episode-reward-mean: 12491.054792177452
    episode-reward-min: 12208.786058887927
    episode-reward-std: 131.43085253913
  training_iteration: 57
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 13.34925651550293
    Q_value-mean: 1006.04296875
    alpha: 0.2904396951198578
    alpha_loss-mean: -0.0002203396725235507
    policy_loss-mean: -1005.7185668945312
  
== Status ==
Memory usage on this node: 81.9/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     57 |          13918.1 |      56 |      25000 |          1425000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.29218119382858276
  date: 2022-05-17_22-34-36
  done: false
  epoch: 57
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.384726619720459
      reward_ctrl-last-mean: -0.5033568382263184
      reward_ctrl-mean-mean: -0.36383978486061097
      reward_ctrl-median-mean: -0.35970160961151126
      reward_ctrl-range-mean: 0.4447062015533447
      reward_run-first-mean: -0.7403607116024031
      reward_run-last-mean: 13.653441702069813
      reward_run-mean-mean: 13.086617014771042
      reward_run-median-mean: 13.716369903858663
      reward_run-range-mean: 16.778614449507085
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12722.77734375
    episode-reward-mean: 12722.77734375
    episode-reward-min: 12722.77734375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 58
  node_ip: 10.43.77.35
  num_train_steps: 1450000
  pid: 283289
  policy:
    actions-max: 0.9971417188644409
    actions-mean: -0.05933861434459686
    actions-min: -0.9984597563743591
    actions-std: 0.7679651379585266
    entropy-mean: -5.766373634338379
    entropy-std: 3.4663703441619873
    scales-max: 0.9093230962753296
    scales-mean: 0.4283849000930786
    scales-min: 0.036338306963443756
    scales-std: 0.14557360112667084
    shifts-max: 3.2664730548858643
    shifts-mean: -0.09175160527229309
    shifts-min: -2.637820243835449
    shifts-std: 1.3944382667541504
  sampler:
    episodes: 1460
    last-path-return: 12477.589812135036
    max-path-return: 12812.905813201955
    pool-size: 1000000
    total-samples: 1460000
  time_since_restore: 14136.177312850952
  time_this_iter_s: 218.038831949234
  time_total_s: 14136.177312850952
  times:
    epoch_after_hook: 1.487991539761424e-06
    epoch_before_hook: 3.423498128540814e-05
    evaluation_metrics: 0.0004060259961988777
    evaluation_paths: 0.49952194301295094
    sample: 15.199886246031383
    timestep_after_hook: 0.03735887253424153
    timestep_before_hook: 0.08566477464046329
    train: 201.71387903398136
    training_metrics: 0.0015596160083077848
    training_paths: 0.0799278499907814
  timestamp: 1652823276
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1450000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.33655560255050665
      reward_ctrl-last-mean: -0.3249318766593933
      reward_ctrl-mean-mean: -0.3604281798684597
      reward_ctrl-median-mean: -0.3555765533447265
      reward_ctrl-range-mean: 0.47607828795909873
      reward_run-first-mean: -0.5825915800296941
      reward_run-last-mean: 13.585878251891245
      reward_run-mean-mean: 12.926249681623329
      reward_run-median-mean: 13.57648185231082
      reward_run-range-mean: 16.632338215204296
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12785.136161775703
    episode-reward-mean: 12565.821501754868
    episode-reward-min: 12403.17169968058
    episode-reward-std: 115.88966545470552
  training_iteration: 58
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 13.435355186462402
    Q_value-mean: 1012.4405517578125
    alpha: 0.2954042851924896
    alpha_loss-mean: 7.260910206241533e-05
    policy_loss-mean: -1012.0899047851562
  
== Status ==
Memory usage on this node: 84.9/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     58 |          14136.2 |      57 |      25000 |          1450000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.2911493182182312
  date: 2022-05-17_22-38-16
  done: false
  epoch: 58
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.34980297088623047
      reward_ctrl-last-mean: -0.32011084556579594
      reward_ctrl-mean-mean: -0.3588178847014904
      reward_ctrl-median-mean: -0.3564143180847168
      reward_ctrl-range-mean: 0.4733374178409577
      reward_run-first-mean: -0.8601281458183061
      reward_run-last-mean: 14.681468814642358
      reward_run-mean-mean: 13.449503133423672
      reward_run-median-mean: 14.015952905711515
      reward_run-range-mean: 16.69207726831947
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13090.685546875
    episode-reward-mean: 13090.685546875
    episode-reward-min: 13090.685546875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 59
  node_ip: 10.43.77.35
  num_train_steps: 1475000
  pid: 283289
  policy:
    actions-max: 0.9999843835830688
    actions-mean: -0.09011626243591309
    actions-min: -0.9992619752883911
    actions-std: 0.7632057070732117
    entropy-mean: -6.224827766418457
    entropy-std: 3.9912445545196533
    scales-max: 1.0118533372879028
    scales-mean: 0.4214373528957367
    scales-min: 0.030693072825670242
    scales-std: 0.1450759321451187
    shifts-max: 3.8649353981018066
    shifts-mean: -0.15404333174228668
    shifts-min: -3.409151554107666
    shifts-std: 1.4176377058029175
  sampler:
    episodes: 1485
    last-path-return: 12574.539406329557
    max-path-return: 12946.18319430809
    pool-size: 1000000
    total-samples: 1485000
  time_since_restore: 14355.75835609436
  time_this_iter_s: 219.5810432434082
  time_total_s: 14355.75835609436
  times:
    epoch_after_hook: 2.174987457692623e-06
    epoch_before_hook: 3.870099317282438e-05
    evaluation_metrics: 0.02304214399191551
    evaluation_paths: 0.5005242330080364
    sample: 15.70803239979432
    timestep_after_hook: 0.03796139746555127
    timestep_before_hook: 0.0860368381254375
    train: 202.55654410927673
    training_metrics: 0.036978917982196435
    training_paths: 0.18618234500172548
  timestamp: 1652823496
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1475000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.28850770711898804
      reward_ctrl-last-mean: -0.300396500825882
      reward_ctrl-mean-mean: -0.3596325361716748
      reward_ctrl-median-mean: -0.3569346690177918
      reward_ctrl-range-mean: 0.4634056758880615
      reward_run-first-mean: -0.6677779601346692
      reward_run-last-mean: 14.229093747985871
      reward_run-mean-mean: 13.023702444636722
      reward_run-median-mean: 13.707086422741412
      reward_run-range-mean: 16.620547960310304
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12831.082272505077
    episode-reward-mean: 12664.06990846505
    episode-reward-min: 12439.02048212495
    episode-reward-std: 113.1775652121887
  training_iteration: 59
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 13.594483375549316
    Q_value-mean: 1020.5029296875
    alpha: 0.29860904812812805
    alpha_loss-mean: 4.7484303649980575e-05
    policy_loss-mean: -1020.1442260742188
  
== Status ==
Memory usage on this node: 82.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     59 |          14355.8 |      58 |      25000 |          1475000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.30213862657546997
  date: 2022-05-17_22-42-01
  done: false
  epoch: 59
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.16087894439697267
      reward_ctrl-last-mean: -0.2063149929046631
      reward_ctrl-mean-mean: -0.35745608953833585
      reward_ctrl-median-mean: -0.35105295181274415
      reward_ctrl-range-mean: 0.5121877551078796
      reward_run-first-mean: 0.05491053901116011
      reward_run-last-mean: 12.211449757646733
      reward_run-mean-mean: 13.273462964884427
      reward_run-median-mean: 13.985724735401845
      reward_run-range-mean: 16.76468004416628
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12916.0068359375
    episode-reward-mean: 12916.0068359375
    episode-reward-min: 12916.0068359375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 60
  node_ip: 10.43.77.35
  num_train_steps: 1500000
  pid: 283289
  policy:
    actions-max: 0.9985549449920654
    actions-mean: -0.023496216163039207
    actions-min: -0.9988020658493042
    actions-std: 0.7667455673217773
    entropy-mean: -5.9424262046813965
    entropy-std: 3.5780458450317383
    scales-max: 0.7774522304534912
    scales-mean: 0.4205004870891571
    scales-min: 0.037599142640829086
    scales-std: 0.1506253182888031
    shifts-max: 3.082310199737549
    shifts-mean: -0.019757190719246864
    shifts-min: -3.1231980323791504
    shifts-std: 1.4072636365890503
  sampler:
    episodes: 1510
    last-path-return: 12740.251663645664
    max-path-return: 13089.018679532826
    pool-size: 1000000
    total-samples: 1510000
  time_since_restore: 14580.228338479996
  time_this_iter_s: 224.46998238563538
  time_total_s: 14580.228338479996
  times:
    epoch_after_hook: 1.620996044948697e-06
    epoch_before_hook: 4.328601062297821e-05
    evaluation_metrics: 0.00040807900950312614
    evaluation_paths: 0.5041139640088659
    sample: 16.098589803266805
    timestep_after_hook: 0.04152990455622785
    timestep_before_hook: 0.09323179291095585
    train: 207.07043948423234
    training_metrics: 0.0015328520094044507
    training_paths: 0.2022192449949216
  timestamp: 1652823721
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1500000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.34278415679931645
      reward_ctrl-last-mean: -0.38135390281677245
      reward_ctrl-mean-mean: -0.3589491907578707
      reward_ctrl-median-mean: -0.35564595818519595
      reward_ctrl-range-mean: 0.4807307261228561
      reward_run-first-mean: -0.7756510039287544
      reward_run-last-mean: 13.625281881142655
      reward_run-mean-mean: 13.168416063568861
      reward_run-median-mean: 13.842408035415474
      reward_run-range-mean: 16.829037602689432
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13013.652079787913
    episode-reward-mean: 12809.46687281099
    episode-reward-min: 12609.299444385892
    episode-reward-std: 122.0532765924563
  training_iteration: 60
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 13.31399154663086
    Q_value-mean: 1028.639892578125
    alpha: 0.30038195848464966
    alpha_loss-mean: -0.00033909111516550183
    policy_loss-mean: -1028.2803955078125
  
== Status ==
Memory usage on this node: 81.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     60 |          14580.2 |      59 |      25000 |          1500000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3100530207157135
  date: 2022-05-17_22-45-39
  done: false
  epoch: 60
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2810374259948731
      reward_ctrl-last-mean: -0.29958620071411135
      reward_ctrl-mean-mean: -0.356618504780531
      reward_ctrl-median-mean: -0.35683292150497437
      reward_ctrl-range-mean: 0.5162395715713501
      reward_run-first-mean: -0.06155497638845528
      reward_run-last-mean: 15.11596154419749
      reward_run-mean-mean: 12.822840438260544
      reward_run-median-mean: 13.702455006457654
      reward_run-range-mean: 16.202027053782253
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12466.2216796875
    episode-reward-mean: 12466.2216796875
    episode-reward-min: 12466.2216796875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 61
  node_ip: 10.43.77.35
  num_train_steps: 1525000
  pid: 283289
  policy:
    actions-max: 0.9987186193466187
    actions-mean: -0.0648878887295723
    actions-min: -0.999256432056427
    actions-std: 0.765794038772583
    entropy-mean: -5.869065761566162
    entropy-std: 3.489866256713867
    scales-max: 0.8977040648460388
    scales-mean: 0.4208480417728424
    scales-min: 0.03583323210477829
    scales-std: 0.15111468732357025
    shifts-max: 3.044788122177124
    shifts-mean: -0.08970048278570175
    shifts-min: -2.9154515266418457
    shifts-std: 1.4069551229476929
  sampler:
    episodes: 1535
    last-path-return: 12967.526975999139
    max-path-return: 13200.089510396958
    pool-size: 1000000
    total-samples: 1535000
  time_since_restore: 14798.052317142487
  time_this_iter_s: 217.82397866249084
  time_total_s: 14798.052317142487
  times:
    epoch_after_hook: 2.0840088836848736e-06
    epoch_before_hook: 3.597501199692488e-05
    evaluation_metrics: 0.0004058629856444895
    evaluation_paths: 0.500747891026549
    sample: 15.100574982003309
    timestep_after_hook: 0.036832807410974056
    timestep_before_hook: 0.0855006150668487
    train: 201.46020975505235
    training_metrics: 0.0014930120087228715
    training_paths: 0.2215212699957192
  timestamp: 1652823939
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1525000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3407733726501465
      reward_ctrl-last-mean: -0.32236220955848693
      reward_ctrl-mean-mean: -0.3597104601442814
      reward_ctrl-median-mean: -0.35784065961837774
      reward_ctrl-range-mean: 0.47642867207527156
      reward_run-first-mean: -0.689632695912614
      reward_run-last-mean: 14.499454378440078
      reward_run-mean-mean: 13.15033282541918
      reward_run-median-mean: 13.91074263996208
      reward_run-range-mean: 16.782536697256198
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13200.089510396965
    episode-reward-mean: 12790.6223652749
    episode-reward-min: 11908.268916301571
    episode-reward-std: 345.075593350839
  training_iteration: 61
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 14.12399959564209
    Q_value-mean: 1036.89453125
    alpha: 0.3052659034729004
    alpha_loss-mean: -0.00019436153525020927
    policy_loss-mean: -1036.5255126953125
  
== Status ==
Memory usage on this node: 87.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     61 |          14798.1 |      60 |      25000 |          1525000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3135342299938202
  date: 2022-05-17_22-49-18
  done: false
  epoch: 61
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.298440432548523
      reward_ctrl-last-mean: -0.25877492427825927
      reward_ctrl-mean-mean: -0.36575099914073944
      reward_ctrl-median-mean: -0.36902574300765995
      reward_ctrl-range-mean: 0.4696286082267761
      reward_run-first-mean: -0.6782687176755137
      reward_run-last-mean: 15.69013625155776
      reward_run-mean-mean: 13.666980403826312
      reward_run-median-mean: 14.450047880544616
      reward_run-range-mean: 17.50416996751515
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13301.228515625
    episode-reward-mean: 13301.228515625
    episode-reward-min: 13301.228515625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 62
  node_ip: 10.43.77.35
  num_train_steps: 1550000
  pid: 283289
  policy:
    actions-max: 0.9992280006408691
    actions-mean: -0.059300512075424194
    actions-min: -0.9993574023246765
    actions-std: 0.7623232007026672
    entropy-mean: -5.911557197570801
    entropy-std: 3.3056304454803467
    scales-max: 1.0008914470672607
    scales-mean: 0.42599669098854065
    scales-min: 0.03193002566695213
    scales-std: 0.15523797273635864
    shifts-max: 2.9267261028289795
    shifts-mean: -0.07281535118818283
    shifts-min: -2.7172367572784424
    shifts-std: 1.400722622871399
  sampler:
    episodes: 1560
    last-path-return: 13087.437146870281
    max-path-return: 13227.943313929829
    pool-size: 1000000
    total-samples: 1560000
  time_since_restore: 15017.560777187347
  time_this_iter_s: 219.50846004486084
  time_total_s: 15017.560777187347
  times:
    epoch_after_hook: 1.548003638163209e-06
    epoch_before_hook: 3.9044010918587446e-05
    evaluation_metrics: 0.0004101649974472821
    evaluation_paths: 0.5284441930125467
    sample: 15.465262141631683
    timestep_after_hook: 0.038311107811750844
    timestep_before_hook: 0.0887062837718986
    train: 202.88007295818534
    training_metrics: 0.0014981180138420314
    training_paths: 0.07570847898023203
  timestamp: 1652824158
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1550000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3279967117309571
      reward_ctrl-last-mean: -0.3875422596931458
      reward_ctrl-mean-mean: -0.3579938326716423
      reward_ctrl-median-mean: -0.35750828742980956
      reward_ctrl-range-mean: 0.4840290236473083
      reward_run-first-mean: -0.7460493907803353
      reward_run-last-mean: 13.9871187640465
      reward_run-mean-mean: 13.367483603138524
      reward_run-median-mean: 14.104914526936469
      reward_run-range-mean: 17.0414372604387
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13224.884570448452
    episode-reward-mean: 13009.48977046688
    episode-reward-min: 12796.905599092548
    episode-reward-std: 157.55479572937548
  training_iteration: 62
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 14.665104866027832
    Q_value-mean: 1042.5701904296875
    alpha: 0.3113153278827667
    alpha_loss-mean: -0.0001298184070037678
    policy_loss-mean: -1042.178955078125
  
== Status ==
Memory usage on this node: 81.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     62 |          15017.6 |      61 |      25000 |          1550000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3305623233318329
  date: 2022-05-17_22-53-01
  done: false
  epoch: 62
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3688809871673584
      reward_ctrl-last-mean: -0.336136531829834
      reward_ctrl-mean-mean: -0.36455971095561984
      reward_ctrl-median-mean: -0.36431800127029423
      reward_ctrl-range-mean: 0.4279155015945434
      reward_run-first-mean: -0.8516253612422734
      reward_run-last-mean: 13.642481798394783
      reward_run-mean-mean: 13.238205046361577
      reward_run-median-mean: 13.899346577344005
      reward_run-range-mean: 16.956761162661966
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 12873.64453125
    episode-reward-mean: 12873.64453125
    episode-reward-min: 12873.64453125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 63
  node_ip: 10.43.77.35
  num_train_steps: 1575000
  pid: 283289
  policy:
    actions-max: 0.9994712471961975
    actions-mean: -0.11361277848482132
    actions-min: -0.998465359210968
    actions-std: 0.7692514657974243
    entropy-mean: -6.078179359436035
    entropy-std: 3.7595837116241455
    scales-max: 1.0181392431259155
    scales-mean: 0.4367235600948334
    scales-min: 0.027530593797564507
    scales-std: 0.15713797509670258
    shifts-max: 3.317452907562256
    shifts-mean: -0.18474648892879486
    shifts-min: -3.725522041320801
    shifts-std: 1.40481698513031
  sampler:
    episodes: 1585
    last-path-return: 13279.91048655689
    max-path-return: 13373.52111447639
    pool-size: 1000000
    total-samples: 1585000
  time_since_restore: 15240.671819210052
  time_this_iter_s: 223.11104202270508
  time_total_s: 15240.671819210052
  times:
    epoch_after_hook: 1.4929973985999823e-06
    epoch_before_hook: 3.48089961335063e-05
    evaluation_metrics: 0.00040995501331053674
    evaluation_paths: 0.534394505986711
    sample: 16.042413134739036
    timestep_after_hook: 0.04016295721521601
    timestep_before_hook: 0.09257739796885289
    train: 205.87034898190177
    training_metrics: 0.0015392840141430497
    training_paths: 0.07817270801751874
  timestamp: 1652824381
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1575000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.29206122159957887
      reward_ctrl-last-mean: -0.3478850865364075
      reward_ctrl-mean-mean: -0.3567761614447832
      reward_ctrl-median-mean: -0.35742248654365544
      reward_ctrl-range-mean: 0.4842245501279831
      reward_run-first-mean: -0.5727244991919769
      reward_run-last-mean: 14.930861144342543
      reward_run-mean-mean: 13.509628570849282
      reward_run-median-mean: 14.264662420170481
      reward_run-range-mean: 17.119486921292594
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13373.521114476393
    episode-reward-mean: 13152.852409404499
    episode-reward-min: 12917.510467796787
    episode-reward-std: 165.87032005480268
  training_iteration: 63
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 15.341907501220703
    Q_value-mean: 1047.87451171875
    alpha: 0.3201808035373688
    alpha_loss-mean: -0.0005555531824938953
    policy_loss-mean: -1047.448486328125
  
== Status ==
Memory usage on this node: 86.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     63 |          15240.7 |      62 |      25000 |          1575000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.32589367032051086
  date: 2022-05-17_22-56-39
  done: false
  epoch: 63
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2574049472808838
      reward_ctrl-last-mean: -0.12039122581481934
      reward_ctrl-mean-mean: -0.3478059379279614
      reward_ctrl-median-mean: -0.3503981351852417
      reward_ctrl-range-mean: 0.4580448567867279
      reward_run-first-mean: -0.22687396158246276
      reward_run-last-mean: 15.486481527161686
      reward_run-mean-mean: 13.638264359920097
      reward_run-median-mean: 14.349158674990008
      reward_run-range-mean: 16.726543465653428
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13290.458984375
    episode-reward-mean: 13290.458984375
    episode-reward-min: 13290.458984375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 64
  node_ip: 10.43.77.35
  num_train_steps: 1600000
  pid: 283289
  policy:
    actions-max: 0.9996950626373291
    actions-mean: -0.10268162935972214
    actions-min: -0.9991431832313538
    actions-std: 0.7700823545455933
    entropy-mean: -6.550536155700684
    entropy-std: 3.4255964756011963
    scales-max: 1.0296188592910767
    scales-mean: 0.42287424206733704
    scales-min: 0.027335403487086296
    scales-std: 0.1579568088054657
    shifts-max: 3.465278148651123
    shifts-mean: -0.19581164419651031
    shifts-min: -3.393404960632324
    shifts-std: 1.427704095840454
  sampler:
    episodes: 1610
    last-path-return: 13513.7676408227
    max-path-return: 13635.647432229476
    pool-size: 1000000
    total-samples: 1610000
  time_since_restore: 15458.285123348236
  time_this_iter_s: 217.6133041381836
  time_total_s: 15458.285123348236
  times:
    epoch_after_hook: 2.1110172383487225e-06
    epoch_before_hook: 3.7048012018203735e-05
    evaluation_metrics: 0.0005438350199256092
    evaluation_paths: 0.5325839339930099
    sample: 15.173799079144374
    timestep_after_hook: 0.036651987058576196
    timestep_before_hook: 0.08574190133367665
    train: 201.28637402222375
    training_metrics: 0.0015468240017071366
    training_paths: 0.07712641698890366
  timestamp: 1652824599
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1600000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.31914904594421384
      reward_ctrl-last-mean: -0.3155568146705628
      reward_ctrl-mean-mean: -0.34980655490994456
      reward_ctrl-median-mean: -0.3499640834331512
      reward_ctrl-range-mean: 0.48245845496654516
      reward_run-first-mean: -0.5636977785851697
      reward_run-last-mean: 15.001302766673234
      reward_run-mean-mean: 13.691203268178437
      reward_run-median-mean: 14.428362152312658
      reward_run-range-mean: 17.125577301053006
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13635.647432229467
    episode-reward-mean: 13341.396713268492
    episode-reward-min: 13104.110618873781
    episode-reward-std: 145.7825369059095
  training_iteration: 64
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 16.060638427734375
    Q_value-mean: 1054.039794921875
    alpha: 0.32350093126296997
    alpha_loss-mean: 0.00016656951629556715
    policy_loss-mean: -1053.6331787109375
  
== Status ==
Memory usage on this node: 86.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     64 |          15458.3 |      63 |      25000 |          1600000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.335083931684494
  date: 2022-05-17_23-00-19
  done: false
  epoch: 64
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.16802202463150026
      reward_ctrl-last-mean: -0.16225656270980837
      reward_ctrl-mean-mean: -0.3475466274261475
      reward_ctrl-median-mean: -0.3456190228462219
      reward_ctrl-range-mean: 0.4661220192909241
      reward_run-first-mean: -0.4005128114673683
      reward_run-last-mean: 15.563918966543042
      reward_run-mean-mean: 13.729956226133968
      reward_run-median-mean: 14.524723673883955
      reward_run-range-mean: 17.1128348247868
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13382.41015625
    episode-reward-mean: 13382.41015625
    episode-reward-min: 13382.41015625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 65
  node_ip: 10.43.77.35
  num_train_steps: 1625000
  pid: 283289
  policy:
    actions-max: 0.9990953803062439
    actions-mean: -0.05133578181266785
    actions-min: -0.9987005591392517
    actions-std: 0.767565906047821
    entropy-mean: -6.099490165710449
    entropy-std: 3.3780367374420166
    scales-max: 0.9469491839408875
    scales-mean: 0.4209018647670746
    scales-min: 0.03223135322332382
    scales-std: 0.15998263657093048
    shifts-max: 2.9870810508728027
    shifts-mean: -0.09906285256147385
    shifts-min: -2.9016897678375244
    shifts-std: 1.3976655006408691
  sampler:
    episodes: 1635
    last-path-return: 12049.91776177282
    max-path-return: 13788.024644483708
    pool-size: 1000000
    total-samples: 1635000
  time_since_restore: 15678.686856031418
  time_this_iter_s: 220.40173268318176
  time_total_s: 15678.686856031418
  times:
    epoch_after_hook: 1.5980040188878775e-06
    epoch_before_hook: 3.245798870921135e-05
    evaluation_metrics: 0.00041262098238803446
    evaluation_paths: 0.5246587959991302
    sample: 15.520101383706788
    timestep_after_hook: 0.03827325362362899
    timestep_before_hook: 0.08862113681971096
    train: 203.71799204088165
    training_metrics: 0.0015802760026417673
    training_paths: 0.0790116399875842
  timestamp: 1652824819
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1625000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3339001572132111
      reward_ctrl-last-mean: -0.3488541460037232
      reward_ctrl-mean-mean: -0.3479370944648982
      reward_ctrl-median-mean: -0.3503637981414795
      reward_ctrl-range-mean: 0.4940922033786774
      reward_run-first-mean: -0.6548638254685041
      reward_run-last-mean: 14.9911948735828
      reward_run-mean-mean: 13.701646922113193
      reward_run-median-mean: 14.616182345600805
      reward_run-range-mean: 17.253682781655193
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13788.024644483703
    episode-reward-mean: 13353.709827648292
    episode-reward-min: 12049.91776177282
    episode-reward-std: 482.47196871576153
  training_iteration: 65
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 16.727035522460938
    Q_value-mean: 1061.4564208984375
    alpha: 0.33158695697784424
    alpha_loss-mean: -0.00026361961499787867
    policy_loss-mean: -1061.040283203125
  
== Status ==
Memory usage on this node: 81.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     65 |          15678.7 |      64 |      25000 |          1625000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3467476963996887
  date: 2022-05-17_23-04-03
  done: false
  epoch: 65
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2016822099685669
      reward_ctrl-last-mean: -0.4475834369659424
      reward_ctrl-mean-mean: -0.30889968551993374
      reward_ctrl-median-mean: -0.30225436687469487
      reward_ctrl-range-mean: 0.5352681338787079
      reward_run-first-mean: -0.5715091091948482
      reward_run-last-mean: -0.4905164278989105
      reward_run-mean-mean: 3.681702397716576
      reward_run-median-mean: 0.14878561268204749
      reward_run-range-mean: 17.428842239797195
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 3372.802734375
    episode-reward-mean: 3372.802734375
    episode-reward-min: 3372.802734375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 66
  node_ip: 10.43.77.35
  num_train_steps: 1650000
  pid: 283289
  policy:
    actions-max: 0.9983708262443542
    actions-mean: -0.049279484897851944
    actions-min: -0.9989266991615295
    actions-std: 0.7686285376548767
    entropy-mean: -6.121892929077148
    entropy-std: 3.606151580810547
    scales-max: 0.7818704843521118
    scales-mean: 0.4195713698863983
    scales-min: 0.0337977297604084
    scales-std: 0.15031999349594116
    shifts-max: 3.803875684738159
    shifts-mean: -0.07218229025602341
    shifts-min: -3.04695200920105
    shifts-std: 1.4232265949249268
  sampler:
    episodes: 1660
    last-path-return: 13713.894133019172
    max-path-return: 13895.21257474354
    pool-size: 1000000
    total-samples: 1660000
  time_since_restore: 15901.954296827316
  time_this_iter_s: 223.26744079589844
  time_total_s: 15901.954296827316
  times:
    epoch_after_hook: 1.5500118024647236e-06
    epoch_before_hook: 2.9641989385709167e-05
    evaluation_metrics: 0.00041298099677078426
    evaluation_paths: 0.5160745430039242
    sample: 15.971616496390197
    timestep_after_hook: 0.04071514794486575
    timestep_before_hook: 0.09217181694111787
    train: 206.10089696315117
    training_metrics: 0.0015612240240443498
    training_paths: 0.08973556099226698
  timestamp: 1652825043
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1650000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.27928073406219484
      reward_ctrl-last-mean: -0.3743091940879822
      reward_ctrl-mean-mean: -0.3475791542023421
      reward_ctrl-median-mean: -0.34935181379318236
      reward_ctrl-range-mean: 0.4932013320922851
      reward_run-first-mean: -0.5489540668638939
      reward_run-last-mean: 15.229150488378309
      reward_run-mean-mean: 13.831241934241822
      reward_run-median-mean: 14.765845687499024
      reward_run-range-mean: 17.65023614259242
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13854.44509782004
    episode-reward-mean: 13483.662780039482
    episode-reward-min: 12950.108625225175
    episode-reward-std: 259.84477519040934
  training_iteration: 66
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 18.071083068847656
    Q_value-mean: 1071.7371826171875
    alpha: 0.3407299220561981
    alpha_loss-mean: -0.0003734961792360991
    policy_loss-mean: -1071.3736572265625
  
== Status ==
Memory usage on this node: 85.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     66 |            15902 |      65 |      25000 |          1650000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.36247602105140686
  date: 2022-05-17_23-07-43
  done: false
  epoch: 66
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4520870685577393
      reward_ctrl-last-mean: -0.3279235124588013
      reward_ctrl-mean-mean: -0.33667452284097676
      reward_ctrl-median-mean: -0.34401611089706424
      reward_ctrl-range-mean: 0.4647648215293884
      reward_run-first-mean: -0.8106936136988269
      reward_run-last-mean: 15.383603617344761
      reward_run-mean-mean: 14.248517359244502
      reward_run-median-mean: 15.18553890780936
      reward_run-range-mean: 17.801617732370524
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13911.84375
    episode-reward-mean: 13911.84375
    episode-reward-min: 13911.84375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 67
  node_ip: 10.43.77.35
  num_train_steps: 1675000
  pid: 283289
  policy:
    actions-max: 0.9993125200271606
    actions-mean: -0.06608020514249802
    actions-min: -0.9989266395568848
    actions-std: 0.7614593505859375
    entropy-mean: -5.948380947113037
    entropy-std: 3.557544469833374
    scales-max: 0.9230781197547913
    scales-mean: 0.4201176166534424
    scales-min: 0.034315235912799835
    scales-std: 0.15775007009506226
    shifts-max: 3.035984992980957
    shifts-mean: -0.1306622177362442
    shifts-min: -2.8681881427764893
    shifts-std: 1.370849609375
  sampler:
    episodes: 1685
    last-path-return: 13606.472691897972
    max-path-return: 13962.734149145923
    pool-size: 1000000
    total-samples: 1685000
  time_since_restore: 16121.931581258774
  time_this_iter_s: 219.97728443145752
  time_total_s: 16121.931581258774
  times:
    epoch_after_hook: 1.5049881767481565e-06
    epoch_before_hook: 4.452597931958735e-05
    evaluation_metrics: 0.0004035299934912473
    evaluation_paths: 0.5042921569838654
    sample: 15.557343991356902
    timestep_after_hook: 0.03800572076579556
    timestep_before_hook: 0.08649585966486484
    train: 201.88957186901825
    training_metrics: 0.001504182000644505
    training_paths: 1.4757080919807777
  timestamp: 1652825263
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1675000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2770956575870514
      reward_ctrl-last-mean: -0.33762813329696656
      reward_ctrl-mean-mean: -0.34823677467763425
      reward_ctrl-median-mean: -0.35191227078437803
      reward_ctrl-range-mean: 0.48097786903381357
      reward_run-first-mean: -0.5793974790057315
      reward_run-last-mean: 14.91645057900655
      reward_run-mean-mean: 14.022988219393975
      reward_run-median-mean: 14.970873011081196
      reward_run-range-mean: 17.633046796152236
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13926.130376883299
    episode-reward-mean: 13674.751444716338
    episode-reward-min: 13241.56711633239
    episode-reward-std: 181.3809954158315
  training_iteration: 67
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 19.895845413208008
    Q_value-mean: 1079.3045654296875
    alpha: 0.35727575421333313
    alpha_loss-mean: -0.0004964402178302407
    policy_loss-mean: -1078.9324951171875
  
== Status ==
Memory usage on this node: 86.9/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     67 |          16121.9 |      66 |      25000 |          1675000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.37217676639556885
  date: 2022-05-17_23-11-24
  done: false
  epoch: 67
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.37521910667419434
      reward_ctrl-last-mean: -0.4194419860839844
      reward_ctrl-mean-mean: -0.34365987956523897
      reward_ctrl-median-mean: -0.3430570363998413
      reward_ctrl-range-mean: 0.47630506753921514
      reward_run-first-mean: -0.31704447556325815
      reward_run-last-mean: 15.113337193465668
      reward_run-mean-mean: 14.413459899079365
      reward_run-median-mean: 15.227812365832847
      reward_run-range-mean: 17.76581851158557
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14069.7998046875
    episode-reward-mean: 14069.7998046875
    episode-reward-min: 14069.7998046875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 68
  node_ip: 10.43.77.35
  num_train_steps: 1700000
  pid: 283289
  policy:
    actions-max: 0.9998834133148193
    actions-mean: -0.08823593705892563
    actions-min: -0.9997195601463318
    actions-std: 0.762126624584198
    entropy-mean: -6.060308456420898
    entropy-std: 3.983675718307495
    scales-max: 0.7891590595245361
    scales-mean: 0.4285213053226471
    scales-min: 0.03324534371495247
    scales-std: 0.15589368343353271
    shifts-max: 4.176239490509033
    shifts-mean: -0.151939257979393
    shifts-min: -2.8937931060791016
    shifts-std: 1.419825553894043
  sampler:
    episodes: 1710
    last-path-return: 13965.827073023615
    max-path-return: 14186.514768902545
    pool-size: 1000000
    total-samples: 1710000
  time_since_restore: 16342.324354887009
  time_this_iter_s: 220.39277362823486
  time_total_s: 16342.324354887009
  times:
    epoch_after_hook: 1.5969853848218918e-06
    epoch_before_hook: 3.676299820654094e-05
    evaluation_metrics: 0.00041444701491855085
    evaluation_paths: 0.49571101999026723
    sample: 15.369424824748421
    timestep_after_hook: 0.03814765514107421
    timestep_before_hook: 0.08807088862522505
    train: 203.8810804784589
    training_metrics: 0.0015621909988112748
    training_paths: 0.07629231599275954
  timestamp: 1652825484
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1700000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3493777561187744
      reward_ctrl-last-mean: -0.39613122105598453
      reward_ctrl-mean-mean: -0.3491662574821711
      reward_ctrl-median-mean: -0.35499470829963686
      reward_ctrl-range-mean: 0.48732065916061407
      reward_run-first-mean: -0.4802722156318957
      reward_run-last-mean: 15.546520998021833
      reward_run-mean-mean: 14.263035249263833
      reward_run-median-mean: 15.136498797668764
      reward_run-range-mean: 17.64889292698527
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14186.514768902563
    episode-reward-mean: 13913.868991781663
    episode-reward-min: 13626.577383278123
    episode-reward-std: 151.70145836103796
  training_iteration: 68
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 21.608875274658203
    Q_value-mean: 1085.5126953125
    alpha: 0.36792218685150146
    alpha_loss-mean: -0.0003148486139252782
    policy_loss-mean: -1085.12939453125
  
== Status ==
Memory usage on this node: 82.3/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     68 |          16342.3 |      67 |      25000 |          1700000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3854404389858246
  date: 2022-05-17_23-15-07
  done: false
  epoch: 68
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.45591416358947756
      reward_ctrl-last-mean: -0.36009740829467773
      reward_ctrl-mean-mean: -0.361009303855896
      reward_ctrl-median-mean: -0.3649386644363404
      reward_ctrl-range-mean: 0.48607338666915895
      reward_run-first-mean: -0.7592498835846525
      reward_run-last-mean: 13.63483562175361
      reward_run-mean-mean: 14.327432006713844
      reward_run-median-mean: 15.202712392870694
      reward_run-range-mean: 17.879512992809758
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13966.4228515625
    episode-reward-mean: 13966.4228515625
    episode-reward-min: 13966.4228515625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 69
  node_ip: 10.43.77.35
  num_train_steps: 1725000
  pid: 283289
  policy:
    actions-max: 0.99970543384552
    actions-mean: -0.08771436661481857
    actions-min: -0.9987296462059021
    actions-std: 0.7692208886146545
    entropy-mean: -6.321292877197266
    entropy-std: 4.206544876098633
    scales-max: 0.9191933274269104
    scales-mean: 0.4199732840061188
    scales-min: 0.03243140131235123
    scales-std: 0.15841539204120636
    shifts-max: 3.8679206371307373
    shifts-mean: -0.13084664940834045
    shifts-min: -2.8851003646850586
    shifts-std: 1.4327952861785889
  sampler:
    episodes: 1735
    last-path-return: 14183.78053875015
    max-path-return: 14363.884259518285
    pool-size: 1000000
    total-samples: 1735000
  time_since_restore: 16566.051431894302
  time_this_iter_s: 223.7270770072937
  time_total_s: 16566.051431894302
  times:
    epoch_after_hook: 1.6329868230968714e-06
    epoch_before_hook: 3.055098932236433e-05
    evaluation_metrics: 0.00041028400301001966
    evaluation_paths: 0.5004915749887004
    sample: 16.00332333231927
    timestep_after_hook: 0.04116289655212313
    timestep_before_hook: 0.09302784880856052
    train: 206.42001259076642
    training_metrics: 0.001479967002524063
    training_paths: 0.21568417898379266
  timestamp: 1652825707
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1725000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.31774046659469607
      reward_ctrl-last-mean: -0.3270763838291168
      reward_ctrl-mean-mean: -0.34549186370313173
      reward_ctrl-median-mean: -0.34921648740768435
      reward_ctrl-range-mean: 0.46620982468128214
      reward_run-first-mean: -0.5695177318479743
      reward_run-last-mean: 15.760909803171899
      reward_run-mean-mean: 14.416468691651072
      reward_run-median-mean: 15.297340137227906
      reward_run-range-mean: 17.831747768155832
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14363.8842595183
    episode-reward-mean: 14070.976827947941
    episode-reward-min: 13630.871954689788
    episode-reward-std: 195.52937684893507
  training_iteration: 69
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 22.595672607421875
    Q_value-mean: 1089.5528564453125
    alpha: 0.3816249668598175
    alpha_loss-mean: -0.0004342030733823776
    policy_loss-mean: -1089.143798828125
  
== Status ==
Memory usage on this node: 87.8/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     69 |          16566.1 |      68 |      25000 |          1725000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.39970725774765015
  date: 2022-05-17_23-18-43
  done: false
  epoch: 69
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2596757888793945
      reward_ctrl-last-mean: -0.2764354705810547
      reward_ctrl-mean-mean: -0.33781375600099567
      reward_ctrl-median-mean: -0.337084436416626
      reward_ctrl-range-mean: 0.45003350973129275
      reward_run-first-mean: -0.594874570026947
      reward_run-last-mean: 16.04418238597873
      reward_run-mean-mean: 14.187031428669377
      reward_run-median-mean: 14.915038961771643
      reward_run-range-mean: 17.719993610047187
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 13849.2177734375
    episode-reward-mean: 13849.2177734375
    episode-reward-min: 13849.2177734375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 70
  node_ip: 10.43.77.35
  num_train_steps: 1750000
  pid: 283289
  policy:
    actions-max: 0.9995591640472412
    actions-mean: -0.06430855393409729
    actions-min: -0.9993447661399841
    actions-std: 0.7667968273162842
    entropy-mean: -5.985206604003906
    entropy-std: 3.6015689373016357
    scales-max: 0.9304330348968506
    scales-mean: 0.42501160502433777
    scales-min: 0.029934849590063095
    scales-std: 0.15717092156410217
    shifts-max: 4.155475616455078
    shifts-mean: -0.13130658864974976
    shifts-min: -3.6716978549957275
    shifts-std: 1.3887304067611694
  sampler:
    episodes: 1760
    last-path-return: 14291.263412052627
    max-path-return: 14376.738728015172
    pool-size: 1000000
    total-samples: 1760000
  time_since_restore: 16781.960203886032
  time_this_iter_s: 215.90877199172974
  time_total_s: 16781.960203886032
  times:
    epoch_after_hook: 1.7049896996468306e-06
    epoch_before_hook: 3.539302269928157e-05
    evaluation_metrics: 0.0004058519843965769
    evaluation_paths: 0.5286477729969192
    sample: 14.902087852271507
    timestep_after_hook: 0.036031485098646954
    timestep_before_hook: 0.08231646058266051
    train: 199.8747730824398
    training_metrics: 0.0014826940023340285
    training_paths: 0.07535166500019841
  timestamp: 1652825923
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1750000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.36349005937576295
      reward_ctrl-last-mean: -0.31211479783058166
      reward_ctrl-mean-mean: -0.3444641740733385
      reward_ctrl-median-mean: -0.3462719941139222
      reward_ctrl-range-mean: 0.47335716009140005
      reward_run-first-mean: -0.7389002381893871
      reward_run-last-mean: 15.923834667742994
      reward_run-mean-mean: 14.428110017715696
      reward_run-median-mean: 15.365030260082875
      reward_run-range-mean: 18.06151058767805
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14376.738728015162
    episode-reward-mean: 14083.64584364236
    episode-reward-min: 13695.371943804124
    episode-reward-std: 203.5484366726941
  training_iteration: 70
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 23.616222381591797
    Q_value-mean: 1096.1048583984375
    alpha: 0.39050179719924927
    alpha_loss-mean: -0.00039854043279774487
    policy_loss-mean: -1095.6904296875
  
== Status ==
Memory usage on this node: 83.8/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     70 |            16782 |      69 |      25000 |          1750000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3973671495914459
  date: 2022-05-17_23-22-25
  done: false
  epoch: 70
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.22835650444030764
      reward_ctrl-last-mean: -0.4146134376525879
      reward_ctrl-mean-mean: -0.34678893780708314
      reward_ctrl-median-mean: -0.34859853982925415
      reward_ctrl-range-mean: 0.4589343428611756
      reward_run-first-mean: -0.5508245897365385
      reward_run-last-mean: 15.357972159140445
      reward_run-mean-mean: 14.843622673320482
      reward_run-median-mean: 15.711997843260406
      reward_run-range-mean: 18.139807312986648
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14496.8330078125
    episode-reward-mean: 14496.8330078125
    episode-reward-min: 14496.8330078125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 71
  node_ip: 10.43.77.35
  num_train_steps: 1775000
  pid: 283289
  policy:
    actions-max: 0.9983739256858826
    actions-mean: -0.11041788011789322
    actions-min: -0.9978931546211243
    actions-std: 0.7620305418968201
    entropy-mean: -6.1824541091918945
    entropy-std: 3.701779842376709
    scales-max: 0.908769965171814
    scales-mean: 0.42781588435173035
    scales-min: 0.03573281690478325
    scales-std: 0.16212180256843567
    shifts-max: 3.9195895195007324
    shifts-mean: -0.1885601282119751
    shifts-min: -2.886040210723877
    shifts-std: 1.3949885368347168
  sampler:
    episodes: 1785
    last-path-return: 14226.648480223426
    max-path-return: 14395.36740030594
    pool-size: 1000000
    total-samples: 1785000
  time_since_restore: 17003.420876026154
  time_this_iter_s: 221.46067214012146
  time_total_s: 17003.420876026154
  times:
    epoch_after_hook: 1.52099528349936e-06
    epoch_before_hook: 4.0551996789872646e-05
    evaluation_metrics: 0.00041342401527799666
    evaluation_paths: 0.49880173697602004
    sample: 15.757798344478942
    timestep_after_hook: 0.03954284996143542
    timestep_before_hook: 0.08922342912410386
    train: 204.5594213384029
    training_metrics: 0.00150130401016213
    training_paths: 0.07415542000671849
  timestamp: 1652826145
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1775000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3166507613658905
      reward_ctrl-last-mean: -0.3143822014331818
      reward_ctrl-mean-mean: -0.34139822708010675
      reward_ctrl-median-mean: -0.34395658850669864
      reward_ctrl-range-mean: 0.4631653219461441
      reward_run-first-mean: -0.7988084995956621
      reward_run-last-mean: 16.007805014069618
      reward_run-mean-mean: 14.50154060855036
      reward_run-median-mean: 15.426562797619951
      reward_run-range-mean: 18.157694718570873
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14395.367400305962
    episode-reward-mean: 14160.142381470254
    episode-reward-min: 13810.938062534515
    episode-reward-std: 163.64983227912222
  training_iteration: 71
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 24.794219970703125
    Q_value-mean: 1102.3394775390625
    alpha: 0.40160393714904785
    alpha_loss-mean: 0.00010916729661403224
    policy_loss-mean: -1101.9097900390625
  
== Status ==
Memory usage on this node: 80.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     71 |          17003.4 |      70 |      25000 |          1775000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.4101131856441498
  date: 2022-05-17_23-26-07
  done: false
  epoch: 71
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.24537105560302735
      reward_ctrl-last-mean: -0.3855300903320313
      reward_ctrl-mean-mean: -0.3459722739934921
      reward_ctrl-median-mean: -0.34850429296493535
      reward_ctrl-range-mean: 0.4645359754562378
      reward_run-first-mean: -0.3086373690476389
      reward_run-last-mean: 15.363509768487802
      reward_run-mean-mean: 14.844074333574131
      reward_run-median-mean: 15.730518565904958
      reward_run-range-mean: 17.912704694856583
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14498.1015625
    episode-reward-mean: 14498.1015625
    episode-reward-min: 14498.1015625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 72
  node_ip: 10.43.77.35
  num_train_steps: 1800000
  pid: 283289
  policy:
    actions-max: 0.999477744102478
    actions-mean: -0.04934009909629822
    actions-min: -0.9985491633415222
    actions-std: 0.7507677674293518
    entropy-mean: -5.818805694580078
    entropy-std: 3.4849133491516113
    scales-max: 0.8125638961791992
    scales-mean: 0.4107765853404999
    scales-min: 0.02654324844479561
    scales-std: 0.16103696823120117
    shifts-max: 3.541159152984619
    shifts-mean: -0.09336427599191666
    shifts-min: -2.7661092281341553
    shifts-std: 1.3643808364868164
  sampler:
    episodes: 1810
    last-path-return: 14409.725887492872
    max-path-return: 14522.057607977873
    pool-size: 1000000
    total-samples: 1810000
  time_since_restore: 17225.19896197319
  time_this_iter_s: 221.77808594703674
  time_total_s: 17225.19896197319
  times:
    epoch_after_hook: 1.7519923858344555e-06
    epoch_before_hook: 3.5931996535509825e-05
    evaluation_metrics: 0.00044832000276073813
    evaluation_paths: 0.5024293010064866
    sample: 15.9063408645452
    timestep_after_hook: 0.04011901034391485
    timestep_before_hook: 0.09102274681208655
    train: 204.7156586216588
    training_metrics: 0.0014735099975951016
    training_paths: 0.07770584599347785
  timestamp: 1652826367
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1800000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.27976920962333673
      reward_ctrl-last-mean: -0.34731734752655036
      reward_ctrl-mean-mean: -0.34178127653062346
      reward_ctrl-median-mean: -0.34331907629966735
      reward_ctrl-range-mean: 0.4721619045734406
      reward_run-first-mean: -0.6281545794392057
      reward_run-last-mean: 16.241560308197904
      reward_run-mean-mean: 14.690636584946068
      reward_run-median-mean: 15.557956358310918
      reward_run-range-mean: 17.99865925368904
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14522.05760797787
    episode-reward-mean: 14348.855308415446
    episode-reward-min: 14181.89100102214
    episode-reward-std: 85.16373594617279
  training_iteration: 72
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 25.26091957092285
    Q_value-mean: 1109.6951904296875
    alpha: 0.4115925431251526
    alpha_loss-mean: -0.0003775799705181271
    policy_loss-mean: -1109.2349853515625
  
== Status ==
Memory usage on this node: 82.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     72 |          17225.2 |      71 |      25000 |          1800000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.4198102056980133
  date: 2022-05-17_23-29-47
  done: false
  epoch: 72
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.30164120197296146
      reward_ctrl-last-mean: -0.33347647190094
      reward_ctrl-mean-mean: -0.3579803280591965
      reward_ctrl-median-mean: -0.35612183809280396
      reward_ctrl-range-mean: 0.44746425151824953
      reward_run-first-mean: -0.6139024045782244
      reward_run-last-mean: 6.0822735199622
      reward_run-mean-mean: 14.36733241284603
      reward_run-median-mean: 15.533299259867022
      reward_run-range-mean: 18.021452607811543
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14009.3515625
    episode-reward-mean: 14009.3515625
    episode-reward-min: 14009.3515625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 73
  node_ip: 10.43.77.35
  num_train_steps: 1825000
  pid: 283289
  policy:
    actions-max: 0.9994205236434937
    actions-mean: -0.06349986791610718
    actions-min: -0.9994398355484009
    actions-std: 0.7631826400756836
    entropy-mean: -6.0304412841796875
    entropy-std: 3.8895833492279053
    scales-max: 0.8942939043045044
    scales-mean: 0.4239022731781006
    scales-min: 0.024652615189552307
    scales-std: 0.1635495126247406
    shifts-max: 4.71818733215332
    shifts-mean: -0.1153903380036354
    shifts-min: -2.911332130432129
    shifts-std: 1.3949552774429321
  sampler:
    episodes: 1835
    last-path-return: 14329.882666985975
    max-path-return: 14581.651422643074
    pool-size: 1000000
    total-samples: 1835000
  time_since_restore: 17444.85556411743
  time_this_iter_s: 219.65660214424133
  time_total_s: 17444.85556411743
  times:
    epoch_after_hook: 1.5490222722291946e-06
    epoch_before_hook: 3.270999877713621e-05
    evaluation_metrics: 0.0004082990053575486
    evaluation_paths: 0.535041597991949
    sample: 15.430300068343058
    timestep_after_hook: 0.038422568613896146
    timestep_before_hook: 0.08713775101932697
    train: 203.05515399231808
    training_metrics: 0.0015398810210172087
    training_paths: 0.07781824801350012
  timestamp: 1652826587
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1825000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.33631468534469605
      reward_ctrl-last-mean: -0.41297834396362304
      reward_ctrl-mean-mean: -0.3414809317648411
      reward_ctrl-median-mean: -0.3418467712402344
      reward_ctrl-range-mean: 0.4713131481409073
      reward_run-first-mean: -0.6390611540513843
      reward_run-last-mean: 15.435929471103691
      reward_run-mean-mean: 14.66472831584955
      reward_run-median-mean: 15.58578087232965
      reward_run-range-mean: 18.170449315850284
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14581.651422643074
    episode-reward-mean: 14323.247384084709
    episode-reward-min: 14022.681115758183
    episode-reward-std: 146.15766421894477
  training_iteration: 73
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 25.737770080566406
    Q_value-mean: 1115.8216552734375
    alpha: 0.4182625710964203
    alpha_loss-mean: -0.000312655494781211
    policy_loss-mean: -1115.31787109375
  
== Status ==
Memory usage on this node: 81.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     73 |          17444.9 |      72 |      25000 |          1825000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.4177052974700928
  date: 2022-05-17_23-33-25
  done: false
  epoch: 73
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2523939609527588
      reward_ctrl-last-mean: -0.3449488878250122
      reward_ctrl-mean-mean: -0.33415848973989487
      reward_ctrl-median-mean: -0.3213160872459412
      reward_ctrl-range-mean: 0.44081434011459353
      reward_run-first-mean: -0.6269937280974992
      reward_run-last-mean: 16.152989705565233
      reward_run-mean-mean: 14.732125328016023
      reward_run-median-mean: 15.699560631876182
      reward_run-range-mean: 18.27108122749621
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14397.966796875
    episode-reward-mean: 14397.966796875
    episode-reward-min: 14397.966796875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 74
  node_ip: 10.43.77.35
  num_train_steps: 1850000
  pid: 283289
  policy:
    actions-max: 0.9994498491287231
    actions-mean: -0.0672510489821434
    actions-min: -0.9991907477378845
    actions-std: 0.7669806480407715
    entropy-mean: -6.838993072509766
    entropy-std: 3.883544921875
    scales-max: 1.004197359085083
    scales-mean: 0.4115827977657318
    scales-min: 0.019974403083324432
    scales-std: 0.165197491645813
    shifts-max: 3.9823081493377686
    shifts-mean: -0.11076746135950089
    shifts-min: -2.9462735652923584
    shifts-std: 1.4208393096923828
  sampler:
    episodes: 1860
    last-path-return: 14532.083721005321
    max-path-return: 14625.098034638031
    pool-size: 1000000
    total-samples: 1860000
  time_since_restore: 17663.52525496483
  time_this_iter_s: 218.66969084739685
  time_total_s: 17663.52525496483
  times:
    epoch_after_hook: 1.7329875845462084e-06
    epoch_before_hook: 4.3180014472454786e-05
    evaluation_metrics: 0.0004105509724467993
    evaluation_paths: 0.5336401239910629
    sample: 15.422541207546601
    timestep_after_hook: 0.03813117818208411
    timestep_before_hook: 0.08573156531201676
    train: 202.08066071153735
    training_metrics: 0.001557944982778281
    training_paths: 0.07920310299959965
  timestamp: 1652826805
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1850000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.31666335940361023
      reward_ctrl-last-mean: -0.3329134154319764
      reward_ctrl-mean-mean: -0.34068625892370935
      reward_ctrl-median-mean: -0.33989506363868716
      reward_ctrl-range-mean: 0.47063078731298447
      reward_run-first-mean: -0.5332376375690112
      reward_run-last-mean: 16.257063801666845
      reward_run-mean-mean: 14.778065423242884
      reward_run-median-mean: 15.635883226508682
      reward_run-range-mean: 18.104213949699684
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14625.098034638022
    episode-reward-mean: 14437.379164319176
    episode-reward-min: 14224.929423749714
    episode-reward-std: 107.07725488807225
  training_iteration: 74
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 25.475236892700195
    Q_value-mean: 1121.7772216796875
    alpha: 0.4229048788547516
    alpha_loss-mean: 0.00013864772336091846
    policy_loss-mean: -1121.23828125
  
== Status ==
Memory usage on this node: 84.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     74 |          17663.5 |      73 |      25000 |          1850000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.43462073802948
  date: 2022-05-17_23-37-06
  done: false
  epoch: 74
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.28089759349823
      reward_ctrl-last-mean: -0.4684772491455078
      reward_ctrl-mean-mean: -0.3282563740253449
      reward_ctrl-median-mean: -0.3418009281158447
      reward_ctrl-range-mean: 0.4731015384197236
      reward_run-first-mean: -0.506281842335784
      reward_run-last-mean: 15.122187140734695
      reward_run-mean-mean: 14.560219352685026
      reward_run-median-mean: 15.414833747339571
      reward_run-range-mean: 17.480534071797866
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14231.962890625
    episode-reward-mean: 14231.962890625
    episode-reward-min: 14231.962890625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 75
  node_ip: 10.43.77.35
  num_train_steps: 1875000
  pid: 283289
  policy:
    actions-max: 0.9994542002677917
    actions-mean: -0.06599500775337219
    actions-min: -0.9996559619903564
    actions-std: 0.763602077960968
    entropy-mean: -5.979467391967773
    entropy-std: 3.338888168334961
    scales-max: 1.0140186548233032
    scales-mean: 0.4244503676891327
    scales-min: 0.025112444534897804
    scales-std: 0.16541142761707306
    shifts-max: 4.090792179107666
    shifts-mean: -0.13213913142681122
    shifts-min: -3.135220527648926
    shifts-std: 1.3675328493118286
  sampler:
    episodes: 1885
    last-path-return: 14447.130601591321
    max-path-return: 14625.098034638031
    pool-size: 1000000
    total-samples: 1885000
  time_since_restore: 17884.358667373657
  time_this_iter_s: 220.83341240882874
  time_total_s: 17884.358667373657
  times:
    epoch_after_hook: 1.6730045899748802e-06
    epoch_before_hook: 3.372298670001328e-05
    evaluation_metrics: 0.00040435700793750584
    evaluation_paths: 0.5010617219959386
    sample: 15.712847639602842
    timestep_after_hook: 0.03894422040320933
    timestep_before_hook: 0.08974045742070302
    train: 203.97196319382056
    training_metrics: 0.001536877010948956
    training_paths: 0.0772955979919061
  timestamp: 1652827026
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1875000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3477534115314484
      reward_ctrl-last-mean: -0.3517803204059601
      reward_ctrl-mean-mean: -0.33960379640579225
      reward_ctrl-median-mean: -0.3399083328247071
      reward_ctrl-range-mean: 0.4758584642410278
      reward_run-first-mean: -0.6839294418519961
      reward_run-last-mean: 15.60694948715468
      reward_run-mean-mean: 14.72895013832984
      reward_run-median-mean: 15.623522359441466
      reward_run-range-mean: 18.161158346531366
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14567.543161444975
    episode-reward-mean: 14389.346341924047
    episode-reward-min: 14128.847245405777
    episode-reward-std: 133.919308641798
  training_iteration: 75
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 26.029315948486328
    Q_value-mean: 1127.7066650390625
    alpha: 0.4290153980255127
    alpha_loss-mean: -0.0005314684240147471
    policy_loss-mean: -1127.1204833984375
  
== Status ==
Memory usage on this node: 87.4/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     75 |          17884.4 |      74 |      25000 |          1875000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.44134292006492615
  date: 2022-05-17_23-40-48
  done: false
  epoch: 75
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.30956802368164066
      reward_ctrl-last-mean: -0.3065628528594971
      reward_ctrl-mean-mean: -0.33257451896667484
      reward_ctrl-median-mean: -0.33473274707794193
      reward_ctrl-range-mean: 0.4912600278854371
      reward_run-first-mean: -0.5944795078937216
      reward_run-last-mean: 16.848743556561203
      reward_run-mean-mean: 14.703729398848521
      reward_run-median-mean: 15.552596709100044
      reward_run-range-mean: 17.98709413895054
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14371.154296875
    episode-reward-mean: 14371.154296875
    episode-reward-min: 14371.154296875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 76
  node_ip: 10.43.77.35
  num_train_steps: 1900000
  pid: 283289
  policy:
    actions-max: 0.9992868900299072
    actions-mean: -0.07353123277425766
    actions-min: -0.9987786412239075
    actions-std: 0.7463613152503967
    entropy-mean: -5.584604263305664
    entropy-std: 3.356687068939209
    scales-max: 0.8651163578033447
    scales-mean: 0.4182681143283844
    scales-min: 0.030988719314336777
    scales-std: 0.1634044647216797
    shifts-max: 3.1731958389282227
    shifts-mean: -0.10519712418317795
    shifts-min: -2.718085527420044
    shifts-std: 1.3347840309143066
  sampler:
    episodes: 1910
    last-path-return: 14304.62469385065
    max-path-return: 14652.530984592675
    pool-size: 1000000
    total-samples: 1910000
  time_since_restore: 18105.908462524414
  time_this_iter_s: 221.54979515075684
  time_total_s: 18105.908462524414
  times:
    epoch_after_hook: 1.5310070011764765e-06
    epoch_before_hook: 3.578999894671142e-05
    evaluation_metrics: 0.00041467099799774587
    evaluation_paths: 0.49818098900141194
    sample: 15.84813196741743
    timestep_after_hook: 0.03975618537515402
    timestep_before_hook: 0.09068262984510511
    train: 204.54701874652528
    training_metrics: 0.0016171519819181412
    training_paths: 0.07912091698381118
  timestamp: 1652827248
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1900000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2817979693412781
      reward_ctrl-last-mean: -0.3319323587417603
      reward_ctrl-mean-mean: -0.3397873209142685
      reward_ctrl-median-mean: -0.3395931684970856
      reward_ctrl-range-mean: 0.4705876970291138
      reward_run-first-mean: -0.574252847892913
      reward_run-last-mean: 16.136419785851785
      reward_run-mean-mean: 14.770282784159585
      reward_run-median-mean: 15.667879388944513
      reward_run-range-mean: 18.167906723933605
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14561.892921386108
    episode-reward-mean: 14430.495463245315
    episode-reward-min: 14291.309355341295
    episode-reward-std: 92.5858086184473
  training_iteration: 76
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 25.88945198059082
    Q_value-mean: 1133.62158203125
    alpha: 0.43363645672798157
    alpha_loss-mean: -0.00015852434444241226
    policy_loss-mean: -1132.9970703125
  
== Status ==
Memory usage on this node: 83.8/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     76 |          18105.9 |      75 |      25000 |          1900000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.432888001203537
  date: 2022-05-17_23-44-29
  done: false
  epoch: 76
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2206270456314087
      reward_ctrl-last-mean: -0.40888981819152836
      reward_ctrl-mean-mean: -0.3391568366229534
      reward_ctrl-median-mean: -0.3459923505783081
      reward_ctrl-range-mean: 0.4694040656089783
      reward_run-first-mean: -0.4789897878244631
      reward_run-last-mean: 15.975610643329219
      reward_run-mean-mean: 14.943940800007178
      reward_run-median-mean: 15.8180240205877
      reward_run-range-mean: 18.039139181074127
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14604.783203125
    episode-reward-mean: 14604.783203125
    episode-reward-min: 14604.783203125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 77
  node_ip: 10.43.77.35
  num_train_steps: 1925000
  pid: 283289
  policy:
    actions-max: 0.9991366863250732
    actions-mean: -0.08005725592374802
    actions-min: -0.9990420937538147
    actions-std: 0.7476136088371277
    entropy-mean: -5.516724586486816
    entropy-std: 3.4047083854675293
    scales-max: 0.9699554443359375
    scales-mean: 0.4184717833995819
    scales-min: 0.03148194029927254
    scales-std: 0.16406679153442383
    shifts-max: 3.159273862838745
    shifts-mean: -0.15605218708515167
    shifts-min: -3.568054676055908
    shifts-std: 1.3354902267456055
  sampler:
    episodes: 1935
    last-path-return: 14375.26093884865
    max-path-return: 14652.530984592675
    pool-size: 1000000
    total-samples: 1935000
  time_since_restore: 18327.40685248375
  time_this_iter_s: 221.49838995933533
  time_total_s: 18327.40685248375
  times:
    epoch_after_hook: 1.9430008251219988e-06
    epoch_before_hook: 3.6308018025010824e-05
    evaluation_metrics: 0.00040434100083075464
    evaluation_paths: 0.5005609139916487
    sample: 16.034762513561873
    timestep_after_hook: 0.03966115094954148
    timestep_before_hook: 0.08877044011023827
    train: 204.2027780553035
    training_metrics: 0.0014759660116396844
    training_paths: 0.18672498501837254
  timestamp: 1652827469
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1925000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3381961297988892
      reward_ctrl-last-mean: -0.4372304010391236
      reward_ctrl-mean-mean: -0.34046961129933595
      reward_ctrl-median-mean: -0.3413016211986542
      reward_ctrl-range-mean: 0.4828122690320015
      reward_run-first-mean: -0.7067237707454482
      reward_run-last-mean: 15.807458724336811
      reward_run-mean-mean: 14.738370234801327
      reward_run-median-mean: 15.690051931796447
      reward_run-range-mean: 18.281154062666232
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14596.350789554406
    episode-reward-mean: 14397.900623501995
    episode-reward-min: 13940.42594870349
    episode-reward-std: 177.20058528889825
  training_iteration: 77
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 24.897035598754883
    Q_value-mean: 1139.7293701171875
    alpha: 0.43583089113235474
    alpha_loss-mean: 0.00030617835000157356
    policy_loss-mean: -1139.053466796875
  
== Status ==
Memory usage on this node: 80.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     77 |          18327.4 |      76 |      25000 |          1925000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.4403012692928314
  date: 2022-05-17_23-48-09
  done: false
  epoch: 77
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2172003746032715
      reward_ctrl-last-mean: -0.42691116333007817
      reward_ctrl-mean-mean: -0.33887616221904754
      reward_ctrl-median-mean: -0.3389538168907166
      reward_ctrl-range-mean: 0.46097152233123784
      reward_run-first-mean: -0.9455658644252063
      reward_run-last-mean: 15.408879026274462
      reward_run-mean-mean: 14.44107011040403
      reward_run-median-mean: 15.61353429395183
      reward_run-range-mean: 18.42445943988155
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14102.193359375
    episode-reward-mean: 14102.193359375
    episode-reward-min: 14102.193359375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 78
  node_ip: 10.43.77.35
  num_train_steps: 1950000
  pid: 283289
  policy:
    actions-max: 0.9981914758682251
    actions-mean: -0.08925756067037582
    actions-min: -0.9991210699081421
    actions-std: 0.7607371211051941
    entropy-mean: -6.315415382385254
    entropy-std: 3.3815085887908936
    scales-max: 0.9943183660507202
    scales-mean: 0.41134360432624817
    scales-min: 0.025495264679193497
    scales-std: 0.16100364923477173
    shifts-max: 3.4643075466156006
    shifts-mean: -0.13849955797195435
    shifts-min: -2.9031667709350586
    shifts-std: 1.3819687366485596
  sampler:
    episodes: 1960
    last-path-return: 14173.286398331707
    max-path-return: 14676.068519838269
    pool-size: 1000000
    total-samples: 1960000
  time_since_restore: 18546.823380470276
  time_this_iter_s: 219.4165279865265
  time_total_s: 18546.823380470276
  times:
    epoch_after_hook: 2.53098551183939e-06
    epoch_before_hook: 3.198999911546707e-05
    evaluation_metrics: 0.010369921015808359
    evaluation_paths: 0.5483530460041948
    sample: 15.669221097923582
    timestep_after_hook: 0.03825173174845986
    timestep_before_hook: 0.08698113323771395
    train: 202.3829093518434
    training_metrics: 0.043099172005895525
    training_paths: 0.20168750401353464
  timestamp: 1652827689
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1950000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.293673495054245
      reward_ctrl-last-mean: -0.3624084877967834
      reward_ctrl-mean-mean: -0.34025476987183095
      reward_ctrl-median-mean: -0.3408719336986542
      reward_ctrl-range-mean: 0.47827757000923155
      reward_run-first-mean: -0.6154742446365631
      reward_run-last-mean: 15.901933222959315
      reward_run-mean-mean: 14.781109135698355
      reward_run-median-mean: 15.690017087008712
      reward_run-range-mean: 18.11759652484302
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14621.675794425688
    episode-reward-mean: 14440.854365826523
    episode-reward-min: 14173.286398331722
    episode-reward-std: 124.26809426348952
  training_iteration: 78
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 24.79155921936035
    Q_value-mean: 1146.6932373046875
    alpha: 0.43614262342453003
    alpha_loss-mean: -0.0002233664272353053
    policy_loss-mean: -1145.9910888671875
  
== Status ==
Memory usage on this node: 83.2/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     78 |          18546.8 |      77 |      25000 |          1950000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.4416584372520447
  date: 2022-05-17_23-51-43
  done: false
  epoch: 78
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.23174128532409669
      reward_ctrl-last-mean: -0.36497623920440675
      reward_ctrl-mean-mean: -0.344707819890976
      reward_ctrl-median-mean: -0.3372589826583863
      reward_ctrl-range-mean: 0.45225595831871035
      reward_run-first-mean: -0.42872001674636145
      reward_run-last-mean: 16.21451362565267
      reward_run-mean-mean: 15.059828604258128
      reward_run-median-mean: 15.875395878790641
      reward_run-range-mean: 17.85332132347323
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14715.1201171875
    episode-reward-mean: 14715.1201171875
    episode-reward-min: 14715.1201171875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 79
  node_ip: 10.43.77.35
  num_train_steps: 1975000
  pid: 283289
  policy:
    actions-max: 0.9999068379402161
    actions-mean: -0.055382270365953445
    actions-min: -0.9976843595504761
    actions-std: 0.7653635740280151
    entropy-mean: -6.055787563323975
    entropy-std: 3.3841395378112793
    scales-max: 0.8941892981529236
    scales-mean: 0.4177469313144684
    scales-min: 0.023531243205070496
    scales-std: 0.16229183971881866
    shifts-max: 3.590763568878174
    shifts-mean: -0.11679613590240479
    shifts-min: -2.8580076694488525
    shifts-std: 1.3768694400787354
  sampler:
    episodes: 1985
    last-path-return: 14527.386517983414
    max-path-return: 14712.381639055222
    pool-size: 1000000
    total-samples: 1985000
  time_since_restore: 18761.14572453499
  time_this_iter_s: 214.32234406471252
  time_total_s: 18761.14572453499
  times:
    epoch_after_hook: 1.6750127542763948e-06
    epoch_before_hook: 3.609899431467056e-05
    evaluation_metrics: 0.0004063319938722998
    evaluation_paths: 0.49947186998906545
    sample: 14.575134838698432
    timestep_after_hook: 0.03489087539492175
    timestep_before_hook: 0.08070278711966239
    train: 198.52771409135312
    training_metrics: 0.0014851920132059604
    training_paths: 0.20147557600284927
  timestamp: 1652827903
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 1975000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3364211654663086
      reward_ctrl-last-mean: -0.35449945688247686
      reward_ctrl-mean-mean: -0.3411240875464678
      reward_ctrl-median-mean: -0.3417683327198029
      reward_ctrl-range-mean: 0.4693915975093842
      reward_run-first-mean: -0.5368996792948197
      reward_run-last-mean: 16.02124624636258
      reward_run-mean-mean: 14.87132156570066
      reward_run-median-mean: 15.748348460206913
      reward_run-range-mean: 18.12501765872188
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14685.431686432334
    episode-reward-mean: 14530.19747815419
    episode-reward-min: 14350.369077414656
    episode-reward-std: 97.44165247017578
  training_iteration: 79
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 23.76439094543457
    Q_value-mean: 1153.790771484375
    alpha: 0.4347601532936096
    alpha_loss-mean: -4.203367279842496e-05
    policy_loss-mean: -1153.05419921875
  
== Status ==
Memory usage on this node: 80.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     79 |          18761.1 |      78 |      25000 |          1975000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.4374571442604065
  date: 2022-05-17_23-55-16
  done: false
  epoch: 79
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3517175674438477
      reward_ctrl-last-mean: -0.13804794549942018
      reward_ctrl-mean-mean: -0.33341681300401693
      reward_ctrl-median-mean: -0.34513838291168214
      reward_ctrl-range-mean: 0.5063919246196747
      reward_run-first-mean: -0.5856138592039279
      reward_run-last-mean: 16.7385557140301
      reward_run-mean-mean: 14.636559551553253
      reward_run-median-mean: 15.54751500316172
      reward_run-range-mean: 18.423972669810748
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14303.142578125
    episode-reward-mean: 14303.142578125
    episode-reward-min: 14303.142578125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 80
  node_ip: 10.43.77.35
  num_train_steps: 2000000
  pid: 283289
  policy:
    actions-max: 0.9986419081687927
    actions-mean: -0.07208061963319778
    actions-min: -0.9997482299804688
    actions-std: 0.7621456980705261
    entropy-mean: -5.924503803253174
    entropy-std: 3.415001392364502
    scales-max: 0.981705904006958
    scales-mean: 0.419854074716568
    scales-min: 0.02332383580505848
    scales-std: 0.1620037704706192
    shifts-max: 3.461142063140869
    shifts-mean: -0.12741078436374664
    shifts-min: -3.4612221717834473
    shifts-std: 1.3770477771759033
  sampler:
    episodes: 2010
    last-path-return: 14625.952429454279
    max-path-return: 14715.401413105204
    pool-size: 1000000
    total-samples: 2010000
  time_since_restore: 18974.09257030487
  time_this_iter_s: 212.9468457698822
  time_total_s: 18974.09257030487
  times:
    epoch_after_hook: 1.5490222722291946e-06
    epoch_before_hook: 3.146901144646108e-05
    evaluation_metrics: 0.00040742100100032985
    evaluation_paths: 0.6256322109838948
    sample: 14.415487372374628
    timestep_after_hook: 0.034020948311081156
    timestep_before_hook: 0.07895296849892475
    train: 197.3199376076227
    training_metrics: 0.0014940770051907748
    training_paths: 0.07823792300769128
  timestamp: 1652828116
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2000000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.29504147291183475
      reward_ctrl-last-mean: -0.34517892003059386
      reward_ctrl-mean-mean: -0.3391434708559513
      reward_ctrl-median-mean: -0.3405708265304566
      reward_ctrl-range-mean: 0.4817192417383195
      reward_run-first-mean: -0.5539103646209368
      reward_run-last-mean: 15.9441510341901
      reward_run-mean-mean: 14.85011476852848
      reward_run-median-mean: 15.713313172383621
      reward_run-range-mean: 18.111781632844682
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14642.782509616303
    episode-reward-mean: 14510.971297672531
    episode-reward-min: 14261.13395191601
    episode-reward-std: 125.83184154597616
  training_iteration: 80
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 23.19668197631836
    Q_value-mean: 1161.0220947265625
    alpha: 0.43476834893226624
    alpha_loss-mean: 0.00016729693743400276
    policy_loss-mean: -1160.2264404296875
  
== Status ==
Memory usage on this node: 82.4/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     80 |          18974.1 |      79 |      25000 |          2000000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.4318750202655792
  date: 2022-05-17_23-58-49
  done: false
  epoch: 80
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3333211898803711
      reward_ctrl-last-mean: -0.5567660808563233
      reward_ctrl-mean-mean: -0.34425155075192454
      reward_ctrl-median-mean: -0.3482801795005799
      reward_ctrl-range-mean: 0.4807583808898926
      reward_run-first-mean: -0.8650678437928044
      reward_run-last-mean: 16.42934614285423
      reward_run-mean-mean: 15.145929109431144
      reward_run-median-mean: 15.988709549039868
      reward_run-range-mean: 18.842894597657203
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14801.677734375
    episode-reward-mean: 14801.677734375
    episode-reward-min: 14801.677734375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 81
  node_ip: 10.43.77.35
  num_train_steps: 2025000
  pid: 283289
  policy:
    actions-max: 0.9996152520179749
    actions-mean: -0.0914049968123436
    actions-min: -0.9990260601043701
    actions-std: 0.7558092474937439
    entropy-mean: -6.011463165283203
    entropy-std: 4.017935752868652
    scales-max: 0.7919486165046692
    scales-mean: 0.4137782156467438
    scales-min: 0.025159334763884544
    scales-std: 0.1601002961397171
    shifts-max: 3.774954080581665
    shifts-mean: -0.14847217500209808
    shifts-min: -2.726907730102539
    shifts-std: 1.3861838579177856
  sampler:
    episodes: 2035
    last-path-return: 14493.577934780158
    max-path-return: 14715.401413105204
    pool-size: 1000000
    total-samples: 2035000
  time_since_restore: 19187.383239507675
  time_this_iter_s: 213.29066920280457
  time_total_s: 19187.383239507675
  times:
    epoch_after_hook: 1.4920078683644533e-06
    epoch_before_hook: 3.401999128982425e-05
    evaluation_metrics: 0.00040560500929132104
    evaluation_paths: 0.5004581660032272
    sample: 14.580644867703086
    timestep_after_hook: 0.03421178658027202
    timestep_before_hook: 0.07877770680352114
    train: 197.62368125127978
    training_metrics: 0.001493788993684575
    training_paths: 0.07693454800755717
  timestamp: 1652828329
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2025000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3366143548488617
      reward_ctrl-last-mean: -0.3980514311790467
      reward_ctrl-mean-mean: -0.35164300523445013
      reward_ctrl-median-mean: -0.35415733575820924
      reward_ctrl-range-mean: 0.47768737748265266
      reward_run-first-mean: -0.40405836096788317
      reward_run-last-mean: 14.422921967467232
      reward_run-mean-mean: 14.252195852293259
      reward_run-median-mean: 15.215729104653866
      reward_run-range-mean: 18.107601390734224
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14705.748328427255
    episode-reward-mean: 13900.552847058807
    episode-reward-min: 8050.542780433508
    episode-reward-std: 1951.668469249243
  training_iteration: 81
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 23.099105834960938
    Q_value-mean: 1167.774658203125
    alpha: 0.43578967452049255
    alpha_loss-mean: 0.0002182796160923317
    policy_loss-mean: -1166.9478759765625
  
== Status ==
Memory usage on this node: 82.4/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     81 |          19187.4 |      80 |      25000 |          2025000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.4276622235774994
  date: 2022-05-18_00-02-22
  done: false
  epoch: 81
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.17933260202407839
      reward_ctrl-last-mean: -0.3789769411087036
      reward_ctrl-mean-mean: -0.3341120217263699
      reward_ctrl-median-mean: -0.3379951238632203
      reward_ctrl-range-mean: 0.4618413388729096
      reward_run-first-mean: -0.272728989398837
      reward_run-last-mean: 15.401024674233668
      reward_run-mean-mean: 14.997073726711697
      reward_run-median-mean: 15.71640845159493
      reward_run-range-mean: 17.730978185716918
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14662.9619140625
    episode-reward-mean: 14662.9619140625
    episode-reward-min: 14662.9619140625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 82
  node_ip: 10.43.77.35
  num_train_steps: 2050000
  pid: 283289
  policy:
    actions-max: 0.9999334812164307
    actions-mean: -0.07103759795427322
    actions-min: -0.9998509883880615
    actions-std: 0.7550208568572998
    entropy-mean: -5.57573938369751
    entropy-std: 3.608753204345703
    scales-max: 1.0397435426712036
    scales-mean: 0.4209998548030853
    scales-min: 0.028697630390524864
    scales-std: 0.16720964014530182
    shifts-max: 4.31387996673584
    shifts-mean: -0.14896178245544434
    shifts-min: -3.246067523956299
    shifts-std: 1.3596179485321045
  sampler:
    episodes: 2060
    last-path-return: 14741.963621085146
    max-path-return: 14741.963621085146
    pool-size: 1000000
    total-samples: 2060000
  time_since_restore: 19400.29594016075
  time_this_iter_s: 212.91270065307617
  time_total_s: 19400.29594016075
  times:
    epoch_after_hook: 1.5200057532638311e-06
    epoch_before_hook: 2.999801654368639e-05
    evaluation_metrics: 0.0004049290146213025
    evaluation_paths: 0.4947801759990398
    sample: 14.503629813785665
    timestep_after_hook: 0.03424161995644681
    timestep_before_hook: 0.08024435688275844
    train: 197.32603558327537
    training_metrics: 0.0015297890058718622
    training_paths: 0.07589897501748055
  timestamp: 1652828542
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2050000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.337686505317688
      reward_ctrl-last-mean: -0.29440958976745607
      reward_ctrl-mean-mean: -0.3411457588762045
      reward_ctrl-median-mean: -0.3432459890842438
      reward_ctrl-range-mean: 0.47668525159358976
      reward_run-first-mean: -0.6709526109168563
      reward_run-last-mean: 16.222644037068903
      reward_run-mean-mean: 14.922863061608723
      reward_run-median-mean: 15.79430208404969
      reward_run-range-mean: 18.27768409808425
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14741.96362108514
    episode-reward-mean: 14581.717302732515
    episode-reward-min: 14357.534610671435
    episode-reward-std: 136.94481071251917
  training_iteration: 82
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 24.487085342407227
    Q_value-mean: 1173.152587890625
    alpha: 0.4368884861469269
    alpha_loss-mean: 0.00023794014123268425
    policy_loss-mean: -1172.289794921875
  
== Status ==
Memory usage on this node: 82.4/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     82 |          19400.3 |      81 |      25000 |          2050000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.44034305214881897
  date: 2022-05-18_00-05-56
  done: false
  epoch: 82
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.37662594318389897
      reward_ctrl-last-mean: -0.18448314666748047
      reward_ctrl-mean-mean: -0.3593231342315674
      reward_ctrl-median-mean: -0.35994758605957033
      reward_ctrl-range-mean: 0.4786228179931641
      reward_run-first-mean: -0.8406241769889063
      reward_run-last-mean: 17.364018894156743
      reward_run-mean-mean: 14.625691210984442
      reward_run-median-mean: 15.868050332884991
      reward_run-range-mean: 18.482009381310885
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14266.3681640625
    episode-reward-mean: 14266.3681640625
    episode-reward-min: 14266.3681640625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 83
  node_ip: 10.43.77.35
  num_train_steps: 2075000
  pid: 283289
  policy:
    actions-max: 0.9999944567680359
    actions-mean: -0.04816519096493721
    actions-min: -0.9986894726753235
    actions-std: 0.7779595851898193
    entropy-mean: -6.273547172546387
    entropy-std: 3.8010947704315186
    scales-max: 1.2209936380386353
    scales-mean: 0.43451571464538574
    scales-min: 0.03161940723657608
    scales-std: 0.16523972153663635
    shifts-max: 3.7917892932891846
    shifts-mean: -0.07273128628730774
    shifts-min: -2.8616151809692383
    shifts-std: 1.4370063543319702
  sampler:
    episodes: 2085
    last-path-return: 14727.601348517655
    max-path-return: 14741.963621085146
    pool-size: 1000000
    total-samples: 2085000
  time_since_restore: 19613.642966270447
  time_this_iter_s: 213.34702610969543
  time_total_s: 19613.642966270447
  times:
    epoch_after_hook: 1.4589750207960606e-06
    epoch_before_hook: 3.375799860805273e-05
    evaluation_metrics: 0.0004060329811181873
    evaluation_paths: 0.4941135559929535
    sample: 14.560087357327575
    timestep_after_hook: 0.034117793053155765
    timestep_before_hook: 0.0793371711333748
    train: 197.7070440670068
    training_metrics: 0.0015754949999973178
    training_paths: 0.07785569000407122
  timestamp: 1652828756
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2075000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.25963874578475954
      reward_ctrl-last-mean: -0.38068579673767095
      reward_ctrl-mean-mean: -0.3407047267580033
      reward_ctrl-median-mean: -0.3431879448890686
      reward_ctrl-range-mean: 0.4747791802883148
      reward_run-first-mean: -0.4760694715011253
      reward_run-last-mean: 15.933139747647147
      reward_run-mean-mean: 14.895104442184007
      reward_run-median-mean: 15.776168542827264
      reward_run-range-mean: 18.216023120830002
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14727.601348517646
    episode-reward-mean: 14554.399715426005
    episode-reward-min: 14359.536920152
    episode-reward-std: 111.3951837242266
  training_iteration: 83
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 23.00617027282715
    Q_value-mean: 1180.8885498046875
    alpha: 0.43024659156799316
    alpha_loss-mean: -0.00041820493061095476
    policy_loss-mean: -1180.00830078125
  
== Status ==
Memory usage on this node: 80.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     83 |          19613.6 |      82 |      25000 |          2075000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.42054036259651184
  date: 2022-05-18_00-09-29
  done: false
  epoch: 83
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3986980438232422
      reward_ctrl-last-mean: -0.36430010795593265
      reward_ctrl-mean-mean: -0.3450482335567474
      reward_ctrl-median-mean: -0.3523072361946106
      reward_ctrl-range-mean: 0.479391098022461
      reward_run-first-mean: -0.7494146563150328
      reward_run-last-mean: 16.17956513775198
      reward_run-mean-mean: 15.060905695254165
      reward_run-median-mean: 15.988599900731657
      reward_run-range-mean: 18.226768394578478
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14715.857421875
    episode-reward-mean: 14715.857421875
    episode-reward-min: 14715.857421875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 84
  node_ip: 10.43.77.35
  num_train_steps: 2100000
  pid: 283289
  policy:
    actions-max: 0.9988296627998352
    actions-mean: -0.06838590651750565
    actions-min: -0.9991925954818726
    actions-std: 0.7515565156936646
    entropy-mean: -5.91636848449707
    entropy-std: 3.8218207359313965
    scales-max: 0.9393225312232971
    scales-mean: 0.40265917778015137
    scales-min: 0.023681635037064552
    scales-std: 0.17003434896469116
    shifts-max: 3.1448888778686523
    shifts-mean: -0.14148414134979248
    shifts-min: -3.090714454650879
    shifts-std: 1.3446180820465088
  sampler:
    episodes: 2110
    last-path-return: 14636.602736753135
    max-path-return: 14767.11076145816
    pool-size: 1000000
    total-samples: 2110000
  time_since_restore: 19826.940287590027
  time_this_iter_s: 213.29732131958008
  time_total_s: 19826.940287590027
  times:
    epoch_after_hook: 1.6449776012450457e-06
    epoch_before_hook: 2.9371993150562048e-05
    evaluation_metrics: 0.0004020890046376735
    evaluation_paths: 0.49520686198957264
    sample: 14.47506961930776
    timestep_after_hook: 0.0343075665878132
    timestep_before_hook: 0.08026035575312562
    train: 197.74247153275064
    training_metrics: 0.001537803007522598
    training_paths: 0.0746117550006602
  timestamp: 1652828969
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2100000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.27912445306777955
      reward_ctrl-last-mean: -0.3222670483589173
      reward_ctrl-mean-mean: -0.3397965832263231
      reward_ctrl-median-mean: -0.34170670509338386
      reward_ctrl-range-mean: 0.4797499263286591
      reward_run-first-mean: -0.43948965986835786
      reward_run-last-mean: 14.615175464998345
      reward_run-mean-mean: 13.735063033474239
      reward_run-median-mean: 14.276476595125573
      reward_run-range-mean: 18.2233280224144
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14767.110761458174
    episode-reward-mean: 13395.266450247917
    episode-reward-min: 2825.854944284427
    episode-reward-std: 3526.6354255744895
  training_iteration: 84
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 22.684200286865234
    Q_value-mean: 1188.6878662109375
    alpha: 0.4279356896877289
    alpha_loss-mean: 0.0006851440411992371
    policy_loss-mean: -1187.77685546875
  
== Status ==
Memory usage on this node: 80.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     84 |          19826.9 |      83 |      25000 |          2100000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.41998621821403503
  date: 2022-05-18_00-13-03
  done: false
  epoch: 84
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2831505537033081
      reward_ctrl-last-mean: -0.4593932628631592
      reward_ctrl-mean-mean: -0.34312100704908377
      reward_ctrl-median-mean: -0.34205149412155156
      reward_ctrl-range-mean: 0.4597933411598206
      reward_run-first-mean: -0.06211481394282181
      reward_run-last-mean: 15.61265646990023
      reward_run-mean-mean: 15.075498790054898
      reward_run-median-mean: 15.940224930027256
      reward_run-range-mean: 17.754079841159495
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14732.3779296875
    episode-reward-mean: 14732.3779296875
    episode-reward-min: 14732.3779296875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 85
  node_ip: 10.43.77.35
  num_train_steps: 2125000
  pid: 283289
  policy:
    actions-max: 0.9991084337234497
    actions-mean: -0.08445940166711807
    actions-min: -0.9990086555480957
    actions-std: 0.7616221904754639
    entropy-mean: -6.004846572875977
    entropy-std: 3.578007698059082
    scales-max: 0.9726710319519043
    scales-mean: 0.41552749276161194
    scales-min: 0.02595713920891285
    scales-std: 0.16669976711273193
    shifts-max: 3.7205517292022705
    shifts-mean: -0.09986745566129684
    shifts-min: -2.838819980621338
    shifts-std: 1.3660175800323486
  sampler:
    episodes: 2135
    last-path-return: 14689.134910609066
    max-path-return: 14805.569782726467
    pool-size: 1000000
    total-samples: 2135000
  time_since_restore: 20040.95754790306
  time_this_iter_s: 214.01726031303406
  time_total_s: 20040.95754790306
  times:
    epoch_after_hook: 1.6829872038215399e-06
    epoch_before_hook: 3.152398858219385e-05
    evaluation_metrics: 0.000425701990025118
    evaluation_paths: 0.49992282697348855
    sample: 14.527533294458408
    timestep_after_hook: 0.0344492505537346
    timestep_before_hook: 0.07965302694356069
    train: 198.4018123151618
    training_metrics: 0.0016377270221710205
    training_paths: 0.07880658400245011
  timestamp: 1652829183
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2125000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.29440473079681395
      reward_ctrl-last-mean: -0.3670282924175263
      reward_ctrl-mean-mean: -0.34229037134051327
      reward_ctrl-median-mean: -0.3457273542881012
      reward_ctrl-range-mean: 0.4594966101646424
      reward_run-first-mean: -0.4540873994083029
      reward_run-last-mean: 16.15583221661973
      reward_run-mean-mean: 14.93648532181479
      reward_run-median-mean: 15.793999423494114
      reward_run-range-mean: 18.210592848268465
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14750.879438587805
    episode-reward-mean: 14594.194950474277
    episode-reward-min: 14156.220188340496
    episode-reward-std: 161.7020819472968
  training_iteration: 85
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 23.338172912597656
    Q_value-mean: 1195.3482666015625
    alpha: 0.42263710498809814
    alpha_loss-mean: 7.150783494580537e-05
    policy_loss-mean: -1194.4298095703125
  
== Status ==
Memory usage on this node: 80.4/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     85 |            20041 |      84 |      25000 |          2125000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.41716697812080383
  date: 2022-05-18_00-16-37
  done: false
  epoch: 85
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.1915748119354248
      reward_ctrl-last-mean: -0.3481021881103516
      reward_ctrl-mean-mean: -0.34591628049016004
      reward_ctrl-median-mean: -0.3556602120399476
      reward_ctrl-range-mean: 0.4535012722015381
      reward_run-first-mean: -0.14864589897003344
      reward_run-last-mean: 17.08077003505423
      reward_run-mean-mean: 15.028252580806212
      reward_run-median-mean: 15.904875779961287
      reward_run-range-mean: 17.529833889752826
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14682.3359375
    episode-reward-mean: 14682.3359375
    episode-reward-min: 14682.3359375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 86
  node_ip: 10.43.77.35
  num_train_steps: 2150000
  pid: 283289
  policy:
    actions-max: 0.9997944831848145
    actions-mean: -0.07874421030282974
    actions-min: -0.998201310634613
    actions-std: 0.7514839768409729
    entropy-mean: -5.7572021484375
    entropy-std: 3.367115020751953
    scales-max: 0.8231271505355835
    scales-mean: 0.41612136363983154
    scales-min: 0.022324560210108757
    scales-std: 0.1643408238887787
    shifts-max: 3.7759711742401123
    shifts-mean: -0.1282961368560791
    shifts-min: -2.6053121089935303
    shifts-std: 1.3608509302139282
  sampler:
    episodes: 2160
    last-path-return: 14755.737023790673
    max-path-return: 14880.164608243871
    pool-size: 1000000
    total-samples: 2160000
  time_since_restore: 20254.384293794632
  time_this_iter_s: 213.42674589157104
  time_total_s: 20254.384293794632
  times:
    epoch_after_hook: 1.781998435035348e-06
    epoch_before_hook: 3.463600296527147e-05
    evaluation_metrics: 0.0004571430035866797
    evaluation_paths: 0.49678135899011977
    sample: 14.52276482063462
    timestep_after_hook: 0.03447704442078248
    timestep_before_hook: 0.07960977038601413
    train: 197.8181445155351
    training_metrics: 0.0015444330056197941
    training_paths: 0.07890566700370982
  timestamp: 1652829397
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2150000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2685513889789582
      reward_ctrl-last-mean: -0.3761680769920349
      reward_ctrl-mean-mean: -0.3433928740370274
      reward_ctrl-median-mean: -0.3472521531581879
      reward_ctrl-range-mean: 0.4721596211194992
      reward_run-first-mean: -0.6139510607398669
      reward_run-last-mean: 16.312725104045057
      reward_run-mean-mean: 15.02402630418953
      reward_run-median-mean: 15.850916933647369
      reward_run-range-mean: 18.305514115956132
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14880.164608243855
    episode-reward-mean: 14680.633430152502
    episode-reward-min: 14335.157926752421
    episode-reward-std: 144.14149676540057
  training_iteration: 86
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 21.857177734375
    Q_value-mean: 1203.3731689453125
    alpha: 0.41965988278388977
    alpha_loss-mean: 0.00013916387979406863
    policy_loss-mean: -1202.42431640625
  
== Status ==
Memory usage on this node: 80.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     86 |          20254.4 |      85 |      25000 |          2150000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.40963631868362427
  date: 2022-05-18_00-20-10
  done: false
  epoch: 86
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.13167208433151245
      reward_ctrl-last-mean: -0.2556422233581543
      reward_ctrl-mean-mean: -0.3441131606519222
      reward_ctrl-median-mean: -0.3392827987670899
      reward_ctrl-range-mean: 0.48736346364021305
      reward_run-first-mean: -0.38609613997754033
      reward_run-last-mean: 16.04246892886522
      reward_run-mean-mean: 15.16760654306686
      reward_run-median-mean: 15.959933081817894
      reward_run-range-mean: 18.13038488520468
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14823.494140625
    episode-reward-mean: 14823.494140625
    episode-reward-min: 14823.494140625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 87
  node_ip: 10.43.77.35
  num_train_steps: 2175000
  pid: 283289
  policy:
    actions-max: 0.9982823729515076
    actions-mean: -0.06004684790968895
    actions-min: -0.9988057613372803
    actions-std: 0.7542783617973328
    entropy-mean: -5.879854202270508
    entropy-std: 3.7152068614959717
    scales-max: 0.8369747996330261
    scales-mean: 0.40951910614967346
    scales-min: 0.02523604780435562
    scales-std: 0.1693343222141266
    shifts-max: 3.1792666912078857
    shifts-mean: -0.08146503567695618
    shifts-min: -3.2170422077178955
    shifts-std: 1.3788180351257324
  sampler:
    episodes: 2185
    last-path-return: 14878.073008905685
    max-path-return: 14880.164608243871
    pool-size: 1000000
    total-samples: 2185000
  time_since_restore: 20467.958829641342
  time_this_iter_s: 213.5745358467102
  time_total_s: 20467.958829641342
  times:
    epoch_after_hook: 1.5900004655122757e-06
    epoch_before_hook: 4.333799006417394e-05
    evaluation_metrics: 0.00040981400525197387
    evaluation_paths: 0.4963506040221546
    sample: 14.579885583691066
    timestep_after_hook: 0.034686984261497855
    timestep_before_hook: 0.08024618998751976
    train: 197.9107782857318
    training_metrics: 0.0015391220222227275
    training_paths: 0.07589815399842337
  timestamp: 1652829610
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2175000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.27238277196884153
      reward_ctrl-last-mean: -0.34259479761123657
      reward_ctrl-mean-mean: -0.34443596790075304
      reward_ctrl-median-mean: -0.34843788623809824
      reward_ctrl-range-mean: 0.4770446985960007
      reward_run-first-mean: -0.3470852803315081
      reward_run-last-mean: 16.329306947491887
      reward_run-mean-mean: 15.067603698559575
      reward_run-median-mean: 15.877292865000285
      reward_run-range-mean: 18.231452930599765
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14878.073008905685
    episode-reward-mean: 14723.16773065882
    episode-reward-min: 14479.274339906551
    episode-reward-std: 110.40924083271462
  training_iteration: 87
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 20.68079948425293
    Q_value-mean: 1211.524169921875
    alpha: 0.41340553760528564
    alpha_loss-mean: 0.0002472373889759183
    policy_loss-mean: -1210.5467529296875
  
== Status ==
Memory usage on this node: 80.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     87 |            20468 |      86 |      25000 |          2175000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3985052704811096
  date: 2022-05-18_00-23-44
  done: false
  epoch: 87
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2421527147293091
      reward_ctrl-last-mean: -0.5159015655517578
      reward_ctrl-mean-mean: -0.3538530341565609
      reward_ctrl-median-mean: -0.35267112255096433
      reward_ctrl-range-mean: 0.47944334149360657
      reward_run-first-mean: -0.44776199376689735
      reward_run-last-mean: 16.003093690610513
      reward_run-mean-mean: 15.06541864692371
      reward_run-median-mean: 15.925065421158706
      reward_run-range-mean: 18.620088322713233
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14711.5654296875
    episode-reward-mean: 14711.5654296875
    episode-reward-min: 14711.5654296875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 88
  node_ip: 10.43.77.35
  num_train_steps: 2200000
  pid: 283289
  policy:
    actions-max: 0.9998862147331238
    actions-mean: -0.05208860710263252
    actions-min: -0.9967908263206482
    actions-std: 0.7558833360671997
    entropy-mean: -5.739002227783203
    entropy-std: 3.8328216075897217
    scales-max: 0.9568442702293396
    scales-mean: 0.4188230335712433
    scales-min: 0.024852033704519272
    scales-std: 0.16312213242053986
    shifts-max: 4.807919979095459
    shifts-mean: -0.07494694739580154
    shifts-min: -2.6301794052124023
    shifts-std: 1.3670685291290283
  sampler:
    episodes: 2210
    last-path-return: 14667.277295806934
    max-path-return: 14880.164608243871
    pool-size: 1000000
    total-samples: 2210000
  time_since_restore: 20681.298398017883
  time_this_iter_s: 213.33956837654114
  time_total_s: 20681.298398017883
  times:
    epoch_after_hook: 1.9849976524710655e-06
    epoch_before_hook: 3.313500201329589e-05
    evaluation_metrics: 0.0004117290081921965
    evaluation_paths: 0.527414816984674
    sample: 14.55553284479538
    timestep_after_hook: 0.03463721668231301
    timestep_before_hook: 0.08021488250233233
    train: 197.66906639467925
    training_metrics: 0.001537921983981505
    training_paths: 0.07655228700605221
  timestamp: 1652829824
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2200000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3015681779384613
      reward_ctrl-last-mean: -0.36163218736648567
      reward_ctrl-mean-mean: -0.3449958123362064
      reward_ctrl-median-mean: -0.3477552556991578
      reward_ctrl-range-mean: 0.48710910856723794
      reward_run-first-mean: -0.5759320603402923
      reward_run-last-mean: 16.073026737378086
      reward_run-mean-mean: 15.077045329674425
      reward_run-median-mean: 15.898437854859466
      reward_run-range-mean: 18.332930352925864
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14857.155991462583
    episode-reward-mean: 14732.049517338219
    episode-reward-min: 14599.208409979376
    episode-reward-std: 84.55709567752521
  training_iteration: 88
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 19.201690673828125
    Q_value-mean: 1219.2840576171875
    alpha: 0.4089250862598419
    alpha_loss-mean: 0.0004457433824427426
    policy_loss-mean: -1218.27978515625
  
== Status ==
Memory usage on this node: 80.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     88 |          20681.3 |      87 |      25000 |          2200000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3957633376121521
  date: 2022-05-18_00-27-17
  done: false
  epoch: 88
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.23701508045196534
      reward_ctrl-last-mean: -0.4928434848785401
      reward_ctrl-mean-mean: -0.3526775374233723
      reward_ctrl-median-mean: -0.34813232421875
      reward_ctrl-range-mean: 0.4807204961776734
      reward_run-first-mean: -0.5848325073691807
      reward_run-last-mean: 15.97668014253486
      reward_run-mean-mean: 15.144015067473315
      reward_run-median-mean: 16.113664080091326
      reward_run-range-mean: 18.311904832302215
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14791.3369140625
    episode-reward-mean: 14791.3369140625
    episode-reward-min: 14791.3369140625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 89
  node_ip: 10.43.77.35
  num_train_steps: 2225000
  pid: 283289
  policy:
    actions-max: 0.9997521042823792
    actions-mean: -0.08422105759382248
    actions-min: -0.9988089799880981
    actions-std: 0.7579125761985779
    entropy-mean: -6.1200270652771
    entropy-std: 4.03231954574585
    scales-max: 0.8532155752182007
    scales-mean: 0.41701623797416687
    scales-min: 0.023936809971928596
    scales-std: 0.16439278423786163
    shifts-max: 3.7069647312164307
    shifts-mean: -0.09379959851503372
    shifts-min: -3.180553913116455
    shifts-std: 1.3833842277526855
  sampler:
    episodes: 2235
    last-path-return: 14587.376815013122
    max-path-return: 14880.164608243871
    pool-size: 1000000
    total-samples: 2235000
  time_since_restore: 20894.95281124115
  time_this_iter_s: 213.6544132232666
  time_total_s: 20894.95281124115
  times:
    epoch_after_hook: 1.715001417323947e-06
    epoch_before_hook: 3.5559991374611855e-05
    evaluation_metrics: 0.0004070839786436409
    evaluation_paths: 0.591860718006501
    sample: 14.508328527736012
    timestep_after_hook: 0.03472978941863403
    timestep_before_hook: 0.08000679008546285
    train: 197.93536680011312
    training_metrics: 0.0014718809979967773
    training_paths: 0.075896141002886
  timestamp: 1652830037
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2225000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.32704152584075935
      reward_ctrl-last-mean: -0.34783905506134033
      reward_ctrl-mean-mean: -0.3454649423837662
      reward_ctrl-median-mean: -0.34806082487106327
      reward_ctrl-range-mean: 0.47522706151008604
      reward_run-first-mean: -0.6751382615890122
      reward_run-last-mean: 16.369718636241032
      reward_run-mean-mean: 14.99592739639328
      reward_run-median-mean: 15.87957928653995
      reward_run-range-mean: 18.328988877673932
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14875.278533380124
    episode-reward-mean: 14650.462454009516
    episode-reward-min: 14246.479373281141
    episode-reward-std: 212.69157625193162
  training_iteration: 89
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 18.8892879486084
    Q_value-mean: 1226.3951416015625
    alpha: 0.40801408886909485
    alpha_loss-mean: 8.65623660502024e-05
    policy_loss-mean: -1225.345458984375
  
== Status ==
Memory usage on this node: 80.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     89 |            20895 |      88 |      25000 |          2225000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.39374449849128723
  date: 2022-05-18_00-30-51
  done: false
  epoch: 89
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.19108405113220217
      reward_ctrl-last-mean: -0.3865010976791382
      reward_ctrl-mean-mean: -0.3432941062808037
      reward_ctrl-median-mean: -0.3455120325088501
      reward_ctrl-range-mean: 0.46528960466384894
      reward_run-first-mean: -0.4893301032610728
      reward_run-last-mean: 16.53317275073732
      reward_run-mean-mean: 15.151713895696947
      reward_run-median-mean: 15.87666214468726
      reward_run-range-mean: 18.40219162117027
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14808.419921875
    episode-reward-mean: 14808.419921875
    episode-reward-min: 14808.419921875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 90
  node_ip: 10.43.77.35
  num_train_steps: 2250000
  pid: 283289
  policy:
    actions-max: 0.999707818031311
    actions-mean: -0.06566555052995682
    actions-min: -0.9981209635734558
    actions-std: 0.7562971115112305
    entropy-mean: -5.805234909057617
    entropy-std: 3.685547351837158
    scales-max: 1.0194932222366333
    scales-mean: 0.40055274963378906
    scales-min: 0.031802479177713394
    scales-std: 0.1663697212934494
    shifts-max: 3.57776141166687
    shifts-mean: -0.11527568101882935
    shifts-min: -2.617645740509033
    shifts-std: 1.36162269115448
  sampler:
    episodes: 2260
    last-path-return: 14707.632024473744
    max-path-return: 14908.037824964285
    pool-size: 1000000
    total-samples: 2260000
  time_since_restore: 21108.291600465775
  time_this_iter_s: 213.33878922462463
  time_total_s: 21108.291600465775
  times:
    epoch_after_hook: 1.7669808585196733e-06
    epoch_before_hook: 4.065601387992501e-05
    evaluation_metrics: 0.00044039098429493606
    evaluation_paths: 0.5279657370119821
    sample: 14.512390748539474
    timestep_after_hook: 0.03478242494747974
    timestep_before_hook: 0.07910723277018405
    train: 197.70791442046175
    training_metrics: 0.0015308820002246648
    training_paths: 0.0785990220028907
  timestamp: 1652830251
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2250000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.27456116437911987
      reward_ctrl-last-mean: -0.34517887234687805
      reward_ctrl-mean-mean: -0.3455280804440379
      reward_ctrl-median-mean: -0.3485885918140411
      reward_ctrl-range-mean: 0.4862851455807686
      reward_run-first-mean: -0.43575663296534745
      reward_run-last-mean: 16.130505317259576
      reward_run-mean-mean: 15.041148358414143
      reward_run-median-mean: 15.91101808238227
      reward_run-range-mean: 18.253681779909655
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14873.578692374615
    episode-reward-mean: 14695.620277970107
    episode-reward-min: 14329.880806234713
    episode-reward-std: 139.99504414383358
  training_iteration: 90
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 18.18297576904297
    Q_value-mean: 1233.1854248046875
    alpha: 0.40440407395362854
    alpha_loss-mean: 0.00012414553202688694
    policy_loss-mean: -1232.0897216796875
  
== Status ==
Memory usage on this node: 80.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     90 |          21108.3 |      89 |      25000 |          2250000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3996393382549286
  date: 2022-05-18_00-34-24
  done: false
  epoch: 90
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.25651257038116454
      reward_ctrl-last-mean: -0.404729175567627
      reward_ctrl-mean-mean: -0.33840801177024843
      reward_ctrl-median-mean: -0.3414965271949768
      reward_ctrl-range-mean: 0.4916201591491699
      reward_run-first-mean: -0.4639548496294568
      reward_run-last-mean: 17.191479993966823
      reward_run-mean-mean: 14.80899747009684
      reward_run-median-mean: 15.639957466509031
      reward_run-range-mean: 18.429363276384244
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14470.58984375
    episode-reward-mean: 14470.58984375
    episode-reward-min: 14470.58984375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 91
  node_ip: 10.43.77.35
  num_train_steps: 2275000
  pid: 283289
  policy:
    actions-max: 0.9985275864601135
    actions-mean: -0.08713053911924362
    actions-min: -0.999045193195343
    actions-std: 0.7389442920684814
    entropy-mean: -5.386902332305908
    entropy-std: 3.257838010787964
    scales-max: 0.8029352426528931
    scales-mean: 0.41176000237464905
    scales-min: 0.020054930821061134
    scales-std: 0.1695791482925415
    shifts-max: 2.9730982780456543
    shifts-mean: -0.1541597992181778
    shifts-min: -2.885861396789551
    shifts-std: 1.311873435974121
  sampler:
    episodes: 2285
    last-path-return: 14769.07667953646
    max-path-return: 14908.037824964285
    pool-size: 1000000
    total-samples: 2285000
  time_since_restore: 21321.624768972397
  time_this_iter_s: 213.33316850662231
  time_total_s: 21321.624768972397
  times:
    epoch_after_hook: 1.8859864212572575e-06
    epoch_before_hook: 3.778599784709513e-05
    evaluation_metrics: 0.0004053330048918724
    evaluation_paths: 0.4978427210007794
    sample: 14.507317535899347
    timestep_after_hook: 0.034726095967926085
    timestep_before_hook: 0.0788432024710346
    train: 197.62834151583957
    training_metrics: 0.0014763959916308522
    training_paths: 0.18865710301906802
  timestamp: 1652830464
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2275000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3005510842800141
      reward_ctrl-last-mean: -0.30575598001480103
      reward_ctrl-mean-mean: -0.3477340015587211
      reward_ctrl-median-mean: -0.3502908289432526
      reward_ctrl-range-mean: 0.48452115088701253
      reward_run-first-mean: -0.6131758716223261
      reward_run-last-mean: 16.740208069265236
      reward_run-mean-mean: 15.115953673856016
      reward_run-median-mean: 15.943006623096906
      reward_run-range-mean: 18.430476138028016
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14891.656072190162
    episode-reward-mean: 14768.219672297293
    episode-reward-min: 14408.190825624943
    episode-reward-std: 137.3674365593852
  training_iteration: 91
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 17.51010513305664
    Q_value-mean: 1241.581787109375
    alpha: 0.39564305543899536
    alpha_loss-mean: -0.00018587974773254246
    policy_loss-mean: -1240.490478515625
  
== Status ==
Memory usage on this node: 80.5/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     91 |          21321.6 |      90 |      25000 |          2275000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3933064341545105
  date: 2022-05-18_00-37-55
  done: false
  epoch: 91
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.15387606620788574
      reward_ctrl-last-mean: -0.5317872524261474
      reward_ctrl-mean-mean: -0.34386204830408096
      reward_ctrl-median-mean: -0.34564627408981324
      reward_ctrl-range-mean: 0.43902842998504643
      reward_run-first-mean: -0.33562785790873323
      reward_run-last-mean: 15.74638440445824
      reward_run-mean-mean: 15.284130518126746
      reward_run-median-mean: 16.05037637916041
      reward_run-range-mean: 18.223221250295246
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14940.267578125
    episode-reward-mean: 14940.267578125
    episode-reward-min: 14940.267578125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 92
  node_ip: 10.43.77.35
  num_train_steps: 2300000
  pid: 283289
  policy:
    actions-max: 0.9992337822914124
    actions-mean: -0.04716235771775246
    actions-min: -0.9996420741081238
    actions-std: 0.7579578757286072
    entropy-mean: -6.022902488708496
    entropy-std: 3.3810606002807617
    scales-max: 1.3442051410675049
    scales-mean: 0.42386746406555176
    scales-min: 0.018070386722683907
    scales-std: 0.1678587794303894
    shifts-max: 3.406151533126831
    shifts-mean: -0.07918866723775864
    shifts-min: -3.0972743034362793
    shifts-std: 1.3831770420074463
  sampler:
    episodes: 2310
    last-path-return: 14891.71380405783
    max-path-return: 14976.635367162433
    pool-size: 1000000
    total-samples: 2310000
  time_since_restore: 21532.328163146973
  time_this_iter_s: 210.7033941745758
  time_total_s: 21532.328163146973
  times:
    epoch_after_hook: 1.5440164133906364e-06
    epoch_before_hook: 3.0351016903296113e-05
    evaluation_metrics: 0.00040749998879618943
    evaluation_paths: 0.48943793901707977
    sample: 13.95118921075482
    timestep_after_hook: 0.03361939324531704
    timestep_before_hook: 0.07758286883472465
    train: 195.59488969884114
    training_metrics: 0.0014550679770763963
    training_paths: 0.16731375400559045
  timestamp: 1652830675
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2300000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.23211044251918794
      reward_ctrl-last-mean: -0.3072144711017609
      reward_ctrl-mean-mean: -0.3493895455181598
      reward_ctrl-median-mean: -0.3523296809196473
      reward_ctrl-range-mean: 0.4863317054510118
      reward_run-first-mean: -0.48595179788658094
      reward_run-last-mean: 16.738557058097513
      reward_run-mean-mean: 15.089311248055889
      reward_run-median-mean: 15.938383721671215
      reward_run-range-mean: 18.41445387107062
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14957.689317647968
    episode-reward-mean: 14739.92170253773
    episode-reward-min: 14336.419785085334
    episode-reward-std: 206.42023108202477
  training_iteration: 92
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 17.563316345214844
    Q_value-mean: 1250.1927490234375
    alpha: 0.38861533999443054
    alpha_loss-mean: 0.0002239679015474394
    policy_loss-mean: -1249.099609375
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     92 |          21532.3 |      91 |      25000 |          2300000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.37381407618522644
  date: 2022-05-18_00-41-22
  done: false
  epoch: 92
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.33934614658355716
      reward_ctrl-last-mean: -0.36743874549865724
      reward_ctrl-mean-mean: -0.34336776588559154
      reward_ctrl-median-mean: -0.3465705752372742
      reward_ctrl-range-mean: 0.4764732778072357
      reward_run-first-mean: -0.5669136129773692
      reward_run-last-mean: 15.624229726297472
      reward_run-mean-mean: 15.26209319473795
      reward_run-median-mean: 15.974224503599999
      reward_run-range-mean: 18.649586447138358
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14918.7265625
    episode-reward-mean: 14918.7265625
    episode-reward-min: 14918.7265625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 93
  node_ip: 10.43.77.35
  num_train_steps: 2325000
  pid: 283289
  policy:
    actions-max: 0.9981138110160828
    actions-mean: -0.06785526871681213
    actions-min: -0.9999369382858276
    actions-std: 0.7500039339065552
    entropy-mean: -5.738386154174805
    entropy-std: 3.555365800857544
    scales-max: 1.0551800727844238
    scales-mean: 0.420235276222229
    scales-min: 0.02788466215133667
    scales-std: 0.16977573931217194
    shifts-max: 3.085035800933838
    shifts-mean: -0.13368399441242218
    shifts-min: -4.420382022857666
    shifts-std: 1.3470383882522583
  sampler:
    episodes: 2335
    last-path-return: 14770.14769089281
    max-path-return: 14976.635367162433
    pool-size: 1000000
    total-samples: 2335000
  time_since_restore: 21739.303687095642
  time_this_iter_s: 206.97552394866943
  time_total_s: 21739.303687095642
  times:
    epoch_after_hook: 1.6030098777264357e-06
    epoch_before_hook: 2.5815999833866954e-05
    evaluation_metrics: 0.0004023280052933842
    evaluation_paths: 0.5199803569994401
    sample: 13.25277781879413
    timestep_after_hook: 0.032584925880655646
    timestep_before_hook: 0.07650232419837266
    train: 192.54419402446365
    training_metrics: 0.0015411550120916218
    training_paths: 0.1641387410054449
  timestamp: 1652830882
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2325000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2364169251918793
      reward_ctrl-last-mean: -0.34458212375640873
      reward_ctrl-mean-mean: -0.34567935779988773
      reward_ctrl-median-mean: -0.3502994191646576
      reward_ctrl-range-mean: 0.4793516588211061
      reward_run-first-mean: -0.413435396802754
      reward_run-last-mean: 16.530689138598746
      reward_run-mean-mean: 15.10910279417062
      reward_run-median-mean: 15.944245556185933
      reward_run-range-mean: 18.34694918176094
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14880.022506570554
    episode-reward-mean: 14763.423436370733
    episode-reward-min: 14584.65986701828
    episode-reward-std: 87.97117339995563
  training_iteration: 93
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 17.620094299316406
    Q_value-mean: 1256.912841796875
    alpha: 0.3838675916194916
    alpha_loss-mean: 0.0007000666810199618
    policy_loss-mean: -1255.793212890625
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     93 |          21739.3 |      92 |      25000 |          2325000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.37978455424308777
  date: 2022-05-18_00-44-49
  done: false
  epoch: 93
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.34893193244934084
      reward_ctrl-last-mean: -0.24462363719940186
      reward_ctrl-mean-mean: -0.3562771330356598
      reward_ctrl-median-mean: -0.3574384927749634
      reward_ctrl-range-mean: 0.49191035032272334
      reward_run-first-mean: -0.6618695902310708
      reward_run-last-mean: 16.680226219500582
      reward_run-mean-mean: 14.851211974681018
      reward_run-median-mean: 15.838068163455432
      reward_run-range-mean: 18.409755685304752
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14494.935546875
    episode-reward-mean: 14494.935546875
    episode-reward-min: 14494.935546875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 94
  node_ip: 10.43.77.35
  num_train_steps: 2350000
  pid: 283289
  policy:
    actions-max: 0.9993886947631836
    actions-mean: -0.04492777958512306
    actions-min: -0.9979486465454102
    actions-std: 0.7673640847206116
    entropy-mean: -6.142207145690918
    entropy-std: 3.8662760257720947
    scales-max: 0.9722644686698914
    scales-mean: 0.4253608286380768
    scales-min: 0.03102572076022625
    scales-std: 0.1665831059217453
    shifts-max: 3.5488014221191406
    shifts-mean: -0.06310310959815979
    shifts-min: -3.5399112701416016
    shifts-std: 1.370129108428955
  sampler:
    episodes: 2360
    last-path-return: 14883.319445466936
    max-path-return: 14996.245675129587
    pool-size: 1000000
    total-samples: 2360000
  time_since_restore: 21945.799586057663
  time_this_iter_s: 206.49589896202087
  time_total_s: 21945.799586057663
  times:
    epoch_after_hook: 1.4090037439018488e-06
    epoch_before_hook: 2.576899714767933e-05
    evaluation_metrics: 0.00040373901720158756
    evaluation_paths: 0.48655986099038273
    sample: 13.242699519061716
    timestep_after_hook: 0.03266571680433117
    timestep_before_hook: 0.07720269737183116
    train: 192.19625362212537
    training_metrics: 0.0014993660151958466
    training_paths: 0.07431286899372935
  timestamp: 1652831089
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2350000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2732872390747071
      reward_ctrl-last-mean: -0.3992066407203675
      reward_ctrl-mean-mean: -0.3475334373009205
      reward_ctrl-median-mean: -0.35112416625022896
      reward_ctrl-range-mean: 0.48084652543067935
      reward_run-first-mean: -0.5529067282590356
      reward_run-last-mean: 15.81883423899626
      reward_run-mean-mean: 15.087069950011719
      reward_run-median-mean: 15.931758204259282
      reward_run-range-mean: 18.297042322436766
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14883.319445466943
    episode-reward-mean: 14739.5365127108
    episode-reward-min: 14282.512433182708
    episode-reward-std: 161.59632069355126
  training_iteration: 94
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 18.486787796020508
    Q_value-mean: 1265.0791015625
    alpha: 0.37785622477531433
    alpha_loss-mean: -0.00016843991761561483
    policy_loss-mean: -1263.9635009765625
  
== Status ==
Memory usage on this node: 13.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     94 |          21945.8 |      93 |      25000 |          2350000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3584900200366974
  date: 2022-05-18_00-48-15
  done: false
  epoch: 94
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.17530269622802735
      reward_ctrl-last-mean: -0.36300957202911377
      reward_ctrl-mean-mean: -0.35025594680309297
      reward_ctrl-median-mean: -0.3569934248924256
      reward_ctrl-range-mean: 0.47202903032302856
      reward_run-first-mean: -0.8451709848347627
      reward_run-last-mean: 15.825287593820576
      reward_run-mean-mean: 15.071854445633164
      reward_run-median-mean: 15.950772342445134
      reward_run-range-mean: 18.46957151492588
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14721.5986328125
    episode-reward-mean: 14721.5986328125
    episode-reward-min: 14721.5986328125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 95
  node_ip: 10.43.77.35
  num_train_steps: 2375000
  pid: 283289
  policy:
    actions-max: 0.9985104203224182
    actions-mean: -0.061695944517850876
    actions-min: -0.9978103041648865
    actions-std: 0.7540570497512817
    entropy-mean: -6.035633087158203
    entropy-std: 3.2781460285186768
    scales-max: 1.5608593225479126
    scales-mean: 0.4104592800140381
    scales-min: 0.022956375032663345
    scales-std: 0.16566991806030273
    shifts-max: 3.166379928588867
    shifts-mean: -0.10304508358240128
    shifts-min: -2.852933645248413
    shifts-std: 1.3714570999145508
  sampler:
    episodes: 2385
    last-path-return: 14810.111536051734
    max-path-return: 14996.245675129587
    pool-size: 1000000
    total-samples: 2385000
  time_since_restore: 22152.50085377693
  time_this_iter_s: 206.7012677192688
  time_total_s: 22152.50085377693
  times:
    epoch_after_hook: 1.5969853848218918e-06
    epoch_before_hook: 2.3922999389469624e-05
    evaluation_metrics: 0.0004046829999424517
    evaluation_paths: 0.49377297001774423
    sample: 13.359136785933515
    timestep_after_hook: 0.032639510347507894
    timestep_before_hook: 0.07726588740479201
    train: 192.18937286394066
    training_metrics: 0.0014776359894312918
    training_paths: 0.16198185199755244
  timestamp: 1652831295
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2375000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.34582543611526495
      reward_ctrl-last-mean: -0.4091861271858216
      reward_ctrl-mean-mean: -0.35107151359140876
      reward_ctrl-median-mean: -0.35369057893753053
      reward_ctrl-range-mean: 0.4681942129135132
      reward_run-first-mean: -0.5700723366142982
      reward_run-last-mean: 16.321832609935655
      reward_run-mean-mean: 15.176181023126162
      reward_run-median-mean: 16.005810210617284
      reward_run-range-mean: 18.441591860507188
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14957.64797179119
    episode-reward-mean: 14825.109509534752
    episode-reward-min: 14648.039174065712
    episode-reward-std: 92.40051159706422
  training_iteration: 95
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 16.06682586669922
    Q_value-mean: 1272.5648193359375
    alpha: 0.3699095845222473
    alpha_loss-mean: 0.0008085203007794917
    policy_loss-mean: -1271.438232421875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     95 |          22152.5 |      94 |      25000 |          2375000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.37454572319984436
  date: 2022-05-18_00-51-42
  done: false
  epoch: 95
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.36820402145385744
      reward_ctrl-last-mean: -0.3011486053466797
      reward_ctrl-mean-mean: -0.3553950781583786
      reward_ctrl-median-mean: -0.3547836661338806
      reward_ctrl-range-mean: 0.48333989977836606
      reward_run-first-mean: -0.801552876624303
      reward_run-last-mean: 17.53254100274262
      reward_run-mean-mean: 15.373255695791144
      reward_run-median-mean: 16.112775991796866
      reward_run-range-mean: 18.74690914071218
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15017.859375
    episode-reward-mean: 15017.859375
    episode-reward-min: 15017.859375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 96
  node_ip: 10.43.77.35
  num_train_steps: 2400000
  pid: 283289
  policy:
    actions-max: 0.9998891949653625
    actions-mean: -0.060988426208496094
    actions-min: -0.9993280172348022
    actions-std: 0.7671230435371399
    entropy-mean: -6.042272567749023
    entropy-std: 3.6218101978302
    scales-max: 1.0837010145187378
    scales-mean: 0.4280184805393219
    scales-min: 0.03280069679021835
    scales-std: 0.16683857142925262
    shifts-max: 3.842909097671509
    shifts-mean: -0.07423656433820724
    shifts-min: -3.1161997318267822
    shifts-std: 1.3943266868591309
  sampler:
    episodes: 2410
    last-path-return: 14632.013309245564
    max-path-return: 15012.498945047435
    pool-size: 1000000
    total-samples: 2410000
  time_since_restore: 22359.279988765717
  time_this_iter_s: 206.7791349887848
  time_total_s: 22359.279988765717
  times:
    epoch_after_hook: 1.5380210243165493e-06
    epoch_before_hook: 2.584498724900186e-05
    evaluation_metrics: 0.00039912399370223284
    evaluation_paths: 0.49336983502143994
    sample: 13.208804186142515
    timestep_after_hook: 0.03260161684011109
    timestep_before_hook: 0.07601476137642749
    train: 192.41798193720751
    training_metrics: 0.0015188420074991882
    training_paths: 0.16421195899602026
  timestamp: 1652831502
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2400000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2778801774978638
      reward_ctrl-last-mean: -0.35825330972671504
      reward_ctrl-mean-mean: -0.35111664004236454
      reward_ctrl-median-mean: -0.3545652401447296
      reward_ctrl-range-mean: 0.4853283855319024
      reward_run-first-mean: -0.6015757722116786
      reward_run-last-mean: 16.235983099059695
      reward_run-mean-mean: 14.99370142920958
      reward_run-median-mean: 15.91800041753055
      reward_run-range-mean: 18.47060912625187
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14910.604446186186
    episode-reward-mean: 14642.584789167213
    episode-reward-min: 14173.42634498546
    episode-reward-std: 240.65136657336285
  training_iteration: 96
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 15.70362377166748
    Q_value-mean: 1280.4388427734375
    alpha: 0.3687247633934021
    alpha_loss-mean: -0.0005246050423011184
    policy_loss-mean: -1279.272216796875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     96 |          22359.3 |      95 |      25000 |          2400000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.37126678228378296
  date: 2022-05-18_00-55-09
  done: false
  epoch: 96
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.20626745223999024
      reward_ctrl-last-mean: -0.28502516746520995
      reward_ctrl-mean-mean: -0.3483180840849876
      reward_ctrl-median-mean: -0.34909709692001345
      reward_ctrl-range-mean: 0.46995196342468265
      reward_run-first-mean: -0.5965391514502006
      reward_run-last-mean: 15.900580534209894
      reward_run-mean-mean: 15.07456318568652
      reward_run-median-mean: 15.83970925168046
      reward_run-range-mean: 18.454867707382203
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14726.2451171875
    episode-reward-mean: 14726.2451171875
    episode-reward-min: 14726.2451171875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 97
  node_ip: 10.43.77.35
  num_train_steps: 2425000
  pid: 283289
  policy:
    actions-max: 0.9991456270217896
    actions-mean: -0.04661563038825989
    actions-min: -0.9981162548065186
    actions-std: 0.7553390860557556
    entropy-mean: -5.660909652709961
    entropy-std: 3.523646116256714
    scales-max: 0.8815736770629883
    scales-mean: 0.4127051830291748
    scales-min: 0.022047867998480797
    scales-std: 0.16571955382823944
    shifts-max: 2.9781174659729004
    shifts-mean: -0.0725930705666542
    shifts-min: -2.7092435359954834
    shifts-std: 1.3476927280426025
  sampler:
    episodes: 2435
    last-path-return: 14783.67160675694
    max-path-return: 15022.176444896357
    pool-size: 1000000
    total-samples: 2435000
  time_since_restore: 22565.782918930054
  time_this_iter_s: 206.50293016433716
  time_total_s: 22565.782918930054
  times:
    epoch_after_hook: 1.4849938452243805e-06
    epoch_before_hook: 2.4900014977902174e-05
    evaluation_metrics: 0.0004204860015306622
    evaluation_paths: 0.48785009401035495
    sample: 13.165847453288734
    timestep_after_hook: 0.03259880922269076
    timestep_before_hook: 0.07809619212639518
    train: 192.27870821091346
    training_metrics: 0.0015583870117552578
    training_paths: 0.07337150198873132
  timestamp: 1652831709
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2425000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.33047600984573366
      reward_ctrl-last-mean: -0.35073357105255126
      reward_ctrl-mean-mean: -0.3518819432538748
      reward_ctrl-median-mean: -0.3545122420787812
      reward_ctrl-range-mean: 0.4705405128002166
      reward_run-first-mean: -0.6635439562506191
      reward_run-last-mean: 16.410324533145058
      reward_run-mean-mean: 15.177520025758042
      reward_run-median-mean: 16.012184797510102
      reward_run-range-mean: 18.623684623096718
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14959.57464489029
    episode-reward-mean: 14825.638082504165
    episode-reward-min: 14682.272829372378
    episode-reward-std: 101.3076293476769
  training_iteration: 97
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 14.83983039855957
    Q_value-mean: 1286.5435791015625
    alpha: 0.3644042909145355
    alpha_loss-mean: 0.0001300620788242668
    policy_loss-mean: -1285.360107421875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     97 |          22565.8 |      96 |      25000 |          2425000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3396385908126831
  date: 2022-05-18_00-58-35
  done: false
  epoch: 97
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.30314991474151615
      reward_ctrl-last-mean: -0.47034692764282227
      reward_ctrl-mean-mean: -0.35448387211561205
      reward_ctrl-median-mean: -0.34780468940734866
      reward_ctrl-range-mean: 0.4420360565185547
      reward_run-first-mean: -0.6699081222332073
      reward_run-last-mean: 16.14958693339986
      reward_run-mean-mean: 15.33269522061482
      reward_run-median-mean: 16.159173739745967
      reward_run-range-mean: 18.52734041677149
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14978.2109375
    episode-reward-mean: 14978.2109375
    episode-reward-min: 14978.2109375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 98
  node_ip: 10.43.77.35
  num_train_steps: 2450000
  pid: 283289
  policy:
    actions-max: 0.9980388879776001
    actions-mean: -0.030991286039352417
    actions-min: -0.9997767210006714
    actions-std: 0.7634024620056152
    entropy-mean: -5.731490612030029
    entropy-std: 3.544051170349121
    scales-max: 0.8841490149497986
    scales-mean: 0.41907739639282227
    scales-min: 0.02177482843399048
    scales-std: 0.16518926620483398
    shifts-max: 3.350001573562622
    shifts-mean: -0.045381415635347366
    shifts-min: -3.344313144683838
    shifts-std: 1.384296178817749
  sampler:
    episodes: 2460
    last-path-return: 14996.115268532561
    max-path-return: 15048.575703377654
    pool-size: 1000000
    total-samples: 2460000
  time_since_restore: 22772.29451060295
  time_this_iter_s: 206.51159167289734
  time_total_s: 22772.29451060295
  times:
    epoch_after_hook: 1.3799872249364853e-06
    epoch_before_hook: 2.4526991182938218e-05
    evaluation_metrics: 0.00040264599374495447
    evaluation_paths: 0.49134093400789425
    sample: 13.151431678998051
    timestep_after_hook: 0.03265800653025508
    timestep_before_hook: 0.07620500650955364
    train: 192.3032570934738
    training_metrics: 0.0015070659865159541
    training_paths: 0.07288555699051358
  timestamp: 1652831915
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2450000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2966770553588868
      reward_ctrl-last-mean: -0.30828473925590516
      reward_ctrl-mean-mean: -0.35230041117966177
      reward_ctrl-median-mean: -0.35652557969093324
      reward_ctrl-range-mean: 0.48261844575405116
      reward_run-first-mean: -0.6514316454496948
      reward_run-last-mean: 16.60752033273957
      reward_run-mean-mean: 15.195341560258774
      reward_run-median-mean: 16.060139338663745
      reward_run-range-mean: 18.580555196085566
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15048.575703377664
    episode-reward-mean: 14843.041149079112
    episode-reward-min: 14242.780359138913
    episode-reward-std: 220.39283875386357
  training_iteration: 98
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 14.61571216583252
    Q_value-mean: 1293.2705078125
    alpha: 0.3568842113018036
    alpha_loss-mean: 0.0011663002660498023
    policy_loss-mean: -1292.0758056640625
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     98 |          22772.3 |      97 |      25000 |          2450000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3553146421909332
  date: 2022-05-18_01-02-03
  done: false
  epoch: 98
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.40633974075317386
      reward_ctrl-last-mean: -0.4541015148162842
      reward_ctrl-mean-mean: -0.35667698702812195
      reward_ctrl-median-mean: -0.3502393245697022
      reward_ctrl-range-mean: 0.4541617393493652
      reward_run-first-mean: -0.7983951250510781
      reward_run-last-mean: 15.929342425113191
      reward_run-mean-mean: 15.25717147936413
      reward_run-median-mean: 16.08846027452728
      reward_run-range-mean: 18.603633589096567
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14900.4951171875
    episode-reward-mean: 14900.4951171875
    episode-reward-min: 14900.4951171875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 99
  node_ip: 10.43.77.35
  num_train_steps: 2475000
  pid: 283289
  policy:
    actions-max: 0.9995369911193848
    actions-mean: -0.03051925264298916
    actions-min: -0.9984333515167236
    actions-std: 0.7660796046257019
    entropy-mean: -6.004575252532959
    entropy-std: 3.43863582611084
    scales-max: 1.1502821445465088
    scales-mean: 0.41478899121284485
    scales-min: 0.023183923214673996
    scales-std: 0.16093206405639648
    shifts-max: 2.97506046295166
    shifts-mean: -0.04364430904388428
    shifts-min: -3.8765387535095215
    shifts-std: 1.3647334575653076
  sampler:
    episodes: 2485
    last-path-return: 14941.715861245371
    max-path-return: 15091.58050983409
    pool-size: 1000000
    total-samples: 2485000
  time_since_restore: 22979.852050065994
  time_this_iter_s: 207.5575394630432
  time_total_s: 22979.852050065994
  times:
    epoch_after_hook: 2.082000719383359e-06
    epoch_before_hook: 2.3810978746041656e-05
    evaluation_metrics: 0.02677464301814325
    evaluation_paths: 0.5202528469962999
    sample: 13.60808112763334
    timestep_after_hook: 0.03266782907303423
    timestep_before_hook: 0.07610176483285613
    train: 192.63997177773854
    training_metrics: 0.02805436699418351
    training_paths: 0.2233424159931019
  timestamp: 1652832123
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2475000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2970793652534485
      reward_ctrl-last-mean: -0.32964959025382995
      reward_ctrl-mean-mean: -0.35375832577466965
      reward_ctrl-median-mean: -0.35675018310546874
      reward_ctrl-range-mean: 0.4796775746345521
      reward_run-first-mean: -0.5658133095222816
      reward_run-last-mean: 16.203568758071697
      reward_run-mean-mean: 15.148017726754034
      reward_run-median-mean: 16.000329355176746
      reward_run-range-mean: 18.463273644546423
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15084.189589267571
    episode-reward-mean: 14794.259400979365
    episode-reward-min: 14574.25182113725
    episode-reward-std: 175.71155312915315
  training_iteration: 99
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 16.04684829711914
    Q_value-mean: 1297.93212890625
    alpha: 0.3533720374107361
    alpha_loss-mean: -0.0004934262251481414
    policy_loss-mean: -1296.7420654296875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |     99 |          22979.9 |      98 |      25000 |          2475000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34921887516975403
  date: 2022-05-18_01-05-30
  done: false
  epoch: 99
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4177111148834229
      reward_ctrl-last-mean: -0.30348169803619385
      reward_ctrl-mean-mean: -0.36311928273439414
      reward_ctrl-median-mean: -0.35896326303482057
      reward_ctrl-range-mean: 0.46847383975982665
      reward_run-first-mean: -0.8102603339095826
      reward_run-last-mean: 15.375438519399722
      reward_run-mean-mean: 14.88087012849278
      reward_run-median-mean: 15.755747434006935
      reward_run-range-mean: 18.990486774151943
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14517.7509765625
    episode-reward-mean: 14517.7509765625
    episode-reward-min: 14517.7509765625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 100
  node_ip: 10.43.77.35
  num_train_steps: 2500000
  pid: 283289
  policy:
    actions-max: 0.9991170763969421
    actions-mean: -0.023960953578352928
    actions-min: -0.9984834790229797
    actions-std: 0.7762978076934814
    entropy-mean: -6.747691631317139
    entropy-std: 4.142734050750732
    scales-max: 0.8529172539710999
    scales-mean: 0.4122399389743805
    scales-min: 0.031175119802355766
    scales-std: 0.15640012919902802
    shifts-max: 3.5458500385284424
    shifts-mean: -0.04303364455699921
    shifts-min: -3.1067395210266113
    shifts-std: 1.4587199687957764
  sampler:
    episodes: 2510
    last-path-return: 14785.987425892332
    max-path-return: 15107.803532567657
    pool-size: 1000000
    total-samples: 2510000
  time_since_restore: 23186.66937828064
  time_this_iter_s: 206.81732821464539
  time_total_s: 23186.66937828064
  times:
    epoch_after_hook: 1.535983756184578e-06
    epoch_before_hook: 2.7123023755848408e-05
    evaluation_metrics: 0.0004073790041729808
    evaluation_paths: 0.5197216369851958
    sample: 13.175385919807013
    timestep_after_hook: 0.032650090724928305
    timestep_before_hook: 0.07687698022346012
    train: 192.4547746197204
    training_metrics: 0.0015272030141204596
    training_paths: 0.1747412889963016
  timestamp: 1652832330
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2500000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2958590292930603
      reward_ctrl-last-mean: -0.36864766836166385
      reward_ctrl-mean-mean: -0.353765822942257
      reward_ctrl-median-mean: -0.3564169716835022
      reward_ctrl-range-mean: 0.48533189415931705
      reward_run-first-mean: -0.5833345901085262
      reward_run-last-mean: 16.569487286981484
      reward_run-mean-mean: 15.24780955000586
      reward_run-median-mean: 16.0577119852681
      reward_run-range-mean: 18.630530360158826
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15107.803532567626
    episode-reward-mean: 14894.043727063607
    episode-reward-min: 14646.593515626273
    episode-reward-std: 128.12307628220265
  training_iteration: 100
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 15.386009216308594
    Q_value-mean: 1302.6728515625
    alpha: 0.3480520248413086
    alpha_loss-mean: 0.00026794426958076656
    policy_loss-mean: -1301.4610595703125
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    100 |          23186.7 |      99 |      25000 |          2500000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34071382880210876
  date: 2022-05-18_01-08-57
  done: false
  epoch: 100
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4679586410522461
      reward_ctrl-last-mean: -0.2370408058166504
      reward_ctrl-mean-mean: -0.35833263211846356
      reward_ctrl-median-mean: -0.35669589042663574
      reward_ctrl-range-mean: 0.48556211590766907
      reward_run-first-mean: -0.786449238941484
      reward_run-last-mean: 16.483101973410612
      reward_run-mean-mean: 15.291865200167743
      reward_run-median-mean: 16.14654071548557
      reward_run-range-mean: 18.65429745219262
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14933.533203125
    episode-reward-mean: 14933.533203125
    episode-reward-min: 14933.533203125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 101
  node_ip: 10.43.77.35
  num_train_steps: 2525000
  pid: 283289
  policy:
    actions-max: 0.9992928504943848
    actions-mean: -0.09003183990716934
    actions-min: -0.9999160766601562
    actions-std: 0.7622592449188232
    entropy-mean: -6.165999412536621
    entropy-std: 3.752368450164795
    scales-max: 1.0766841173171997
    scales-mean: 0.41726136207580566
    scales-min: 0.019683539867401123
    scales-std: 0.1615796685218811
    shifts-max: 3.4275314807891846
    shifts-mean: -0.1322549283504486
    shifts-min: -4.327452182769775
    shifts-std: 1.3837867975234985
  sampler:
    episodes: 2535
    last-path-return: 14844.826755974105
    max-path-return: 15107.803532567657
    pool-size: 1000000
    total-samples: 2535000
  time_since_restore: 23393.743487119675
  time_this_iter_s: 207.07410883903503
  time_total_s: 23393.743487119675
  times:
    epoch_after_hook: 1.5299883671104908e-06
    epoch_before_hook: 2.6074005290865898e-05
    evaluation_metrics: 0.0004191060143057257
    evaluation_paths: 0.488662582996767
    sample: 13.24390344080166
    timestep_after_hook: 0.03268409211887047
    timestep_before_hook: 0.07624912378378212
    train: 192.7761149230064
    training_metrics: 0.0015257560007739812
    training_paths: 0.07298615900799632
  timestamp: 1652832537
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2525000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.28695774316787725
      reward_ctrl-last-mean: -0.3660105276107788
      reward_ctrl-mean-mean: -0.35054739034354687
      reward_ctrl-median-mean: -0.3555466687679291
      reward_ctrl-range-mean: 0.4914817467331886
      reward_run-first-mean: -0.5482977542289269
      reward_run-last-mean: 14.62835676664804
      reward_run-mean-mean: 14.869268581013085
      reward_run-median-mean: 15.998497511677954
      reward_run-range-mean: 18.548381579896596
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15060.635228401734
    episode-reward-mean: 14518.72119066954
    episode-reward-min: 11072.356050913497
    episode-reward-std: 1154.1840273325488
  training_iteration: 101
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 14.941954612731934
    Q_value-mean: 1309.1497802734375
    alpha: 0.34422898292541504
    alpha_loss-mean: 0.0003684028924908489
    policy_loss-mean: -1307.9283447265625
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    101 |          23393.7 |     100 |      25000 |          2525000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3378216326236725
  date: 2022-05-18_01-12-24
  done: false
  epoch: 101
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.19432096481323244
      reward_ctrl-last-mean: -0.3136260271072388
      reward_ctrl-mean-mean: -0.35241385281085974
      reward_ctrl-median-mean: -0.35357233285903933
      reward_ctrl-range-mean: 0.46986571550369266
      reward_run-first-mean: -0.062145245885544265
      reward_run-last-mean: 16.88934526028561
      reward_run-mean-mean: 15.296674448184854
      reward_run-median-mean: 16.0845214598271
      reward_run-range-mean: 18.160830060692987
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14944.26171875
    episode-reward-mean: 14944.26171875
    episode-reward-min: 14944.26171875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 102
  node_ip: 10.43.77.35
  num_train_steps: 2550000
  pid: 283289
  policy:
    actions-max: 0.999032735824585
    actions-mean: -0.07338164001703262
    actions-min: -0.9998904466629028
    actions-std: 0.778800904750824
    entropy-mean: -6.276163578033447
    entropy-std: 3.822688579559326
    scales-max: 0.868753969669342
    scales-mean: 0.42768537998199463
    scales-min: 0.031879957765340805
    scales-std: 0.15069669485092163
    shifts-max: 3.4067580699920654
    shifts-mean: -0.10263802856206894
    shifts-min: -3.2220137119293213
    shifts-std: 1.3851484060287476
  sampler:
    episodes: 2560
    last-path-return: 14754.932086761151
    max-path-return: 15117.626105862668
    pool-size: 1000000
    total-samples: 2560000
  time_since_restore: 23600.94950890541
  time_this_iter_s: 207.20602178573608
  time_total_s: 23600.94950890541
  times:
    epoch_after_hook: 1.5260011423379183e-06
    epoch_before_hook: 2.446299185976386e-05
    evaluation_metrics: 0.0004135729977861047
    evaluation_paths: 0.4895079590205569
    sample: 13.324988353677327
    timestep_after_hook: 0.03264643019065261
    timestep_before_hook: 0.07765565026784316
    train: 192.8238998730376
    training_metrics: 0.0015289730217773467
    training_paths: 0.073888482991606
  timestamp: 1652832744
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2550000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3118235874176025
      reward_ctrl-last-mean: -0.3550076723098755
      reward_ctrl-mean-mean: -0.3453911911976338
      reward_ctrl-median-mean: -0.3488785338401795
      reward_ctrl-range-mean: 0.4887014335393906
      reward_run-first-mean: -0.6108455307050866
      reward_run-last-mean: 14.703424409484978
      reward_run-mean-mean: 13.76554557673228
      reward_run-median-mean: 14.495528701629956
      reward_run-range-mean: 17.80658016818468
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15117.626105862666
    episode-reward-mean: 13420.154385534644
    episode-reward-min: 48.9228064810174
    episode-reward-std: 4459.092691051487
  training_iteration: 102
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 14.200235366821289
    Q_value-mean: 1315.569091796875
    alpha: 0.33744630217552185
    alpha_loss-mean: 0.00015746447024866939
    policy_loss-mean: -1314.3365478515625
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    102 |          23600.9 |     101 |      25000 |          2550000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34773749113082886
  date: 2022-05-18_01-15-51
  done: false
  epoch: 102
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4382408142089844
      reward_ctrl-last-mean: -0.2880956411361694
      reward_ctrl-mean-mean: -0.35368975577354433
      reward_ctrl-median-mean: -0.35771998167037966
      reward_ctrl-range-mean: 0.48162405490875243
      reward_run-first-mean: -1.0097402414999102
      reward_run-last-mean: 17.2206907466375
      reward_run-mean-mean: 15.282730098393325
      reward_run-median-mean: 16.076459643178822
      reward_run-range-mean: 18.81613617812604
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14929.041015625
    episode-reward-mean: 14929.041015625
    episode-reward-min: 14929.041015625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 103
  node_ip: 10.43.77.35
  num_train_steps: 2575000
  pid: 283289
  policy:
    actions-max: 0.9978329539299011
    actions-mean: -0.09398367255926132
    actions-min: -0.999015212059021
    actions-std: 0.76805579662323
    entropy-mean: -6.694042205810547
    entropy-std: 3.9446957111358643
    scales-max: 1.5466487407684326
    scales-mean: 0.4099288880825043
    scales-min: 0.026944484561681747
    scales-std: 0.16180391609668732
    shifts-max: 3.6347131729125977
    shifts-mean: -0.16144461929798126
    shifts-min: -3.5098588466644287
    shifts-std: 1.4316617250442505
  sampler:
    episodes: 2585
    last-path-return: 14926.894926805302
    max-path-return: 15117.626105862668
    pool-size: 1000000
    total-samples: 2585000
  time_since_restore: 23807.672832250595
  time_this_iter_s: 206.72332334518433
  time_total_s: 23807.672832250595
  times:
    epoch_after_hook: 1.5830155462026596e-06
    epoch_before_hook: 2.5260000256821513e-05
    evaluation_metrics: 0.0004098209901712835
    evaluation_paths: 0.4882214269891847
    sample: 13.278457331151003
    timestep_after_hook: 0.03255425955285318
    timestep_before_hook: 0.07718007787480019
    train: 192.38842125041992
    training_metrics: 0.0015078189899213612
    training_paths: 0.07573301301454194
  timestamp: 1652832951
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2575000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.28089936614036565
      reward_ctrl-last-mean: -0.39877512454986574
      reward_ctrl-mean-mean: -0.35689880935907364
      reward_ctrl-median-mean: -0.3586446487903595
      reward_ctrl-range-mean: 0.47654347658157353
      reward_run-first-mean: -0.521847153096975
      reward_run-last-mean: 16.29820514520975
      reward_run-mean-mean: 15.234338945835969
      reward_run-median-mean: 16.102189764347543
      reward_run-range-mean: 18.665172258107813
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15108.820197498299
    episode-reward-mean: 14877.440136476896
    episode-reward-min: 14579.527292885628
    episode-reward-std: 175.74561942426652
  training_iteration: 103
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 14.658051490783691
    Q_value-mean: 1319.326416015625
    alpha: 0.3389396071434021
    alpha_loss-mean: -0.00036002835258841515
    policy_loss-mean: -1318.0577392578125
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    103 |          23807.7 |     102 |      25000 |          2575000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3328252136707306
  date: 2022-05-18_01-19-18
  done: false
  epoch: 103
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.1368542790412903
      reward_ctrl-last-mean: -0.2851850986480713
      reward_ctrl-mean-mean: -0.3586725790977478
      reward_ctrl-median-mean: -0.3617703795433045
      reward_ctrl-range-mean: 0.4904668807983399
      reward_run-first-mean: -0.2131839913256145
      reward_run-last-mean: 15.981098723243576
      reward_run-mean-mean: 14.431909118135213
      reward_run-median-mean: 15.958349899086102
      reward_run-range-mean: 18.512827296697616
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14073.2373046875
    episode-reward-mean: 14073.2373046875
    episode-reward-min: 14073.2373046875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 104
  node_ip: 10.43.77.35
  num_train_steps: 2600000
  pid: 283289
  policy:
    actions-max: 0.9962350726127625
    actions-mean: -0.04259546101093292
    actions-min: -0.9999990463256836
    actions-std: 0.7682687044143677
    entropy-mean: -5.979207992553711
    entropy-std: 3.6425108909606934
    scales-max: 1.5484459400177002
    scales-mean: 0.4234185218811035
    scales-min: 0.03291163221001625
    scales-std: 0.16339746117591858
    shifts-max: 2.939383029937744
    shifts-mean: -0.057614367455244064
    shifts-min: -6.107332706451416
    shifts-std: 1.4026840925216675
  sampler:
    episodes: 2610
    last-path-return: 15039.955279736412
    max-path-return: 15189.010290151644
    pool-size: 1000000
    total-samples: 2610000
  time_since_restore: 24014.840353250504
  time_this_iter_s: 207.16752099990845
  time_total_s: 24014.840353250504
  times:
    epoch_after_hook: 1.5069963410496712e-06
    epoch_before_hook: 2.4281005607917905e-05
    evaluation_metrics: 0.00040932800038717687
    evaluation_paths: 0.48727321400656365
    sample: 13.692427695175866
    timestep_after_hook: 0.03251529787667096
    timestep_before_hook: 0.07586515537695959
    train: 192.4231298348168
    training_metrics: 0.001489908987423405
    training_paths: 0.0736707930045668
  timestamp: 1652833158
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2600000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2170454925298691
      reward_ctrl-last-mean: -0.33674546957015994
      reward_ctrl-mean-mean: -0.35226228183269503
      reward_ctrl-median-mean: -0.354895932674408
      reward_ctrl-range-mean: 0.4892386019229889
      reward_run-first-mean: -0.425328550247564
      reward_run-last-mean: 16.45503974374583
      reward_run-mean-mean: 15.200720401135328
      reward_run-median-mean: 16.063013561952857
      reward_run-range-mean: 18.568483369098892
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15057.639004842167
    episode-reward-mean: 14848.45811930263
    episode-reward-min: 14480.918021851881
    episode-reward-std: 175.17610727748166
  training_iteration: 104
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 15.847479820251465
    Q_value-mean: 1321.1263427734375
    alpha: 0.3358279764652252
    alpha_loss-mean: 0.0006436404655687511
    policy_loss-mean: -1319.8695068359375
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    104 |          24014.8 |     103 |      25000 |          2600000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3396456837654114
  date: 2022-05-18_01-22-46
  done: false
  epoch: 104
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3653669118881226
      reward_ctrl-last-mean: -0.44851136207580566
      reward_ctrl-mean-mean: -0.34864857524037357
      reward_ctrl-median-mean: -0.35751731395721437
      reward_ctrl-range-mean: 0.47504006028175355
      reward_run-first-mean: -0.7507756801705341
      reward_run-last-mean: 16.516729049453716
      reward_run-mean-mean: 15.0860872655981
      reward_run-median-mean: 15.89815182468783
      reward_run-range-mean: 18.575974391422438
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14737.4384765625
    episode-reward-mean: 14737.4384765625
    episode-reward-min: 14737.4384765625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 105
  node_ip: 10.43.77.35
  num_train_steps: 2625000
  pid: 283289
  policy:
    actions-max: 0.9985530376434326
    actions-mean: -0.03157561272382736
    actions-min: -0.9989103674888611
    actions-std: 0.7646676301956177
    entropy-mean: -5.988302707672119
    entropy-std: 3.537158250808716
    scales-max: 1.221510887145996
    scales-mean: 0.41398775577545166
    scales-min: 0.026182936504483223
    scales-std: 0.15892156958580017
    shifts-max: 3.066800355911255
    shifts-mean: -0.044095247983932495
    shifts-min: -2.8827085494995117
    shifts-std: 1.3745681047439575
  sampler:
    episodes: 2635
    last-path-return: 14920.109179097686
    max-path-return: 15189.010290151644
    pool-size: 1000000
    total-samples: 2635000
  time_since_restore: 24222.4021320343
  time_this_iter_s: 207.56177878379822
  time_total_s: 24222.4021320343
  times:
    epoch_after_hook: 1.4269899111241102e-06
    epoch_before_hook: 2.4693988962098956e-05
    evaluation_metrics: 0.0004189040046185255
    evaluation_paths: 0.5162533239927143
    sample: 14.356815987906884
    timestep_after_hook: 0.032485465839272365
    timestep_before_hook: 0.07787298137554899
    train: 192.12258434656542
    training_metrics: 0.001580930984346196
    training_paths: 0.0736119509965647
  timestamp: 1652833366
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2625000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.36167630910873416
      reward_ctrl-last-mean: -0.4077320790290832
      reward_ctrl-mean-mean: -0.35692116311013705
      reward_ctrl-median-mean: -0.36023028731346135
      reward_ctrl-range-mean: 0.4896512454748153
      reward_run-first-mean: -0.5343879018198923
      reward_run-last-mean: 16.56933029451011
      reward_run-mean-mean: 15.162709661999608
      reward_run-median-mean: 16.013822024888853
      reward_run-range-mean: 18.643745379368927
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15072.071828508473
    episode-reward-mean: 14805.788498889471
    episode-reward-min: 14365.860813167557
    episode-reward-std: 221.8437525891702
  training_iteration: 105
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 15.267226219177246
    Q_value-mean: 1323.41455078125
    alpha: 0.3381953239440918
    alpha_loss-mean: -0.0002285814844071865
    policy_loss-mean: -1322.1239013671875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    105 |          24222.4 |     104 |      25000 |          2625000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34200695157051086
  date: 2022-05-18_01-26-13
  done: false
  epoch: 105
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.2721766471862793
      reward_ctrl-last-mean: -0.3588423252105713
      reward_ctrl-mean-mean: -0.36170074177980427
      reward_ctrl-median-mean: -0.3585714340209961
      reward_ctrl-range-mean: 0.46442080736160285
      reward_run-first-mean: -0.42268913961782206
      reward_run-last-mean: 15.682265488762823
      reward_run-mean-mean: 15.434336565492119
      reward_run-median-mean: 16.23685006693904
      reward_run-range-mean: 19.21367592766703
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15072.63671875
    episode-reward-mean: 15072.63671875
    episode-reward-min: 15072.63671875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 106
  node_ip: 10.43.77.35
  num_train_steps: 2650000
  pid: 283289
  policy:
    actions-max: 0.999961793422699
    actions-mean: -0.05844927951693535
    actions-min: -0.9983587265014648
    actions-std: 0.7631102204322815
    entropy-mean: -5.969470977783203
    entropy-std: 3.181037187576294
    scales-max: 1.15939199924469
    scales-mean: 0.42725464701652527
    scales-min: 0.030246373265981674
    scales-std: 0.1649131029844284
    shifts-max: 2.8926827907562256
    shifts-mean: -0.06976739317178726
    shifts-min: -3.388547420501709
    shifts-std: 1.3803619146347046
  sampler:
    episodes: 2660
    last-path-return: 15059.66291378994
    max-path-return: 15189.010290151644
    pool-size: 1000000
    total-samples: 2660000
  time_since_restore: 24429.02491259575
  time_this_iter_s: 206.62278056144714
  time_total_s: 24429.02491259575
  times:
    epoch_after_hook: 1.6849953681230545e-06
    epoch_before_hook: 2.557001425884664e-05
    evaluation_metrics: 0.0004126239800825715
    evaluation_paths: 0.5187819310231134
    sample: 13.302224620449124
    timestep_after_hook: 0.03245347770280205
    timestep_before_hook: 0.07715664035640657
    train: 192.23587457739632
    training_metrics: 0.0015477239794563502
    training_paths: 0.07326210298924707
  timestamp: 1652833573
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2650000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2983307278156281
      reward_ctrl-last-mean: -0.38498428821563724
      reward_ctrl-mean-mean: -0.3485016437321901
      reward_ctrl-median-mean: -0.3509425592422486
      reward_ctrl-range-mean: 0.49717419207096103
      reward_run-first-mean: -0.505879538617092
      reward_run-last-mean: 14.393297245548752
      reward_run-mean-mean: 13.797872171183949
      reward_run-median-mean: 14.423824879511463
      reward_run-range-mean: 18.774834555495325
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15059.662913789925
    episode-reward-mean: 13449.37052745176
    episode-reward-min: 2900.9551902734543
    episode-reward-std: 3540.199861835088
  training_iteration: 106
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 15.694680213928223
    Q_value-mean: 1324.7781982421875
    alpha: 0.338056355714798
    alpha_loss-mean: 1.764795342751313e-05
    policy_loss-mean: -1323.466796875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    106 |            24429 |     105 |      25000 |          2650000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3496791422367096
  date: 2022-05-18_01-29-40
  done: false
  epoch: 106
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.18041160106658938
      reward_ctrl-last-mean: -0.1937542796134949
      reward_ctrl-mean-mean: -0.3652747615337372
      reward_ctrl-median-mean: -0.3638309001922608
      reward_ctrl-range-mean: 0.47995243072509763
      reward_run-first-mean: -0.3183815403635354
      reward_run-last-mean: 17.439878850032073
      reward_run-mean-mean: 14.996875883358415
      reward_run-median-mean: 15.947220487092295
      reward_run-range-mean: 18.863149801616935
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14631.6015625
    episode-reward-mean: 14631.6015625
    episode-reward-min: 14631.6015625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 107
  node_ip: 10.43.77.35
  num_train_steps: 2675000
  pid: 283289
  policy:
    actions-max: 0.9994519948959351
    actions-mean: -0.07279094308614731
    actions-min: -0.9994143843650818
    actions-std: 0.7601515650749207
    entropy-mean: -5.718233585357666
    entropy-std: 3.4396729469299316
    scales-max: 1.004791021347046
    scales-mean: 0.42434534430503845
    scales-min: 0.03667643666267395
    scales-std: 0.16164003312587738
    shifts-max: 2.9942855834960938
    shifts-mean: -0.14250917732715607
    shifts-min: -3.4994750022888184
    shifts-std: 1.360769271850586
  sampler:
    episodes: 2685
    last-path-return: 14950.87984834766
    max-path-return: 15189.010290151644
    pool-size: 1000000
    total-samples: 2685000
  time_since_restore: 24635.59223127365
  time_this_iter_s: 206.56731867790222
  time_total_s: 24635.59223127365
  times:
    epoch_after_hook: 1.8110149540007114e-06
    epoch_before_hook: 2.955499803647399e-05
    evaluation_metrics: 0.0004214979999233037
    evaluation_paths: 0.48857528500957415
    sample: 13.20169767003972
    timestep_after_hook: 0.032632923423079774
    timestep_before_hook: 0.07653121757903136
    train: 192.311161909136
    training_metrics: 0.0015956210263539106
    training_paths: 0.07398449201718904
  timestamp: 1652833780
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2675000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.24889880746603016
      reward_ctrl-last-mean: -0.3774952733516693
      reward_ctrl-mean-mean: -0.3544763117960096
      reward_ctrl-median-mean: -0.3599473023414612
      reward_ctrl-range-mean: 0.4939892944693566
      reward_run-first-mean: -0.4373520288859626
      reward_run-last-mean: 16.221513204108078
      reward_run-mean-mean: 15.129265001284883
      reward_run-median-mean: 16.04549352758491
      reward_run-range-mean: 18.38060023464133
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14967.617534047806
    episode-reward-mean: 14774.788689488876
    episode-reward-min: 14266.875237334982
    episode-reward-std: 223.13761874096411
  training_iteration: 107
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 16.49983787536621
    Q_value-mean: 1324.5911865234375
    alpha: 0.34225496649742126
    alpha_loss-mean: -0.00020596920512616634
    policy_loss-mean: -1323.2230224609375
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    107 |          24635.6 |     106 |      25000 |          2675000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3468119502067566
  date: 2022-05-18_01-33-07
  done: false
  epoch: 107
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.33215098381042485
      reward_ctrl-last-mean: -0.2965425491333008
      reward_ctrl-mean-mean: -0.3518382827341556
      reward_ctrl-median-mean: -0.3531309962272644
      reward_ctrl-range-mean: 0.5050415813922882
      reward_run-first-mean: -0.7061832357790961
      reward_run-last-mean: 17.245357971476096
      reward_run-mean-mean: 15.407043758951815
      reward_run-median-mean: 16.176159318924306
      reward_run-range-mean: 18.823387104357607
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15055.205078125
    episode-reward-mean: 15055.205078125
    episode-reward-min: 15055.205078125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 108
  node_ip: 10.43.77.35
  num_train_steps: 2700000
  pid: 283289
  policy:
    actions-max: 0.9999026656150818
    actions-mean: -0.0447741337120533
    actions-min: -0.9998840093612671
    actions-std: 0.7676759362220764
    entropy-mean: -6.183852195739746
    entropy-std: 4.134334564208984
    scales-max: 0.8327357172966003
    scales-mean: 0.41960814595222473
    scales-min: 0.013609941117465496
    scales-std: 0.157815620303154
    shifts-max: 5.2806830406188965
    shifts-mean: -0.056544214487075806
    shifts-min: -4.659436225891113
    shifts-std: 1.4171462059020996
  sampler:
    episodes: 2710
    last-path-return: 14995.178976947016
    max-path-return: 15189.010290151644
    pool-size: 1000000
    total-samples: 2710000
  time_since_restore: 24842.166464805603
  time_this_iter_s: 206.5742335319519
  time_total_s: 24842.166464805603
  times:
    epoch_after_hook: 1.6039994079619646e-06
    epoch_before_hook: 2.4998997105285525e-05
    evaluation_metrics: 0.0004014620208181441
    evaluation_paths: 0.4879122350248508
    sample: 13.366294781822944
    timestep_after_hook: 0.03264605678850785
    timestep_before_hook: 0.07692704460350797
    train: 192.15319863893092
    training_metrics: 0.0015217499749269336
    training_paths: 0.07383713201852515
  timestamp: 1652833987
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2700000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.24269261598587039
      reward_ctrl-last-mean: -0.30437595367431647
      reward_ctrl-mean-mean: -0.3464309212476015
      reward_ctrl-median-mean: -0.3491537785530091
      reward_ctrl-range-mean: 0.49261669397354124
      reward_run-first-mean: -0.344335676884987
      reward_run-last-mean: 13.986793202580316
      reward_run-mean-mean: 13.897833450748863
      reward_run-median-mean: 14.395713324374128
      reward_run-range-mean: 18.3305788923372
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14995.178976947003
    episode-reward-mean: 13551.402529501263
    episode-reward-min: 3152.936772975153
    episode-reward-std: 3478.5007638798197
  training_iteration: 108
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 16.38972282409668
    Q_value-mean: 1323.18896484375
    alpha: 0.34672266244888306
    alpha_loss-mean: 0.0001397668820573017
    policy_loss-mean: -1321.7784423828125
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    108 |          24842.2 |     107 |      25000 |          2700000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34280210733413696
  date: 2022-05-18_01-36-35
  done: false
  epoch: 108
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.35430493354797366
      reward_ctrl-last-mean: -0.28059256076812744
      reward_ctrl-mean-mean: -0.35311649268269535
      reward_ctrl-median-mean: -0.3562985539436341
      reward_ctrl-range-mean: 0.46798345446586614
      reward_run-first-mean: 0.05347749128634047
      reward_run-last-mean: 16.84930916651865
      reward_run-mean-mean: 15.524340955242707
      reward_run-median-mean: 16.34660151034609
      reward_run-range-mean: 18.164411790879356
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15171.224609375
    episode-reward-mean: 15171.224609375
    episode-reward-min: 15171.224609375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 109
  node_ip: 10.43.77.35
  num_train_steps: 2725000
  pid: 283289
  policy:
    actions-max: 0.9993106126785278
    actions-mean: -0.05851415917277336
    actions-min: -0.9974260330200195
    actions-std: 0.7608988881111145
    entropy-mean: -6.100057125091553
    entropy-std: 3.785944700241089
    scales-max: 0.9116851091384888
    scales-mean: 0.4165695607662201
    scales-min: 0.0317099429666996
    scales-std: 0.16028407216072083
    shifts-max: 3.429563522338867
    shifts-mean: -0.07689765840768814
    shifts-min: -2.85417103767395
    shifts-std: 1.3703519105911255
  sampler:
    episodes: 2735
    last-path-return: 15080.630817776397
    max-path-return: 15189.010290151644
    pool-size: 1000000
    total-samples: 2735000
  time_since_restore: 25050.22072339058
  time_this_iter_s: 208.0542585849762
  time_total_s: 25050.22072339058
  times:
    epoch_after_hook: 1.4720135368406773e-06
    epoch_before_hook: 2.6395980967208743e-05
    evaluation_metrics: 0.00040716599323786795
    evaluation_paths: 0.4876484540000092
    sample: 13.300278034934308
    timestep_after_hook: 0.032517542043933645
    timestep_before_hook: 0.0761755520652514
    train: 193.61228166733054
    training_metrics: 0.0015215989842545241
    training_paths: 0.07350053897243924
  timestamp: 1652834195
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2725000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2714151000976563
      reward_ctrl-last-mean: -0.36288915157318125
      reward_ctrl-mean-mean: -0.3541578416591883
      reward_ctrl-median-mean: -0.35863064289093016
      reward_ctrl-range-mean: 0.486654726266861
      reward_run-first-mean: -0.334314852799965
      reward_run-last-mean: 16.07679229899395
      reward_run-mean-mean: 15.033527636203107
      reward_run-median-mean: 16.041430727324766
      reward_run-range-mean: 18.73737785260492
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15091.222457792011
    episode-reward-mean: 14679.369794543916
    episode-reward-min: 13195.118714763592
    episode-reward-std: 532.1419301631723
  training_iteration: 109
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 16.396665573120117
    Q_value-mean: 1322.4525146484375
    alpha: 0.34137508273124695
    alpha_loss-mean: 0.00018249887216370553
    policy_loss-mean: -1321.066650390625
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    109 |          25050.2 |     108 |      25000 |          2725000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.32414719462394714
  date: 2022-05-18_01-40-01
  done: false
  epoch: 109
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.42028470039367677
      reward_ctrl-last-mean: -0.30828375816345216
      reward_ctrl-mean-mean: -0.3510145224571228
      reward_ctrl-median-mean: -0.3499751091003418
      reward_ctrl-range-mean: 0.47718585729599
      reward_run-first-mean: -0.8228464345153194
      reward_run-last-mean: 16.07195847046114
      reward_run-mean-mean: 14.653371752628978
      reward_run-median-mean: 15.927770965902255
      reward_run-range-mean: 18.7034770620777
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14302.357421875
    episode-reward-mean: 14302.357421875
    episode-reward-min: 14302.357421875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 110
  node_ip: 10.43.77.35
  num_train_steps: 2750000
  pid: 283289
  policy:
    actions-max: 0.9993199110031128
    actions-mean: -0.018800897523760796
    actions-min: -0.9988071322441101
    actions-std: 0.7667291164398193
    entropy-mean: -5.828539848327637
    entropy-std: 3.709681749343872
    scales-max: 1.4120486974716187
    scales-mean: 0.4188730716705322
    scales-min: 0.028002409264445305
    scales-std: 0.16309493780136108
    shifts-max: 3.2781641483306885
    shifts-mean: -0.012080262415111065
    shifts-min: -3.410428524017334
    shifts-std: 1.3747284412384033
  sampler:
    episodes: 2760
    last-path-return: 15137.979533772654
    max-path-return: 15193.104132107714
    pool-size: 1000000
    total-samples: 2760000
  time_since_restore: 25256.934535503387
  time_this_iter_s: 206.71381211280823
  time_total_s: 25256.934535503387
  times:
    epoch_after_hook: 1.4980032574385405e-06
    epoch_before_hook: 2.484399010427296e-05
    evaluation_metrics: 0.00040271200123243034
    evaluation_paths: 0.4915031709824689
    sample: 13.26812285577762
    timestep_after_hook: 0.03251859432202764
    timestep_before_hook: 0.07575908480794169
    train: 192.38865526096197
    training_metrics: 0.0015071420057211071
    training_paths: 0.07391408400144428
  timestamp: 1652834401
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2750000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.321934711933136
      reward_ctrl-last-mean: -0.3242252063751221
      reward_ctrl-mean-mean: -0.351656700977087
      reward_ctrl-median-mean: -0.3560706007480622
      reward_ctrl-range-mean: 0.4831947946548462
      reward_run-first-mean: -0.5374486207133088
      reward_run-last-mean: 15.1079030580986
      reward_run-mean-mean: 15.212820379186581
      reward_run-median-mean: 16.13774176046681
      reward_run-range-mean: 18.696105295953377
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15193.104132107714
    episode-reward-mean: 14861.163678209496
    episode-reward-min: 12951.364505300517
    episode-reward-std: 640.0343126585136
  training_iteration: 110
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 16.063312530517578
    Q_value-mean: 1323.64404296875
    alpha: 0.3440415561199188
    alpha_loss-mean: 0.0007214350625872612
    policy_loss-mean: -1322.2313232421875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    110 |          25256.9 |     109 |      25000 |          2750000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3485279083251953
  date: 2022-05-18_01-43-28
  done: false
  epoch: 110
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4319077014923096
      reward_ctrl-last-mean: -0.22577011585235596
      reward_ctrl-mean-mean: -0.3532874979317189
      reward_ctrl-median-mean: -0.35890032052993776
      reward_ctrl-range-mean: 0.4879289388656616
      reward_run-first-mean: -0.6985954170791564
      reward_run-last-mean: 17.216739771308767
      reward_run-mean-mean: 15.175160592051554
      reward_run-median-mean: 16.045273032887337
      reward_run-range-mean: 18.638439230646608
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14821.8740234375
    episode-reward-mean: 14821.8740234375
    episode-reward-min: 14821.8740234375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 111
  node_ip: 10.43.77.35
  num_train_steps: 2775000
  pid: 283289
  policy:
    actions-max: 0.9987512826919556
    actions-mean: -0.06325038522481918
    actions-min: -0.9976425170898438
    actions-std: 0.746965765953064
    entropy-mean: -5.884129047393799
    entropy-std: 3.7684450149536133
    scales-max: 0.8035759329795837
    scales-mean: 0.4073265492916107
    scales-min: 0.02868424728512764
    scales-std: 0.1592695564031601
    shifts-max: 3.2334179878234863
    shifts-mean: -0.08130655437707901
    shifts-min: -3.120347261428833
    shifts-std: 1.3524657487869263
  sampler:
    episodes: 2785
    last-path-return: 14949.23538435209
    max-path-return: 15193.104132107714
    pool-size: 1000000
    total-samples: 2785000
  time_since_restore: 25463.63619160652
  time_this_iter_s: 206.70165610313416
  time_total_s: 25463.63619160652
  times:
    epoch_after_hook: 1.4069955796003342e-06
    epoch_before_hook: 2.435100032016635e-05
    evaluation_metrics: 0.0004045109963044524
    evaluation_paths: 0.48870027798693627
    sample: 13.354752565996023
    timestep_after_hook: 0.03260563951334916
    timestep_before_hook: 0.07658146557514556
    train: 192.2910718731291
    training_metrics: 0.0015173419960774481
    training_paths: 0.07428963601705618
  timestamp: 1652834608
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2775000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3220941352844238
      reward_ctrl-last-mean: -0.291794114112854
      reward_ctrl-mean-mean: -0.34800340092659005
      reward_ctrl-median-mean: -0.35073366522789
      reward_ctrl-range-mean: 0.49516282945871354
      reward_run-first-mean: -0.3214887012882805
      reward_run-last-mean: 12.916000996817502
      reward_run-mean-mean: 13.547356534631504
      reward_run-median-mean: 14.367902753620982
      reward_run-range-mean: 18.844034105631046
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15068.924346401598
    episode-reward-mean: 13199.353133704915
    episode-reward-min: 3122.6185164284198
    episode-reward-std: 3711.850340377884
  training_iteration: 111
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 17.021106719970703
    Q_value-mean: 1325.5899658203125
    alpha: 0.33745139837265015
    alpha_loss-mean: -0.0008038980304263532
    policy_loss-mean: -1324.2265625
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    111 |          25463.6 |     110 |      25000 |          2775000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.33869272470474243
  date: 2022-05-18_01-46-55
  done: false
  epoch: 111
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.24655187129974365
      reward_ctrl-last-mean: -0.4919928550720215
      reward_ctrl-mean-mean: -0.34958138343095785
      reward_ctrl-median-mean: -0.3513204097747803
      reward_ctrl-range-mean: 0.4490174293518066
      reward_run-first-mean: -0.5838518720864089
      reward_run-last-mean: 16.11907346656608
      reward_run-mean-mean: 15.38941262755908
      reward_run-median-mean: 16.178901771483822
      reward_run-range-mean: 18.623482001732093
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15039.8310546875
    episode-reward-mean: 15039.8310546875
    episode-reward-min: 15039.8310546875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 112
  node_ip: 10.43.77.35
  num_train_steps: 2800000
  pid: 283289
  policy:
    actions-max: 0.9995461702346802
    actions-mean: -0.058493632823228836
    actions-min: -0.9989190101623535
    actions-std: 0.7709643840789795
    entropy-mean: -6.204641819000244
    entropy-std: 3.8160388469696045
    scales-max: 0.9673914313316345
    scales-mean: 0.4161454439163208
    scales-min: 0.022778332233428955
    scales-std: 0.16246339678764343
    shifts-max: 3.489604949951172
    shifts-mean: -0.11772904545068741
    shifts-min: -2.8481974601745605
    shifts-std: 1.3915505409240723
  sampler:
    episodes: 2810
    last-path-return: 15085.0499577026
    max-path-return: 15193.104132107714
    pool-size: 1000000
    total-samples: 2810000
  time_since_restore: 25670.242076396942
  time_this_iter_s: 206.60588479042053
  time_total_s: 25670.242076396942
  times:
    epoch_after_hook: 1.5620025806128979e-06
    epoch_before_hook: 2.5635992642492056e-05
    evaluation_metrics: 0.00041142001282423735
    evaluation_paths: 0.4865889399952721
    sample: 13.288428543048212
    timestep_after_hook: 0.032609837187919766
    timestep_before_hook: 0.07650175562594086
    train: 192.26515108934836
    training_metrics: 0.0016027019883040339
    training_paths: 0.07368662298540585
  timestamp: 1652834815
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2800000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3389913105964661
      reward_ctrl-last-mean: -0.35643561601638796
      reward_ctrl-mean-mean: -0.35587694271802905
      reward_ctrl-median-mean: -0.3604921543598175
      reward_ctrl-range-mean: 0.482018318772316
      reward_run-first-mean: -0.5670383871981076
      reward_run-last-mean: 16.829727001955916
      reward_run-mean-mean: 15.18243607754753
      reward_run-median-mean: 16.060200406635744
      reward_run-range-mean: 18.759054919177853
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15085.049957702606
    episode-reward-mean: 14826.559134829498
    episode-reward-min: 13999.638065491396
    episode-reward-std: 303.91899343394033
  training_iteration: 112
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 18.914051055908203
    Q_value-mean: 1323.4248046875
    alpha: 0.34524568915367126
    alpha_loss-mean: 0.0003943839983548969
    policy_loss-mean: -1322.0277099609375
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    112 |          25670.2 |     111 |      25000 |          2800000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3517308235168457
  date: 2022-05-18_01-50-22
  done: false
  epoch: 112
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.4063309192657471
      reward_ctrl-last-mean: -0.2250915765762329
      reward_ctrl-mean-mean: -0.340610608458519
      reward_ctrl-median-mean: -0.3446236848831177
      reward_ctrl-range-mean: 0.48396126031875614
      reward_run-first-mean: -0.9804397402508849
      reward_run-last-mean: 17.290394476990514
      reward_run-mean-mean: 15.35709479302593
      reward_run-median-mean: 16.132146253501674
      reward_run-range-mean: 18.647263965814005
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15016.4833984375
    episode-reward-mean: 15016.4833984375
    episode-reward-min: 15016.4833984375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 113
  node_ip: 10.43.77.35
  num_train_steps: 2825000
  pid: 283289
  policy:
    actions-max: 0.9986187815666199
    actions-mean: -0.06887224316596985
    actions-min: -1.0
    actions-std: 0.762383759021759
    entropy-mean: -6.074521064758301
    entropy-std: 3.9608266353607178
    scales-max: 2.003234624862671
    scales-mean: 0.415872186422348
    scales-min: 0.030079655349254608
    scales-std: 0.17381569743156433
    shifts-max: 4.779796600341797
    shifts-mean: -0.10369034856557846
    shifts-min: -5.447135925292969
    shifts-std: 1.3879376649856567
  sampler:
    episodes: 2835
    last-path-return: 14963.890153308137
    max-path-return: 15196.851220816701
    pool-size: 1000000
    total-samples: 2835000
  time_since_restore: 25877.12956213951
  time_this_iter_s: 206.88748574256897
  time_total_s: 25877.12956213951
  times:
    epoch_after_hook: 1.4200049918144941e-06
    epoch_before_hook: 2.4038017727434635e-05
    evaluation_metrics: 0.00041055798646993935
    evaluation_paths: 0.4924113919842057
    sample: 13.195941068144748
    timestep_after_hook: 0.032724958640756086
    timestep_before_hook: 0.07579129107762128
    train: 192.63198581524193
    training_metrics: 0.0016039449837990105
    training_paths: 0.07395743802771904
  timestamp: 1652835022
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2825000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3365364122390747
      reward_ctrl-last-mean: -0.3652901220321656
      reward_ctrl-mean-mean: -0.35367042057096965
      reward_ctrl-median-mean: -0.3571155095100403
      reward_ctrl-range-mean: 0.47150801658630365
      reward_run-first-mean: -0.7640497696776041
      reward_run-last-mean: 16.492609972950504
      reward_run-mean-mean: 15.316283827126039
      reward_run-median-mean: 16.164649491893897
      reward_run-range-mean: 18.731150525866276
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15196.851220816705
    episode-reward-mean: 14962.613406555069
    episode-reward-min: 14400.049682214336
    episode-reward-std: 210.40695871076207
  training_iteration: 113
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 18.387327194213867
    Q_value-mean: 1322.313232421875
    alpha: 0.347161203622818
    alpha_loss-mean: -0.0004242369905114174
    policy_loss-mean: -1320.9041748046875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    113 |          25877.1 |     112 |      25000 |          2825000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34722450375556946
  date: 2022-05-18_01-53-49
  done: false
  epoch: 113
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.11908299922943116
      reward_ctrl-last-mean: -0.541520357131958
      reward_ctrl-mean-mean: -0.3592180978894233
      reward_ctrl-median-mean: -0.35921081304550173
      reward_ctrl-range-mean: 0.46853296756744384
      reward_run-first-mean: -0.38284123538793763
      reward_run-last-mean: 15.828289404896623
      reward_run-mean-mean: 15.22803098750667
      reward_run-median-mean: 16.142247358519057
      reward_run-range-mean: 18.246316481607817
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14868.8125
    episode-reward-mean: 14868.8125
    episode-reward-min: 14868.8125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 114
  node_ip: 10.43.77.35
  num_train_steps: 2850000
  pid: 283289
  policy:
    actions-max: 0.9999257922172546
    actions-mean: -0.07921599596738815
    actions-min: -0.9978612065315247
    actions-std: 0.7561800479888916
    entropy-mean: -5.803073883056641
    entropy-std: 3.7292747497558594
    scales-max: 1.0931980609893799
    scales-mean: 0.41359278559684753
    scales-min: 0.030511435121297836
    scales-std: 0.16558438539505005
    shifts-max: 4.162867546081543
    shifts-mean: -0.13042020797729492
    shifts-min: -2.765606164932251
    shifts-std: 1.356216549873352
  sampler:
    episodes: 2860
    last-path-return: 14894.824383866904
    max-path-return: 15196.851220816701
    pool-size: 1000000
    total-samples: 2860000
  time_since_restore: 26083.86477804184
  time_this_iter_s: 206.7352159023285
  time_total_s: 26083.86477804184
  times:
    epoch_after_hook: 1.514999894425273e-06
    epoch_before_hook: 2.4130975361913443e-05
    evaluation_metrics: 0.00042060299892909825
    evaluation_paths: 0.4894207500037737
    sample: 13.323601889103884
    timestep_after_hook: 0.032661696313880384
    timestep_before_hook: 0.0768423706467729
    train: 192.26681695663137
    training_metrics: 0.001614554988918826
    training_paths: 0.16207206298713572
  timestamp: 1652835229
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2850000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2987836837768555
      reward_ctrl-last-mean: -0.34436737060546874
      reward_ctrl-mean-mean: -0.34311897345840936
      reward_ctrl-median-mean: -0.3447191905975342
      reward_ctrl-range-mean: 0.4839397302269936
      reward_run-first-mean: -0.5299136141587348
      reward_run-last-mean: 14.254714183459157
      reward_run-mean-mean: 14.01080125086295
      reward_run-median-mean: 14.558837007760602
      reward_run-range-mean: 18.555493850874576
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15180.796671942699
    episode-reward-mean: 13667.682277404543
    episode-reward-min: 2071.6678646416494
    episode-reward-std: 3871.0865729225025
  training_iteration: 114
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 18.027944564819336
    Q_value-mean: 1322.7197265625
    alpha: 0.34546253085136414
    alpha_loss-mean: 0.00026788757531903684
    policy_loss-mean: -1321.3095703125
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    114 |          26083.9 |     113 |      25000 |          2850000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.35210496187210083
  date: 2022-05-18_01-57-15
  done: false
  epoch: 114
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.15621819496154787
      reward_ctrl-last-mean: -0.2763553619384766
      reward_ctrl-mean-mean: -0.35736426782608033
      reward_ctrl-median-mean: -0.3496174573898316
      reward_ctrl-range-mean: 0.4677455306053162
      reward_run-first-mean: -0.3797079152717703
      reward_run-last-mean: 17.482184052262255
      reward_run-mean-mean: 15.434270647747201
      reward_run-median-mean: 16.343276430812068
      reward_run-range-mean: 18.92391662765198
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15076.90625
    episode-reward-mean: 15076.90625
    episode-reward-min: 15076.90625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 115
  node_ip: 10.43.77.35
  num_train_steps: 2875000
  pid: 283289
  policy:
    actions-max: 0.9992924928665161
    actions-mean: -0.0027173261623829603
    actions-min: -0.9998742938041687
    actions-std: 0.7790273427963257
    entropy-mean: -6.08607292175293
    entropy-std: 3.760627269744873
    scales-max: 0.8872702121734619
    scales-mean: 0.42942699790000916
    scales-min: 0.03219382464885712
    scales-std: 0.1580810397863388
    shifts-max: 3.2363762855529785
    shifts-mean: 0.01608344353735447
    shifts-min: -5.009181022644043
    shifts-std: 1.4135462045669556
  sampler:
    episodes: 2885
    last-path-return: 14951.626608672019
    max-path-return: 15196.851220816701
    pool-size: 1000000
    total-samples: 2885000
  time_since_restore: 26290.3562207222
  time_this_iter_s: 206.4914426803589
  time_total_s: 26290.3562207222
  times:
    epoch_after_hook: 1.4849938452243805e-06
    epoch_before_hook: 2.527900505810976e-05
    evaluation_metrics: 0.0004018420004285872
    evaluation_paths: 0.4891413610021118
    sample: 13.162511911825277
    timestep_after_hook: 0.0326106124848593
    timestep_before_hook: 0.0761346562358085
    train: 192.18492995141423
    training_metrics: 0.0014484839921351522
    training_paths: 0.16290915000718087
  timestamp: 1652835435
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2875000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3105127894878387
      reward_ctrl-last-mean: -0.319198341369629
      reward_ctrl-mean-mean: -0.3527598289883137
      reward_ctrl-median-mean: -0.3557400786876678
      reward_ctrl-range-mean: 0.48346040606498714
      reward_run-first-mean: -0.5067775800324104
      reward_run-last-mean: 14.494568076978794
      reward_run-mean-mean: 14.706091036082432
      reward_run-median-mean: 16.04792874578297
      reward_run-range-mean: 18.73691373908565
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15138.76756055135
    episode-reward-mean: 14353.331207094117
    episode-reward-min: 10292.291991960023
    episode-reward-std: 1401.8842877503141
  training_iteration: 115
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 18.958314895629883
    Q_value-mean: 1320.9638671875
    alpha: 0.3485243022441864
    alpha_loss-mean: -5.025663267588243e-05
    policy_loss-mean: -1319.5367431640625
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    115 |          26290.4 |     114 |      25000 |          2875000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3345533609390259
  date: 2022-05-18_02-00-42
  done: false
  epoch: 115
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.23495373725891114
      reward_ctrl-last-mean: -0.3957845687866211
      reward_ctrl-mean-mean: -0.3537209704399109
      reward_ctrl-median-mean: -0.3530530214309693
      reward_ctrl-range-mean: 0.5125218868255615
      reward_run-first-mean: -0.9890688068946532
      reward_run-last-mean: 15.630023133676332
      reward_run-mean-mean: 14.712627371268667
      reward_run-median-mean: 15.801281003683414
      reward_run-range-mean: 18.81488550632385
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14358.90625
    episode-reward-mean: 14358.90625
    episode-reward-min: 14358.90625
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 116
  node_ip: 10.43.77.35
  num_train_steps: 2900000
  pid: 283289
  policy:
    actions-max: 0.9996411204338074
    actions-mean: -0.05521450936794281
    actions-min: -0.9996495246887207
    actions-std: 0.7644496560096741
    entropy-mean: -5.937935829162598
    entropy-std: 4.001102924346924
    scales-max: 1.0528862476348877
    scales-mean: 0.4135681688785553
    scales-min: 0.03394895792007446
    scales-std: 0.15773479640483856
    shifts-max: 3.818093776702881
    shifts-mean: -0.09037670493125916
    shifts-min: -3.922344207763672
    shifts-std: 1.3997695446014404
  sampler:
    episodes: 2910
    last-path-return: 14955.365326454652
    max-path-return: 15232.460526326477
    pool-size: 1000000
    total-samples: 2910000
  time_since_restore: 26496.908250808716
  time_this_iter_s: 206.55203008651733
  time_total_s: 26496.908250808716
  times:
    epoch_after_hook: 1.6060075722634792e-06
    epoch_before_hook: 3.068198566325009e-05
    evaluation_metrics: 0.00040237398934550583
    evaluation_paths: 0.4856404770107474
    sample: 13.30490560468752
    timestep_after_hook: 0.032446684286696836
    timestep_before_hook: 0.07579442451242357
    train: 192.19455988684786
    training_metrics: 0.0015152739943005145
    training_paths: 0.07531528698746115
  timestamp: 1652835642
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2900000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3340460157394409
      reward_ctrl-last-mean: -0.3710925364494324
      reward_ctrl-mean-mean: -0.35428397244215015
      reward_ctrl-median-mean: -0.35771812677383424
      reward_ctrl-range-mean: 0.47665044903755194
      reward_run-first-mean: -0.4951695834489264
      reward_run-last-mean: 16.19198514763525
      reward_run-mean-mean: 15.094853495584122
      reward_run-median-mean: 16.066153033951082
      reward_run-range-mean: 18.534699974867344
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15070.589280024004
    episode-reward-mean: 14740.56952314197
    episode-reward-min: 13836.97186191258
    episode-reward-std: 397.67033683304544
  training_iteration: 116
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 20.113460540771484
    Q_value-mean: 1323.0343017578125
    alpha: 0.34410423040390015
    alpha_loss-mean: 0.000725420075468719
    policy_loss-mean: -1321.6453857421875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    116 |          26496.9 |     115 |      25000 |          2900000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.3344019651412964
  date: 2022-05-18_02-04-08
  done: false
  epoch: 116
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.43283767700195314
      reward_ctrl-last-mean: -0.11245468854904175
      reward_ctrl-mean-mean: -0.3393811883211136
      reward_ctrl-median-mean: -0.33844747543334963
      reward_ctrl-range-mean: 0.4560606002807618
      reward_run-first-mean: -0.5090001143301076
      reward_run-last-mean: 17.218001411538353
      reward_run-mean-mean: 15.44918142923785
      reward_run-median-mean: 16.157547826943528
      reward_run-range-mean: 18.266130272586693
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15109.7998046875
    episode-reward-mean: 15109.7998046875
    episode-reward-min: 15109.7998046875
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 117
  node_ip: 10.43.77.35
  num_train_steps: 2925000
  pid: 283289
  policy:
    actions-max: 0.9985426068305969
    actions-mean: -0.05691168084740639
    actions-min: -0.9990127682685852
    actions-std: 0.7525234818458557
    entropy-mean: -5.761006832122803
    entropy-std: 3.612032413482666
    scales-max: 0.8254150152206421
    scales-mean: 0.4015449583530426
    scales-min: 0.02839982882142067
    scales-std: 0.15981927514076233
    shifts-max: 2.77726149559021
    shifts-mean: -0.11914841085672379
    shifts-min: -3.0726544857025146
    shifts-std: 1.344663381576538
  sampler:
    episodes: 2935
    last-path-return: 15036.683060086923
    max-path-return: 15232.460526326477
    pool-size: 1000000
    total-samples: 2935000
  time_since_restore: 26703.434211969376
  time_this_iter_s: 206.5259611606598
  time_total_s: 26703.434211969376
  times:
    epoch_after_hook: 1.5720142982900143e-06
    epoch_before_hook: 2.4612003471702337e-05
    evaluation_metrics: 0.0004023670044261962
    evaluation_paths: 0.48579307200270705
    sample: 13.240752892830642
    timestep_after_hook: 0.03254014771664515
    timestep_before_hook: 0.07614882191410288
    train: 192.2339230705693
    training_metrics: 0.0015311309834942222
    training_paths: 0.07311187000595964
  timestamp: 1652835848
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2925000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2924098920822144
      reward_ctrl-last-mean: -0.35671584606170653
      reward_ctrl-mean-mean: -0.35263610562980174
      reward_ctrl-median-mean: -0.3561998903751374
      reward_ctrl-range-mean: 0.4833634829521179
      reward_run-first-mean: -0.6144830666485112
      reward_run-last-mean: 16.412378954252517
      reward_run-mean-mean: 15.283572948389875
      reward_run-median-mean: 16.144529056704187
      reward_run-range-mean: 18.56115887487206
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15141.286716429993
    episode-reward-mean: 14930.936842760071
    episode-reward-min: 14567.938356893981
    episode-reward-std: 179.2237696018694
  training_iteration: 117
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 21.967166900634766
    Q_value-mean: 1323.10986328125
    alpha: 0.3487073481082916
    alpha_loss-mean: 1.6070194760686718e-05
    policy_loss-mean: -1321.6944580078125
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    117 |          26703.4 |     116 |      25000 |          2925000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34423792362213135
  date: 2022-05-18_02-07-35
  done: false
  epoch: 117
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.24439861774444582
      reward_ctrl-last-mean: -0.44486517906188966
      reward_ctrl-mean-mean: -0.3497545825600624
      reward_ctrl-median-mean: -0.3614867925643921
      reward_ctrl-range-mean: 0.48263162374496466
      reward_run-first-mean: -0.42309339900824694
      reward_run-last-mean: 15.887299072951464
      reward_run-mean-mean: 14.727150900844515
      reward_run-median-mean: 15.826667841205335
      reward_run-range-mean: 18.185572272661684
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14377.396484375
    episode-reward-mean: 14377.396484375
    episode-reward-min: 14377.396484375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 118
  node_ip: 10.43.77.35
  num_train_steps: 2950000
  pid: 283289
  policy:
    actions-max: 0.9999996423721313
    actions-mean: -0.03164111450314522
    actions-min: -0.9999756813049316
    actions-std: 0.7683982849121094
    entropy-mean: -6.026514053344727
    entropy-std: 3.9434704780578613
    scales-max: 0.8656677603721619
    scales-mean: 0.4124045670032501
    scales-min: 0.03497932106256485
    scales-std: 0.15802092850208282
    shifts-max: 7.1221923828125
    shifts-mean: -0.031563788652420044
    shifts-min: -5.39150857925415
    shifts-std: 1.41343355178833
  sampler:
    episodes: 2960
    last-path-return: 14954.70659297416
    max-path-return: 15232.460526326477
    pool-size: 1000000
    total-samples: 2960000
  time_since_restore: 26910.031877994537
  time_this_iter_s: 206.59766602516174
  time_total_s: 26910.031877994537
  times:
    epoch_after_hook: 1.5379919204860926e-06
    epoch_before_hook: 2.52070021815598e-05
    evaluation_metrics: 0.0004079759819433093
    evaluation_paths: 0.4878077610046603
    sample: 13.176546279108152
    timestep_after_hook: 0.03258755124988966
    timestep_before_hook: 0.07563785812817514
    train: 192.27941117875162
    training_metrics: 0.0014766929962206632
    training_paths: 0.1624750749906525
  timestamp: 1652836055
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2950000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2988270604610443
      reward_ctrl-last-mean: -0.3281995177268982
      reward_ctrl-mean-mean: -0.34855740905761723
      reward_ctrl-median-mean: -0.3513153207302094
      reward_ctrl-range-mean: 0.4804124873876572
      reward_run-first-mean: -0.5778356373034089
      reward_run-last-mean: 15.027549480330094
      reward_run-mean-mean: 14.432057575823766
      reward_run-median-mean: 14.747725613484008
      reward_run-range-mean: 18.803375263123613
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15153.634765679837
    episode-reward-mean: 14083.500166766147
    episode-reward-min: 6437.675420753198
    episode-reward-std: 2555.7155925530096
  training_iteration: 118
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 22.002052307128906
    Q_value-mean: 1322.786376953125
    alpha: 0.34783828258514404
    alpha_loss-mean: -0.00024653912987560034
    policy_loss-mean: -1321.3541259765625
  
== Status ==
Memory usage on this node: 13.7/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    118 |            26910 |     117 |      25000 |          2950000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34862950444221497
  date: 2022-05-18_02-11-02
  done: false
  epoch: 118
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.3971468210220337
      reward_ctrl-last-mean: -0.3322858572006226
      reward_ctrl-mean-mean: -0.3428470297694206
      reward_ctrl-median-mean: -0.3486976981163025
      reward_ctrl-range-mean: 0.5186675906181335
      reward_run-first-mean: -0.7941545649149867
      reward_run-last-mean: 17.222352156177294
      reward_run-mean-mean: 14.96859437600337
      reward_run-median-mean: 15.861057938675458
      reward_run-range-mean: 18.742955387378213
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 14625.7470703125
    episode-reward-mean: 14625.7470703125
    episode-reward-min: 14625.7470703125
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 119
  node_ip: 10.43.77.35
  num_train_steps: 2975000
  pid: 283289
  policy:
    actions-max: 1.0
    actions-mean: -0.03182562068104744
    actions-min: -0.9999150037765503
    actions-std: 0.7635217905044556
    entropy-mean: -6.0617218017578125
    entropy-std: 4.406188488006592
    scales-max: 1.1588168144226074
    scales-mean: 0.40464887022972107
    scales-min: 0.013675177469849586
    scales-std: 0.15573076903820038
    shifts-max: 7.565428256988525
    shifts-mean: -0.052777379751205444
    shifts-min: -4.906698226928711
    shifts-std: 1.3917442560195923
  sampler:
    episodes: 2985
    last-path-return: 15090.977461201728
    max-path-return: 15232.460526326477
    pool-size: 1000000
    total-samples: 2985000
  time_since_restore: 27116.987400770187
  time_this_iter_s: 206.95552277565002
  time_total_s: 27116.987400770187
  times:
    epoch_after_hook: 1.8700084183365107e-06
    epoch_before_hook: 2.5721994461491704e-05
    evaluation_metrics: 0.008153445000061765
    evaluation_paths: 0.5240943859971594
    sample: 13.414428868913092
    timestep_after_hook: 0.03248643811093643
    timestep_before_hook: 0.07656006448087282
    train: 192.4278435119195
    training_metrics: 0.006172623980091885
    training_paths: 0.07435117900604382
  timestamp: 1652836262
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 2975000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.3324545383453369
      reward_ctrl-last-mean: -0.36626917839050294
      reward_ctrl-mean-mean: -0.3555582309633494
      reward_ctrl-median-mean: -0.3586556267738342
      reward_ctrl-range-mean: 0.47834403932094577
      reward_run-first-mean: -0.5686959977543186
      reward_run-last-mean: 16.470537329803847
      reward_run-mean-mean: 15.240361903918275
      reward_run-median-mean: 16.095281374950133
      reward_run-range-mean: 18.79794880095712
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15125.872682473022
    episode-reward-mean: 14884.80367295493
    episode-reward-min: 14416.943848493118
    episode-reward-std: 245.1249491759678
  training_iteration: 119
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 22.412050247192383
    Q_value-mean: 1321.5010986328125
    alpha: 0.35091620683670044
    alpha_loss-mean: 5.6524277169955894e-05
    policy_loss-mean: -1320.054931640625
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    119 |            27117 |     118 |      25000 |          2975000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34768936038017273
  date: 2022-05-18_02-14-29
  done: false
  epoch: 119
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.32089996337890625
      reward_ctrl-last-mean: -0.2938960075378418
      reward_ctrl-mean-mean: -0.3563772949457169
      reward_ctrl-median-mean: -0.35338134765625007
      reward_ctrl-range-mean: 0.441618013381958
      reward_run-first-mean: -0.901636802731503
      reward_run-last-mean: 17.366281163988333
      reward_run-mean-mean: 15.393971428460311
      reward_run-median-mean: 16.32974881918244
      reward_run-range-mean: 18.92029505791612
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15037.59375
    episode-reward-mean: 15037.59375
    episode-reward-min: 15037.59375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 120
  node_ip: 10.43.77.35
  num_train_steps: 3000000
  pid: 283289
  policy:
    actions-max: 0.9994532465934753
    actions-mean: -0.0065599605441093445
    actions-min: -0.9990545511245728
    actions-std: 0.7654885053634644
    entropy-mean: -6.007743835449219
    entropy-std: 3.7272140979766846
    scales-max: 0.8445427417755127
    scales-mean: 0.41251087188720703
    scales-min: 0.023808641359210014
    scales-std: 0.16532734036445618
    shifts-max: 3.6187455654144287
    shifts-mean: 0.014624953269958496
    shifts-min: -3.6748318672180176
    shifts-std: 1.3572572469711304
  sampler:
    episodes: 3010
    last-path-return: 14481.609763504412
    max-path-return: 15232.460526326477
    pool-size: 1000000
    total-samples: 3010000
  time_since_restore: 27323.98278617859
  time_this_iter_s: 206.9953854084015
  time_total_s: 27323.98278617859
  times:
    epoch_after_hook: 1.4289980754256248e-06
    epoch_before_hook: 2.5290995836257935e-05
    evaluation_metrics: 0.0004020220076199621
    evaluation_paths: 0.48442512200563215
    sample: 13.425991960742977
    timestep_after_hook: 0.03260063339257613
    timestep_before_hook: 0.0761223591689486
    train: 192.51948056017864
    training_metrics: 0.0014970320044085383
    training_paths: 0.07383893697988242
  timestamp: 1652836469
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 3000000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2903135490417481
      reward_ctrl-last-mean: -0.33747656822204586
      reward_ctrl-mean-mean: -0.35635778270542623
      reward_ctrl-median-mean: -0.3600524139404297
      reward_ctrl-range-mean: 0.48695250809192664
      reward_run-first-mean: -0.6205316460601776
      reward_run-last-mean: 14.760831890899567
      reward_run-mean-mean: 14.571117201489045
      reward_run-median-mean: 15.511190327807668
      reward_run-range-mean: 18.53039989996118
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15182.298062229598
    episode-reward-mean: 14214.759418783622
    episode-reward-min: 8293.161208167816
    episode-reward-std: 1986.130780181625
  training_iteration: 120
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 22.666852951049805
    Q_value-mean: 1320.7296142578125
    alpha: 0.3456360995769501
    alpha_loss-mean: 9.347370360046625e-05
    policy_loss-mean: -1319.3094482421875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 RUNNING)
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status   | loc                |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | RUNNING  | 10.43.77.35:283289 |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    120 |            27324 |     119 |      25000 |          3000000 |
+--------------------------+----------+--------------------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Result for id=31acc_00000-seed=9479:
  alpha: 0.34768936038017273
  date: 2022-05-18_02-14-29
  done: true
  epoch: 119
  evaluation:
    environment_infos:
      reward_ctrl-first-mean: -0.32089996337890625
      reward_ctrl-last-mean: -0.2938960075378418
      reward_ctrl-mean-mean: -0.3563772949457169
      reward_ctrl-median-mean: -0.35338134765625007
      reward_ctrl-range-mean: 0.441618013381958
      reward_run-first-mean: -0.901636802731503
      reward_run-last-mean: 17.366281163988333
      reward_run-mean-mean: 15.393971428460311
      reward_run-median-mean: 16.32974881918244
      reward_run-range-mean: 18.92029505791612
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15037.59375
    episode-reward-mean: 15037.59375
    episode-reward-min: 15037.59375
    episode-reward-std: 0.0
  experiment_id: aa6a66a2866746f0a9d46236d60e4b5e
  hostname: cpu-q-259
  iterations_since_restore: 121
  node_ip: 10.43.77.35
  num_train_steps: 3000000
  pid: 283289
  policy:
    actions-max: 0.9994532465934753
    actions-mean: -0.0065599605441093445
    actions-min: -0.9990545511245728
    actions-std: 0.7654885053634644
    entropy-mean: -6.007743835449219
    entropy-std: 3.7272140979766846
    scales-max: 0.8445427417755127
    scales-mean: 0.41251087188720703
    scales-min: 0.023808641359210014
    scales-std: 0.16532734036445618
    shifts-max: 3.6187455654144287
    shifts-mean: 0.014624953269958496
    shifts-min: -3.6748318672180176
    shifts-std: 1.3572572469711304
  sampler:
    episodes: 3010
    last-path-return: 14481.609763504412
    max-path-return: 15232.460526326477
    pool-size: 1000000
    total-samples: 3010000
  time_since_restore: 27323.982830762863
  time_this_iter_s: 4.458427429199219e-05
  time_total_s: 27323.982830762863
  times:
    epoch_after_hook: 1.4289980754256248e-06
    epoch_before_hook: 2.5290995836257935e-05
    evaluation_metrics: 0.0004020220076199621
    evaluation_paths: 0.48442512200563215
    sample: 13.425991960742977
    timestep_after_hook: 0.03260063339257613
    timestep_before_hook: 0.0761223591689486
    train: 192.51948056017864
    training_metrics: 0.0014970320044085383
    training_paths: 0.07383893697988242
  timestamp: 1652836469
  timestep: 25000
  timesteps_since_restore: 0
  total_timestep: 3000000
  training:
    environment_infos:
      reward_ctrl-first-mean: -0.2903135490417481
      reward_ctrl-last-mean: -0.33747656822204586
      reward_ctrl-mean-mean: -0.35635778270542623
      reward_ctrl-median-mean: -0.3600524139404297
      reward_ctrl-range-mean: 0.48695250809192664
      reward_run-first-mean: -0.6205316460601776
      reward_run-last-mean: 14.760831890899567
      reward_run-mean-mean: 14.571117201489045
      reward_run-median-mean: 15.511190327807668
      reward_run-range-mean: 18.53039989996118
    episode-length-max: 1000
    episode-length-mean: 1000.0
    episode-length-min: 1000
    episode-length-std: 0.0
    episode-reward-max: 15182.298062229598
    episode-reward-mean: 14214.759418783622
    episode-reward-min: 8293.161208167816
    episode-reward-std: 1986.130780181625
  training_iteration: 121
  trial_id: 31acc_00000
  update:
    Q_loss-mean: 22.666852951049805
    Q_value-mean: 1320.7296142578125
    alpha: 0.3456360995769501
    alpha_loss-mean: 9.347370360046625e-05
    policy_loss-mean: -1319.3094482421875
  
== Status ==
Memory usage on this node: 13.6/251.1 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/1 CPUs, 0/0 GPUs, 0.0/160.99 GiB heap, 0.0/50.34 GiB objects
Result logdir: /rds/user/ajc348/hpc-work/softlearning/gym/HalfCheetah/v2/2022-05-17T18-38-36-half_cheetah_v2_3M
Number of trials: 1/1 (1 TERMINATED)
+--------------------------+------------+-------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+
| Trial name               | status     | loc   |   algorithm_params/config/num_warmup_samples | environment_params/evaluation                                            | exploration_policy_params/config/observation_keys   |   replay_pool_params/config/max_size |   run_params/seed |   iter |   total time (s) |   epoch |   timestep |   total_timestep |
|--------------------------+------------+-------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------|
| id=31acc_00000-seed=9479 | TERMINATED |       |                                        10000 | {'domain': 'HalfCheetah', 'task': 'v2', 'universe': 'gym', 'kwargs': {}} |                                                     |                              1000000 |              9479 |    121 |            27324 |     119 |      25000 |          3000000 |
+--------------------------+------------+-------+----------------------------------------------+--------------------------------------------------------------------------+-----------------------------------------------------+--------------------------------------+-------------------+--------+------------------+---------+------------+------------------+


Time: Wed 18 May 02:14:43 BST 2022
