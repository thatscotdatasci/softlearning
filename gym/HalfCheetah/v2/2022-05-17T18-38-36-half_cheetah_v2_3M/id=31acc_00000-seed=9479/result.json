{"alpha": 0.022199438884854317, "policy": {"shifts-mean": 0.15410666167736053, "shifts-std": 1.5152584314346313, "shifts-max": 6.150871276855469, "shifts-min": -5.133410453796387, "scales-mean": 0.4585624933242798, "scales-std": 0.13413293659687042, "scales-max": 0.850675642490387, "scales-min": 0.05785929784178734, "entropy-mean": -5.925097465515137, "entropy-std": 5.327149391174316, "actions-mean": 0.062251586467027664, "actions-std": 0.7550143003463745, "actions-min": -0.9999655485153198, "actions-max": 0.9999919533729553}, "evaluation": {"episode-reward-mean": 2083.8544921875, "episode-reward-min": 2083.8544921875, "episode-reward-max": 2083.8544921875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.15881838137952534, "reward_run-last-mean": 3.043933509962642, "reward_run-mean-mean": 2.489522605371327, "reward_run-median-mean": 2.5072648085321703, "reward_run-range-mean": 4.9004801345415085, "reward_ctrl-first-mean": -0.0733493447303772, "reward_ctrl-last-mean": -0.24177770614624025, "reward_ctrl-mean-mean": -0.40566818028092383, "reward_ctrl-median-mean": -0.4013489961624146, "reward_ctrl-range-mean": 0.5176917433738708}}, "training": {"episode-reward-mean": 1223.2310862100655, "episode-reward-min": 341.20224356278743, "episode-reward-max": 2192.613764987499, "episode-reward-std": 666.3774889400128, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.11756213770337857, "reward_run-last-mean": 1.2229291202939976, "reward_run-mean-mean": 1.5735910558948452, "reward_run-median-mean": 1.5497981126034228, "reward_run-range-mean": 5.370052736386373, "reward_ctrl-first-mean": -0.21595763325691225, "reward_ctrl-last-mean": -0.36651077270507815, "reward_ctrl-mean-mean": -0.3503599696847796, "reward_ctrl-median-mean": -0.35137261390686036, "reward_ctrl-range-mean": 0.5083147391676903}}, "update": {"Q_value-mean": 31.682151794433594, "Q_loss-mean": 0.8549200892448425, "policy_loss-mean": -32.87811279296875, "alpha": 0.16832508146762848, "alpha_loss-mean": 1.4849790334701538}, "times": {"epoch_before_hook": 6.268199649639428e-05, "timestep_before_hook": 0.15682598284911364, "sample": 30.426710831641685, "train": 354.45912373505416, "timestep_after_hook": 0.07371451702783816, "training_paths": 0.1164847589971032, "evaluation_paths": 0.628755097015528, "training_metrics": 0.0024790540046524256, "evaluation_metrics": 0.0005245979991741478, "epoch_after_hook": 5.029025487601757e-06}, "sampler": {"pool-size": 35000, "max-path-return": 2192.6137649875004, "last-path-return": 2192.6137649875004, "episodes": 35, "total-samples": 35000}, "epoch": 0, "timestep": 25000, "total_timestep": 25000, "num_train_steps": 25000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 1, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_18-45-31", "timestamp": 1652809531, "time_this_iter_s": 395.0176303386688, "time_total_s": 395.0176303386688, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 395.0176303386688, "timesteps_since_restore": 0, "iterations_since_restore": 1, "trial_id": "31acc_00000"}
{"alpha": 0.05950060859322548, "policy": {"shifts-mean": -0.18694020807743073, "shifts-std": 1.505892038345337, "shifts-max": 4.100767612457275, "shifts-min": -4.588189125061035, "scales-mean": 0.45082521438598633, "scales-std": 0.12832054495811462, "scales-max": 0.8492934703826904, "scales-min": 0.11528021097183228, "entropy-mean": -5.80190896987915, "entropy-std": 4.736921787261963, "actions-mean": -0.10309091210365295, "actions-std": 0.7640261650085449, "actions-min": -0.9998109340667725, "actions-max": 0.9998502731323242}, "evaluation": {"episode-reward-mean": 4094.70166015625, "episode-reward-min": 4094.70166015625, "episode-reward-max": 4094.70166015625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.21844404751881624, "reward_run-last-mean": 3.343079540268832, "reward_run-mean-mean": 4.499761381835619, "reward_run-median-mean": 4.546663723275799, "reward_run-range-mean": 7.736369048701644, "reward_ctrl-first-mean": -0.17286659479141236, "reward_ctrl-last-mean": -0.3042518138885498, "reward_ctrl-mean-mean": -0.40505981182456013, "reward_ctrl-median-mean": -0.41622602939605713, "reward_ctrl-range-mean": 0.5346337914466859}}, "training": {"episode-reward-mean": 3557.2080884079755, "episode-reward-min": 2087.0890662988045, "episode-reward-max": 3999.383280721253, "episode-reward-std": 513.4161246000078, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.02403387039441019, "reward_run-last-mean": 3.9548878424637053, "reward_run-mean-mean": 3.95635086619721, "reward_run-median-mean": 4.0815336445482675, "reward_run-range-mean": 7.244057052967378, "reward_ctrl-first-mean": -0.13933264911174775, "reward_ctrl-last-mean": -0.4188309216499329, "reward_ctrl-mean-mean": -0.3991427777892351, "reward_ctrl-median-mean": -0.40815962672233586, "reward_ctrl-range-mean": 0.5119784712791444}}, "update": {"Q_value-mean": 86.8278579711914, "Q_loss-mean": 3.01059627532959, "policy_loss-mean": -88.13670349121094, "alpha": 0.04310385137796402, "alpha_loss-mean": -0.001724769244901836}, "times": {"epoch_before_hook": 5.1144015742465854e-05, "timestep_before_hook": 0.15804931175080128, "sample": 30.08659325444023, "train": 351.9322879568499, "timestep_after_hook": 0.07314514962490648, "training_paths": 0.14995126097346656, "evaluation_paths": 0.6532335710071493, "training_metrics": 0.0022374410182237625, "evaluation_metrics": 0.0005151730147190392, "epoch_after_hook": 5.651003448292613e-06}, "sampler": {"pool-size": 60000, "max-path-return": 3999.383280721255, "last-path-return": 3999.383280721255, "episodes": 60, "total-samples": 60000}, "epoch": 1, "timestep": 25000, "total_timestep": 50000, "num_train_steps": 50000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 2, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_18-51-55", "timestamp": 1652809915, "time_this_iter_s": 384.0894355773926, "time_total_s": 779.1070659160614, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 779.1070659160614, "timesteps_since_restore": 0, "iterations_since_restore": 2, "trial_id": "31acc_00000"}
{"alpha": 0.08804360777139664, "policy": {"shifts-mean": -0.19690358638763428, "shifts-std": 1.498092770576477, "shifts-max": 4.336303234100342, "shifts-min": -3.5031967163085938, "scales-mean": 0.4709673225879669, "scales-std": 0.12476688623428345, "scales-max": 1.1031697988510132, "scales-min": 0.12076408416032791, "entropy-mean": -5.94718599319458, "entropy-std": 4.554985046386719, "actions-mean": -0.12800033390522003, "actions-std": 0.7713759541511536, "actions-min": -0.9992426633834839, "actions-max": 0.9996910691261292}, "evaluation": {"episode-reward-mean": 4781.29052734375, "episode-reward-min": 4781.29052734375, "episode-reward-max": 4781.29052734375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.133546697744103, "reward_run-last-mean": 6.416320448184933, "reward_run-mean-mean": 5.180508922117181, "reward_run-median-mean": 5.248296437416968, "reward_run-range-mean": 8.614834599173358, "reward_ctrl-first-mean": -0.21874232292175294, "reward_ctrl-last-mean": -0.5243102073669433, "reward_ctrl-mean-mean": -0.3992183406889439, "reward_ctrl-median-mean": -0.4058669567108154, "reward_ctrl-range-mean": 0.526886111497879}}, "training": {"episode-reward-mean": 4415.596922883826, "episode-reward-min": 3270.943760394851, "episode-reward-max": 4919.544245501505, "episode-reward-std": 452.12730783276925, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.1371819524852076, "reward_run-last-mean": 4.691249035474016, "reward_run-mean-mean": 4.815453765154021, "reward_run-median-mean": 4.913175667319123, "reward_run-range-mean": 8.182498679555511, "reward_ctrl-first-mean": -0.19464985251426697, "reward_ctrl-last-mean": -0.38328874111175537, "reward_ctrl-mean-mean": -0.3998568422701955, "reward_ctrl-median-mean": -0.40519793868064885, "reward_ctrl-range-mean": 0.4941297772526741}}, "update": {"Q_value-mean": 185.26608276367188, "Q_loss-mean": 5.122433185577393, "policy_loss-mean": -186.63748168945312, "alpha": 0.07621338218450546, "alpha_loss-mean": -0.0012231569271534681}, "times": {"epoch_before_hook": 4.820601316168904e-05, "timestep_before_hook": 0.15820196745335124, "sample": 30.174345034756698, "train": 351.82655100073316, "timestep_after_hook": 0.07491712420596741, "training_paths": 0.11609811100061052, "evaluation_paths": 0.63337003000197, "training_metrics": 0.002001996006583795, "evaluation_metrics": 0.0004970039881300181, "epoch_after_hook": 1.8520222511142492e-06}, "sampler": {"pool-size": 85000, "max-path-return": 4919.544245501507, "last-path-return": 4919.544245501507, "episodes": 85, "total-samples": 85000}, "epoch": 2, "timestep": 25000, "total_timestep": 75000, "num_train_steps": 75000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 3, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_18-58-19", "timestamp": 1652810299, "time_this_iter_s": 384.0243384838104, "time_total_s": 1163.1314043998718, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 1163.1314043998718, "timesteps_since_restore": 0, "iterations_since_restore": 3, "trial_id": "31acc_00000"}
{"alpha": 0.10586971044540405, "policy": {"shifts-mean": -0.3315093517303467, "shifts-std": 1.4689444303512573, "shifts-max": 4.7216339111328125, "shifts-min": -4.00874662399292, "scales-mean": 0.46625956892967224, "scales-std": 0.13416379690170288, "scales-max": 1.2242717742919922, "scales-min": 0.0866270437836647, "entropy-mean": -6.087279319763184, "entropy-std": 4.239784240722656, "actions-mean": -0.17577631771564484, "actions-std": 0.7696006298065186, "actions-min": -0.9994962811470032, "actions-max": 0.9997616410255432}, "evaluation": {"episode-reward-mean": 5663.96533203125, "episode-reward-min": 5663.96533203125, "episode-reward-max": 5663.96533203125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.08454814080399622, "reward_run-last-mean": 6.305442817318863, "reward_run-mean-mean": 6.078497783938641, "reward_run-median-mean": 6.130801802543715, "reward_run-range-mean": 9.204205547122587, "reward_ctrl-first-mean": -0.12877511978149414, "reward_ctrl-last-mean": -0.3860980033874512, "reward_ctrl-mean-mean": -0.4145326640963555, "reward_ctrl-median-mean": -0.4224157571792603, "reward_ctrl-range-mean": 0.4787153363227844}}, "training": {"episode-reward-mean": 5518.3693636173975, "episode-reward-min": 5414.461818996722, "episode-reward-max": 5698.879639230726, "episode-reward-std": 71.44848658524484, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.2657656228646282, "reward_run-last-mean": 6.321624985130711, "reward_run-mean-mean": 5.932543589788773, "reward_run-median-mean": 5.974386806282929, "reward_run-range-mean": 9.13139855156181, "reward_ctrl-first-mean": -0.24554731726646425, "reward_ctrl-last-mean": -0.47550985574722293, "reward_ctrl-mean-mean": -0.4141742261713744, "reward_ctrl-median-mean": -0.418761329650879, "reward_ctrl-range-mean": 0.4746575117111206}}, "update": {"Q_value-mean": 257.36065673828125, "Q_loss-mean": 6.602622032165527, "policy_loss-mean": -258.64471435546875, "alpha": 0.09585023671388626, "alpha_loss-mean": -0.0007824900094419718}, "times": {"epoch_before_hook": 5.325101665221155e-05, "timestep_before_hook": 0.15901179786305875, "sample": 30.357837532937992, "train": 351.89774048147956, "timestep_after_hook": 0.076373110874556, "training_paths": 0.2933255600219127, "evaluation_paths": 0.6407989700092003, "training_metrics": 0.00190917297732085, "evaluation_metrics": 0.0004990160232409835, "epoch_after_hook": 1.9849976524710655e-06}, "sampler": {"pool-size": 110000, "max-path-return": 5698.879639230722, "last-path-return": 5515.9880157819025, "episodes": 110, "total-samples": 110000}, "epoch": 3, "timestep": 25000, "total_timestep": 100000, "num_train_steps": 100000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 4, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-04-43", "timestamp": 1652810683, "time_this_iter_s": 384.4667947292328, "time_total_s": 1547.5981991291046, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 1547.5981991291046, "timesteps_since_restore": 0, "iterations_since_restore": 4, "trial_id": "31acc_00000"}
{"alpha": 0.12576137483119965, "policy": {"shifts-mean": -0.17720605432987213, "shifts-std": 1.483383297920227, "shifts-max": 3.19850754737854, "shifts-min": -4.07259464263916, "scales-mean": 0.466850608587265, "scales-std": 0.12897659838199615, "scales-max": 1.0569173097610474, "scales-min": 0.10452701151371002, "entropy-mean": -5.979002952575684, "entropy-std": 4.756860256195068, "actions-mean": -0.11459016054868698, "actions-std": 0.7749812602996826, "actions-min": -0.9995713233947754, "actions-max": 0.9990144968032837}, "evaluation": {"episode-reward-mean": 6175.54833984375, "episode-reward-min": 6175.54833984375, "episode-reward-max": 6175.54833984375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.23332484954471966, "reward_run-last-mean": 5.808750079604579, "reward_run-mean-mean": 6.569378963136845, "reward_run-median-mean": 6.5785892037416716, "reward_run-range-mean": 9.284014124074632, "reward_ctrl-first-mean": -0.2382814407348633, "reward_ctrl-last-mean": -0.26884377002716064, "reward_ctrl-mean-mean": -0.393830669093132, "reward_ctrl-median-mean": -0.3935290813446045, "reward_ctrl-range-mean": 0.40230846405029297}}, "training": {"episode-reward-mean": 6099.195508354045, "episode-reward-min": 5960.523460057004, "episode-reward-max": 6276.437446710966, "episode-reward-std": 88.24782759974259, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.2500533081154015, "reward_run-last-mean": 6.621606572392807, "reward_run-mean-mean": 6.504391351882555, "reward_run-median-mean": 6.55734539181821, "reward_run-range-mean": 9.64075932787944, "reward_ctrl-first-mean": -0.2809224009513855, "reward_ctrl-last-mean": -0.36444481849670407, "reward_ctrl-mean-mean": -0.4051958435285091, "reward_ctrl-median-mean": -0.40764671087265014, "reward_ctrl-range-mean": 0.43352537870407104}}, "update": {"Q_value-mean": 318.1428527832031, "Q_loss-mean": 6.689094543457031, "policy_loss-mean": -319.31683349609375, "alpha": 0.1183723658323288, "alpha_loss-mean": -0.0008293612045235932}, "times": {"epoch_before_hook": 5.897998926229775e-05, "timestep_before_hook": 0.1553615087759681, "sample": 30.14139546651859, "train": 351.91378094328684, "timestep_after_hook": 0.07498146485886537, "training_paths": 0.11725906800711527, "evaluation_paths": 0.633554470987292, "training_metrics": 0.0020585019956342876, "evaluation_metrics": 0.0005242119950708002, "epoch_after_hook": 2.3139873519539833e-06}, "sampler": {"pool-size": 135000, "max-path-return": 6276.437446710968, "last-path-return": 6136.796107375714, "episodes": 135, "total-samples": 135000}, "epoch": 4, "timestep": 25000, "total_timestep": 125000, "num_train_steps": 125000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 5, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-11-08", "timestamp": 1652811068, "time_this_iter_s": 384.07560181617737, "time_total_s": 1931.673800945282, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 1931.673800945282, "timesteps_since_restore": 0, "iterations_since_restore": 5, "trial_id": "31acc_00000"}
{"alpha": 0.13825488090515137, "policy": {"shifts-mean": -0.23601919412612915, "shifts-std": 1.4854445457458496, "shifts-max": 3.2490952014923096, "shifts-min": -3.040971279144287, "scales-mean": 0.44614076614379883, "scales-std": 0.12976311147212982, "scales-max": 0.9331845641136169, "scales-min": 0.08529362082481384, "entropy-mean": -6.341861724853516, "entropy-std": 4.311136722564697, "actions-mean": -0.1547747105360031, "actions-std": 0.7782714366912842, "actions-min": -0.9990962147712708, "actions-max": 0.9995456337928772}, "evaluation": {"episode-reward-mean": 6450.4384765625, "episode-reward-min": 6450.4384765625, "episode-reward-max": 6450.4384765625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6129854944426161, "reward_run-last-mean": 6.025211695069856, "reward_run-mean-mean": 6.835883897672385, "reward_run-median-mean": 6.8805960592787585, "reward_run-range-mean": 10.198089603559472, "reward_ctrl-first-mean": -0.22699494361877443, "reward_ctrl-last-mean": -0.2764929294586182, "reward_ctrl-mean-mean": -0.3854455160617829, "reward_ctrl-median-mean": -0.38868653774261475, "reward_ctrl-range-mean": 0.46709496974945064}}, "training": {"episode-reward-mean": 6563.881424268557, "episode-reward-min": 6316.148971800387, "episode-reward-max": 6748.168533022307, "episode-reward-std": 104.07723348390378, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.17919234157122285, "reward_run-last-mean": 7.455479578135055, "reward_run-mean-mean": 6.956333715410901, "reward_run-median-mean": 7.013914596229753, "reward_run-range-mean": 10.062320992843121, "reward_ctrl-first-mean": -0.25133527636528014, "reward_ctrl-last-mean": -0.3993199849128723, "reward_ctrl-mean-mean": -0.3924522911423445, "reward_ctrl-median-mean": -0.3940505838394165, "reward_ctrl-range-mean": 0.46188883125782015}}, "update": {"Q_value-mean": 370.4268798828125, "Q_loss-mean": 6.398662567138672, "policy_loss-mean": -371.5450439453125, "alpha": 0.132320836186409, "alpha_loss-mean": -0.0005224936176091433}, "times": {"epoch_before_hook": 5.3902011131867766e-05, "timestep_before_hook": 0.1533803231723141, "sample": 29.71880228992086, "train": 349.0041448142438, "timestep_after_hook": 0.07408364658476785, "training_paths": 0.11343850701814517, "evaluation_paths": 0.6062202480097767, "training_metrics": 0.002478976995917037, "evaluation_metrics": 0.0005069820035714656, "epoch_after_hook": 1.9060098566114902e-06}, "sampler": {"pool-size": 160000, "max-path-return": 6748.168533022316, "last-path-return": 6590.85037719583, "episodes": 160, "total-samples": 160000}, "epoch": 5, "timestep": 25000, "total_timestep": 150000, "num_train_steps": 150000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 6, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-17-28", "timestamp": 1652811448, "time_this_iter_s": 380.69902181625366, "time_total_s": 2312.3728227615356, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 2312.3728227615356, "timesteps_since_restore": 0, "iterations_since_restore": 6, "trial_id": "31acc_00000"}
{"alpha": 0.14737991988658905, "policy": {"shifts-mean": -0.28102126717567444, "shifts-std": 1.4166382551193237, "shifts-max": 3.7480130195617676, "shifts-min": -3.9125936031341553, "scales-mean": 0.45058849453926086, "scales-std": 0.14292488992214203, "scales-max": 0.9479813575744629, "scales-min": 0.09716526418924332, "entropy-mean": -5.8431549072265625, "entropy-std": 4.350927829742432, "actions-mean": -0.1666199117898941, "actions-std": 0.7622854113578796, "actions-min": -0.9984803795814514, "actions-max": 0.9993131756782532}, "evaluation": {"episode-reward-mean": 7031.02734375, "episode-reward-min": 7031.02734375, "episode-reward-max": 7031.02734375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4883629255495579, "reward_run-last-mean": 7.639927486735587, "reward_run-mean-mean": 7.428468752317396, "reward_run-median-mean": 7.492623277191228, "reward_run-range-mean": 10.74805598182042, "reward_ctrl-first-mean": -0.2564684867858887, "reward_ctrl-last-mean": -0.4311888694763184, "reward_ctrl-mean-mean": -0.3974410125076771, "reward_ctrl-median-mean": -0.39893273115158084, "reward_ctrl-range-mean": 0.4928339779376984}}, "training": {"episode-reward-mean": 6959.0722854489195, "episode-reward-min": 6836.191928459975, "episode-reward-max": 7106.066316327311, "episode-reward-std": 83.96861055506122, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.15491474351528584, "reward_run-last-mean": 7.552071977222795, "reward_run-mean-mean": 7.347904797905097, "reward_run-median-mean": 7.445379864146743, "reward_run-range-mean": 10.485342092847736, "reward_ctrl-first-mean": -0.27026398777961735, "reward_ctrl-last-mean": -0.41234587192535405, "reward_ctrl-mean-mean": -0.3888325124561788, "reward_ctrl-median-mean": -0.3905576419830322, "reward_ctrl-range-mean": 0.44535244107246397}}, "update": {"Q_value-mean": 418.4893493652344, "Q_loss-mean": 6.320980072021484, "policy_loss-mean": -419.5848693847656, "alpha": 0.14320896565914154, "alpha_loss-mean": -0.0003357154782861471}, "times": {"epoch_before_hook": 4.3517007725313306e-05, "timestep_before_hook": 0.15441229072166607, "sample": 28.87445648838184, "train": 343.5311189080239, "timestep_after_hook": 0.07336725891218521, "training_paths": 0.3051337110227905, "evaluation_paths": 0.6063655909965746, "training_metrics": 0.0019193600164726377, "evaluation_metrics": 0.0005096509994473308, "epoch_after_hook": 2.0980078261345625e-06}, "sampler": {"pool-size": 185000, "max-path-return": 7106.066316327309, "last-path-return": 7048.158218490495, "episodes": 185, "total-samples": 185000}, "epoch": 6, "timestep": 25000, "total_timestep": 175000, "num_train_steps": 175000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 7, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-23-43", "timestamp": 1652811823, "time_this_iter_s": 374.5637717247009, "time_total_s": 2686.9365944862366, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 2686.9365944862366, "timesteps_since_restore": 0, "iterations_since_restore": 7, "trial_id": "31acc_00000"}
{"alpha": 0.1538650542497635, "policy": {"shifts-mean": -0.2500855624675751, "shifts-std": 1.4224984645843506, "shifts-max": 3.797487735748291, "shifts-min": -3.7064762115478516, "scales-mean": 0.4359166622161865, "scales-std": 0.142588809132576, "scales-max": 0.9226990342140198, "scales-min": 0.0831800177693367, "entropy-mean": -6.056148052215576, "entropy-std": 4.136134147644043, "actions-mean": -0.15381880104541779, "actions-std": 0.7622804045677185, "actions-min": -0.9998754262924194, "actions-max": 0.9992172718048096}, "evaluation": {"episode-reward-mean": 7358.576171875, "episode-reward-min": 7358.576171875, "episode-reward-max": 7358.576171875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.28451071554156965, "reward_run-last-mean": 6.646038139998609, "reward_run-mean-mean": 7.745381375502073, "reward_run-median-mean": 7.93147307236886, "reward_run-range-mean": 10.774814565107693, "reward_ctrl-first-mean": -0.2332152843475342, "reward_ctrl-last-mean": -0.35339667797088625, "reward_ctrl-mean-mean": -0.3868049441277981, "reward_ctrl-median-mean": -0.38536490201950074, "reward_ctrl-range-mean": 0.5229190170764922}}, "training": {"episode-reward-mean": 7177.993584106216, "episode-reward-min": 6938.351649182236, "episode-reward-max": 7379.784041072393, "episode-reward-std": 132.1363972094192, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.10126282332809544, "reward_run-last-mean": 7.236132627684128, "reward_run-mean-mean": 7.564487176227819, "reward_run-median-mean": 7.692618685990361, "reward_run-range-mean": 10.742294066995441, "reward_ctrl-first-mean": -0.2691700279712677, "reward_ctrl-last-mean": -0.39747816801071173, "reward_ctrl-mean-mean": -0.3864935921216011, "reward_ctrl-median-mean": -0.3896478939056397, "reward_ctrl-range-mean": 0.4654908829927445}}, "update": {"Q_value-mean": 455.5530090332031, "Q_loss-mean": 6.587486267089844, "policy_loss-mean": -456.5584411621094, "alpha": 0.15088807046413422, "alpha_loss-mean": -0.00023792854335624725}, "times": {"epoch_before_hook": 4.7442008508369327e-05, "timestep_before_hook": 0.15574367792578414, "sample": 29.11167699145153, "train": 342.7856098851771, "timestep_after_hook": 0.07246786207542755, "training_paths": 0.11537874600617215, "evaluation_paths": 0.6068036879878491, "training_metrics": 0.0018773539923131466, "evaluation_metrics": 0.0004886790120508522, "epoch_after_hook": 2.176006091758609e-06}, "sampler": {"pool-size": 210000, "max-path-return": 7379.784041072397, "last-path-return": 7345.283383977722, "episodes": 210, "total-samples": 210000}, "epoch": 7, "timestep": 25000, "total_timestep": 200000, "num_train_steps": 200000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 8, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-29-57", "timestamp": 1652812197, "time_this_iter_s": 373.86071848869324, "time_total_s": 3060.79731297493, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 3060.79731297493, "timesteps_since_restore": 0, "iterations_since_restore": 8, "trial_id": "31acc_00000"}
{"alpha": 0.15855103731155396, "policy": {"shifts-mean": -0.2139015942811966, "shifts-std": 1.4103283882141113, "shifts-max": 3.5545153617858887, "shifts-min": -3.4061851501464844, "scales-mean": 0.43496665358543396, "scales-std": 0.13836978375911713, "scales-max": 0.9194713234901428, "scales-min": 0.09539686888456345, "entropy-mean": -5.69830322265625, "entropy-std": 3.630026340484619, "actions-mean": -0.13072136044502258, "actions-std": 0.7632993459701538, "actions-min": -0.9988478422164917, "actions-max": 0.9987526535987854}, "evaluation": {"episode-reward-mean": 7727.53076171875, "episode-reward-min": 7727.53076171875, "episode-reward-max": 7727.53076171875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.1441812394409646, "reward_run-last-mean": 8.602109895720105, "reward_run-mean-mean": 8.111557226988145, "reward_run-median-mean": 8.290388124232209, "reward_run-range-mean": 11.108913888378662, "reward_ctrl-first-mean": -0.24404044151306153, "reward_ctrl-last-mean": -0.4029249668121338, "reward_ctrl-mean-mean": -0.38402650730609894, "reward_ctrl-median-mean": -0.38991277217864995, "reward_ctrl-range-mean": 0.4323052048683167}}, "training": {"episode-reward-mean": 7439.100790501732, "episode-reward-min": 7318.2109377034485, "episode-reward-max": 7535.438333392038, "episode-reward-std": 67.26922951034913, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.013798574176090119, "reward_run-last-mean": 7.990005202598127, "reward_run-mean-mean": 7.823996860555904, "reward_run-median-mean": 7.9647462603650325, "reward_run-range-mean": 10.880188859195425, "reward_ctrl-first-mean": -0.19537485539913177, "reward_ctrl-last-mean": -0.40385856389999386, "reward_ctrl-mean-mean": -0.3848960700541735, "reward_ctrl-median-mean": -0.38719590783119207, "reward_ctrl-range-mean": 0.46856584787368777}}, "update": {"Q_value-mean": 484.3205871582031, "Q_loss-mean": 6.35822868347168, "policy_loss-mean": -485.22369384765625, "alpha": 0.1573621779680252, "alpha_loss-mean": -0.00017020420636981726}, "times": {"epoch_before_hook": 5.5182987125590444e-05, "timestep_before_hook": 0.1543758574698586, "sample": 28.828204164048657, "train": 343.0869865528657, "timestep_after_hook": 0.07206356682581827, "training_paths": 0.1139674220175948, "evaluation_paths": 0.6485956189862918, "training_metrics": 0.0020256400166545063, "evaluation_metrics": 0.0005000380042474717, "epoch_after_hook": 2.0190200302749872e-06}, "sampler": {"pool-size": 235000, "max-path-return": 7535.438333392048, "last-path-return": 7367.702090199405, "episodes": 235, "total-samples": 235000}, "epoch": 8, "timestep": 25000, "total_timestep": 225000, "num_train_steps": 225000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 9, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-36-11", "timestamp": 1652812571, "time_this_iter_s": 373.91929841041565, "time_total_s": 3434.7166113853455, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 3434.7166113853455, "timesteps_since_restore": 0, "iterations_since_restore": 9, "trial_id": "31acc_00000"}
{"alpha": 0.16426204144954681, "policy": {"shifts-mean": -0.23680800199508667, "shifts-std": 1.412227749824524, "shifts-max": 3.4297001361846924, "shifts-min": -3.502443552017212, "scales-mean": 0.447147935628891, "scales-std": 0.14893895387649536, "scales-max": 1.0722196102142334, "scales-min": 0.08774545788764954, "entropy-mean": -5.8750834465026855, "entropy-std": 4.09315299987793, "actions-mean": -0.14319442212581635, "actions-std": 0.7676969766616821, "actions-min": -0.9998288154602051, "actions-max": 0.9990720748901367}, "evaluation": {"episode-reward-mean": 7673.63623046875, "episode-reward-min": 7673.63623046875, "episode-reward-max": 7673.63623046875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.029629990988093158, "reward_run-last-mean": 8.657359147215402, "reward_run-mean-mean": 8.059597226695688, "reward_run-median-mean": 8.252104657610104, "reward_run-range-mean": 11.200969344577503, "reward_ctrl-first-mean": -0.11770148277282716, "reward_ctrl-last-mean": -0.449742603302002, "reward_ctrl-mean-mean": -0.38596135292053224, "reward_ctrl-median-mean": -0.38988579511642457, "reward_ctrl-range-mean": 0.4642479658126831}}, "training": {"episode-reward-mean": 7662.628204988949, "episode-reward-min": 7385.885952774295, "episode-reward-max": 7775.492026741203, "episode-reward-std": 101.68503405410121, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.20858969159600482, "reward_run-last-mean": 8.232899310575817, "reward_run-mean-mean": 8.051196861956829, "reward_run-median-mean": 8.225594151696232, "reward_run-range-mean": 11.169873841430036, "reward_ctrl-first-mean": -0.23098433256149292, "reward_ctrl-last-mean": -0.3887218570709229, "reward_ctrl-mean-mean": -0.38856865696787835, "reward_ctrl-median-mean": -0.3919589996337891, "reward_ctrl-range-mean": 0.45378440558910366}}, "update": {"Q_value-mean": 509.4193115234375, "Q_loss-mean": 6.280170440673828, "policy_loss-mean": -510.26458740234375, "alpha": 0.16337798535823822, "alpha_loss-mean": -0.00021158660820219666}, "times": {"epoch_before_hook": 4.884498775936663e-05, "timestep_before_hook": 0.14802815768052824, "sample": 28.145745327026816, "train": 325.94021937812795, "timestep_after_hook": 0.07007743953727186, "training_paths": 0.10165360500104725, "evaluation_paths": 0.5374928429955617, "training_metrics": 0.0017546750023029745, "evaluation_metrics": 0.000439864001236856, "epoch_after_hook": 1.7569982446730137e-06}, "sampler": {"pool-size": 260000, "max-path-return": 7775.492026741209, "last-path-return": 7663.894859981359, "episodes": 260, "total-samples": 260000}, "epoch": 9, "timestep": 25000, "total_timestep": 250000, "num_train_steps": 250000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 10, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-42-07", "timestamp": 1652812927, "time_this_iter_s": 355.9143748283386, "time_total_s": 3790.630986213684, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 3790.630986213684, "timesteps_since_restore": 0, "iterations_since_restore": 10, "trial_id": "31acc_00000"}
{"alpha": 0.17014767229557037, "policy": {"shifts-mean": -0.17284707725048065, "shifts-std": 1.4259865283966064, "shifts-max": 2.8674583435058594, "shifts-min": -3.1955575942993164, "scales-mean": 0.43696093559265137, "scales-std": 0.1454901248216629, "scales-max": 0.9322066307067871, "scales-min": 0.06484885513782501, "entropy-mean": -5.580212593078613, "entropy-std": 3.9826407432556152, "actions-mean": -0.11648019403219223, "actions-std": 0.7616689205169678, "actions-min": -0.9985833764076233, "actions-max": 0.9990971684455872}, "evaluation": {"episode-reward-mean": 7840.73583984375, "episode-reward-min": 7840.73583984375, "episode-reward-max": 7840.73583984375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.19933023059930527, "reward_run-last-mean": 6.939778872161924, "reward_run-mean-mean": 8.232079346609831, "reward_run-median-mean": 8.447625966563237, "reward_run-range-mean": 10.944192855362001, "reward_ctrl-first-mean": -0.22323129177093506, "reward_ctrl-last-mean": -0.43580679893493657, "reward_ctrl-mean-mean": -0.3913436512589455, "reward_ctrl-median-mean": -0.3981058597564697, "reward_ctrl-range-mean": 0.4581918954849244}}, "training": {"episode-reward-mean": 7817.7778038985825, "episode-reward-min": 7652.004967557186, "episode-reward-max": 7976.782187135611, "episode-reward-std": 93.16875273285211, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.1811959698150796, "reward_run-last-mean": 8.594659340700218, "reward_run-mean-mean": 8.202667703771422, "reward_run-median-mean": 8.394054706241164, "reward_run-range-mean": 11.398065415014656, "reward_ctrl-first-mean": -0.25024118423461916, "reward_ctrl-last-mean": -0.46485960006713867, "reward_ctrl-mean-mean": -0.38488989987283945, "reward_ctrl-median-mean": -0.38948403477668764, "reward_ctrl-range-mean": 0.4366928800940514}}, "update": {"Q_value-mean": 532.2579345703125, "Q_loss-mean": 6.193983554840088, "policy_loss-mean": -533.0496826171875, "alpha": 0.16678601503372192, "alpha_loss-mean": -0.00020492363546509296}, "times": {"epoch_before_hook": 4.404099308885634e-05, "timestep_before_hook": 0.1288354483549483, "sample": 22.683870938868495, "train": 251.5882202112407, "timestep_after_hook": 0.059631644311593845, "training_paths": 1.1518343269999605, "evaluation_paths": 0.5020069669990335, "training_metrics": 0.038442552991909906, "evaluation_metrics": 0.030158020003000274, "epoch_after_hook": 2.6459747459739447e-06}, "sampler": {"pool-size": 285000, "max-path-return": 7976.782187135611, "last-path-return": 7831.251356882679, "episodes": 285, "total-samples": 285000}, "epoch": 10, "timestep": 25000, "total_timestep": 275000, "num_train_steps": 275000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 11, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-46-44", "timestamp": 1652813204, "time_this_iter_s": 276.95560479164124, "time_total_s": 4067.5865910053253, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 4067.5865910053253, "timesteps_since_restore": 0, "iterations_since_restore": 11, "trial_id": "31acc_00000"}
{"alpha": 0.1715940237045288, "policy": {"shifts-mean": -0.2413676232099533, "shifts-std": 1.3849608898162842, "shifts-max": 2.9764225482940674, "shifts-min": -3.187659978866577, "scales-mean": 0.4348708391189575, "scales-std": 0.14293380081653595, "scales-max": 0.9946785569190979, "scales-min": 0.0750543400645256, "entropy-mean": -5.467388153076172, "entropy-std": 3.9786133766174316, "actions-mean": -0.14487159252166748, "actions-std": 0.7582166194915771, "actions-min": -0.9992715716362, "actions-max": 0.9990127086639404}, "evaluation": {"episode-reward-mean": 8053.40625, "episode-reward-min": 8053.40625, "episode-reward-max": 8053.40625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.22561150739145885, "reward_run-last-mean": 9.56939884479766, "reward_run-mean-mean": 8.433165983077737, "reward_run-median-mean": 8.61746464432457, "reward_run-range-mean": 11.423775858365776, "reward_ctrl-first-mean": -0.16089640855789186, "reward_ctrl-last-mean": -0.263336706161499, "reward_ctrl-mean-mean": -0.37975963143706326, "reward_ctrl-median-mean": -0.38584184646606445, "reward_ctrl-range-mean": 0.47085950970649726}}, "training": {"episode-reward-mean": 8006.2622864251, "episode-reward-min": 7836.707405433795, "episode-reward-max": 8154.127828408833, "episode-reward-std": 90.08414479576612, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.1651066896620088, "reward_run-last-mean": 9.086210496936474, "reward_run-mean-mean": 8.390534960313902, "reward_run-median-mean": 8.593037831667147, "reward_run-range-mean": 11.269861086556412, "reward_ctrl-first-mean": -0.24018869280815122, "reward_ctrl-last-mean": -0.37701159477233886, "reward_ctrl-mean-mean": -0.38427267388880254, "reward_ctrl-median-mean": -0.3905615162849426, "reward_ctrl-range-mean": 0.44070518136024467}}, "update": {"Q_value-mean": 552.2485961914062, "Q_loss-mean": 6.132842540740967, "policy_loss-mean": -552.9794311523438, "alpha": 0.17115327715873718, "alpha_loss-mean": -3.414420280023478e-05}, "times": {"epoch_before_hook": 4.502700176090002e-05, "timestep_before_hook": 0.0814449125318788, "sample": 14.022959271358559, "train": 197.1123740222829, "timestep_after_hook": 0.035824968304950744, "training_paths": 0.07329044400830753, "evaluation_paths": 0.5021230700076558, "training_metrics": 0.001574572001118213, "evaluation_metrics": 0.0004140559758525342, "epoch_after_hook": 1.9650033209472895e-06}, "sampler": {"pool-size": 310000, "max-path-return": 8154.127828408835, "last-path-return": 8154.127828408835, "episodes": 310, "total-samples": 310000}, "epoch": 11, "timestep": 25000, "total_timestep": 300000, "num_train_steps": 300000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 12, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-50-17", "timestamp": 1652813417, "time_this_iter_s": 212.24279642105103, "time_total_s": 4279.829387426376, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 4279.829387426376, "timesteps_since_restore": 0, "iterations_since_restore": 12, "trial_id": "31acc_00000"}
{"alpha": 0.17634464800357819, "policy": {"shifts-mean": -0.23076288402080536, "shifts-std": 1.4253995418548584, "shifts-max": 4.120570659637451, "shifts-min": -3.2267956733703613, "scales-mean": 0.4384712874889374, "scales-std": 0.14377500116825104, "scales-max": 0.960061252117157, "scales-min": 0.07630438357591629, "entropy-mean": -6.0131988525390625, "entropy-std": 3.89868426322937, "actions-mean": -0.14112721383571625, "actions-std": 0.7740066647529602, "actions-min": -0.9996902346611023, "actions-max": 0.999991238117218}, "evaluation": {"episode-reward-mean": 8238.1787109375, "episode-reward-min": 8238.1787109375, "episode-reward-max": 8238.1787109375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.08015821401420153, "reward_run-last-mean": 8.205923811458433, "reward_run-mean-mean": 8.620768589321893, "reward_run-median-mean": 8.830489421359964, "reward_run-range-mean": 11.416878332327105, "reward_ctrl-first-mean": -0.39329190254211427, "reward_ctrl-last-mean": -0.35212125778198244, "reward_ctrl-mean-mean": -0.38259007334709166, "reward_ctrl-median-mean": -0.38728121519088743, "reward_ctrl-range-mean": 0.4295280337333679}}, "training": {"episode-reward-mean": 8151.405118556055, "episode-reward-min": 7917.475664257929, "episode-reward-max": 8327.25500680272, "episode-reward-std": 115.5668086746575, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.027110781593184002, "reward_run-last-mean": 8.849652074645974, "reward_run-mean-mean": 8.531221213557455, "reward_run-median-mean": 8.788306472709262, "reward_run-range-mean": 11.422231237422466, "reward_ctrl-first-mean": -0.28419150173664093, "reward_ctrl-last-mean": -0.3653200387954712, "reward_ctrl-mean-mean": -0.3798160950013995, "reward_ctrl-median-mean": -0.3869995391368866, "reward_ctrl-range-mean": 0.44533455699682245}}, "update": {"Q_value-mean": 569.4923095703125, "Q_loss-mean": 6.099319934844971, "policy_loss-mean": -570.1720581054688, "alpha": 0.17363274097442627, "alpha_loss-mean": -0.00018397091480437666}, "times": {"epoch_before_hook": 2.434599446132779e-05, "timestep_before_hook": 0.07656831666827202, "sample": 13.406050615711138, "train": 192.9286053305259, "timestep_after_hook": 0.03284886144683696, "training_paths": 0.07325029600178823, "evaluation_paths": 0.4863445730006788, "training_metrics": 0.0016295900277327746, "evaluation_metrics": 0.00041456500184722245, "epoch_after_hook": 1.8769933376461267e-06}, "sampler": {"pool-size": 335000, "max-path-return": 8327.255006802705, "last-path-return": 7917.475664257921, "episodes": 335, "total-samples": 335000}, "epoch": 12, "timestep": 25000, "total_timestep": 325000, "num_train_steps": 325000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 13, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-53-45", "timestamp": 1652813625, "time_this_iter_s": 207.38751578330994, "time_total_s": 4487.216903209686, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 4487.216903209686, "timesteps_since_restore": 0, "iterations_since_restore": 13, "trial_id": "31acc_00000"}
{"alpha": 0.1800745129585266, "policy": {"shifts-mean": -0.18429672718048096, "shifts-std": 1.4959131479263306, "shifts-max": 3.3692595958709717, "shifts-min": -3.236908435821533, "scales-mean": 0.436251163482666, "scales-std": 0.14019076526165009, "scales-max": 0.9330440163612366, "scales-min": 0.0779397264122963, "entropy-mean": -6.280763149261475, "entropy-std": 3.824463367462158, "actions-mean": -0.11144986748695374, "actions-std": 0.7807572484016418, "actions-min": -0.9992490410804749, "actions-max": 0.9997829794883728}, "evaluation": {"episode-reward-mean": 8240.591796875, "episode-reward-min": 8240.591796875, "episode-reward-max": 8240.591796875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.04361951666329619, "reward_run-last-mean": 9.339915936703846, "reward_run-mean-mean": 8.620294854844175, "reward_run-median-mean": 8.844619480225049, "reward_run-range-mean": 11.183331855065047, "reward_ctrl-first-mean": -0.2538149118423462, "reward_ctrl-last-mean": -0.42257242202758794, "reward_ctrl-mean-mean": -0.3797027329325676, "reward_ctrl-median-mean": -0.38221943378448486, "reward_ctrl-range-mean": 0.47124456167221074}}, "training": {"episode-reward-mean": 8283.965658592642, "episode-reward-min": 8169.181249426027, "episode-reward-max": 8380.768080978996, "episode-reward-std": 78.67007750928845, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5036783320783399, "reward_run-last-mean": 9.199947024606558, "reward_run-mean-mean": 8.663594908633291, "reward_run-median-mean": 8.908003865391137, "reward_run-range-mean": 11.765804874396961, "reward_ctrl-first-mean": -0.28898084759712217, "reward_ctrl-last-mean": -0.4020692849159241, "reward_ctrl-mean-mean": -0.37962925004065035, "reward_ctrl-median-mean": -0.3862716460227966, "reward_ctrl-range-mean": 0.45322274506092075}}, "update": {"Q_value-mean": 586.2257690429688, "Q_loss-mean": 6.161900520324707, "policy_loss-mean": -586.8655395507812, "alpha": 0.17807595431804657, "alpha_loss-mean": -0.00012478740245569497}, "times": {"epoch_before_hook": 2.453001798130572e-05, "timestep_before_hook": 0.0755467286799103, "sample": 13.33903772366466, "train": 192.9049502419366, "timestep_after_hook": 0.03271629009395838, "training_paths": 0.1613353920110967, "evaluation_paths": 0.4918866240186617, "training_metrics": 0.0015760809765197337, "evaluation_metrics": 0.00041390801197849214, "epoch_after_hook": 1.7569982446730137e-06}, "sampler": {"pool-size": 360000, "max-path-return": 8444.2553735818, "last-path-return": 8189.271720085203, "episodes": 360, "total-samples": 360000}, "epoch": 13, "timestep": 25000, "total_timestep": 350000, "num_train_steps": 350000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 14, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_19-57-12", "timestamp": 1652813832, "time_this_iter_s": 207.3881013393402, "time_total_s": 4694.6050045490265, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 4694.6050045490265, "timesteps_since_restore": 0, "iterations_since_restore": 14, "trial_id": "31acc_00000"}
{"alpha": 0.17960378527641296, "policy": {"shifts-mean": -0.1960337907075882, "shifts-std": 1.4366191625595093, "shifts-max": 3.211284875869751, "shifts-min": -3.7163562774658203, "scales-mean": 0.4364370107650757, "scales-std": 0.14843012392520905, "scales-max": 0.9938739538192749, "scales-min": 0.06526491045951843, "entropy-mean": -5.722756862640381, "entropy-std": 4.0544633865356445, "actions-mean": -0.12415393441915512, "actions-std": 0.7669513821601868, "actions-min": -0.998360276222229, "actions-max": 0.9998376369476318}, "evaluation": {"episode-reward-mean": 8790.2529296875, "episode-reward-min": 8790.2529296875, "episode-reward-max": 8790.2529296875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.43062615588052866, "reward_run-last-mean": 8.020703657767854, "reward_run-mean-mean": 9.160549616806692, "reward_run-median-mean": 9.40642591026041, "reward_run-range-mean": 11.946878692618567, "reward_ctrl-first-mean": -0.30068678855895997, "reward_ctrl-last-mean": -0.36339540481567384, "reward_ctrl-mean-mean": -0.37029694576263433, "reward_ctrl-median-mean": -0.37875548601150516, "reward_ctrl-range-mean": 0.414596951007843}}, "training": {"episode-reward-mean": 8515.749309796634, "episode-reward-min": 8434.296166098336, "episode-reward-max": 8641.205020618418, "episode-reward-std": 75.5273471727419, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5855414387567297, "reward_run-last-mean": 9.018776916505203, "reward_run-mean-mean": 8.890533869204765, "reward_run-median-mean": 9.148147743175329, "reward_run-range-mean": 12.049084021174043, "reward_ctrl-first-mean": -0.3155976629257203, "reward_ctrl-last-mean": -0.38928194999694826, "reward_ctrl-mean-mean": -0.37478455940812827, "reward_ctrl-median-mean": -0.38131594061851504, "reward_ctrl-range-mean": 0.4804996100068092}}, "update": {"Q_value-mean": 601.7694702148438, "Q_loss-mean": 6.057456970214844, "policy_loss-mean": -602.3811645507812, "alpha": 0.18082556128501892, "alpha_loss-mean": 5.456874714582227e-05}, "times": {"epoch_before_hook": 2.474401844665408e-05, "timestep_before_hook": 0.07636822701897472, "sample": 13.456194112921366, "train": 192.66636286510038, "timestep_after_hook": 0.032763558643637225, "training_paths": 0.07449432701105252, "evaluation_paths": 0.4860083909879904, "training_metrics": 0.0015601209888700396, "evaluation_metrics": 0.00040902799810282886, "epoch_after_hook": 1.8049904610961676e-06}, "sampler": {"pool-size": 385000, "max-path-return": 8641.20502061841, "last-path-return": 8441.149319688837, "episodes": 385, "total-samples": 385000}, "epoch": 14, "timestep": 25000, "total_timestep": 375000, "num_train_steps": 375000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 15, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-00-39", "timestamp": 1652814039, "time_this_iter_s": 207.17558193206787, "time_total_s": 4901.780586481094, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 4901.780586481094, "timesteps_since_restore": 0, "iterations_since_restore": 15, "trial_id": "31acc_00000"}
{"alpha": 0.18656688928604126, "policy": {"shifts-mean": -0.1481311172246933, "shifts-std": 1.4521740674972534, "shifts-max": 3.0489490032196045, "shifts-min": -3.324122428894043, "scales-mean": 0.43463611602783203, "scales-std": 0.1383054554462433, "scales-max": 0.8623189330101013, "scales-min": 0.061941735446453094, "entropy-mean": -6.2167205810546875, "entropy-std": 3.947084665298462, "actions-mean": -0.11212112754583359, "actions-std": 0.771454393863678, "actions-min": -0.9996487498283386, "actions-max": 0.998942494392395}, "evaluation": {"episode-reward-mean": 8850.57421875, "episode-reward-min": 8850.57421875, "episode-reward-max": 8850.57421875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7375750985927474, "reward_run-last-mean": 9.979274873995791, "reward_run-mean-mean": 9.221625811541239, "reward_run-median-mean": 9.529665586875424, "reward_run-range-mean": 13.168638335520605, "reward_ctrl-first-mean": -0.3263342142105103, "reward_ctrl-last-mean": -0.23515636920928956, "reward_ctrl-mean-mean": -0.3710511719346047, "reward_ctrl-median-mean": -0.37626605033874516, "reward_ctrl-range-mean": 0.42381219863891606}}, "training": {"episode-reward-mean": 8662.109192851965, "episode-reward-min": 8381.578138586721, "episode-reward-max": 8894.569437595554, "episode-reward-std": 146.22401104752535, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4554418066525131, "reward_run-last-mean": 9.622161887739594, "reward_run-mean-mean": 9.031980143166964, "reward_run-median-mean": 9.311391806755317, "reward_run-range-mean": 12.040939227533183, "reward_ctrl-first-mean": -0.2945772159099579, "reward_ctrl-last-mean": -0.42460518836975103, "reward_ctrl-mean-mean": -0.3698709503149986, "reward_ctrl-median-mean": -0.3783485078811646, "reward_ctrl-range-mean": 0.4643571442365647}}, "update": {"Q_value-mean": 618.4446411132812, "Q_loss-mean": 6.101614475250244, "policy_loss-mean": -619.0615844726562, "alpha": 0.18275819718837738, "alpha_loss-mean": -0.00025435234420001507}, "times": {"epoch_before_hook": 2.7180009055882692e-05, "timestep_before_hook": 0.0754139490891248, "sample": 13.253857195435558, "train": 192.6198833992239, "timestep_after_hook": 0.032593511044979095, "training_paths": 0.10115849200519733, "evaluation_paths": 0.48905716501758434, "training_metrics": 0.0016812369867693633, "evaluation_metrics": 0.0004121529927942902, "epoch_after_hook": 1.9060098566114902e-06}, "sampler": {"pool-size": 410000, "max-path-return": 8894.569437595545, "last-path-return": 8786.63024960607, "episodes": 410, "total-samples": 410000}, "epoch": 15, "timestep": 25000, "total_timestep": 400000, "num_train_steps": 400000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 16, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-04-06", "timestamp": 1652814246, "time_this_iter_s": 206.95408058166504, "time_total_s": 5108.734667062759, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 5108.734667062759, "timesteps_since_restore": 0, "iterations_since_restore": 16, "trial_id": "31acc_00000"}
{"alpha": 0.19194556772708893, "policy": {"shifts-mean": -0.25816312432289124, "shifts-std": 1.42946457862854, "shifts-max": 4.069427013397217, "shifts-min": -3.3402957916259766, "scales-mean": 0.43986329436302185, "scales-std": 0.14576344192028046, "scales-max": 1.0253366231918335, "scales-min": 0.06410588324069977, "entropy-mean": -6.026243686676025, "entropy-std": 4.162206172943115, "actions-mean": -0.16210885345935822, "actions-std": 0.7632049918174744, "actions-min": -0.9987203478813171, "actions-max": 0.9994295835494995}, "evaluation": {"episode-reward-mean": 9090.2802734375, "episode-reward-min": 9090.2802734375, "episode-reward-max": 9090.2802734375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.3266015303978617, "reward_run-last-mean": 8.991679113526061, "reward_run-mean-mean": 9.45943003829528, "reward_run-median-mean": 9.797222645294994, "reward_run-range-mean": 12.954787230964369, "reward_ctrl-first-mean": -0.27661919593811035, "reward_ctrl-last-mean": -0.48337779045104984, "reward_ctrl-mean-mean": -0.3691492931306362, "reward_ctrl-median-mean": -0.37629014253616333, "reward_ctrl-range-mean": 0.5256632566452026}}, "training": {"episode-reward-mean": 8950.35908961172, "episode-reward-min": 8725.747468666774, "episode-reward-max": 9170.27440698415, "episode-reward-std": 148.40007530428213, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4192854729498987, "reward_run-last-mean": 9.635833294894269, "reward_run-mean-mean": 9.316984512953711, "reward_run-median-mean": 9.618822723390835, "reward_run-range-mean": 12.583333343072267, "reward_ctrl-first-mean": -0.31370993375778206, "reward_ctrl-last-mean": -0.37842417120933536, "reward_ctrl-mean-mean": -0.36662542334198955, "reward_ctrl-median-mean": -0.37294523119926454, "reward_ctrl-range-mean": 0.4813334882259369}}, "update": {"Q_value-mean": 635.3953857421875, "Q_loss-mean": 6.334258556365967, "policy_loss-mean": -636.0131225585938, "alpha": 0.1894715428352356, "alpha_loss-mean": -0.000200844879145734}, "times": {"epoch_before_hook": 2.6563997380435467e-05, "timestep_before_hook": 0.07505231307004578, "sample": 13.202611212065676, "train": 192.48533973511076, "timestep_after_hook": 0.032465127762407064, "training_paths": 0.19348011899273843, "evaluation_paths": 0.4868807519960683, "training_metrics": 0.0014913759951014072, "evaluation_metrics": 0.0004248830082360655, "epoch_after_hook": 1.5179975889623165e-06}, "sampler": {"pool-size": 435000, "max-path-return": 9170.274406984156, "last-path-return": 8778.6573722687, "episodes": 435, "total-samples": 435000}, "epoch": 16, "timestep": 25000, "total_timestep": 425000, "num_train_steps": 425000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 17, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-07-33", "timestamp": 1652814453, "time_this_iter_s": 206.8564248085022, "time_total_s": 5315.591091871262, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 5315.591091871262, "timesteps_since_restore": 0, "iterations_since_restore": 17, "trial_id": "31acc_00000"}
{"alpha": 0.1985863298177719, "policy": {"shifts-mean": -0.20472539961338043, "shifts-std": 1.4394266605377197, "shifts-max": 2.978785276412964, "shifts-min": -3.3222532272338867, "scales-mean": 0.43954452872276306, "scales-std": 0.14463815093040466, "scales-max": 1.0896445512771606, "scales-min": 0.07006161659955978, "entropy-mean": -6.021575450897217, "entropy-std": 4.0538835525512695, "actions-mean": -0.12675423920154572, "actions-std": 0.7703405022621155, "actions-min": -0.9990057945251465, "actions-max": 0.9981767535209656}, "evaluation": {"episode-reward-mean": 8879.873046875, "episode-reward-min": 8879.873046875, "episode-reward-max": 8879.873046875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.3852341877903914, "reward_run-last-mean": 8.852573934948396, "reward_run-mean-mean": 9.249958247984395, "reward_run-median-mean": 9.537027838584358, "reward_run-range-mean": 12.368128913609205, "reward_ctrl-first-mean": -0.25436518192291263, "reward_ctrl-last-mean": -0.3780505180358887, "reward_ctrl-mean-mean": -0.37008528006672864, "reward_ctrl-median-mean": -0.37875238656997684, "reward_ctrl-range-mean": 0.4771505773067474}}, "training": {"episode-reward-mean": 8911.771795207678, "episode-reward-min": 8769.790885695482, "episode-reward-max": 9055.727804848, "episode-reward-std": 79.7603718610456, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6786767350052745, "reward_run-last-mean": 9.683882189138899, "reward_run-mean-mean": 9.275956703008235, "reward_run-median-mean": 9.594802325256481, "reward_run-range-mean": 12.66257742839672, "reward_ctrl-first-mean": -0.3324544680118561, "reward_ctrl-last-mean": -0.38614112854003907, "reward_ctrl-mean-mean": -0.36418490780055524, "reward_ctrl-median-mean": -0.3677844762802124, "reward_ctrl-range-mean": 0.48202312767505645}}, "update": {"Q_value-mean": 651.9114990234375, "Q_loss-mean": 6.601991653442383, "policy_loss-mean": -652.5408935546875, "alpha": 0.19493678212165833, "alpha_loss-mean": -0.00022254833311308175}, "times": {"epoch_before_hook": 2.7083995519205928e-05, "timestep_before_hook": 0.07559798035072163, "sample": 13.193161250761477, "train": 192.39490208844654, "timestep_after_hook": 0.03252857970073819, "training_paths": 0.07269395602634177, "evaluation_paths": 0.5152799100033008, "training_metrics": 0.0015520440065301955, "evaluation_metrics": 0.0004052520089317113, "epoch_after_hook": 1.5060068108141422e-06}, "sampler": {"pool-size": 460000, "max-path-return": 9224.631452485475, "last-path-return": 8946.537504171774, "episodes": 460, "total-samples": 460000}, "epoch": 17, "timestep": 25000, "total_timestep": 450000, "num_train_steps": 450000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 18, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-11-00", "timestamp": 1652814660, "time_this_iter_s": 206.66522073745728, "time_total_s": 5522.256312608719, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 5522.256312608719, "timesteps_since_restore": 0, "iterations_since_restore": 18, "trial_id": "31acc_00000"}
{"alpha": 0.20211979746818542, "policy": {"shifts-mean": -0.15107125043869019, "shifts-std": 1.4874882698059082, "shifts-max": 3.3745994567871094, "shifts-min": -3.415684700012207, "scales-mean": 0.44326353073120117, "scales-std": 0.143283873796463, "scales-max": 1.2126268148422241, "scales-min": 0.06772424280643463, "entropy-mean": -6.42937707901001, "entropy-std": 4.0117950439453125, "actions-mean": -0.09828416258096695, "actions-std": 0.7820942997932434, "actions-min": -0.9994451999664307, "actions-max": 0.9998683929443359}, "evaluation": {"episode-reward-mean": 9083.9150390625, "episode-reward-min": 9083.9150390625, "episode-reward-max": 9083.9150390625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -1.0152784955476943, "reward_run-last-mean": 10.63513480803067, "reward_run-mean-mean": 9.452100678311437, "reward_run-median-mean": 9.766199634539703, "reward_run-range-mean": 13.234940343576785, "reward_ctrl-first-mean": -0.5075154304504395, "reward_ctrl-last-mean": -0.49445562362670903, "reward_ctrl-mean-mean": -0.36818571976423264, "reward_ctrl-median-mean": -0.3699858903884888, "reward_ctrl-range-mean": 0.5106927394866944}}, "training": {"episode-reward-mean": 9079.004677915222, "episode-reward-min": 8809.451901403972, "episode-reward-max": 9264.145581690487, "episode-reward-std": 145.97645144420184, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6299985580386482, "reward_run-last-mean": 9.972923367561634, "reward_run-mean-mean": 9.445023030926233, "reward_run-median-mean": 9.761215054782937, "reward_run-range-mean": 12.847311019444822, "reward_ctrl-first-mean": -0.3266850638389588, "reward_ctrl-last-mean": -0.38412961602211004, "reward_ctrl-mean-mean": -0.3660183530110121, "reward_ctrl-median-mean": -0.3696352851390839, "reward_ctrl-range-mean": 0.49851809620857235}}, "update": {"Q_value-mean": 665.6677856445312, "Q_loss-mean": 6.874915599822998, "policy_loss-mean": -666.2684936523438, "alpha": 0.2002570927143097, "alpha_loss-mean": -0.00012009830243187025}, "times": {"epoch_before_hook": 2.717200550250709e-05, "timestep_before_hook": 0.0757474213896785, "sample": 13.250174311280716, "train": 192.2517053630727, "timestep_after_hook": 0.03265566861955449, "training_paths": 0.07349621399771422, "evaluation_paths": 0.517671280016657, "training_metrics": 0.001561048993607983, "evaluation_metrics": 0.00041076098568737507, "epoch_after_hook": 1.52099528349936e-06}, "sampler": {"pool-size": 485000, "max-path-return": 9264.145581690485, "last-path-return": 9050.419671416452, "episodes": 485, "total-samples": 485000}, "epoch": 18, "timestep": 25000, "total_timestep": 475000, "num_train_steps": 475000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 19, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-14-27", "timestamp": 1652814867, "time_this_iter_s": 206.58272171020508, "time_total_s": 5728.839034318924, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 5728.839034318924, "timesteps_since_restore": 0, "iterations_since_restore": 19, "trial_id": "31acc_00000"}
{"alpha": 0.20519877970218658, "policy": {"shifts-mean": -0.053522396832704544, "shifts-std": 1.4197922945022583, "shifts-max": 2.938211441040039, "shifts-min": -3.188901901245117, "scales-mean": 0.4266093671321869, "scales-std": 0.14707651734352112, "scales-max": 0.9312865138053894, "scales-min": 0.0634421780705452, "entropy-mean": -5.663161277770996, "entropy-std": 3.8161888122558594, "actions-mean": -0.04280361533164978, "actions-std": 0.763923168182373, "actions-min": -0.9989880919456482, "actions-max": 0.9994984865188599}, "evaluation": {"episode-reward-mean": 9595.30859375, "episode-reward-min": 9595.30859375, "episode-reward-max": 9595.30859375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.010572843448042636, "reward_run-last-mean": 11.074829629449141, "reward_run-mean-mean": 9.969975956866321, "reward_run-median-mean": 10.338555976152861, "reward_run-range-mean": 12.498815057850054, "reward_ctrl-first-mean": -0.30381422042846684, "reward_ctrl-last-mean": -0.3281955480575562, "reward_ctrl-mean-mean": -0.3746675509929657, "reward_ctrl-median-mean": -0.37742985486984254, "reward_ctrl-range-mean": 0.44344543218612664}}, "training": {"episode-reward-mean": 9323.581094026591, "episode-reward-min": 9008.884512433466, "episode-reward-max": 9583.549448481299, "episode-reward-std": 180.40926328380888, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7114882714382957, "reward_run-last-mean": 9.164647719819754, "reward_run-mean-mean": 9.692056986925033, "reward_run-median-mean": 10.064243691027713, "reward_run-range-mean": 13.190480884365012, "reward_ctrl-first-mean": -0.343131639957428, "reward_ctrl-last-mean": -0.3638856196403504, "reward_ctrl-mean-mean": -0.3684758928984404, "reward_ctrl-median-mean": -0.3705809545516968, "reward_ctrl-range-mean": 0.4792059850692749}}, "update": {"Q_value-mean": 677.7772216796875, "Q_loss-mean": 7.075190544128418, "policy_loss-mean": -678.3653564453125, "alpha": 0.20344185829162598, "alpha_loss-mean": -9.982415940612555e-05}, "times": {"epoch_before_hook": 2.7147005312144756e-05, "timestep_before_hook": 0.07893207939923741, "sample": 14.190206117229536, "train": 196.55231632792857, "timestep_after_hook": 0.03460895494208671, "training_paths": 0.18745632498757914, "evaluation_paths": 0.494941444019787, "training_metrics": 0.0015365110011771321, "evaluation_metrics": 0.0004433470021467656, "epoch_after_hook": 1.6570265870541334e-06}, "sampler": {"pool-size": 510000, "max-path-return": 9583.54944848131, "last-path-return": 9254.89455065543, "episodes": 510, "total-samples": 510000}, "epoch": 19, "timestep": 25000, "total_timestep": 500000, "num_train_steps": 500000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 20, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-17-59", "timestamp": 1652815079, "time_this_iter_s": 211.93033146858215, "time_total_s": 5940.769365787506, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 5940.769365787506, "timesteps_since_restore": 0, "iterations_since_restore": 20, "trial_id": "31acc_00000"}
{"alpha": 0.2070680856704712, "policy": {"shifts-mean": -0.14928176999092102, "shifts-std": 1.4296417236328125, "shifts-max": 3.3914999961853027, "shifts-min": -3.1685476303100586, "scales-mean": 0.42382264137268066, "scales-std": 0.14622822403907776, "scales-max": 1.2539410591125488, "scales-min": 0.06569813191890717, "entropy-mean": -6.256186485290527, "entropy-std": 3.70078706741333, "actions-mean": -0.10784301161766052, "actions-std": 0.7714298367500305, "actions-min": -0.9989715814590454, "actions-max": 0.9987780451774597}, "evaluation": {"episode-reward-mean": 9292.263671875, "episode-reward-min": 9292.263671875, "episode-reward-max": 9292.263671875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7859432104961966, "reward_run-last-mean": 10.585856228044577, "reward_run-mean-mean": 9.657313408601729, "reward_run-median-mean": 9.992486252514254, "reward_run-range-mean": 12.956945010610905, "reward_ctrl-first-mean": -0.3247278928756714, "reward_ctrl-last-mean": -0.4918840885162354, "reward_ctrl-mean-mean": -0.36504954804182055, "reward_ctrl-median-mean": -0.36878899335861204, "reward_ctrl-range-mean": 0.4786068737506867}}, "training": {"episode-reward-mean": 9191.857071274913, "episode-reward-min": 8940.523708080633, "episode-reward-max": 9439.827419560577, "episode-reward-std": 138.37835889251784, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.394973951166082, "reward_run-last-mean": 10.297325198076578, "reward_run-mean-mean": 9.561369649364746, "reward_run-median-mean": 9.944468397126663, "reward_run-range-mean": 13.064398789902336, "reward_ctrl-first-mean": -0.3139385151863098, "reward_ctrl-last-mean": -0.37689418673515324, "reward_ctrl-mean-mean": -0.3695125780898333, "reward_ctrl-median-mean": -0.37489542961120603, "reward_ctrl-range-mean": 0.48591185986995705}}, "update": {"Q_value-mean": 688.8213500976562, "Q_loss-mean": 7.485815525054932, "policy_loss-mean": -689.3802490234375, "alpha": 0.20695260167121887, "alpha_loss-mean": -5.69316471228376e-05}, "times": {"epoch_before_hook": 3.857002593576908e-05, "timestep_before_hook": 0.08054292015731335, "sample": 14.558669978374382, "train": 198.59686460485682, "timestep_after_hook": 0.03557510345126502, "training_paths": 0.17495884699746966, "evaluation_paths": 0.5002899240062106, "training_metrics": 0.0015258780040312558, "evaluation_metrics": 0.00041174099897034466, "epoch_after_hook": 1.6239937394857407e-06}, "sampler": {"pool-size": 535000, "max-path-return": 9583.54944848131, "last-path-return": 9172.111007197718, "episodes": 535, "total-samples": 535000}, "epoch": 20, "timestep": 25000, "total_timestep": 525000, "num_train_steps": 525000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 21, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-21-33", "timestamp": 1652815293, "time_this_iter_s": 214.34470200538635, "time_total_s": 6155.1140677928925, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 6155.1140677928925, "timesteps_since_restore": 0, "iterations_since_restore": 21, "trial_id": "31acc_00000"}
{"alpha": 0.20830832421779633, "policy": {"shifts-mean": -0.11121112108230591, "shifts-std": 1.4396229982376099, "shifts-max": 3.339726209640503, "shifts-min": -3.7519822120666504, "scales-mean": 0.42393890023231506, "scales-std": 0.13837957382202148, "scales-max": 0.9944995045661926, "scales-min": 0.06440271437168121, "entropy-mean": -6.171405792236328, "entropy-std": 3.6697561740875244, "actions-mean": -0.08460863679647446, "actions-std": 0.7734015583992004, "actions-min": -0.9995993375778198, "actions-max": 0.9993911385536194}, "evaluation": {"episode-reward-mean": 9596.4296875, "episode-reward-min": 9596.4296875, "episode-reward-max": 9596.4296875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.663890673372974, "reward_run-last-mean": 11.376478429286863, "reward_run-mean-mean": 9.974222568258439, "reward_run-median-mean": 10.383178155636301, "reward_run-range-mean": 13.473929367686791, "reward_ctrl-first-mean": -0.4113960266113281, "reward_ctrl-last-mean": -0.26768102645874026, "reward_ctrl-mean-mean": -0.3777929647564888, "reward_ctrl-median-mean": -0.38059581518173224, "reward_ctrl-range-mean": 0.4597880005836487}}, "training": {"episode-reward-mean": 9517.508168156533, "episode-reward-min": 9303.264945873281, "episode-reward-max": 9783.369526629238, "episode-reward-std": 168.6012367413888, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5732634744857813, "reward_run-last-mean": 10.310655445557359, "reward_run-mean-mean": 9.889047110859545, "reward_run-median-mean": 10.2628897578047, "reward_run-range-mean": 13.387586277228767, "reward_ctrl-first-mean": -0.32960883855819706, "reward_ctrl-last-mean": -0.4603061866760254, "reward_ctrl-mean-mean": -0.3715389427030087, "reward_ctrl-median-mean": -0.3748792731761933, "reward_ctrl-range-mean": 0.4906802392005921}}, "update": {"Q_value-mean": 698.1612548828125, "Q_loss-mean": 7.795734882354736, "policy_loss-mean": -698.701171875, "alpha": 0.21068669855594635, "alpha_loss-mean": -3.756444129976444e-05}, "times": {"epoch_before_hook": 3.569797263480723e-05, "timestep_before_hook": 0.0792300928151235, "sample": 14.551519198488677, "train": 198.24206301104277, "timestep_after_hook": 0.03533424672787078, "training_paths": 0.1824773330008611, "evaluation_paths": 0.4971586080209818, "training_metrics": 0.0015222559741232544, "evaluation_metrics": 0.00040863099275156856, "epoch_after_hook": 1.6700068954378366e-06}, "sampler": {"pool-size": 560000, "max-path-return": 9827.576183382564, "last-path-return": 9442.534333633714, "episodes": 560, "total-samples": 560000}, "epoch": 21, "timestep": 25000, "total_timestep": 550000, "num_train_steps": 550000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 22, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-25-07", "timestamp": 1652815507, "time_this_iter_s": 213.98284721374512, "time_total_s": 6369.096915006638, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 6369.096915006638, "timesteps_since_restore": 0, "iterations_since_restore": 22, "trial_id": "31acc_00000"}
{"alpha": 0.21391192078590393, "policy": {"shifts-mean": -0.11894648522138596, "shifts-std": 1.4287667274475098, "shifts-max": 2.890838861465454, "shifts-min": -3.302110195159912, "scales-mean": 0.42434433102607727, "scales-std": 0.13897864520549774, "scales-max": 0.955313503742218, "scales-min": 0.06262825429439545, "entropy-mean": -5.807882785797119, "entropy-std": 3.615964651107788, "actions-mean": -0.09542643278837204, "actions-std": 0.7689362168312073, "actions-min": -0.9970395565032959, "actions-max": 0.9989908337593079}, "evaluation": {"episode-reward-mean": 9804.69921875, "episode-reward-min": 9804.69921875, "episode-reward-max": 9804.69921875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.44960613538075106, "reward_run-last-mean": 11.858336846678412, "reward_run-mean-mean": 10.176414361096358, "reward_run-median-mean": 10.58286291973019, "reward_run-range-mean": 13.631292621478755, "reward_ctrl-first-mean": -0.22416086196899415, "reward_ctrl-last-mean": -0.28350205421447755, "reward_ctrl-mean-mean": -0.37171459473371504, "reward_ctrl-median-mean": -0.37336794137954715, "reward_ctrl-range-mean": 0.4805238366127014}}, "training": {"episode-reward-mean": 9599.131837617759, "episode-reward-min": 9452.842471687538, "episode-reward-max": 9811.465845082868, "episode-reward-std": 94.45578541926116, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5845643427325936, "reward_run-last-mean": 10.734314488027053, "reward_run-mean-mean": 9.971947862375979, "reward_run-median-mean": 10.359570547939754, "reward_run-range-mean": 13.529778048553101, "reward_ctrl-first-mean": -0.3200820159912109, "reward_ctrl-last-mean": -0.39529653072357174, "reward_ctrl-mean-mean": -0.3728160247582198, "reward_ctrl-median-mean": -0.37416175246238703, "reward_ctrl-range-mean": 0.4700557440519333}}, "update": {"Q_value-mean": 708.3607177734375, "Q_loss-mean": 7.7927656173706055, "policy_loss-mean": -708.8908081054688, "alpha": 0.21180851757526398, "alpha_loss-mean": -0.00018708044080995023}, "times": {"epoch_before_hook": 2.891398617066443e-05, "timestep_before_hook": 0.08046778856078163, "sample": 14.46490708499914, "train": 198.32342052203603, "timestep_after_hook": 0.035151341173332185, "training_paths": 0.07955651500378735, "evaluation_paths": 0.4955292159866076, "training_metrics": 0.001510093017714098, "evaluation_metrics": 0.0004153389891143888, "epoch_after_hook": 1.4849938452243805e-06}, "sampler": {"pool-size": 585000, "max-path-return": 9942.240415492639, "last-path-return": 9517.53449369178, "episodes": 585, "total-samples": 585000}, "epoch": 22, "timestep": 25000, "total_timestep": 575000, "num_train_steps": 575000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 23, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-28-41", "timestamp": 1652815721, "time_this_iter_s": 213.87401461601257, "time_total_s": 6582.97092962265, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 6582.97092962265, "timesteps_since_restore": 0, "iterations_since_restore": 23, "trial_id": "31acc_00000"}
{"alpha": 0.21545752882957458, "policy": {"shifts-mean": -0.12870998680591583, "shifts-std": 1.481703758239746, "shifts-max": 4.014768600463867, "shifts-min": -3.1550703048706055, "scales-mean": 0.429428368806839, "scales-std": 0.145354762673378, "scales-max": 0.9973981380462646, "scales-min": 0.05386018753051758, "entropy-mean": -6.648721694946289, "entropy-std": 3.7376930713653564, "actions-mean": -0.08399218320846558, "actions-std": 0.7847181558609009, "actions-min": -0.9991336464881897, "actions-max": 0.9993731379508972}, "evaluation": {"episode-reward-mean": 9858.2841796875, "episode-reward-min": 9858.2841796875, "episode-reward-max": 9858.2841796875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8450773723466005, "reward_run-last-mean": 10.33124044368492, "reward_run-mean-mean": 10.235179394174736, "reward_run-median-mean": 10.571147579688045, "reward_run-range-mean": 13.863623393702234, "reward_ctrl-first-mean": -0.45618996620178226, "reward_ctrl-last-mean": -0.48038873672485355, "reward_ctrl-mean-mean": -0.3768953010737896, "reward_ctrl-median-mean": -0.3764021635055542, "reward_ctrl-range-mean": 0.4900616824626923}}, "training": {"episode-reward-mean": 9754.192527635107, "episode-reward-min": 9634.459973419856, "episode-reward-max": 9875.512522576762, "episode-reward-std": 77.54461424525644, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.632017555623488, "reward_run-last-mean": 10.689197795935456, "reward_run-mean-mean": 10.128417437126943, "reward_run-median-mean": 10.550024349832562, "reward_run-range-mean": 13.61851288461565, "reward_ctrl-first-mean": -0.3595812797546387, "reward_ctrl-last-mean": -0.41625100612640387, "reward_ctrl-mean-mean": -0.374224909491837, "reward_ctrl-median-mean": -0.3748960065841675, "reward_ctrl-range-mean": 0.49465169519186025}}, "update": {"Q_value-mean": 717.689697265625, "Q_loss-mean": 7.920141220092773, "policy_loss-mean": -718.1973876953125, "alpha": 0.21466875076293945, "alpha_loss-mean": -4.095870826859027e-05}, "times": {"epoch_before_hook": 3.557800664566457e-05, "timestep_before_hook": 0.08054555166745558, "sample": 14.611621058691526, "train": 198.44844957237365, "timestep_after_hook": 0.035230373847298324, "training_paths": 0.07687485098722391, "evaluation_paths": 0.4947425360151101, "training_metrics": 0.0015822030254639685, "evaluation_metrics": 0.0006471830129157752, "epoch_after_hook": 1.7529819160699844e-06}, "sampler": {"pool-size": 610000, "max-path-return": 9972.99534809325, "last-path-return": 9723.794064350053, "episodes": 610, "total-samples": 610000}, "epoch": 23, "timestep": 25000, "total_timestep": 600000, "num_train_steps": 600000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 24, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-32-15", "timestamp": 1652815935, "time_this_iter_s": 214.14265632629395, "time_total_s": 6797.113585948944, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 6797.113585948944, "timesteps_since_restore": 0, "iterations_since_restore": 24, "trial_id": "31acc_00000"}
{"alpha": 0.22047783434391022, "policy": {"shifts-mean": -0.15500514209270477, "shifts-std": 1.4682743549346924, "shifts-max": 4.231002330780029, "shifts-min": -3.129948139190674, "scales-mean": 0.43185853958129883, "scales-std": 0.1375516653060913, "scales-max": 0.9265667796134949, "scales-min": 0.05852280184626579, "entropy-mean": -6.6494574546813965, "entropy-std": 3.452357530593872, "actions-mean": -0.10312121361494064, "actions-std": 0.782640278339386, "actions-min": -0.9990745186805725, "actions-max": 0.9996539950370789}, "evaluation": {"episode-reward-mean": 10068.45703125, "episode-reward-min": 10068.45703125, "episode-reward-max": 10068.45703125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.17253331333940441, "reward_run-last-mean": 12.520893317773698, "reward_run-mean-mean": 10.44820881952248, "reward_run-median-mean": 10.909156212253208, "reward_run-range-mean": 13.506323760843829, "reward_ctrl-first-mean": -0.2193955421447754, "reward_ctrl-last-mean": -0.4340414524078369, "reward_ctrl-mean-mean": -0.37975101002454753, "reward_ctrl-median-mean": -0.3792962670326233, "reward_ctrl-range-mean": 0.47290302515029903}}, "training": {"episode-reward-mean": 9926.091617448192, "episode-reward-min": 9843.253718555126, "episode-reward-max": 9997.461387347552, "episode-reward-std": 50.82465877528603, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.42520302836723733, "reward_run-last-mean": 10.862288314281955, "reward_run-mean-mean": 10.301794296724063, "reward_run-median-mean": 10.707302046308612, "reward_run-range-mean": 13.704727891408831, "reward_ctrl-first-mean": -0.2759537869691848, "reward_ctrl-last-mean": -0.35455268144607544, "reward_ctrl-mean-mean": -0.37570267927587037, "reward_ctrl-median-mean": -0.3777788579463959, "reward_ctrl-range-mean": 0.47887151479721063}}, "update": {"Q_value-mean": 726.6056518554688, "Q_loss-mean": 7.9952392578125, "policy_loss-mean": -727.0946655273438, "alpha": 0.21541376411914825, "alpha_loss-mean": -0.00016935326857492328}, "times": {"epoch_before_hook": 2.9326998628675938e-05, "timestep_before_hook": 0.08033760730177164, "sample": 14.541744689515326, "train": 198.47428720307653, "timestep_after_hook": 0.03522800831706263, "training_paths": 0.07826231099897996, "evaluation_paths": 0.4981380040117074, "training_metrics": 0.001580471987836063, "evaluation_metrics": 0.0004065389803145081, "epoch_after_hook": 1.5370023902505636e-06}, "sampler": {"pool-size": 635000, "max-path-return": 9997.46138734755, "last-path-return": 9985.114978155798, "episodes": 635, "total-samples": 635000}, "epoch": 24, "timestep": 25000, "total_timestep": 625000, "num_train_steps": 625000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 25, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-35-50", "timestamp": 1652816150, "time_this_iter_s": 214.10236525535583, "time_total_s": 7011.2159512043, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 7011.2159512043, "timesteps_since_restore": 0, "iterations_since_restore": 25, "trial_id": "31acc_00000"}
{"alpha": 0.21626222133636475, "policy": {"shifts-mean": -0.08884397894144058, "shifts-std": 1.4211183786392212, "shifts-max": 2.8243625164031982, "shifts-min": -2.793408155441284, "scales-mean": 0.43443727493286133, "scales-std": 0.15185488760471344, "scales-max": 0.9847413301467896, "scales-min": 0.05683721974492073, "entropy-mean": -5.693262100219727, "entropy-std": 4.138848304748535, "actions-mean": -0.0720660611987114, "actions-std": 0.7694460153579712, "actions-min": -0.9996245503425598, "actions-max": 0.9991702437400818}, "evaluation": {"episode-reward-mean": 9841.28515625, "episode-reward-min": 9841.28515625, "episode-reward-max": 9841.28515625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7164582019599259, "reward_run-last-mean": 11.763193094291182, "reward_run-mean-mean": 10.208970062428838, "reward_run-median-mean": 10.653985022257615, "reward_run-range-mean": 14.449774851700953, "reward_ctrl-first-mean": -0.41588468551635743, "reward_ctrl-last-mean": -0.16373128890991212, "reward_ctrl-mean-mean": -0.3676847068548203, "reward_ctrl-median-mean": -0.36139286756515504, "reward_ctrl-range-mean": 0.47756249904632564}}, "training": {"episode-reward-mean": 9946.160756585825, "episode-reward-min": 9737.167145508201, "episode-reward-max": 10163.049975990216, "episode-reward-std": 141.36283313678751, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.532053905112555, "reward_run-last-mean": 10.953066734760341, "reward_run-mean-mean": 10.320248718841302, "reward_run-median-mean": 10.749974257184604, "reward_run-range-mean": 13.826814646916437, "reward_ctrl-first-mean": -0.2911977076530457, "reward_ctrl-last-mean": -0.396417191028595, "reward_ctrl-mean-mean": -0.3740879622554779, "reward_ctrl-median-mean": -0.37294321298599253, "reward_ctrl-range-mean": 0.46522812128067026}}, "update": {"Q_value-mean": 734.7139892578125, "Q_loss-mean": 8.062649726867676, "policy_loss-mean": -735.1763305664062, "alpha": 0.21862204372882843, "alpha_loss-mean": 0.00017225071496795863}, "times": {"epoch_before_hook": 4.250500933267176e-05, "timestep_before_hook": 0.0807713138347026, "sample": 14.599624333786778, "train": 198.3905243750196, "timestep_after_hook": 0.03522091658669524, "training_paths": 0.07784820400411263, "evaluation_paths": 0.49908746700384654, "training_metrics": 0.001534224982606247, "evaluation_metrics": 0.00041339200106449425, "epoch_after_hook": 1.6039994079619646e-06}, "sampler": {"pool-size": 660000, "max-path-return": 10163.049975990216, "last-path-return": 10013.565680822327, "episodes": 660, "total-samples": 660000}, "epoch": 25, "timestep": 25000, "total_timestep": 650000, "num_train_steps": 650000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 26, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-39-24", "timestamp": 1652816364, "time_this_iter_s": 214.07861232757568, "time_total_s": 7225.294563531876, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 7225.294563531876, "timesteps_since_restore": 0, "iterations_since_restore": 26, "trial_id": "31acc_00000"}
{"alpha": 0.22058004140853882, "policy": {"shifts-mean": -0.15593086183071136, "shifts-std": 1.4358278512954712, "shifts-max": 3.1845641136169434, "shifts-min": -3.0355026721954346, "scales-mean": 0.4325588047504425, "scales-std": 0.14112289249897003, "scales-max": 1.0330450534820557, "scales-min": 0.05706328526139259, "entropy-mean": -5.731443881988525, "entropy-std": 3.644120454788208, "actions-mean": -0.10263055562973022, "actions-std": 0.7652143239974976, "actions-min": -0.9994863867759705, "actions-max": 0.9990674257278442}, "evaluation": {"episode-reward-mean": 10236.712890625, "episode-reward-min": 10236.712890625, "episode-reward-max": 10236.712890625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6874413857666752, "reward_run-last-mean": 10.564931283759051, "reward_run-mean-mean": 10.611679590291592, "reward_run-median-mean": 11.169215470521863, "reward_run-range-mean": 13.909370762171335, "reward_ctrl-first-mean": -0.36053071022033695, "reward_ctrl-last-mean": -0.45627608299255373, "reward_ctrl-mean-mean": -0.37496709249615673, "reward_ctrl-median-mean": -0.37532297372817996, "reward_ctrl-range-mean": 0.48329866528511045}}, "training": {"episode-reward-mean": 10101.697900031311, "episode-reward-min": 9973.008926192835, "episode-reward-max": 10351.271564919207, "episode-reward-std": 131.17086240689105, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5335880352839035, "reward_run-last-mean": 10.766035343382555, "reward_run-mean-mean": 10.475107221334081, "reward_run-median-mean": 10.91659483661823, "reward_run-range-mean": 14.107416873360027, "reward_ctrl-first-mean": -0.28775376558303833, "reward_ctrl-last-mean": -0.40025014162063605, "reward_ctrl-mean-mean": -0.3734093213027716, "reward_ctrl-median-mean": -0.3726298904418946, "reward_ctrl-range-mean": 0.4724470460414887}}, "update": {"Q_value-mean": 742.43896484375, "Q_loss-mean": 8.036458015441895, "policy_loss-mean": -742.8759765625, "alpha": 0.21979400515556335, "alpha_loss-mean": -0.0001570351014379412}, "times": {"epoch_before_hook": 3.156901220791042e-05, "timestep_before_hook": 0.08042862021829933, "sample": 14.500772280793171, "train": 198.44739016448148, "timestep_after_hook": 0.03515296205296181, "training_paths": 0.07507536601042375, "evaluation_paths": 0.49814786299248226, "training_metrics": 0.001586794009199366, "evaluation_metrics": 0.0004135899944230914, "epoch_after_hook": 1.61500065587461e-06}, "sampler": {"pool-size": 685000, "max-path-return": 10351.271564919205, "last-path-return": 10023.114404307746, "episodes": 685, "total-samples": 685000}, "epoch": 26, "timestep": 25000, "total_timestep": 675000, "num_train_steps": 675000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 27, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-42-58", "timestamp": 1652816578, "time_this_iter_s": 214.03199744224548, "time_total_s": 7439.326560974121, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 7439.326560974121, "timesteps_since_restore": 0, "iterations_since_restore": 27, "trial_id": "31acc_00000"}
{"alpha": 0.22118625044822693, "policy": {"shifts-mean": -0.1236756220459938, "shifts-std": 1.4618637561798096, "shifts-max": 2.9815196990966797, "shifts-min": -2.994767665863037, "scales-mean": 0.43790724873542786, "scales-std": 0.14109395444393158, "scales-max": 0.8827002644538879, "scales-min": 0.050462570041418076, "entropy-mean": -6.2462053298950195, "entropy-std": 3.841710329055786, "actions-mean": -0.09664701670408249, "actions-std": 0.77621990442276, "actions-min": -0.9984558820724487, "actions-max": 0.9989731907844543}, "evaluation": {"episode-reward-mean": 10284.4560546875, "episode-reward-min": 10284.4560546875, "episode-reward-max": 10284.4560546875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.07247964939169904, "reward_run-last-mean": 11.859761509626878, "reward_run-mean-mean": 10.657164863104757, "reward_run-median-mean": 11.053378841703818, "reward_run-range-mean": 13.299181180386359, "reward_ctrl-first-mean": -0.24490463733673096, "reward_ctrl-last-mean": -0.4462133407592774, "reward_ctrl-mean-mean": -0.37270910162925724, "reward_ctrl-median-mean": -0.37027213573455814, "reward_ctrl-range-mean": 0.4482995986938476}}, "training": {"episode-reward-mean": 10058.607847928202, "episode-reward-min": 9796.806160239834, "episode-reward-max": 10346.480478147401, "episode-reward-std": 171.73223892495164, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.641128294220476, "reward_run-last-mean": 11.092120304919035, "reward_run-mean-mean": 10.432535700832997, "reward_run-median-mean": 10.869454767303111, "reward_run-range-mean": 14.152707240089416, "reward_ctrl-first-mean": -0.3701643705368043, "reward_ctrl-last-mean": -0.37209525823593137, "reward_ctrl-mean-mean": -0.3739278529047966, "reward_ctrl-median-mean": -0.3723168849945069, "reward_ctrl-range-mean": 0.4623452746868134}}, "update": {"Q_value-mean": 750.4161376953125, "Q_loss-mean": 8.20634651184082, "policy_loss-mean": -750.8372802734375, "alpha": 0.22262878715991974, "alpha_loss-mean": -2.413029142189771e-05}, "times": {"epoch_before_hook": 3.6013982025906444e-05, "timestep_before_hook": 0.08052795586991124, "sample": 14.608903863816522, "train": 200.55444278850337, "timestep_after_hook": 0.035166515241144225, "training_paths": 0.07778868000605144, "evaluation_paths": 0.49486668000463396, "training_metrics": 0.001572219975059852, "evaluation_metrics": 0.0004009900148957968, "epoch_after_hook": 1.6550184227526188e-06}, "sampler": {"pool-size": 710000, "max-path-return": 10351.271564919205, "last-path-return": 10017.536177006457, "episodes": 710, "total-samples": 710000}, "epoch": 27, "timestep": 25000, "total_timestep": 700000, "num_train_steps": 700000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 28, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-46-34", "timestamp": 1652816794, "time_this_iter_s": 216.27655124664307, "time_total_s": 7655.603112220764, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 7655.603112220764, "timesteps_since_restore": 0, "iterations_since_restore": 28, "trial_id": "31acc_00000"}
{"alpha": 0.22764183580875397, "policy": {"shifts-mean": -0.12962345778942108, "shifts-std": 1.4151209592819214, "shifts-max": 4.486889839172363, "shifts-min": -3.2043466567993164, "scales-mean": 0.43496379256248474, "scales-std": 0.1447347104549408, "scales-max": 0.922058641910553, "scales-min": 0.04980037733912468, "entropy-mean": -5.963622093200684, "entropy-std": 3.761500120162964, "actions-mean": -0.09828000515699387, "actions-std": 0.7667789459228516, "actions-min": -0.9999127984046936, "actions-max": 0.9993669986724854}, "evaluation": {"episode-reward-mean": 10241.8359375, "episode-reward-min": 10241.8359375, "episode-reward-max": 10241.8359375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.2953032640914914, "reward_run-last-mean": 12.247513188688117, "reward_run-mean-mean": 10.617164374671647, "reward_run-median-mean": 11.044529272885555, "reward_run-range-mean": 14.300396831321205, "reward_ctrl-first-mean": -0.31693382263183595, "reward_ctrl-last-mean": -0.4045753002166748, "reward_ctrl-mean-mean": -0.375328019297123, "reward_ctrl-median-mean": -0.37313988208770754, "reward_ctrl-range-mean": 0.4548880815505981}}, "training": {"episode-reward-mean": 10205.039558458764, "episode-reward-min": 9990.099102775472, "episode-reward-max": 10423.463011901289, "episode-reward-std": 128.36315802967752, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.48779893821293785, "reward_run-last-mean": 10.941962615358307, "reward_run-mean-mean": 10.577533731784067, "reward_run-median-mean": 11.036182587708268, "reward_run-range-mean": 14.103520400311151, "reward_ctrl-first-mean": -0.23877874970436097, "reward_ctrl-last-mean": -0.41840535402297974, "reward_ctrl-mean-mean": -0.3724941733253002, "reward_ctrl-median-mean": -0.3712957417964936, "reward_ctrl-range-mean": 0.4715501081943511}}, "update": {"Q_value-mean": 758.4332885742188, "Q_loss-mean": 8.267685890197754, "policy_loss-mean": -758.8411865234375, "alpha": 0.22484664618968964, "alpha_loss-mean": -0.00020917929941788316}, "times": {"epoch_before_hook": 3.086499054916203e-05, "timestep_before_hook": 0.08118328233831562, "sample": 14.594614888628712, "train": 199.22425850041327, "timestep_after_hook": 0.03523824276635423, "training_paths": 0.07928456898662262, "evaluation_paths": 0.49945243599358946, "training_metrics": 0.0016173830081243068, "evaluation_metrics": 0.00041423700167797506, "epoch_after_hook": 1.8069986253976822e-06}, "sampler": {"pool-size": 735000, "max-path-return": 10543.95424223624, "last-path-return": 10195.212242754533, "episodes": 735, "total-samples": 735000}, "epoch": 28, "timestep": 25000, "total_timestep": 725000, "num_train_steps": 725000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 29, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-50-09", "timestamp": 1652817009, "time_this_iter_s": 214.9107630252838, "time_total_s": 7870.513875246048, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 7870.513875246048, "timesteps_since_restore": 0, "iterations_since_restore": 29, "trial_id": "31acc_00000"}
{"alpha": 0.22420375049114227, "policy": {"shifts-mean": -0.13935332000255585, "shifts-std": 1.4262694120407104, "shifts-max": 2.983494758605957, "shifts-min": -3.3134241104125977, "scales-mean": 0.4449883997440338, "scales-std": 0.15164726972579956, "scales-max": 1.0669716596603394, "scales-min": 0.05242143198847771, "entropy-mean": -5.6912102699279785, "entropy-std": 3.8314335346221924, "actions-mean": -0.08215832710266113, "actions-std": 0.7693884372711182, "actions-min": -0.9991846084594727, "actions-max": 0.9991532564163208}, "evaluation": {"episode-reward-mean": 10107.556640625, "episode-reward-min": 10107.556640625, "episode-reward-max": 10107.556640625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6053459133766067, "reward_run-last-mean": 9.977111175874143, "reward_run-mean-mean": 10.484434990150973, "reward_run-median-mean": 10.942427442548706, "reward_run-range-mean": 14.175228805745835, "reward_ctrl-first-mean": -0.14807716608047486, "reward_ctrl-last-mean": -0.4068220138549805, "reward_ctrl-mean-mean": -0.3768781112670898, "reward_ctrl-median-mean": -0.3769716858863831, "reward_ctrl-range-mean": 0.45588719844818115}}, "training": {"episode-reward-mean": 10300.701931482803, "episode-reward-min": 10015.965342125412, "episode-reward-max": 10545.515978717547, "episode-reward-std": 144.03098752571705, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6546700620499597, "reward_run-last-mean": 11.488214633063535, "reward_run-mean-mean": 10.672363835081708, "reward_run-median-mean": 11.099817784930387, "reward_run-range-mean": 14.283384547607085, "reward_ctrl-first-mean": -0.3289094185829163, "reward_ctrl-last-mean": -0.4028744494915008, "reward_ctrl-mean-mean": -0.3716619035989046, "reward_ctrl-median-mean": -0.3710713028907776, "reward_ctrl-range-mean": 0.46984836876392366}}, "update": {"Q_value-mean": 766.3026123046875, "Q_loss-mean": 8.461969375610352, "policy_loss-mean": -766.7036743164062, "alpha": 0.227692112326622, "alpha_loss-mean": 0.0001338851870968938}, "times": {"epoch_before_hook": 3.109898534603417e-05, "timestep_before_hook": 0.08020865291473456, "sample": 14.656504859565757, "train": 198.58987763291225, "timestep_after_hook": 0.03539740145788528, "training_paths": 0.07803959099692293, "evaluation_paths": 0.4948666050040629, "training_metrics": 0.0015673179877921939, "evaluation_metrics": 0.00042159599252045155, "epoch_after_hook": 1.5959958545863628e-06}, "sampler": {"pool-size": 760000, "max-path-return": 10545.515978717534, "last-path-return": 10425.165366373061, "episodes": 760, "total-samples": 760000}, "epoch": 29, "timestep": 25000, "total_timestep": 750000, "num_train_steps": 750000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 30, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-53-43", "timestamp": 1652817223, "time_this_iter_s": 214.33058857917786, "time_total_s": 8084.844463825226, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 8084.844463825226, "timesteps_since_restore": 0, "iterations_since_restore": 30, "trial_id": "31acc_00000"}
{"alpha": 0.23373757302761078, "policy": {"shifts-mean": -0.12968270480632782, "shifts-std": 1.428821325302124, "shifts-max": 3.528622627258301, "shifts-min": -3.052485227584839, "scales-mean": 0.42884349822998047, "scales-std": 0.13634367287158966, "scales-max": 0.9346093535423279, "scales-min": 0.04270937293767929, "entropy-mean": -6.059335231781006, "entropy-std": 3.8833768367767334, "actions-mean": -0.09319013357162476, "actions-std": 0.7714420557022095, "actions-min": -0.9991418719291687, "actions-max": 0.9989680647850037}, "evaluation": {"episode-reward-mean": 10609.1552734375, "episode-reward-min": 10609.1552734375, "episode-reward-max": 10609.1552734375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5541977461018118, "reward_run-last-mean": 11.068888446270648, "reward_run-mean-mean": 10.980181165417202, "reward_run-median-mean": 11.373827261083704, "reward_run-range-mean": 14.413547842378824, "reward_ctrl-first-mean": -0.4168587684631348, "reward_ctrl-last-mean": -0.2742161273956299, "reward_ctrl-mean-mean": -0.3710256901860237, "reward_ctrl-median-mean": -0.3653234720230103, "reward_ctrl-range-mean": 0.4526165723800659}}, "training": {"episode-reward-mean": 10367.225191040077, "episode-reward-min": 10169.07332215055, "episode-reward-max": 10594.539678586105, "episode-reward-std": 144.15264803552225, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.689077709177737, "reward_run-last-mean": 11.737181086246892, "reward_run-mean-mean": 10.736949326717893, "reward_run-median-mean": 11.212401999354235, "reward_run-range-mean": 14.300285502098044, "reward_ctrl-first-mean": -0.3229896378517151, "reward_ctrl-last-mean": -0.37808490037918097, "reward_ctrl-mean-mean": -0.36972413567781454, "reward_ctrl-median-mean": -0.36797704696655276, "reward_ctrl-range-mean": 0.4694858145713807}}, "update": {"Q_value-mean": 774.5547485351562, "Q_loss-mean": 8.55911922454834, "policy_loss-mean": -774.9524536132812, "alpha": 0.22953273355960846, "alpha_loss-mean": -0.00032577887759543955}, "times": {"epoch_before_hook": 3.972998820245266e-05, "timestep_before_hook": 0.08140284309047274, "sample": 14.468300632957835, "train": 199.3192898253037, "timestep_after_hook": 0.035692301142262295, "training_paths": 0.075956413988024, "evaluation_paths": 0.5909811460005585, "training_metrics": 0.0015108860097825527, "evaluation_metrics": 0.0004161469987593591, "epoch_after_hook": 1.7709971871227026e-06}, "sampler": {"pool-size": 785000, "max-path-return": 10594.53967858611, "last-path-return": 10361.400855426496, "episodes": 785, "total-samples": 785000}, "epoch": 30, "timestep": 25000, "total_timestep": 775000, "num_train_steps": 775000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 31, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_20-57-19", "timestamp": 1652817439, "time_this_iter_s": 214.96886610984802, "time_total_s": 8299.813329935074, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 8299.813329935074, "timesteps_since_restore": 0, "iterations_since_restore": 31, "trial_id": "31acc_00000"}
{"alpha": 0.23100532591342926, "policy": {"shifts-mean": -0.08379346132278442, "shifts-std": 1.466059684753418, "shifts-max": 3.2425661087036133, "shifts-min": -3.0917341709136963, "scales-mean": 0.43259891867637634, "scales-std": 0.13792899250984192, "scales-max": 0.9251584410667419, "scales-min": 0.04967077076435089, "entropy-mean": -6.168814182281494, "entropy-std": 3.5619421005249023, "actions-mean": -0.05902663245797157, "actions-std": 0.7784348726272583, "actions-min": -0.999609649181366, "actions-max": 0.9995755553245544}, "evaluation": {"episode-reward-mean": 10622.9658203125, "episode-reward-min": 10622.9658203125, "episode-reward-max": 10622.9658203125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5658706956063961, "reward_run-last-mean": 12.14314336212965, "reward_run-mean-mean": 10.992160714083967, "reward_run-median-mean": 11.48790135138114, "reward_run-range-mean": 14.740398180776545, "reward_ctrl-first-mean": -0.18825278282165528, "reward_ctrl-last-mean": -0.36051459312438966, "reward_ctrl-mean-mean": -0.36919460144042965, "reward_ctrl-median-mean": -0.36564162969589237, "reward_ctrl-range-mean": 0.4307741045951843}}, "training": {"episode-reward-mean": 10589.623643300929, "episode-reward-min": 10357.317914838772, "episode-reward-max": 10832.164894348349, "episode-reward-std": 131.9496548098241, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6497094074374952, "reward_run-last-mean": 11.17603695825619, "reward_run-mean-mean": 10.958941865945857, "reward_run-median-mean": 11.44472230488909, "reward_run-range-mean": 14.429866261114052, "reward_ctrl-first-mean": -0.3186478769779205, "reward_ctrl-last-mean": -0.39165405273437504, "reward_ctrl-mean-mean": -0.3693182226449251, "reward_ctrl-median-mean": -0.36771155595779426, "reward_ctrl-range-mean": 0.45975970149040224}}, "update": {"Q_value-mean": 782.1495971679688, "Q_loss-mean": 8.694229125976562, "policy_loss-mean": -782.5379028320312, "alpha": 0.23141619563102722, "alpha_loss-mean": 0.00010808724618982524}, "times": {"epoch_before_hook": 3.5981007385998964e-05, "timestep_before_hook": 0.08181673087528907, "sample": 14.462001234351192, "train": 199.05397455915227, "timestep_after_hook": 0.03557267409632914, "training_paths": 0.0758309899829328, "evaluation_paths": 0.49458545399829745, "training_metrics": 0.0015882230072747916, "evaluation_metrics": 0.001045819983119145, "epoch_after_hook": 1.9909930415451527e-06}, "sampler": {"pool-size": 810000, "max-path-return": 10832.164894348372, "last-path-return": 10357.317914838788, "episodes": 810, "total-samples": 810000}, "epoch": 31, "timestep": 25000, "total_timestep": 800000, "num_train_steps": 800000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 32, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-00-54", "timestamp": 1652817654, "time_this_iter_s": 214.6026749610901, "time_total_s": 8514.416004896164, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 8514.416004896164, "timesteps_since_restore": 0, "iterations_since_restore": 32, "trial_id": "31acc_00000"}
{"alpha": 0.23506440222263336, "policy": {"shifts-mean": -0.03179587796330452, "shifts-std": 1.465414047241211, "shifts-max": 2.859819173812866, "shifts-min": -3.023688554763794, "scales-mean": 0.4262971580028534, "scales-std": 0.1378219574689865, "scales-max": 0.9725854396820068, "scales-min": 0.05010303482413292, "entropy-mean": -6.410278797149658, "entropy-std": 3.6368913650512695, "actions-mean": -0.044510871171951294, "actions-std": 0.7880699634552002, "actions-min": -0.9987500905990601, "actions-max": 0.9988577961921692}, "evaluation": {"episode-reward-mean": 10496.44140625, "episode-reward-min": 10496.44140625, "episode-reward-max": 10496.44140625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4321892906352415, "reward_run-last-mean": 11.743542249676011, "reward_run-mean-mean": 10.856176950982833, "reward_run-median-mean": 11.332148546587177, "reward_run-range-mean": 14.875254048458588, "reward_ctrl-first-mean": -0.2678675174713135, "reward_ctrl-last-mean": -0.26786131858825685, "reward_ctrl-mean-mean": -0.35973549616336825, "reward_ctrl-median-mean": -0.3593615531921387, "reward_ctrl-range-mean": 0.477510404586792}}, "training": {"episode-reward-mean": 10541.2484666239, "episode-reward-min": 10340.529361551144, "episode-reward-max": 10677.823537621409, "episode-reward-std": 110.14474223377994, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6981275716775859, "reward_run-last-mean": 11.403305626742394, "reward_run-mean-mean": 10.91094847993898, "reward_run-median-mean": 11.381698890910968, "reward_run-range-mean": 14.506550283160806, "reward_ctrl-first-mean": -0.29078837752342224, "reward_ctrl-last-mean": -0.39502674460411075, "reward_ctrl-mean-mean": -0.36970001331508157, "reward_ctrl-median-mean": -0.36683381319046027, "reward_ctrl-range-mean": 0.47429361939430237}}, "update": {"Q_value-mean": 790.0422973632812, "Q_loss-mean": 8.890167236328125, "policy_loss-mean": -790.4196166992188, "alpha": 0.2337992936372757, "alpha_loss-mean": -0.0001260338758584112}, "times": {"epoch_before_hook": 2.9031012672930956e-05, "timestep_before_hook": 0.08220372494542971, "sample": 14.526553323928965, "train": 198.81698029951076, "timestep_after_hook": 0.03543047225684859, "training_paths": 0.07640893501229584, "evaluation_paths": 0.4960765169817023, "training_metrics": 0.0016275100060738623, "evaluation_metrics": 0.00041042102384380996, "epoch_after_hook": 1.5129917301237583e-06}, "sampler": {"pool-size": 835000, "max-path-return": 10832.164894348372, "last-path-return": 10447.646201431053, "episodes": 835, "total-samples": 835000}, "epoch": 32, "timestep": 25000, "total_timestep": 825000, "num_train_steps": 825000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 33, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-04-28", "timestamp": 1652817868, "time_this_iter_s": 214.43084335327148, "time_total_s": 8728.846848249435, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 8728.846848249435, "timesteps_since_restore": 0, "iterations_since_restore": 33, "trial_id": "31acc_00000"}
{"alpha": 0.2358207404613495, "policy": {"shifts-mean": -0.08044420927762985, "shifts-std": 1.4411356449127197, "shifts-max": 3.0471792221069336, "shifts-min": -3.2474074363708496, "scales-mean": 0.42783260345458984, "scales-std": 0.1426200568675995, "scales-max": 0.9641332626342773, "scales-min": 0.05526283383369446, "entropy-mean": -6.110387325286865, "entropy-std": 3.8678104877471924, "actions-mean": -0.061995502561330795, "actions-std": 0.7759808897972107, "actions-min": -0.9986793398857117, "actions-max": 0.9997778534889221}, "evaluation": {"episode-reward-mean": 10700.59765625, "episode-reward-min": 10700.59765625, "episode-reward-max": 10700.59765625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.20015213568867, "reward_run-last-mean": 10.997706475493487, "reward_run-mean-mean": 11.063350311676615, "reward_run-median-mean": 11.506847651600367, "reward_run-range-mean": 14.671352176082511, "reward_ctrl-first-mean": -0.17254900932312012, "reward_ctrl-last-mean": -0.2677313327789307, "reward_ctrl-mean-mean": -0.36275265312194827, "reward_ctrl-median-mean": -0.35739020109176634, "reward_ctrl-range-mean": 0.4476222276687622}}, "training": {"episode-reward-mean": 10533.82679093328, "episode-reward-min": 10386.842856804657, "episode-reward-max": 10850.505922840628, "episode-reward-std": 133.21286514854782, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6755254923459304, "reward_run-last-mean": 11.683935323832657, "reward_run-mean-mean": 10.903047782842783, "reward_run-median-mean": 11.38809212166155, "reward_run-range-mean": 14.843479397785131, "reward_ctrl-first-mean": -0.32615658521652224, "reward_ctrl-last-mean": -0.3810520505905151, "reward_ctrl-mean-mean": -0.3692209919095039, "reward_ctrl-median-mean": -0.3662169003486634, "reward_ctrl-range-mean": 0.47773995280265813}}, "update": {"Q_value-mean": 797.1956176757812, "Q_loss-mean": 9.106226921081543, "policy_loss-mean": -797.5679321289062, "alpha": 0.23767001926898956, "alpha_loss-mean": 1.4613485745940125e-06}, "times": {"epoch_before_hook": 3.330002073198557e-05, "timestep_before_hook": 0.08107796829426661, "sample": 14.615920471202116, "train": 198.55024570628302, "timestep_after_hook": 0.035415967722656205, "training_paths": 0.07699208499980159, "evaluation_paths": 0.6245816209993791, "training_metrics": 0.001506462984252721, "evaluation_metrics": 0.0004106760025024414, "epoch_after_hook": 1.614011125639081e-06}, "sampler": {"pool-size": 860000, "max-path-return": 10850.505922840612, "last-path-return": 10463.276475265966, "episodes": 860, "total-samples": 860000}, "epoch": 33, "timestep": 25000, "total_timestep": 850000, "num_train_steps": 850000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 34, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-08-02", "timestamp": 1652818082, "time_this_iter_s": 214.38116788864136, "time_total_s": 8943.228016138077, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 8943.228016138077, "timesteps_since_restore": 0, "iterations_since_restore": 34, "trial_id": "31acc_00000"}
{"alpha": 0.24363870918750763, "policy": {"shifts-mean": -0.11858821660280228, "shifts-std": 1.3807440996170044, "shifts-max": 3.1514627933502197, "shifts-min": -2.9327392578125, "scales-mean": 0.43336427211761475, "scales-std": 0.14064130187034607, "scales-max": 0.8976392149925232, "scales-min": 0.05109822750091553, "entropy-mean": -5.38877010345459, "entropy-std": 3.8380179405212402, "actions-mean": -0.0811314657330513, "actions-std": 0.7617810368537903, "actions-min": -0.9989785552024841, "actions-max": 0.99925696849823}, "evaluation": {"episode-reward-mean": 10998.8095703125, "episode-reward-min": 10998.8095703125, "episode-reward-max": 10998.8095703125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.13632767011546587, "reward_run-last-mean": 13.113230431104057, "reward_run-mean-mean": 11.363487429717575, "reward_run-median-mean": 11.915358560507912, "reward_run-range-mean": 14.512669805921476, "reward_ctrl-first-mean": -0.26836981773376467, "reward_ctrl-last-mean": -0.27294416427612306, "reward_ctrl-mean-mean": -0.3646777613759041, "reward_ctrl-median-mean": -0.3584466099739075, "reward_ctrl-range-mean": 0.4640642523765564}}, "training": {"episode-reward-mean": 10709.366463267706, "episode-reward-min": 10311.658099515524, "episode-reward-max": 10972.022064365554, "episode-reward-std": 181.00751697470187, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6748270161937482, "reward_run-last-mean": 11.418455009737727, "reward_run-mean-mean": 11.078125680268906, "reward_run-median-mean": 11.566487770077757, "reward_run-range-mean": 14.71826994893394, "reward_ctrl-first-mean": -0.34809854030609133, "reward_ctrl-last-mean": -0.37646020293235777, "reward_ctrl-mean-mean": -0.36875921700119974, "reward_ctrl-median-mean": -0.36570191383361816, "reward_ctrl-range-mean": 0.4716316425800323}}, "update": {"Q_value-mean": 804.306640625, "Q_loss-mean": 9.144649505615234, "policy_loss-mean": -804.6804809570312, "alpha": 0.23889686167240143, "alpha_loss-mean": -0.0002397926291450858}, "times": {"epoch_before_hook": 2.8223992558196187e-05, "timestep_before_hook": 0.08176374726463109, "sample": 14.60987968556583, "train": 198.405185397889, "timestep_after_hook": 0.035304119053762406, "training_paths": 0.076371912000468, "evaluation_paths": 0.4932700780045707, "training_metrics": 0.0015780050016473979, "evaluation_metrics": 0.00041549900197423995, "epoch_after_hook": 1.5289988368749619e-06}, "sampler": {"pool-size": 885000, "max-path-return": 10972.022064365558, "last-path-return": 10536.018155089523, "episodes": 885, "total-samples": 885000}, "epoch": 34, "timestep": 25000, "total_timestep": 875000, "num_train_steps": 875000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 35, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-11-36", "timestamp": 1652818296, "time_this_iter_s": 214.0987229347229, "time_total_s": 9157.3267390728, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 9157.3267390728, "timesteps_since_restore": 0, "iterations_since_restore": 35, "trial_id": "31acc_00000"}
{"alpha": 0.24447020888328552, "policy": {"shifts-mean": -0.11099348217248917, "shifts-std": 1.4398596286773682, "shifts-max": 3.192656993865967, "shifts-min": -3.368716239929199, "scales-mean": 0.42624759674072266, "scales-std": 0.13630539178848267, "scales-max": 0.8594719767570496, "scales-min": 0.045811351388692856, "entropy-mean": -6.133235454559326, "entropy-std": 3.759840488433838, "actions-mean": -0.07916510105133057, "actions-std": 0.7733889818191528, "actions-min": -0.998924195766449, "actions-max": 0.999148428440094}, "evaluation": {"episode-reward-mean": 10747.1123046875, "episode-reward-min": 10747.1123046875, "episode-reward-max": 10747.1123046875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.12717420883170544, "reward_run-last-mean": 11.625651972942705, "reward_run-mean-mean": 11.122812728190521, "reward_run-median-mean": 11.622390826627793, "reward_run-range-mean": 14.383541617543012, "reward_ctrl-first-mean": -0.35137851238250734, "reward_ctrl-last-mean": -0.3572823524475098, "reward_ctrl-mean-mean": -0.37570015107393273, "reward_ctrl-median-mean": -0.3744751214981079, "reward_ctrl-range-mean": 0.5151290178298951}}, "training": {"episode-reward-mean": 10792.947865364737, "episode-reward-min": 10503.621353322971, "episode-reward-max": 10948.59890458345, "episode-reward-std": 135.20021824050124, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5971714024715705, "reward_run-last-mean": 11.606123118666346, "reward_run-mean-mean": 11.160996249501293, "reward_run-median-mean": 11.669501463956259, "reward_run-range-mean": 14.810694311799903, "reward_ctrl-first-mean": -0.3094231128692627, "reward_ctrl-last-mean": -0.4237137770652771, "reward_ctrl-mean-mean": -0.3680483841365576, "reward_ctrl-median-mean": -0.363323575258255, "reward_ctrl-range-mean": 0.456576698422432}}, "update": {"Q_value-mean": 811.465576171875, "Q_loss-mean": 9.483134269714355, "policy_loss-mean": -811.8311767578125, "alpha": 0.24278435111045837, "alpha_loss-mean": -2.9022121452726424e-05}, "times": {"epoch_before_hook": 3.622501390054822e-05, "timestep_before_hook": 0.08232148876413703, "sample": 14.545203320623841, "train": 198.77500804173178, "timestep_after_hook": 0.03547453792998567, "training_paths": 0.18806325501645915, "evaluation_paths": 0.4994757990061771, "training_metrics": 0.0015165539807640016, "evaluation_metrics": 0.00041182999848388135, "epoch_after_hook": 1.6960257198661566e-06}, "sampler": {"pool-size": 910000, "max-path-return": 10972.022064365558, "last-path-return": 10927.69810650494, "episodes": 910, "total-samples": 910000}, "epoch": 35, "timestep": 25000, "total_timestep": 900000, "num_train_steps": 900000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 36, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-15-11", "timestamp": 1652818511, "time_this_iter_s": 214.52440810203552, "time_total_s": 9371.851147174835, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 9371.851147174835, "timesteps_since_restore": 0, "iterations_since_restore": 36, "trial_id": "31acc_00000"}
{"alpha": 0.24347680807113647, "policy": {"shifts-mean": -0.06495547294616699, "shifts-std": 1.442439317703247, "shifts-max": 3.2487993240356445, "shifts-min": -3.7461490631103516, "scales-mean": 0.4294358789920807, "scales-std": 0.14288215339183807, "scales-max": 0.963567316532135, "scales-min": 0.04067979380488396, "entropy-mean": -5.975118160247803, "entropy-std": 3.7147533893585205, "actions-mean": -0.0532468743622303, "actions-std": 0.7752664089202881, "actions-min": -0.9994641542434692, "actions-max": 0.9988723993301392}, "evaluation": {"episode-reward-mean": 11016.111328125, "episode-reward-min": 11016.111328125, "episode-reward-max": 11016.111328125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4101514084319405, "reward_run-last-mean": 12.01303327247615, "reward_run-mean-mean": 11.37785404672865, "reward_run-median-mean": 11.939471719966122, "reward_run-range-mean": 14.933588528440733, "reward_ctrl-first-mean": -0.24886755943298342, "reward_ctrl-last-mean": -0.4851853847503662, "reward_ctrl-mean-mean": -0.3617423885822296, "reward_ctrl-median-mean": -0.35703443288803105, "reward_ctrl-range-mean": 0.4449741959571838}}, "training": {"episode-reward-mean": 10878.727265912637, "episode-reward-min": 10643.185155842686, "episode-reward-max": 11074.791762722452, "episode-reward-std": 140.18507459633975, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.49849625792138674, "reward_run-last-mean": 11.99310673975151, "reward_run-mean-mean": 11.244573944656896, "reward_run-median-mean": 11.770345793323955, "reward_run-range-mean": 15.066283274030933, "reward_ctrl-first-mean": -0.19334643959999087, "reward_ctrl-last-mean": -0.35892812490463255, "reward_ctrl-mean-mean": -0.3658466787442565, "reward_ctrl-median-mean": -0.3603391778469086, "reward_ctrl-range-mean": 0.4650098457932472}}, "update": {"Q_value-mean": 818.033203125, "Q_loss-mean": 9.715717315673828, "policy_loss-mean": -818.3966674804688, "alpha": 0.24420295655727386, "alpha_loss-mean": 4.067530608153902e-05}, "times": {"epoch_before_hook": 3.474002005532384e-05, "timestep_before_hook": 0.08234796795295551, "sample": 14.72768515982898, "train": 198.4169849366881, "timestep_after_hook": 0.03514720386010595, "training_paths": 0.07575659299618565, "evaluation_paths": 0.5302393150050193, "training_metrics": 0.0015306219866033643, "evaluation_metrics": 0.0004191999905742705, "epoch_after_hook": 1.828011590987444e-06}, "sampler": {"pool-size": 935000, "max-path-return": 11097.991387464646, "last-path-return": 10916.767850322083, "episodes": 935, "total-samples": 935000}, "epoch": 36, "timestep": 25000, "total_timestep": 925000, "num_train_steps": 925000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 37, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-18-45", "timestamp": 1652818725, "time_this_iter_s": 214.2659249305725, "time_total_s": 9586.117072105408, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 9586.117072105408, "timesteps_since_restore": 0, "iterations_since_restore": 37, "trial_id": "31acc_00000"}
{"alpha": 0.2462220937013626, "policy": {"shifts-mean": -0.12129070609807968, "shifts-std": 1.4141793251037598, "shifts-max": 3.048062801361084, "shifts-min": -2.9604978561401367, "scales-mean": 0.4345983564853668, "scales-std": 0.14694809913635254, "scales-max": 1.3624540567398071, "scales-min": 0.05380996689200401, "entropy-mean": -5.580487251281738, "entropy-std": 3.52616024017334, "actions-mean": -0.07953902333974838, "actions-std": 0.7661957740783691, "actions-min": -0.9990435838699341, "actions-max": 0.9995429515838623}, "evaluation": {"episode-reward-mean": 10656.640625, "episode-reward-min": 10656.640625, "episode-reward-max": 10656.640625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.15524625358781796, "reward_run-last-mean": 11.43903136031895, "reward_run-mean-mean": 11.020066983940339, "reward_run-median-mean": 11.559962429744246, "reward_run-range-mean": 14.135672330566846, "reward_ctrl-first-mean": -0.2896549463272095, "reward_ctrl-last-mean": -0.5066148757934571, "reward_ctrl-mean-mean": -0.3634269520044327, "reward_ctrl-median-mean": -0.36336631774902345, "reward_ctrl-range-mean": 0.4419392585754395}}, "training": {"episode-reward-mean": 10951.532942544229, "episode-reward-min": 10709.376276579129, "episode-reward-max": 11217.245615713884, "episode-reward-std": 148.09016646128987, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6239726913643786, "reward_run-last-mean": 11.79929871343461, "reward_run-mean-mean": 11.317140777104504, "reward_run-median-mean": 11.852906867405501, "reward_run-range-mean": 14.932262074969552, "reward_ctrl-first-mean": -0.30783733367919924, "reward_ctrl-last-mean": -0.35941056728363036, "reward_ctrl-mean-mean": -0.3656078345602751, "reward_ctrl-median-mean": -0.3609258663654328, "reward_ctrl-range-mean": 0.46963591277599337}}, "update": {"Q_value-mean": 824.6465454101562, "Q_loss-mean": 9.791993141174316, "policy_loss-mean": -825.0108642578125, "alpha": 0.2447907030582428, "alpha_loss-mean": -7.026243838481605e-05}, "times": {"epoch_before_hook": 3.176601603627205e-05, "timestep_before_hook": 0.08235563029302284, "sample": 14.521292166697094, "train": 198.49731090391288, "timestep_after_hook": 0.03520705326809548, "training_paths": 0.07645015200250782, "evaluation_paths": 0.5008854259795044, "training_metrics": 0.0015109119995031506, "evaluation_metrics": 0.00041501797386445105, "epoch_after_hook": 1.6539997886866331e-06}, "sampler": {"pool-size": 960000, "max-path-return": 11217.245615713895, "last-path-return": 10804.358657040408, "episodes": 960, "total-samples": 960000}, "epoch": 37, "timestep": 25000, "total_timestep": 950000, "num_train_steps": 950000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 38, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-22-19", "timestamp": 1652818939, "time_this_iter_s": 214.11215567588806, "time_total_s": 9800.229227781296, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 9800.229227781296, "timesteps_since_restore": 0, "iterations_since_restore": 38, "trial_id": "31acc_00000"}
{"alpha": 0.2515779435634613, "policy": {"shifts-mean": -0.11856911331415176, "shifts-std": 1.4111080169677734, "shifts-max": 3.105013847351074, "shifts-min": -3.5182242393493652, "scales-mean": 0.4388643205165863, "scales-std": 0.1473144143819809, "scales-max": 1.0638550519943237, "scales-min": 0.049057357013225555, "entropy-mean": -5.540996551513672, "entropy-std": 3.726602792739868, "actions-mean": -0.07392752915620804, "actions-std": 0.7674404978752136, "actions-min": -0.9984793663024902, "actions-max": 0.998760461807251}, "evaluation": {"episode-reward-mean": 11062.59765625, "episode-reward-min": 11062.59765625, "episode-reward-max": 11062.59765625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6737618893998467, "reward_run-last-mean": 12.170484685320844, "reward_run-mean-mean": 11.433812736888644, "reward_run-median-mean": 11.97329869202349, "reward_run-range-mean": 15.140595053500155, "reward_ctrl-first-mean": -0.4664012908935547, "reward_ctrl-last-mean": -0.3558203458786011, "reward_ctrl-mean-mean": -0.37121428261995315, "reward_ctrl-median-mean": -0.3681025505065918, "reward_ctrl-range-mean": 0.4262654781341553}}, "training": {"episode-reward-mean": 10874.384484764518, "episode-reward-min": 10440.23028902376, "episode-reward-max": 11093.737694286585, "episode-reward-std": 202.941183727537, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5924616625486212, "reward_run-last-mean": 11.380192341384145, "reward_run-mean-mean": 11.241461693687619, "reward_run-median-mean": 11.801921241588325, "reward_run-range-mean": 14.983067620201535, "reward_ctrl-first-mean": -0.2469113087654114, "reward_ctrl-last-mean": -0.37990034341812134, "reward_ctrl-mean-mean": -0.3670772089231015, "reward_ctrl-median-mean": -0.36114337563514715, "reward_ctrl-range-mean": 0.4607484352588653}}, "update": {"Q_value-mean": 831.8666381835938, "Q_loss-mean": 10.064395904541016, "policy_loss-mean": -832.2348022460938, "alpha": 0.24644501507282257, "alpha_loss-mean": -0.00019184108532499522}, "times": {"epoch_before_hook": 3.607498365454376e-05, "timestep_before_hook": 0.08220440457807854, "sample": 14.960688296501758, "train": 198.9841622468375, "timestep_after_hook": 0.035514359769877046, "training_paths": 0.07693234700127505, "evaluation_paths": 0.5066366729734, "training_metrics": 0.037797338009113446, "evaluation_metrics": 0.01680995899369009, "epoch_after_hook": 2.082000719383359e-06}, "sampler": {"pool-size": 985000, "max-path-return": 11272.596973592657, "last-path-return": 10801.786687059453, "episodes": 985, "total-samples": 985000}, "epoch": 38, "timestep": 25000, "total_timestep": 975000, "num_train_steps": 975000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 39, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-25-55", "timestamp": 1652819155, "time_this_iter_s": 215.11418843269348, "time_total_s": 10015.34341621399, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 10015.34341621399, "timesteps_since_restore": 0, "iterations_since_restore": 39, "trial_id": "31acc_00000"}
{"alpha": 0.251133531332016, "policy": {"shifts-mean": -0.08342579752206802, "shifts-std": 1.4630141258239746, "shifts-max": 3.2490298748016357, "shifts-min": -2.9939122200012207, "scales-mean": 0.43769359588623047, "scales-std": 0.14468613266944885, "scales-max": 0.9106974005699158, "scales-min": 0.05260581523180008, "entropy-mean": -6.2446818351745605, "entropy-std": 3.8174171447753906, "actions-mean": -0.05816689506173134, "actions-std": 0.7811248898506165, "actions-min": -0.9990257620811462, "actions-max": 0.9998145699501038}, "evaluation": {"episode-reward-mean": 11031.21875, "episode-reward-min": 11031.21875, "episode-reward-max": 11031.21875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7710466646344313, "reward_run-last-mean": 13.12763814584514, "reward_run-mean-mean": 11.396053808743957, "reward_run-median-mean": 11.96791658865095, "reward_run-range-mean": 15.328040763829247, "reward_ctrl-first-mean": -0.35582942962646485, "reward_ctrl-last-mean": -0.3698967695236206, "reward_ctrl-mean-mean": -0.36483519853353497, "reward_ctrl-median-mean": -0.36213662624359133, "reward_ctrl-range-mean": 0.43124560117721566}}, "training": {"episode-reward-mean": 11031.934898519174, "episode-reward-min": 10823.94522432734, "episode-reward-max": 11254.42245167281, "episode-reward-std": 143.9690011547815, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6172515372628095, "reward_run-last-mean": 12.46551357327121, "reward_run-mean-mean": 11.39803044716324, "reward_run-median-mean": 11.906896948195993, "reward_run-range-mean": 14.885436393028135, "reward_ctrl-first-mean": -0.2894835090637207, "reward_ctrl-last-mean": -0.36858811378479006, "reward_ctrl-mean-mean": -0.3660955486440659, "reward_ctrl-median-mean": -0.36105984926223755, "reward_ctrl-range-mean": 0.47300282835960383}}, "update": {"Q_value-mean": 838.1112670898438, "Q_loss-mean": 10.493329048156738, "policy_loss-mean": -838.4524536132812, "alpha": 0.2497842013835907, "alpha_loss-mean": 2.5532197469146922e-05}, "times": {"epoch_before_hook": 4.0277023799717426e-05, "timestep_before_hook": 0.08286830861470662, "sample": 14.684458169795107, "train": 198.93953660337138, "timestep_after_hook": 0.035659404122270644, "training_paths": 0.07716400400386192, "evaluation_paths": 0.4953780459763948, "training_metrics": 0.0015663869853597134, "evaluation_metrics": 0.0004027170070912689, "epoch_after_hook": 1.5849946066737175e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11272.596973592657, "last-path-return": 10823.945224327348, "episodes": 1010, "total-samples": 1010000}, "epoch": 39, "timestep": 25000, "total_timestep": 1000000, "num_train_steps": 1000000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 40, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-29-29", "timestamp": 1652819369, "time_this_iter_s": 214.71518349647522, "time_total_s": 10230.058599710464, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 10230.058599710464, "timesteps_since_restore": 0, "iterations_since_restore": 40, "trial_id": "31acc_00000"}
{"alpha": 0.26050272583961487, "policy": {"shifts-mean": -0.12494761496782303, "shifts-std": 1.4005191326141357, "shifts-max": 4.469730377197266, "shifts-min": -2.940481662750244, "scales-mean": 0.43023261427879333, "scales-std": 0.1469658613204956, "scales-max": 1.9729077816009521, "scales-min": 0.0467737652361393, "entropy-mean": -5.806929111480713, "entropy-std": 3.5814216136932373, "actions-mean": -0.0828644335269928, "actions-std": 0.7651903629302979, "actions-min": -0.9981891512870789, "actions-max": 0.9999292492866516}, "evaluation": {"episode-reward-mean": 10924.916015625, "episode-reward-min": 10924.916015625, "episode-reward-max": 10924.916015625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7325470835603302, "reward_run-last-mean": 11.83079974552129, "reward_run-mean-mean": 11.286204444458528, "reward_run-median-mean": 11.702968657033352, "reward_run-range-mean": 14.58528747051717, "reward_ctrl-first-mean": -0.330751895904541, "reward_ctrl-last-mean": -0.36380810737609864, "reward_ctrl-mean-mean": -0.3612881629228592, "reward_ctrl-median-mean": -0.356797206401825, "reward_ctrl-range-mean": 0.4712376296520233}}, "training": {"episode-reward-mean": 10991.021027080958, "episode-reward-min": 10807.130348468923, "episode-reward-max": 11267.99452388977, "episode-reward-std": 162.75609436048617, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4239444205938086, "reward_run-last-mean": 11.78083910060218, "reward_run-mean-mean": 11.350811888453311, "reward_run-median-mean": 11.91132915168403, "reward_run-range-mean": 14.949155102170343, "reward_ctrl-first-mean": -0.3638068318367005, "reward_ctrl-last-mean": -0.3656049823760986, "reward_ctrl-mean-mean": -0.35979086137235167, "reward_ctrl-median-mean": -0.3539651465415955, "reward_ctrl-range-mean": 0.4650131565332414}}, "update": {"Q_value-mean": 852.5311889648438, "Q_loss-mean": 10.709284782409668, "policy_loss-mean": -852.7494506835938, "alpha": 0.25445953011512756, "alpha_loss-mean": -0.0002714360598474741}, "times": {"epoch_before_hook": 3.958801971748471e-05, "timestep_before_hook": 0.08292799291666597, "sample": 14.589814627513988, "train": 198.91302064058254, "timestep_after_hook": 0.03537061286624521, "training_paths": 0.07591693801805377, "evaluation_paths": 0.4975491270015482, "training_metrics": 0.0016206009895540774, "evaluation_metrics": 0.0004098770150449127, "epoch_after_hook": 1.6370031516999006e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11426.926294659708, "last-path-return": 11104.493210666657, "episodes": 1035, "total-samples": 1035000}, "epoch": 40, "timestep": 25000, "total_timestep": 1025000, "num_train_steps": 1025000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 41, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-33-04", "timestamp": 1652819584, "time_this_iter_s": 214.59505105018616, "time_total_s": 10444.65365076065, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 10444.65365076065, "timesteps_since_restore": 0, "iterations_since_restore": 41, "trial_id": "31acc_00000"}
{"alpha": 0.2619117200374603, "policy": {"shifts-mean": -0.12407169491052628, "shifts-std": 1.479229211807251, "shifts-max": 10.66416072845459, "shifts-min": -7.44043493270874, "scales-mean": 0.4389190673828125, "scales-std": 0.14613713324069977, "scales-max": 1.6390721797943115, "scales-min": 0.047420985996723175, "entropy-mean": -6.201725006103516, "entropy-std": 4.964018821716309, "actions-mean": -0.09164601564407349, "actions-std": 0.7772794961929321, "actions-min": -0.9999997019767761, "actions-max": 1.0}, "evaluation": {"episode-reward-mean": 11563.3203125, "episode-reward-min": 11563.3203125, "episode-reward-max": 11563.3203125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6782538302866701, "reward_run-last-mean": 11.865381164086557, "reward_run-mean-mean": 11.923049571532571, "reward_run-median-mean": 12.48442083882594, "reward_run-range-mean": 16.046262958233033, "reward_ctrl-first-mean": -0.2792853832244873, "reward_ctrl-last-mean": -0.4546829700469971, "reward_ctrl-mean-mean": -0.35972878439426426, "reward_ctrl-median-mean": -0.35651048421859743, "reward_ctrl-range-mean": 0.4473854064941406}}, "training": {"episode-reward-mean": 11091.401712942143, "episode-reward-min": 10545.554609406741, "episode-reward-max": 11368.721045081535, "episode-reward-std": 208.8338004886391, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4463351361372042, "reward_run-last-mean": 12.467533240805551, "reward_run-mean-mean": 11.453571165161748, "reward_run-median-mean": 12.046327452280124, "reward_run-range-mean": 15.162528207039959, "reward_ctrl-first-mean": -0.2842336046695709, "reward_ctrl-last-mean": -0.3442195844650269, "reward_ctrl-mean-mean": -0.3621694522196055, "reward_ctrl-median-mean": -0.35622459530830386, "reward_ctrl-range-mean": 0.4622020286321641}}, "update": {"Q_value-mean": 865.8395385742188, "Q_loss-mean": 10.84577751159668, "policy_loss-mean": -865.9443359375, "alpha": 0.2580304741859436, "alpha_loss-mean": -1.9788074496318586e-05}, "times": {"epoch_before_hook": 3.838801058009267e-05, "timestep_before_hook": 0.08247052118531428, "sample": 14.44399985531345, "train": 198.91763036631164, "timestep_after_hook": 0.03533937130123377, "training_paths": 0.07464291600626893, "evaluation_paths": 0.4948835209943354, "training_metrics": 0.001555525988806039, "evaluation_metrics": 0.0004174379864707589, "epoch_after_hook": 1.8970167730003595e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11426.926294659708, "last-path-return": 11175.05912020461, "episodes": 1060, "total-samples": 1060000}, "epoch": 41, "timestep": 25000, "total_timestep": 1050000, "num_train_steps": 1050000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 42, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-36-39", "timestamp": 1652819799, "time_this_iter_s": 214.44842433929443, "time_total_s": 10659.102075099945, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 10659.102075099945, "timesteps_since_restore": 0, "iterations_since_restore": 42, "trial_id": "31acc_00000"}
{"alpha": 0.2580571472644806, "policy": {"shifts-mean": -0.12401499599218369, "shifts-std": 1.45124089717865, "shifts-max": 4.261814117431641, "shifts-min": -4.029851913452148, "scales-mean": 0.4355272948741913, "scales-std": 0.14095331728458405, "scales-max": 0.8137083053588867, "scales-min": 0.04778505116701126, "entropy-mean": -6.101694107055664, "entropy-std": 3.5926947593688965, "actions-mean": -0.07876568287611008, "actions-std": 0.7762560248374939, "actions-min": -0.9994966983795166, "actions-max": 0.9997113943099976}, "evaluation": {"episode-reward-mean": 11375.7109375, "episode-reward-min": 11375.7109375, "episode-reward-max": 11375.7109375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6458755057640356, "reward_run-last-mean": 11.785061888535893, "reward_run-mean-mean": 11.73258037887925, "reward_run-median-mean": 12.275958156112665, "reward_run-range-mean": 15.286955482273026, "reward_ctrl-first-mean": -0.32400724887847904, "reward_ctrl-last-mean": -0.23276853561401367, "reward_ctrl-mean-mean": -0.35686994541883466, "reward_ctrl-median-mean": -0.3525619983673096, "reward_ctrl-range-mean": 0.43274313211441046}}, "training": {"episode-reward-mean": 11197.15193584013, "episode-reward-min": 10874.146422097387, "episode-reward-max": 11389.67652646822, "episode-reward-std": 158.87190090206138, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.22329953950827192, "reward_run-last-mean": 11.627811636339175, "reward_run-mean-mean": 11.557563798439384, "reward_run-median-mean": 12.106026478775718, "reward_run-range-mean": 15.20942169618328, "reward_ctrl-first-mean": -0.2703273904323578, "reward_ctrl-last-mean": -0.3579831004142761, "reward_ctrl-mean-mean": -0.3604118625992537, "reward_ctrl-median-mean": -0.3562928175926208, "reward_ctrl-range-mean": 0.464864781498909}}, "update": {"Q_value-mean": 877.8911743164062, "Q_loss-mean": 10.723572731018066, "policy_loss-mean": -877.9135131835938, "alpha": 0.2588406801223755, "alpha_loss-mean": 0.00011686562356771901}, "times": {"epoch_before_hook": 3.9431004552170634e-05, "timestep_before_hook": 0.08195838739629835, "sample": 14.478679844003636, "train": 199.22974864428397, "timestep_after_hook": 0.03540234063984826, "training_paths": 0.0773651659837924, "evaluation_paths": 0.49606956500792876, "training_metrics": 0.001716715982183814, "evaluation_metrics": 0.00041693600360304117, "epoch_after_hook": 1.581996912136674e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11426.926294659708, "last-path-return": 11246.918272562687, "episodes": 1085, "total-samples": 1085000}, "epoch": 42, "timestep": 25000, "total_timestep": 1075000, "num_train_steps": 1075000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 43, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-40-13", "timestamp": 1652820013, "time_this_iter_s": 214.80000519752502, "time_total_s": 10873.90208029747, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 10873.90208029747, "timesteps_since_restore": 0, "iterations_since_restore": 43, "trial_id": "31acc_00000"}
{"alpha": 0.2560593783855438, "policy": {"shifts-mean": -0.15353620052337646, "shifts-std": 1.4116756916046143, "shifts-max": 3.0157222747802734, "shifts-min": -2.9515981674194336, "scales-mean": 0.4308299124240875, "scales-std": 0.1364137828350067, "scales-max": 0.8021596670150757, "scales-min": 0.04403696581721306, "entropy-mean": -5.813079357147217, "entropy-std": 3.431821584701538, "actions-mean": -0.0981394350528717, "actions-std": 0.7637456655502319, "actions-min": -0.9987055659294128, "actions-max": 0.9983646273612976}, "evaluation": {"episode-reward-mean": 11237.00390625, "episode-reward-min": 11237.00390625, "episode-reward-max": 11237.00390625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.9782094215307648, "reward_run-last-mean": 13.482452204177662, "reward_run-mean-mean": 11.59419196857772, "reward_run-median-mean": 12.2468826804932, "reward_run-range-mean": 15.519660680099756, "reward_ctrl-first-mean": -0.2810531616210938, "reward_ctrl-last-mean": -0.22416834831237795, "reward_ctrl-mean-mean": -0.3571875686764718, "reward_ctrl-median-mean": -0.3510175943374634, "reward_ctrl-range-mean": 0.47269308567047125}}, "training": {"episode-reward-mean": 11350.534414995782, "episode-reward-min": 11155.474787149873, "episode-reward-max": 11577.355815178675, "episode-reward-std": 121.70084369720564, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.3194885803331333, "reward_run-last-mean": 12.771914700072784, "reward_run-mean-mean": 11.708962270805708, "reward_run-median-mean": 12.242231177999251, "reward_run-range-mean": 15.247866290731935, "reward_ctrl-first-mean": -0.327042920589447, "reward_ctrl-last-mean": -0.35958031415939334, "reward_ctrl-mean-mean": -0.3584278558099269, "reward_ctrl-median-mean": -0.3531257390975952, "reward_ctrl-range-mean": 0.44981249988079075}}, "update": {"Q_value-mean": 890.5699462890625, "Q_loss-mean": 10.43603515625, "policy_loss-mean": -890.5308227539062, "alpha": 0.2574262320995331, "alpha_loss-mean": 9.524683264316991e-05}, "times": {"epoch_before_hook": 3.598298644647002e-05, "timestep_before_hook": 0.08230089509743266, "sample": 14.52028751114267, "train": 198.91279424892855, "timestep_after_hook": 0.035423308290774, "training_paths": 0.07599875400774181, "evaluation_paths": 0.5285582309879828, "training_metrics": 0.0015667510160710663, "evaluation_metrics": 0.0004126479907426983, "epoch_after_hook": 1.5079858712852001e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11707.639923728755, "last-path-return": 11335.11785022602, "episodes": 1110, "total-samples": 1110000}, "epoch": 43, "timestep": 25000, "total_timestep": 1100000, "num_train_steps": 1100000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 44, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-43-48", "timestamp": 1652820228, "time_this_iter_s": 214.55436372756958, "time_total_s": 11088.45644402504, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 11088.45644402504, "timesteps_since_restore": 0, "iterations_since_restore": 44, "trial_id": "31acc_00000"}
{"alpha": 0.2598855197429657, "policy": {"shifts-mean": -0.1282549351453781, "shifts-std": 1.4521684646606445, "shifts-max": 3.2857840061187744, "shifts-min": -3.6810593605041504, "scales-mean": 0.4347918927669525, "scales-std": 0.14380638301372528, "scales-max": 0.928987979888916, "scales-min": 0.041488390415906906, "entropy-mean": -6.295383930206299, "entropy-std": 3.5878872871398926, "actions-mean": -0.07868077605962753, "actions-std": 0.7795325517654419, "actions-min": -0.9994017481803894, "actions-max": 0.9996485710144043}, "evaluation": {"episode-reward-mean": 11417.255859375, "episode-reward-min": 11417.255859375, "episode-reward-max": 11417.255859375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6521683020332288, "reward_run-last-mean": 12.825106717878043, "reward_run-mean-mean": 11.781915817861266, "reward_run-median-mean": 12.368356533092424, "reward_run-range-mean": 15.153879129015063, "reward_ctrl-first-mean": -0.3605879068374634, "reward_ctrl-last-mean": -0.3274133920669556, "reward_ctrl-mean-mean": -0.36466002917289736, "reward_ctrl-median-mean": -0.36193418502807617, "reward_ctrl-range-mean": 0.49968092441558837}}, "training": {"episode-reward-mean": 11454.301091217436, "episode-reward-min": 11234.387590325345, "episode-reward-max": 11611.016231965015, "episode-reward-std": 109.50779805040521, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.38548117883796257, "reward_run-last-mean": 12.79515655396176, "reward_run-mean-mean": 11.815157729659713, "reward_run-median-mean": 12.398307029465997, "reward_run-range-mean": 15.373412385420215, "reward_ctrl-first-mean": -0.3574267745018006, "reward_ctrl-last-mean": -0.4214597010612488, "reward_ctrl-mean-mean": -0.36085663844227794, "reward_ctrl-median-mean": -0.3556941735744477, "reward_ctrl-range-mean": 0.4441366422176361}}, "update": {"Q_value-mean": 902.6152954101562, "Q_loss-mean": 10.438309669494629, "policy_loss-mean": -902.5401611328125, "alpha": 0.25836247205734253, "alpha_loss-mean": -0.00012965372297912836}, "times": {"epoch_before_hook": 2.794401370920241e-05, "timestep_before_hook": 0.08173201227327809, "sample": 14.508713851857465, "train": 198.75040544601507, "timestep_after_hook": 0.03548549785045907, "training_paths": 0.07816439200541936, "evaluation_paths": 0.49511220600106753, "training_metrics": 0.0015670119901187718, "evaluation_metrics": 0.0004030319978483021, "epoch_after_hook": 1.601001713424921e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11707.639923728755, "last-path-return": 11369.171038539627, "episodes": 1135, "total-samples": 1135000}, "epoch": 44, "timestep": 25000, "total_timestep": 1125000, "num_train_steps": 1125000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 45, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-47-22", "timestamp": 1652820442, "time_this_iter_s": 214.34852385520935, "time_total_s": 11302.804967880249, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 11302.804967880249, "timesteps_since_restore": 0, "iterations_since_restore": 45, "trial_id": "31acc_00000"}
{"alpha": 0.2584758698940277, "policy": {"shifts-mean": -0.018140247091650963, "shifts-std": 1.4138981103897095, "shifts-max": 3.584653615951538, "shifts-min": -3.132967948913574, "scales-mean": 0.4274492561817169, "scales-std": 0.14798317849636078, "scales-max": 0.8248616456985474, "scales-min": 0.04546615108847618, "entropy-mean": -5.876923561096191, "entropy-std": 3.485153913497925, "actions-mean": -0.03269132599234581, "actions-std": 0.7689033150672913, "actions-min": -0.9997230768203735, "actions-max": 0.9997419118881226}, "evaluation": {"episode-reward-mean": 11442.9384765625, "episode-reward-min": 11442.9384765625, "episode-reward-max": 11442.9384765625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.24628630578309912, "reward_run-last-mean": 12.702900470037548, "reward_run-mean-mean": 11.800394126498478, "reward_run-median-mean": 12.348647518317648, "reward_run-range-mean": 15.116241873925249, "reward_ctrl-first-mean": -0.3112751245498657, "reward_ctrl-last-mean": -0.3570870637893677, "reward_ctrl-mean-mean": -0.35745618914961813, "reward_ctrl-median-mean": -0.3528526544570923, "reward_ctrl-range-mean": 0.47805508375167854}}, "training": {"episode-reward-mean": 11488.55132597321, "episode-reward-min": 11329.996237246705, "episode-reward-max": 11642.40785952649, "episode-reward-std": 81.03926905461107, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5955029131581893, "reward_run-last-mean": 12.053454687655858, "reward_run-mean-mean": 11.848478185122843, "reward_run-median-mean": 12.381089473613315, "reward_run-range-mean": 15.368538835804213, "reward_ctrl-first-mean": -0.28551518380641944, "reward_ctrl-last-mean": -0.3757201218605042, "reward_ctrl-mean-mean": -0.35992685914963485, "reward_ctrl-median-mean": -0.355521754026413, "reward_ctrl-range-mean": 0.4746622988581657}}, "update": {"Q_value-mean": 913.6158447265625, "Q_loss-mean": 10.529730796813965, "policy_loss-mean": -913.5103149414062, "alpha": 0.2604694068431854, "alpha_loss-mean": 7.467499381164089e-05}, "times": {"epoch_before_hook": 3.145600203424692e-05, "timestep_before_hook": 0.08255774242570624, "sample": 14.602377358154627, "train": 198.89818573079538, "timestep_after_hook": 0.03556027339072898, "training_paths": 0.07572941898251884, "evaluation_paths": 0.498657767981058, "training_metrics": 0.0015946400235407054, "evaluation_metrics": 0.00040886399801820517, "epoch_after_hook": 1.6179983504116535e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11707.639923728755, "last-path-return": 11558.534363812154, "episodes": 1160, "total-samples": 1160000}, "epoch": 45, "timestep": 25000, "total_timestep": 1150000, "num_train_steps": 1150000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 46, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-50-57", "timestamp": 1652820657, "time_this_iter_s": 214.59457778930664, "time_total_s": 11517.399545669556, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 11517.399545669556, "timesteps_since_restore": 0, "iterations_since_restore": 46, "trial_id": "31acc_00000"}
{"alpha": 0.2606669068336487, "policy": {"shifts-mean": -0.12191972136497498, "shifts-std": 1.429007649421692, "shifts-max": 3.210221529006958, "shifts-min": -4.420228958129883, "scales-mean": 0.41968855261802673, "scales-std": 0.14604225754737854, "scales-max": 0.8384299278259277, "scales-min": 0.04122181609272957, "entropy-mean": -6.170092582702637, "entropy-std": 3.6956748962402344, "actions-mean": -0.08361165970563889, "actions-std": 0.7684648633003235, "actions-min": -0.9999244213104248, "actions-max": 0.999129593372345}, "evaluation": {"episode-reward-mean": 11781.544921875, "episode-reward-min": 11781.544921875, "episode-reward-max": 11781.544921875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5092970153323996, "reward_run-last-mean": 12.53809799014789, "reward_run-mean-mean": 12.14269051565055, "reward_run-median-mean": 12.675602552654368, "reward_run-range-mean": 15.582391713609146, "reward_ctrl-first-mean": -0.22514061927795412, "reward_ctrl-last-mean": -0.5462839126586915, "reward_ctrl-mean-mean": -0.36114509158134467, "reward_ctrl-median-mean": -0.35827093124389653, "reward_ctrl-range-mean": 0.43388140201568604}}, "training": {"episode-reward-mean": 11459.70549267987, "episode-reward-min": 11103.29069809354, "episode-reward-max": 11659.00744662021, "episode-reward-std": 163.09170273828593, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4236012925236915, "reward_run-last-mean": 12.673510755276311, "reward_run-mean-mean": 11.817806027527249, "reward_run-median-mean": 12.36531575388259, "reward_run-range-mean": 15.416282114214065, "reward_ctrl-first-mean": -0.26808768868446353, "reward_ctrl-last-mean": -0.3758725929260255, "reward_ctrl-mean-mean": -0.3581005348473788, "reward_ctrl-median-mean": -0.35230754256248475, "reward_ctrl-range-mean": 0.4585535031557083}}, "update": {"Q_value-mean": 923.4924926757812, "Q_loss-mean": 10.657280921936035, "policy_loss-mean": -923.3521728515625, "alpha": 0.26222965121269226, "alpha_loss-mean": -7.104608812369406e-05}, "times": {"epoch_before_hook": 2.987799234688282e-05, "timestep_before_hook": 0.07951740696444176, "sample": 14.576982041617157, "train": 198.27591650540126, "timestep_after_hook": 0.03458774447790347, "training_paths": 0.08061865300987847, "evaluation_paths": 0.5442209760076366, "training_metrics": 0.002658381999935955, "evaluation_metrics": 0.0004193419881630689, "epoch_after_hook": 1.567997969686985e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11786.164717442422, "last-path-return": 11637.821936706383, "episodes": 1185, "total-samples": 1185000}, "epoch": 46, "timestep": 25000, "total_timestep": 1175000, "num_train_steps": 1175000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 47, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-54-31", "timestamp": 1652820871, "time_this_iter_s": 213.98731684684753, "time_total_s": 11731.386862516403, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 11731.386862516403, "timesteps_since_restore": 0, "iterations_since_restore": 47, "trial_id": "31acc_00000"}
{"alpha": 0.26624056696891785, "policy": {"shifts-mean": -0.02820916660130024, "shifts-std": 1.425144076347351, "shifts-max": 3.589966058731079, "shifts-min": -3.582368850708008, "scales-mean": 0.427882581949234, "scales-std": 0.14334635436534882, "scales-max": 0.8250442147254944, "scales-min": 0.041907306760549545, "entropy-mean": -5.854467868804932, "entropy-std": 3.691054344177246, "actions-mean": -0.024469083175063133, "actions-std": 0.7713674902915955, "actions-min": -0.9991762042045593, "actions-max": 0.9988132119178772}, "evaluation": {"episode-reward-mean": 11622.7373046875, "episode-reward-min": 11622.7373046875, "episode-reward-max": 11622.7373046875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8176227267412342, "reward_run-last-mean": 14.211403589144993, "reward_run-mean-mean": 11.972916660536123, "reward_run-median-mean": 12.701061217572374, "reward_run-range-mean": 16.02706743779632, "reward_ctrl-first-mean": -0.4342045307159424, "reward_ctrl-last-mean": -0.30229732990264896, "reward_ctrl-mean-mean": -0.350179221367836, "reward_ctrl-median-mean": -0.3482341885566712, "reward_ctrl-range-mean": 0.4347417712211609}}, "training": {"episode-reward-mean": 11578.347577712564, "episode-reward-min": 11323.788009122618, "episode-reward-max": 11813.324296866704, "episode-reward-std": 148.46424318541665, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6286954398992268, "reward_run-last-mean": 12.856056633257367, "reward_run-mean-mean": 11.935687699610023, "reward_run-median-mean": 12.537405070301602, "reward_run-range-mean": 15.65942565716125, "reward_ctrl-first-mean": -0.3060415756702423, "reward_ctrl-last-mean": -0.3717523193359375, "reward_ctrl-mean-mean": -0.3573401218974591, "reward_ctrl-median-mean": -0.3526280021667481, "reward_ctrl-range-mean": 0.46830217301845545}}, "update": {"Q_value-mean": 933.095703125, "Q_loss-mean": 10.893781661987305, "policy_loss-mean": -932.9309692382812, "alpha": 0.26353567838668823, "alpha_loss-mean": -0.00018313083273824304}, "times": {"epoch_before_hook": 4.425999941304326e-05, "timestep_before_hook": 0.0786836113256868, "sample": 14.527276802924462, "train": 197.6677998159721, "timestep_after_hook": 0.03412435558857396, "training_paths": 0.07544849999248981, "evaluation_paths": 0.4953835370251909, "training_metrics": 0.0015489629877265543, "evaluation_metrics": 0.0004092159797437489, "epoch_after_hook": 1.660024281591177e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11903.703240853383, "last-path-return": 11484.274975566903, "episodes": 1210, "total-samples": 1210000}, "epoch": 47, "timestep": 25000, "total_timestep": 1200000, "num_train_steps": 1200000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 48, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_21-58-04", "timestamp": 1652821084, "time_this_iter_s": 213.27309036254883, "time_total_s": 11944.659952878952, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 11944.659952878952, "timesteps_since_restore": 0, "iterations_since_restore": 48, "trial_id": "31acc_00000"}
{"alpha": 0.27317944169044495, "policy": {"shifts-mean": -0.04947808012366295, "shifts-std": 1.4193757772445679, "shifts-max": 3.249654531478882, "shifts-min": -2.9209208488464355, "scales-mean": 0.42695775628089905, "scales-std": 0.1469372659921646, "scales-max": 0.831866443157196, "scales-min": 0.03993891179561615, "entropy-mean": -5.766892910003662, "entropy-std": 3.978177070617676, "actions-mean": -0.03883789852261543, "actions-std": 0.7659714818000793, "actions-min": -0.9981748461723328, "actions-max": 0.9992084503173828}, "evaluation": {"episode-reward-mean": 11577.6416015625, "episode-reward-min": 11577.6416015625, "episode-reward-max": 11577.6416015625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6282547708763759, "reward_run-last-mean": 12.645786434063666, "reward_run-mean-mean": 11.932557968624165, "reward_run-median-mean": 12.430587876371249, "reward_run-range-mean": 15.63982969873414, "reward_ctrl-first-mean": -0.2577540874481201, "reward_ctrl-last-mean": -0.32848942279815674, "reward_ctrl-mean-mean": -0.3549160762071609, "reward_ctrl-median-mean": -0.3527495861053467, "reward_ctrl-range-mean": 0.4581409096717835}}, "training": {"episode-reward-mean": 11193.807342316111, "episode-reward-min": 7200.711070598743, "episode-reward-max": 11883.47165424539, "episode-reward-std": 1337.817272372112, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6612279012803978, "reward_run-last-mean": 11.310494238144202, "reward_run-mean-mean": 11.551436351802252, "reward_run-median-mean": 12.447593207088069, "reward_run-range-mean": 15.912739879976144, "reward_ctrl-first-mean": -0.3244038093090058, "reward_ctrl-last-mean": -0.3289768600463867, "reward_ctrl-mean-mean": -0.35762900948613885, "reward_ctrl-median-mean": -0.35257291436195376, "reward_ctrl-range-mean": 0.468821448981762}}, "update": {"Q_value-mean": 942.504638671875, "Q_loss-mean": 11.08984661102295, "policy_loss-mean": -942.3178100585938, "alpha": 0.26520851254463196, "alpha_loss-mean": -0.00023705585044808686}, "times": {"epoch_before_hook": 3.313401248306036e-05, "timestep_before_hook": 0.08512648119358346, "sample": 15.568220133107388, "train": 202.07769653576543, "timestep_after_hook": 0.03737093915697187, "training_paths": 0.42164652998326346, "evaluation_paths": 0.49628850098815747, "training_metrics": 0.0014834530011285096, "evaluation_metrics": 0.0004122370155528188, "epoch_after_hook": 1.5310070011764765e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 11972.202213876813, "last-path-return": 11716.627681859942, "episodes": 1235, "total-samples": 1235000}, "epoch": 48, "timestep": 25000, "total_timestep": 1225000, "num_train_steps": 1225000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 49, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-01-44", "timestamp": 1652821304, "time_this_iter_s": 219.11366534233093, "time_total_s": 12163.773618221283, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 12163.773618221283, "timesteps_since_restore": 0, "iterations_since_restore": 49, "trial_id": "31acc_00000"}
{"alpha": 0.2709236443042755, "policy": {"shifts-mean": -0.11364739388227463, "shifts-std": 1.4071037769317627, "shifts-max": 3.1609535217285156, "shifts-min": -3.009783983230591, "scales-mean": 0.42048513889312744, "scales-std": 0.15049618482589722, "scales-max": 0.84351646900177, "scales-min": 0.03960232064127922, "entropy-mean": -5.910960674285889, "entropy-std": 3.6348013877868652, "actions-mean": -0.07612746953964233, "actions-std": 0.7700865864753723, "actions-min": -0.9983056783676147, "actions-max": 0.99891597032547}, "evaluation": {"episode-reward-mean": 11991.3984375, "episode-reward-min": 11991.3984375, "episode-reward-max": 11991.3984375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6618159878568827, "reward_run-last-mean": 13.484424062658036, "reward_run-mean-mean": 12.347239463156498, "reward_run-median-mean": 12.915594394597747, "reward_run-range-mean": 15.676500943299473, "reward_ctrl-first-mean": -0.20590751171112062, "reward_ctrl-last-mean": -0.3303144931793213, "reward_ctrl-mean-mean": -0.35584098707437517, "reward_ctrl-median-mean": -0.3528442978858948, "reward_ctrl-range-mean": 0.467647385597229}}, "training": {"episode-reward-mean": 11775.312828859507, "episode-reward-min": 11419.589918681842, "episode-reward-max": 12007.175839906582, "episode-reward-std": 188.6202397590863, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7391187794688694, "reward_run-last-mean": 12.984461348342847, "reward_run-mean-mean": 12.129829201643883, "reward_run-median-mean": 12.72397601214604, "reward_run-range-mean": 15.827696790741118, "reward_ctrl-first-mean": -0.3274515497684479, "reward_ctrl-last-mean": -0.3236855387687683, "reward_ctrl-mean-mean": -0.35451637278437614, "reward_ctrl-median-mean": -0.35045624494552613, "reward_ctrl-range-mean": 0.46421609163284305}}, "update": {"Q_value-mean": 950.0888671875, "Q_loss-mean": 11.501886367797852, "policy_loss-mean": -949.8733520507812, "alpha": 0.26789671182632446, "alpha_loss-mean": 7.299616117961705e-05}, "times": {"epoch_before_hook": 3.1664996640756726e-05, "timestep_before_hook": 0.08688478960539214, "sample": 15.136680939001963, "train": 201.9922413530876, "timestep_after_hook": 0.03696463842061348, "training_paths": 0.08060101300361566, "evaluation_paths": 0.5483353020099457, "training_metrics": 0.0015447720070369542, "evaluation_metrics": 0.0004084190004505217, "epoch_after_hook": 1.535983756184578e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12007.175839906591, "last-path-return": 11928.611965231225, "episodes": 1260, "total-samples": 1260000}, "epoch": 49, "timestep": 25000, "total_timestep": 1250000, "num_train_steps": 1250000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 50, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-05-22", "timestamp": 1652821522, "time_this_iter_s": 218.306232213974, "time_total_s": 12382.079850435257, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 12382.079850435257, "timesteps_since_restore": 0, "iterations_since_restore": 50, "trial_id": "31acc_00000"}
{"alpha": 0.27481427788734436, "policy": {"shifts-mean": -0.1150444746017456, "shifts-std": 1.4057209491729736, "shifts-max": 4.714439868927002, "shifts-min": -3.059542655944824, "scales-mean": 0.42369166016578674, "scales-std": 0.15135321021080017, "scales-max": 1.1822975873947144, "scales-min": 0.03570735454559326, "entropy-mean": -5.772224426269531, "entropy-std": 3.544969320297241, "actions-mean": -0.07094067335128784, "actions-std": 0.7651678919792175, "actions-min": -0.9985973834991455, "actions-max": 0.9999856352806091}, "evaluation": {"episode-reward-mean": 12273.62890625, "episode-reward-min": 12273.62890625, "episode-reward-max": 12273.62890625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7375856030682071, "reward_run-last-mean": 13.244695454886823, "reward_run-mean-mean": 12.627078624492299, "reward_run-median-mean": 13.174151146529312, "reward_run-range-mean": 16.056401735315756, "reward_ctrl-first-mean": -0.46265783309936526, "reward_ctrl-last-mean": -0.4705066680908203, "reward_ctrl-mean-mean": -0.353449183344841, "reward_ctrl-median-mean": -0.34956836700439453, "reward_ctrl-range-mean": 0.4539222717285157}}, "training": {"episode-reward-mean": 11931.677895006764, "episode-reward-min": 11764.037333491335, "episode-reward-max": 12200.894727507744, "episode-reward-std": 132.85695156546544, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6162694534408232, "reward_run-last-mean": 12.566015043576499, "reward_run-mean-mean": 12.286305233639109, "reward_run-median-mean": 12.877882651514284, "reward_run-range-mean": 15.867829882255327, "reward_ctrl-first-mean": -0.32352456092834475, "reward_ctrl-last-mean": -0.3345052099227905, "reward_ctrl-mean-mean": -0.3546273386323452, "reward_ctrl-median-mean": -0.34954128265380857, "reward_ctrl-range-mean": 0.44629523158073436}}, "update": {"Q_value-mean": 958.2430419921875, "Q_loss-mean": 11.585989952087402, "policy_loss-mean": -958.019287109375, "alpha": 0.2705830931663513, "alpha_loss-mean": -9.248081187251955e-05}, "times": {"epoch_before_hook": 3.710499731823802e-05, "timestep_before_hook": 0.08200078489608131, "sample": 14.743276196386432, "train": 199.12220202031313, "timestep_after_hook": 0.03518287921906449, "training_paths": 0.07954649897874333, "evaluation_paths": 0.5371082649799064, "training_metrics": 0.0015194180014077574, "evaluation_metrics": 0.0004045089881401509, "epoch_after_hook": 2.0300212781876326e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12200.894727507739, "last-path-return": 11826.1313652641, "episodes": 1285, "total-samples": 1285000}, "epoch": 50, "timestep": 25000, "total_timestep": 1275000, "num_train_steps": 1275000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 51, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-08-57", "timestamp": 1652821737, "time_this_iter_s": 215.00345730781555, "time_total_s": 12597.083307743073, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 12597.083307743073, "timesteps_since_restore": 0, "iterations_since_restore": 51, "trial_id": "31acc_00000"}
{"alpha": 0.27485063672065735, "policy": {"shifts-mean": -0.1291683167219162, "shifts-std": 1.4124864339828491, "shifts-max": 3.6325056552886963, "shifts-min": -3.007375955581665, "scales-mean": 0.4324606955051422, "scales-std": 0.152299702167511, "scales-max": 1.124097228050232, "scales-min": 0.039757903665304184, "entropy-mean": -5.923018455505371, "entropy-std": 3.5777430534362793, "actions-mean": -0.0803183987736702, "actions-std": 0.7617443799972534, "actions-min": -0.9991578459739685, "actions-max": 0.9991766214370728}, "evaluation": {"episode-reward-mean": 12030.470703125, "episode-reward-min": 12030.470703125, "episode-reward-max": 12030.470703125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.870434878898137, "reward_run-last-mean": 15.307263203621915, "reward_run-mean-mean": 12.387077606052712, "reward_run-median-mean": 13.259737179189415, "reward_run-range-mean": 16.583823515996684, "reward_ctrl-first-mean": -0.38738431930541994, "reward_ctrl-last-mean": -0.3212159156799317, "reward_ctrl-mean-mean": -0.35660634697079663, "reward_ctrl-median-mean": -0.34891517162323005, "reward_ctrl-range-mean": 0.4948889553546906}}, "training": {"episode-reward-mean": 11973.051807731552, "episode-reward-min": 11749.737899586478, "episode-reward-max": 12197.84020855671, "episode-reward-std": 147.90623505209504, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7207668753053403, "reward_run-last-mean": 12.66400016785019, "reward_run-mean-mean": 12.33209144837932, "reward_run-median-mean": 12.94233284353247, "reward_run-range-mean": 16.109202309217768, "reward_ctrl-first-mean": -0.3347732043266296, "reward_ctrl-last-mean": -0.35554137706756594, "reward_ctrl-mean-mean": -0.359039640647769, "reward_ctrl-median-mean": -0.35304998874664306, "reward_ctrl-range-mean": 0.4636952298879624}}, "update": {"Q_value-mean": 967.3607177734375, "Q_loss-mean": 12.109183311462402, "policy_loss-mean": -967.1277465820312, "alpha": 0.27432069182395935, "alpha_loss-mean": 3.256248601246625e-05}, "times": {"epoch_before_hook": 4.569700104184449e-05, "timestep_before_hook": 0.09248479650705121, "sample": 15.953330796997761, "train": 205.69603909080615, "timestep_after_hook": 0.04055274146958254, "training_paths": 0.07856794801773503, "evaluation_paths": 0.5266383360140026, "training_metrics": 0.0015330349851865321, "evaluation_metrics": 0.00040870998054742813, "epoch_after_hook": 1.62801006808877e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12200.894727507739, "last-path-return": 11809.014098231011, "episodes": 1310, "total-samples": 1310000}, "epoch": 51, "timestep": 25000, "total_timestep": 1300000, "num_train_steps": 1300000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 52, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-12-40", "timestamp": 1652821960, "time_this_iter_s": 222.83942866325378, "time_total_s": 12819.922736406326, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 12819.922736406326, "timesteps_since_restore": 0, "iterations_since_restore": 52, "trial_id": "31acc_00000"}
{"alpha": 0.2776820659637451, "policy": {"shifts-mean": -0.13428346812725067, "shifts-std": 1.3853870630264282, "shifts-max": 3.6664390563964844, "shifts-min": -3.362483263015747, "scales-mean": 0.4329237937927246, "scales-std": 0.14288605749607086, "scales-max": 0.8786475658416748, "scales-min": 0.042810432612895966, "entropy-mean": -5.7967939376831055, "entropy-std": 3.4312596321105957, "actions-mean": -0.07620077580213547, "actions-std": 0.7630319595336914, "actions-min": -0.998537003993988, "actions-max": 0.999951183795929}, "evaluation": {"episode-reward-mean": 11910.4765625, "episode-reward-min": 11910.4765625, "episode-reward-max": 11910.4765625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.657468175157801, "reward_run-last-mean": 13.055720149998251, "reward_run-mean-mean": 12.27044165977235, "reward_run-median-mean": 12.842325980374198, "reward_run-range-mean": 16.142426554836295, "reward_ctrl-first-mean": -0.24702656269073486, "reward_ctrl-last-mean": -0.33478469848632814, "reward_ctrl-mean-mean": -0.3599650797843933, "reward_ctrl-median-mean": -0.3561354398727417, "reward_ctrl-range-mean": 0.4725651144981385}}, "training": {"episode-reward-mean": 12043.49014643924, "episode-reward-min": 11684.978275259713, "episode-reward-max": 12263.425351906495, "episode-reward-std": 185.72536196431042, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5090395471374171, "reward_run-last-mean": 13.422655588859016, "reward_run-mean-mean": 12.400994901309774, "reward_run-median-mean": 13.002012423103736, "reward_run-range-mean": 16.02388249845081, "reward_ctrl-first-mean": -0.3314397954940796, "reward_ctrl-last-mean": -0.2819267821311951, "reward_ctrl-mean-mean": -0.357504754870534, "reward_ctrl-median-mean": -0.35127517104148864, "reward_ctrl-range-mean": 0.4705153280496598}}, "update": {"Q_value-mean": 975.2354125976562, "Q_loss-mean": 12.333372116088867, "policy_loss-mean": -974.9779052734375, "alpha": 0.27674275636672974, "alpha_loss-mean": -7.308441126951948e-05}, "times": {"epoch_before_hook": 2.9943010304123163e-05, "timestep_before_hook": 0.08038368113921024, "sample": 14.456829910603119, "train": 197.77851296402514, "timestep_after_hook": 0.03431394218932837, "training_paths": 0.07900452398462221, "evaluation_paths": 0.4973885379731655, "training_metrics": 0.0015940610028337687, "evaluation_metrics": 0.00041627997416071594, "epoch_after_hook": 1.6929989214986563e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12394.13800167813, "last-path-return": 12260.624527719872, "episodes": 1335, "total-samples": 1335000}, "epoch": 52, "timestep": 25000, "total_timestep": 1325000, "num_train_steps": 1325000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 53, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-16-13", "timestamp": 1652822173, "time_this_iter_s": 213.3223602771759, "time_total_s": 13033.245096683502, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 13033.245096683502, "timesteps_since_restore": 0, "iterations_since_restore": 53, "trial_id": "31acc_00000"}
{"alpha": 0.27221497893333435, "policy": {"shifts-mean": -0.07370505481958389, "shifts-std": 1.4574205875396729, "shifts-max": 4.042789459228516, "shifts-min": -3.4121928215026855, "scales-mean": 0.43410900235176086, "scales-std": 0.1547478288412094, "scales-max": 0.8422871232032776, "scales-min": 0.03461045026779175, "entropy-mean": -6.336741924285889, "entropy-std": 3.5445828437805176, "actions-mean": -0.063435398042202, "actions-std": 0.7754952907562256, "actions-min": -0.9989693760871887, "actions-max": 0.9995597004890442}, "evaluation": {"episode-reward-mean": 12117.99609375, "episode-reward-min": 12117.99609375, "episode-reward-max": 12117.99609375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4655155541748515, "reward_run-last-mean": 13.391873724422112, "reward_run-mean-mean": 12.476201843087042, "reward_run-median-mean": 13.140051806345241, "reward_run-range-mean": 16.494581655987474, "reward_ctrl-first-mean": -0.3049151659011841, "reward_ctrl-last-mean": -0.2993788719177246, "reward_ctrl-mean-mean": -0.3582054712951184, "reward_ctrl-median-mean": -0.34797937870025636, "reward_ctrl-range-mean": 0.47663223147392275}}, "training": {"episode-reward-mean": 12190.075448480584, "episode-reward-min": 11944.679390549612, "episode-reward-max": 12342.617955862166, "episode-reward-std": 118.40836670986047, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.44328107753661977, "reward_run-last-mean": 13.10950639036605, "reward_run-mean-mean": 12.548648537217714, "reward_run-median-mean": 13.145734725428923, "reward_run-range-mean": 16.04294244198977, "reward_ctrl-first-mean": -0.32494420051574713, "reward_ctrl-last-mean": -0.3728841400146485, "reward_ctrl-mean-mean": -0.3585730887371302, "reward_ctrl-median-mean": -0.35347861528396607, "reward_ctrl-range-mean": 0.46669010698795327}}, "update": {"Q_value-mean": 982.880859375, "Q_loss-mean": 12.99065113067627, "policy_loss-mean": -982.6187744140625, "alpha": 0.2784852385520935, "alpha_loss-mean": 0.00018691210425458848}, "times": {"epoch_before_hook": 3.2912008464336395e-05, "timestep_before_hook": 0.09371638917946257, "sample": 16.04566098182113, "train": 206.55200290534412, "timestep_after_hook": 0.040693317248951644, "training_paths": 0.07692368101561442, "evaluation_paths": 0.4967508619884029, "training_metrics": 0.001561638986459002, "evaluation_metrics": 0.0004147040017414838, "epoch_after_hook": 1.5929981600493193e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12464.617168915753, "last-path-return": 12194.955280252292, "episodes": 1360, "total-samples": 1360000}, "epoch": 53, "timestep": 25000, "total_timestep": 1350000, "num_train_steps": 1350000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 54, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-19-57", "timestamp": 1652822397, "time_this_iter_s": 223.76073718070984, "time_total_s": 13257.005833864212, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 13257.005833864212, "timesteps_since_restore": 0, "iterations_since_restore": 54, "trial_id": "31acc_00000"}
{"alpha": 0.2783542275428772, "policy": {"shifts-mean": -0.08129341155290604, "shifts-std": 1.4043673276901245, "shifts-max": 3.210162401199341, "shifts-min": -2.7620017528533936, "scales-mean": 0.42816033959388733, "scales-std": 0.15451589226722717, "scales-max": 0.9488092660903931, "scales-min": 0.03534591943025589, "entropy-mean": -5.973868370056152, "entropy-std": 3.597461462020874, "actions-mean": -0.04821496084332466, "actions-std": 0.7655888795852661, "actions-min": -0.9986218810081482, "actions-max": 0.9997000098228455}, "evaluation": {"episode-reward-mean": 12437.537109375, "episode-reward-min": 12437.537109375, "episode-reward-max": 12437.537109375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.46176885921727334, "reward_run-last-mean": 14.957842158962649, "reward_run-mean-mean": 12.786218154431346, "reward_run-median-mean": 13.317799696099257, "reward_run-range-mean": 16.110969772097164, "reward_ctrl-first-mean": -0.33107273578643803, "reward_ctrl-last-mean": -0.2613349199295044, "reward_ctrl-mean-mean": -0.3486809751927853, "reward_ctrl-median-mean": -0.3424809813499451, "reward_ctrl-range-mean": 0.4853609323501587}}, "training": {"episode-reward-mean": 12243.74526468375, "episode-reward-min": 12153.034139318966, "episode-reward-max": 12334.60185251158, "episode-reward-std": 69.19665806521273, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.73158533049969, "reward_run-last-mean": 13.525593042766332, "reward_run-mean-mean": 12.602280449675707, "reward_run-median-mean": 13.21097540196412, "reward_run-range-mean": 16.377998725645863, "reward_ctrl-first-mean": -0.33212476968765264, "reward_ctrl-last-mean": -0.34977288007736207, "reward_ctrl-mean-mean": -0.3585351849919558, "reward_ctrl-median-mean": -0.3546365284919739, "reward_ctrl-range-mean": 0.4716478383541108}}, "update": {"Q_value-mean": 991.2542114257812, "Q_loss-mean": 13.086457252502441, "policy_loss-mean": -990.9793701171875, "alpha": 0.28050461411476135, "alpha_loss-mean": -0.00016238422540482134}, "times": {"epoch_before_hook": 3.4554977901279926e-05, "timestep_before_hook": 0.09020350454375148, "sample": 15.614330455980962, "train": 204.5557082989544, "timestep_after_hook": 0.038966518332017586, "training_paths": 0.0792244509793818, "evaluation_paths": 0.5355324760021176, "training_metrics": 0.001606254983926192, "evaluation_metrics": 0.0004168259911239147, "epoch_after_hook": 1.9520230125635862e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12467.030045465342, "last-path-return": 12299.299105951784, "episodes": 1385, "total-samples": 1385000}, "epoch": 54, "timestep": 25000, "total_timestep": 1375000, "num_train_steps": 1375000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 55, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-23-38", "timestamp": 1652822618, "time_this_iter_s": 221.35414028167725, "time_total_s": 13478.35997414589, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 13478.35997414589, "timesteps_since_restore": 0, "iterations_since_restore": 55, "trial_id": "31acc_00000"}
{"alpha": 0.2874715030193329, "policy": {"shifts-mean": -0.07066772878170013, "shifts-std": 1.3710781335830688, "shifts-max": 2.924830913543701, "shifts-min": -3.0516583919525146, "scales-mean": 0.4231839179992676, "scales-std": 0.15525436401367188, "scales-max": 0.7749921679496765, "scales-min": 0.03320129215717316, "entropy-mean": -5.651468753814697, "entropy-std": 3.4348745346069336, "actions-mean": -0.04954390600323677, "actions-std": 0.7564761638641357, "actions-min": -0.9979667663574219, "actions-max": 0.9983731508255005}, "evaluation": {"episode-reward-mean": 12279.681640625, "episode-reward-min": 12279.681640625, "episode-reward-max": 12279.681640625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5325904763460154, "reward_run-last-mean": 15.113158908914102, "reward_run-mean-mean": 12.63524751947727, "reward_run-median-mean": 13.39818158567084, "reward_run-range-mean": 16.395450372015592, "reward_ctrl-first-mean": -0.3419516563415528, "reward_ctrl-last-mean": -0.19671447277069093, "reward_ctrl-mean-mean": -0.3555660666823387, "reward_ctrl-median-mean": -0.35018031597137456, "reward_ctrl-range-mean": 0.4766652762889862}}, "training": {"episode-reward-mean": 12362.548153879869, "episode-reward-min": 11937.068613793697, "episode-reward-max": 12610.002819023208, "episode-reward-std": 186.2891480808798, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5468163847530829, "reward_run-last-mean": 13.933225515412005, "reward_run-mean-mean": 12.720426107209551, "reward_run-median-mean": 13.395781109910866, "reward_run-range-mean": 16.360034832081215, "reward_ctrl-first-mean": -0.26608320474624636, "reward_ctrl-last-mean": -0.35679479837417605, "reward_ctrl-mean-mean": -0.35787795332968236, "reward_ctrl-median-mean": -0.35130699872970583, "reward_ctrl-range-mean": 0.4642355495691299}}, "update": {"Q_value-mean": 998.413330078125, "Q_loss-mean": 13.056642532348633, "policy_loss-mean": -998.1133422851562, "alpha": 0.28478291630744934, "alpha_loss-mean": -0.00026705695199780166}, "times": {"epoch_before_hook": 3.68300243280828e-05, "timestep_before_hook": 0.08458585813059472, "sample": 15.228117129212478, "train": 201.02640209058882, "timestep_after_hook": 0.03690908715361729, "training_paths": 0.07839915400836617, "evaluation_paths": 0.5021884159941692, "training_metrics": 0.00158361200010404, "evaluation_metrics": 0.00040496099973097444, "epoch_after_hook": 1.5120021998882294e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12610.002819023193, "last-path-return": 12213.855267548784, "episodes": 1410, "total-samples": 1410000}, "epoch": 55, "timestep": 25000, "total_timestep": 1400000, "num_train_steps": 1400000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 56, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-27-16", "timestamp": 1652822836, "time_this_iter_s": 217.3766791820526, "time_total_s": 13695.736653327942, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 13695.736653327942, "timesteps_since_restore": 0, "iterations_since_restore": 56, "trial_id": "31acc_00000"}
{"alpha": 0.29347696900367737, "policy": {"shifts-mean": -0.147874116897583, "shifts-std": 1.3804155588150024, "shifts-max": 3.0967276096343994, "shifts-min": -3.255584955215454, "scales-mean": 0.4205683767795563, "scales-std": 0.15038876235485077, "scales-max": 0.8067720532417297, "scales-min": 0.035619478672742844, "entropy-mean": -5.933408737182617, "entropy-std": 3.4278857707977295, "actions-mean": -0.09239683300256729, "actions-std": 0.7576768398284912, "actions-min": -0.9980716109275818, "actions-max": 0.9995096325874329}, "evaluation": {"episode-reward-mean": 12196.91796875, "episode-reward-min": 12196.91796875, "episode-reward-max": 12196.91796875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6846112071594213, "reward_run-last-mean": 12.937142541918547, "reward_run-mean-mean": 12.56257614034095, "reward_run-median-mean": 13.305479438795373, "reward_run-range-mean": 16.718956119113844, "reward_ctrl-first-mean": -0.263039231300354, "reward_ctrl-last-mean": -0.3775903463363648, "reward_ctrl-mean-mean": -0.3656582300305366, "reward_ctrl-median-mean": -0.3618847131729126, "reward_ctrl-range-mean": 0.4526706337928772}}, "training": {"episode-reward-mean": 12491.054792177452, "episode-reward-min": 12208.786058887927, "episode-reward-max": 12667.829489029162, "episode-reward-std": 131.43085253913, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.426029139475149, "reward_run-last-mean": 13.666068562846249, "reward_run-mean-mean": 12.853184137245785, "reward_run-median-mean": 13.494447062137079, "reward_run-range-mean": 16.326630081463442, "reward_ctrl-first-mean": -0.31103978633880613, "reward_ctrl-last-mean": -0.33262213587760925, "reward_ctrl-mean-mean": -0.3621293450683355, "reward_ctrl-median-mean": -0.3573250997066498, "reward_ctrl-range-mean": 0.46935275971889495}}, "update": {"Q_value-mean": 1006.04296875, "Q_loss-mean": 13.34925651550293, "policy_loss-mean": -1005.7185668945312, "alpha": 0.2904396951198578, "alpha_loss-mean": -0.0002203396725235507}, "times": {"epoch_before_hook": 3.710400778800249e-05, "timestep_before_hook": 0.09072136922623031, "sample": 15.844102978677256, "train": 205.40131021421985, "timestep_after_hook": 0.04017529706470668, "training_paths": 0.07566070900065824, "evaluation_paths": 0.4987300119828433, "training_metrics": 0.0016377579886466265, "evaluation_metrics": 0.00042685100925154984, "epoch_after_hook": 1.5620025806128979e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12689.88149806782, "last-path-return": 12667.829489029167, "episodes": 1435, "total-samples": 1435000}, "epoch": 56, "timestep": 25000, "total_timestep": 1425000, "num_train_steps": 1425000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 57, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-30-58", "timestamp": 1652823058, "time_this_iter_s": 222.40182757377625, "time_total_s": 13918.138480901718, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 13918.138480901718, "timesteps_since_restore": 0, "iterations_since_restore": 57, "trial_id": "31acc_00000"}
{"alpha": 0.29218119382858276, "policy": {"shifts-mean": -0.09175160527229309, "shifts-std": 1.3944382667541504, "shifts-max": 3.2664730548858643, "shifts-min": -2.637820243835449, "scales-mean": 0.4283849000930786, "scales-std": 0.14557360112667084, "scales-max": 0.9093230962753296, "scales-min": 0.036338306963443756, "entropy-mean": -5.766373634338379, "entropy-std": 3.4663703441619873, "actions-mean": -0.05933861434459686, "actions-std": 0.7679651379585266, "actions-min": -0.9984597563743591, "actions-max": 0.9971417188644409}, "evaluation": {"episode-reward-mean": 12722.77734375, "episode-reward-min": 12722.77734375, "episode-reward-max": 12722.77734375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7403607116024031, "reward_run-last-mean": 13.653441702069813, "reward_run-mean-mean": 13.086617014771042, "reward_run-median-mean": 13.716369903858663, "reward_run-range-mean": 16.778614449507085, "reward_ctrl-first-mean": -0.384726619720459, "reward_ctrl-last-mean": -0.5033568382263184, "reward_ctrl-mean-mean": -0.36383978486061097, "reward_ctrl-median-mean": -0.35970160961151126, "reward_ctrl-range-mean": 0.4447062015533447}}, "training": {"episode-reward-mean": 12565.821501754868, "episode-reward-min": 12403.17169968058, "episode-reward-max": 12785.136161775703, "episode-reward-std": 115.88966545470552, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5825915800296941, "reward_run-last-mean": 13.585878251891245, "reward_run-mean-mean": 12.926249681623329, "reward_run-median-mean": 13.57648185231082, "reward_run-range-mean": 16.632338215204296, "reward_ctrl-first-mean": -0.33655560255050665, "reward_ctrl-last-mean": -0.3249318766593933, "reward_ctrl-mean-mean": -0.3604281798684597, "reward_ctrl-median-mean": -0.3555765533447265, "reward_ctrl-range-mean": 0.47607828795909873}}, "update": {"Q_value-mean": 1012.4405517578125, "Q_loss-mean": 13.435355186462402, "policy_loss-mean": -1012.0899047851562, "alpha": 0.2954042851924896, "alpha_loss-mean": 7.260910206241533e-05}, "times": {"epoch_before_hook": 3.423498128540814e-05, "timestep_before_hook": 0.08566477464046329, "sample": 15.199886246031383, "train": 201.71387903398136, "timestep_after_hook": 0.03735887253424153, "training_paths": 0.0799278499907814, "evaluation_paths": 0.49952194301295094, "training_metrics": 0.0015596160083077848, "evaluation_metrics": 0.0004060259961988777, "epoch_after_hook": 1.487991539761424e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12812.905813201955, "last-path-return": 12477.589812135036, "episodes": 1460, "total-samples": 1460000}, "epoch": 57, "timestep": 25000, "total_timestep": 1450000, "num_train_steps": 1450000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 58, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-34-36", "timestamp": 1652823276, "time_this_iter_s": 218.038831949234, "time_total_s": 14136.177312850952, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 14136.177312850952, "timesteps_since_restore": 0, "iterations_since_restore": 58, "trial_id": "31acc_00000"}
{"alpha": 0.2911493182182312, "policy": {"shifts-mean": -0.15404333174228668, "shifts-std": 1.4176377058029175, "shifts-max": 3.8649353981018066, "shifts-min": -3.409151554107666, "scales-mean": 0.4214373528957367, "scales-std": 0.1450759321451187, "scales-max": 1.0118533372879028, "scales-min": 0.030693072825670242, "entropy-mean": -6.224827766418457, "entropy-std": 3.9912445545196533, "actions-mean": -0.09011626243591309, "actions-std": 0.7632057070732117, "actions-min": -0.9992619752883911, "actions-max": 0.9999843835830688}, "evaluation": {"episode-reward-mean": 13090.685546875, "episode-reward-min": 13090.685546875, "episode-reward-max": 13090.685546875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8601281458183061, "reward_run-last-mean": 14.681468814642358, "reward_run-mean-mean": 13.449503133423672, "reward_run-median-mean": 14.015952905711515, "reward_run-range-mean": 16.69207726831947, "reward_ctrl-first-mean": -0.34980297088623047, "reward_ctrl-last-mean": -0.32011084556579594, "reward_ctrl-mean-mean": -0.3588178847014904, "reward_ctrl-median-mean": -0.3564143180847168, "reward_ctrl-range-mean": 0.4733374178409577}}, "training": {"episode-reward-mean": 12664.06990846505, "episode-reward-min": 12439.02048212495, "episode-reward-max": 12831.082272505077, "episode-reward-std": 113.1775652121887, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6677779601346692, "reward_run-last-mean": 14.229093747985871, "reward_run-mean-mean": 13.023702444636722, "reward_run-median-mean": 13.707086422741412, "reward_run-range-mean": 16.620547960310304, "reward_ctrl-first-mean": -0.28850770711898804, "reward_ctrl-last-mean": -0.300396500825882, "reward_ctrl-mean-mean": -0.3596325361716748, "reward_ctrl-median-mean": -0.3569346690177918, "reward_ctrl-range-mean": 0.4634056758880615}}, "update": {"Q_value-mean": 1020.5029296875, "Q_loss-mean": 13.594483375549316, "policy_loss-mean": -1020.1442260742188, "alpha": 0.29860904812812805, "alpha_loss-mean": 4.7484303649980575e-05}, "times": {"epoch_before_hook": 3.870099317282438e-05, "timestep_before_hook": 0.0860368381254375, "sample": 15.70803239979432, "train": 202.55654410927673, "timestep_after_hook": 0.03796139746555127, "training_paths": 0.18618234500172548, "evaluation_paths": 0.5005242330080364, "training_metrics": 0.036978917982196435, "evaluation_metrics": 0.02304214399191551, "epoch_after_hook": 2.174987457692623e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 12946.18319430809, "last-path-return": 12574.539406329557, "episodes": 1485, "total-samples": 1485000}, "epoch": 58, "timestep": 25000, "total_timestep": 1475000, "num_train_steps": 1475000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 59, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-38-16", "timestamp": 1652823496, "time_this_iter_s": 219.5810432434082, "time_total_s": 14355.75835609436, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 14355.75835609436, "timesteps_since_restore": 0, "iterations_since_restore": 59, "trial_id": "31acc_00000"}
{"alpha": 0.30213862657546997, "policy": {"shifts-mean": -0.019757190719246864, "shifts-std": 1.4072636365890503, "shifts-max": 3.082310199737549, "shifts-min": -3.1231980323791504, "scales-mean": 0.4205004870891571, "scales-std": 0.1506253182888031, "scales-max": 0.7774522304534912, "scales-min": 0.037599142640829086, "entropy-mean": -5.9424262046813965, "entropy-std": 3.5780458450317383, "actions-mean": -0.023496216163039207, "actions-std": 0.7667455673217773, "actions-min": -0.9988020658493042, "actions-max": 0.9985549449920654}, "evaluation": {"episode-reward-mean": 12916.0068359375, "episode-reward-min": 12916.0068359375, "episode-reward-max": 12916.0068359375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.05491053901116011, "reward_run-last-mean": 12.211449757646733, "reward_run-mean-mean": 13.273462964884427, "reward_run-median-mean": 13.985724735401845, "reward_run-range-mean": 16.76468004416628, "reward_ctrl-first-mean": -0.16087894439697267, "reward_ctrl-last-mean": -0.2063149929046631, "reward_ctrl-mean-mean": -0.35745608953833585, "reward_ctrl-median-mean": -0.35105295181274415, "reward_ctrl-range-mean": 0.5121877551078796}}, "training": {"episode-reward-mean": 12809.46687281099, "episode-reward-min": 12609.299444385892, "episode-reward-max": 13013.652079787913, "episode-reward-std": 122.0532765924563, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7756510039287544, "reward_run-last-mean": 13.625281881142655, "reward_run-mean-mean": 13.168416063568861, "reward_run-median-mean": 13.842408035415474, "reward_run-range-mean": 16.829037602689432, "reward_ctrl-first-mean": -0.34278415679931645, "reward_ctrl-last-mean": -0.38135390281677245, "reward_ctrl-mean-mean": -0.3589491907578707, "reward_ctrl-median-mean": -0.35564595818519595, "reward_ctrl-range-mean": 0.4807307261228561}}, "update": {"Q_value-mean": 1028.639892578125, "Q_loss-mean": 13.31399154663086, "policy_loss-mean": -1028.2803955078125, "alpha": 0.30038195848464966, "alpha_loss-mean": -0.00033909111516550183}, "times": {"epoch_before_hook": 4.328601062297821e-05, "timestep_before_hook": 0.09323179291095585, "sample": 16.098589803266805, "train": 207.07043948423234, "timestep_after_hook": 0.04152990455622785, "training_paths": 0.2022192449949216, "evaluation_paths": 0.5041139640088659, "training_metrics": 0.0015328520094044507, "evaluation_metrics": 0.00040807900950312614, "epoch_after_hook": 1.620996044948697e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 13089.018679532826, "last-path-return": 12740.251663645664, "episodes": 1510, "total-samples": 1510000}, "epoch": 59, "timestep": 25000, "total_timestep": 1500000, "num_train_steps": 1500000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 60, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-42-01", "timestamp": 1652823721, "time_this_iter_s": 224.46998238563538, "time_total_s": 14580.228338479996, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 14580.228338479996, "timesteps_since_restore": 0, "iterations_since_restore": 60, "trial_id": "31acc_00000"}
{"alpha": 0.3100530207157135, "policy": {"shifts-mean": -0.08970048278570175, "shifts-std": 1.4069551229476929, "shifts-max": 3.044788122177124, "shifts-min": -2.9154515266418457, "scales-mean": 0.4208480417728424, "scales-std": 0.15111468732357025, "scales-max": 0.8977040648460388, "scales-min": 0.03583323210477829, "entropy-mean": -5.869065761566162, "entropy-std": 3.489866256713867, "actions-mean": -0.0648878887295723, "actions-std": 0.765794038772583, "actions-min": -0.999256432056427, "actions-max": 0.9987186193466187}, "evaluation": {"episode-reward-mean": 12466.2216796875, "episode-reward-min": 12466.2216796875, "episode-reward-max": 12466.2216796875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.06155497638845528, "reward_run-last-mean": 15.11596154419749, "reward_run-mean-mean": 12.822840438260544, "reward_run-median-mean": 13.702455006457654, "reward_run-range-mean": 16.202027053782253, "reward_ctrl-first-mean": -0.2810374259948731, "reward_ctrl-last-mean": -0.29958620071411135, "reward_ctrl-mean-mean": -0.356618504780531, "reward_ctrl-median-mean": -0.35683292150497437, "reward_ctrl-range-mean": 0.5162395715713501}}, "training": {"episode-reward-mean": 12790.6223652749, "episode-reward-min": 11908.268916301571, "episode-reward-max": 13200.089510396965, "episode-reward-std": 345.075593350839, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.689632695912614, "reward_run-last-mean": 14.499454378440078, "reward_run-mean-mean": 13.15033282541918, "reward_run-median-mean": 13.91074263996208, "reward_run-range-mean": 16.782536697256198, "reward_ctrl-first-mean": -0.3407733726501465, "reward_ctrl-last-mean": -0.32236220955848693, "reward_ctrl-mean-mean": -0.3597104601442814, "reward_ctrl-median-mean": -0.35784065961837774, "reward_ctrl-range-mean": 0.47642867207527156}}, "update": {"Q_value-mean": 1036.89453125, "Q_loss-mean": 14.12399959564209, "policy_loss-mean": -1036.5255126953125, "alpha": 0.3052659034729004, "alpha_loss-mean": -0.00019436153525020927}, "times": {"epoch_before_hook": 3.597501199692488e-05, "timestep_before_hook": 0.0855006150668487, "sample": 15.100574982003309, "train": 201.46020975505235, "timestep_after_hook": 0.036832807410974056, "training_paths": 0.2215212699957192, "evaluation_paths": 0.500747891026549, "training_metrics": 0.0014930120087228715, "evaluation_metrics": 0.0004058629856444895, "epoch_after_hook": 2.0840088836848736e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 13200.089510396958, "last-path-return": 12967.526975999139, "episodes": 1535, "total-samples": 1535000}, "epoch": 60, "timestep": 25000, "total_timestep": 1525000, "num_train_steps": 1525000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 61, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-45-39", "timestamp": 1652823939, "time_this_iter_s": 217.82397866249084, "time_total_s": 14798.052317142487, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 14798.052317142487, "timesteps_since_restore": 0, "iterations_since_restore": 61, "trial_id": "31acc_00000"}
{"alpha": 0.3135342299938202, "policy": {"shifts-mean": -0.07281535118818283, "shifts-std": 1.400722622871399, "shifts-max": 2.9267261028289795, "shifts-min": -2.7172367572784424, "scales-mean": 0.42599669098854065, "scales-std": 0.15523797273635864, "scales-max": 1.0008914470672607, "scales-min": 0.03193002566695213, "entropy-mean": -5.911557197570801, "entropy-std": 3.3056304454803467, "actions-mean": -0.059300512075424194, "actions-std": 0.7623232007026672, "actions-min": -0.9993574023246765, "actions-max": 0.9992280006408691}, "evaluation": {"episode-reward-mean": 13301.228515625, "episode-reward-min": 13301.228515625, "episode-reward-max": 13301.228515625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6782687176755137, "reward_run-last-mean": 15.69013625155776, "reward_run-mean-mean": 13.666980403826312, "reward_run-median-mean": 14.450047880544616, "reward_run-range-mean": 17.50416996751515, "reward_ctrl-first-mean": -0.298440432548523, "reward_ctrl-last-mean": -0.25877492427825927, "reward_ctrl-mean-mean": -0.36575099914073944, "reward_ctrl-median-mean": -0.36902574300765995, "reward_ctrl-range-mean": 0.4696286082267761}}, "training": {"episode-reward-mean": 13009.48977046688, "episode-reward-min": 12796.905599092548, "episode-reward-max": 13224.884570448452, "episode-reward-std": 157.55479572937548, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7460493907803353, "reward_run-last-mean": 13.9871187640465, "reward_run-mean-mean": 13.367483603138524, "reward_run-median-mean": 14.104914526936469, "reward_run-range-mean": 17.0414372604387, "reward_ctrl-first-mean": -0.3279967117309571, "reward_ctrl-last-mean": -0.3875422596931458, "reward_ctrl-mean-mean": -0.3579938326716423, "reward_ctrl-median-mean": -0.35750828742980956, "reward_ctrl-range-mean": 0.4840290236473083}}, "update": {"Q_value-mean": 1042.5701904296875, "Q_loss-mean": 14.665104866027832, "policy_loss-mean": -1042.178955078125, "alpha": 0.3113153278827667, "alpha_loss-mean": -0.0001298184070037678}, "times": {"epoch_before_hook": 3.9044010918587446e-05, "timestep_before_hook": 0.0887062837718986, "sample": 15.465262141631683, "train": 202.88007295818534, "timestep_after_hook": 0.038311107811750844, "training_paths": 0.07570847898023203, "evaluation_paths": 0.5284441930125467, "training_metrics": 0.0014981180138420314, "evaluation_metrics": 0.0004101649974472821, "epoch_after_hook": 1.548003638163209e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 13227.943313929829, "last-path-return": 13087.437146870281, "episodes": 1560, "total-samples": 1560000}, "epoch": 61, "timestep": 25000, "total_timestep": 1550000, "num_train_steps": 1550000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 62, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-49-18", "timestamp": 1652824158, "time_this_iter_s": 219.50846004486084, "time_total_s": 15017.560777187347, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 15017.560777187347, "timesteps_since_restore": 0, "iterations_since_restore": 62, "trial_id": "31acc_00000"}
{"alpha": 0.3305623233318329, "policy": {"shifts-mean": -0.18474648892879486, "shifts-std": 1.40481698513031, "shifts-max": 3.317452907562256, "shifts-min": -3.725522041320801, "scales-mean": 0.4367235600948334, "scales-std": 0.15713797509670258, "scales-max": 1.0181392431259155, "scales-min": 0.027530593797564507, "entropy-mean": -6.078179359436035, "entropy-std": 3.7595837116241455, "actions-mean": -0.11361277848482132, "actions-std": 0.7692514657974243, "actions-min": -0.998465359210968, "actions-max": 0.9994712471961975}, "evaluation": {"episode-reward-mean": 12873.64453125, "episode-reward-min": 12873.64453125, "episode-reward-max": 12873.64453125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8516253612422734, "reward_run-last-mean": 13.642481798394783, "reward_run-mean-mean": 13.238205046361577, "reward_run-median-mean": 13.899346577344005, "reward_run-range-mean": 16.956761162661966, "reward_ctrl-first-mean": -0.3688809871673584, "reward_ctrl-last-mean": -0.336136531829834, "reward_ctrl-mean-mean": -0.36455971095561984, "reward_ctrl-median-mean": -0.36431800127029423, "reward_ctrl-range-mean": 0.4279155015945434}}, "training": {"episode-reward-mean": 13152.852409404499, "episode-reward-min": 12917.510467796787, "episode-reward-max": 13373.521114476393, "episode-reward-std": 165.87032005480268, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5727244991919769, "reward_run-last-mean": 14.930861144342543, "reward_run-mean-mean": 13.509628570849282, "reward_run-median-mean": 14.264662420170481, "reward_run-range-mean": 17.119486921292594, "reward_ctrl-first-mean": -0.29206122159957887, "reward_ctrl-last-mean": -0.3478850865364075, "reward_ctrl-mean-mean": -0.3567761614447832, "reward_ctrl-median-mean": -0.35742248654365544, "reward_ctrl-range-mean": 0.4842245501279831}}, "update": {"Q_value-mean": 1047.87451171875, "Q_loss-mean": 15.341907501220703, "policy_loss-mean": -1047.448486328125, "alpha": 0.3201808035373688, "alpha_loss-mean": -0.0005555531824938953}, "times": {"epoch_before_hook": 3.48089961335063e-05, "timestep_before_hook": 0.09257739796885289, "sample": 16.042413134739036, "train": 205.87034898190177, "timestep_after_hook": 0.04016295721521601, "training_paths": 0.07817270801751874, "evaluation_paths": 0.534394505986711, "training_metrics": 0.0015392840141430497, "evaluation_metrics": 0.00040995501331053674, "epoch_after_hook": 1.4929973985999823e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 13373.52111447639, "last-path-return": 13279.91048655689, "episodes": 1585, "total-samples": 1585000}, "epoch": 62, "timestep": 25000, "total_timestep": 1575000, "num_train_steps": 1575000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 63, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-53-01", "timestamp": 1652824381, "time_this_iter_s": 223.11104202270508, "time_total_s": 15240.671819210052, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 15240.671819210052, "timesteps_since_restore": 0, "iterations_since_restore": 63, "trial_id": "31acc_00000"}
{"alpha": 0.32589367032051086, "policy": {"shifts-mean": -0.19581164419651031, "shifts-std": 1.427704095840454, "shifts-max": 3.465278148651123, "shifts-min": -3.393404960632324, "scales-mean": 0.42287424206733704, "scales-std": 0.1579568088054657, "scales-max": 1.0296188592910767, "scales-min": 0.027335403487086296, "entropy-mean": -6.550536155700684, "entropy-std": 3.4255964756011963, "actions-mean": -0.10268162935972214, "actions-std": 0.7700823545455933, "actions-min": -0.9991431832313538, "actions-max": 0.9996950626373291}, "evaluation": {"episode-reward-mean": 13290.458984375, "episode-reward-min": 13290.458984375, "episode-reward-max": 13290.458984375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.22687396158246276, "reward_run-last-mean": 15.486481527161686, "reward_run-mean-mean": 13.638264359920097, "reward_run-median-mean": 14.349158674990008, "reward_run-range-mean": 16.726543465653428, "reward_ctrl-first-mean": -0.2574049472808838, "reward_ctrl-last-mean": -0.12039122581481934, "reward_ctrl-mean-mean": -0.3478059379279614, "reward_ctrl-median-mean": -0.3503981351852417, "reward_ctrl-range-mean": 0.4580448567867279}}, "training": {"episode-reward-mean": 13341.396713268492, "episode-reward-min": 13104.110618873781, "episode-reward-max": 13635.647432229467, "episode-reward-std": 145.7825369059095, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5636977785851697, "reward_run-last-mean": 15.001302766673234, "reward_run-mean-mean": 13.691203268178437, "reward_run-median-mean": 14.428362152312658, "reward_run-range-mean": 17.125577301053006, "reward_ctrl-first-mean": -0.31914904594421384, "reward_ctrl-last-mean": -0.3155568146705628, "reward_ctrl-mean-mean": -0.34980655490994456, "reward_ctrl-median-mean": -0.3499640834331512, "reward_ctrl-range-mean": 0.48245845496654516}}, "update": {"Q_value-mean": 1054.039794921875, "Q_loss-mean": 16.060638427734375, "policy_loss-mean": -1053.6331787109375, "alpha": 0.32350093126296997, "alpha_loss-mean": 0.00016656951629556715}, "times": {"epoch_before_hook": 3.7048012018203735e-05, "timestep_before_hook": 0.08574190133367665, "sample": 15.173799079144374, "train": 201.28637402222375, "timestep_after_hook": 0.036651987058576196, "training_paths": 0.07712641698890366, "evaluation_paths": 0.5325839339930099, "training_metrics": 0.0015468240017071366, "evaluation_metrics": 0.0005438350199256092, "epoch_after_hook": 2.1110172383487225e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 13635.647432229476, "last-path-return": 13513.7676408227, "episodes": 1610, "total-samples": 1610000}, "epoch": 63, "timestep": 25000, "total_timestep": 1600000, "num_train_steps": 1600000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 64, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_22-56-39", "timestamp": 1652824599, "time_this_iter_s": 217.6133041381836, "time_total_s": 15458.285123348236, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 15458.285123348236, "timesteps_since_restore": 0, "iterations_since_restore": 64, "trial_id": "31acc_00000"}
{"alpha": 0.335083931684494, "policy": {"shifts-mean": -0.09906285256147385, "shifts-std": 1.3976655006408691, "shifts-max": 2.9870810508728027, "shifts-min": -2.9016897678375244, "scales-mean": 0.4209018647670746, "scales-std": 0.15998263657093048, "scales-max": 0.9469491839408875, "scales-min": 0.03223135322332382, "entropy-mean": -6.099490165710449, "entropy-std": 3.3780367374420166, "actions-mean": -0.05133578181266785, "actions-std": 0.767565906047821, "actions-min": -0.9987005591392517, "actions-max": 0.9990953803062439}, "evaluation": {"episode-reward-mean": 13382.41015625, "episode-reward-min": 13382.41015625, "episode-reward-max": 13382.41015625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4005128114673683, "reward_run-last-mean": 15.563918966543042, "reward_run-mean-mean": 13.729956226133968, "reward_run-median-mean": 14.524723673883955, "reward_run-range-mean": 17.1128348247868, "reward_ctrl-first-mean": -0.16802202463150026, "reward_ctrl-last-mean": -0.16225656270980837, "reward_ctrl-mean-mean": -0.3475466274261475, "reward_ctrl-median-mean": -0.3456190228462219, "reward_ctrl-range-mean": 0.4661220192909241}}, "training": {"episode-reward-mean": 13353.709827648292, "episode-reward-min": 12049.91776177282, "episode-reward-max": 13788.024644483703, "episode-reward-std": 482.47196871576153, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6548638254685041, "reward_run-last-mean": 14.9911948735828, "reward_run-mean-mean": 13.701646922113193, "reward_run-median-mean": 14.616182345600805, "reward_run-range-mean": 17.253682781655193, "reward_ctrl-first-mean": -0.3339001572132111, "reward_ctrl-last-mean": -0.3488541460037232, "reward_ctrl-mean-mean": -0.3479370944648982, "reward_ctrl-median-mean": -0.3503637981414795, "reward_ctrl-range-mean": 0.4940922033786774}}, "update": {"Q_value-mean": 1061.4564208984375, "Q_loss-mean": 16.727035522460938, "policy_loss-mean": -1061.040283203125, "alpha": 0.33158695697784424, "alpha_loss-mean": -0.00026361961499787867}, "times": {"epoch_before_hook": 3.245798870921135e-05, "timestep_before_hook": 0.08862113681971096, "sample": 15.520101383706788, "train": 203.71799204088165, "timestep_after_hook": 0.03827325362362899, "training_paths": 0.0790116399875842, "evaluation_paths": 0.5246587959991302, "training_metrics": 0.0015802760026417673, "evaluation_metrics": 0.00041262098238803446, "epoch_after_hook": 1.5980040188878775e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 13788.024644483708, "last-path-return": 12049.91776177282, "episodes": 1635, "total-samples": 1635000}, "epoch": 64, "timestep": 25000, "total_timestep": 1625000, "num_train_steps": 1625000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 65, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-00-19", "timestamp": 1652824819, "time_this_iter_s": 220.40173268318176, "time_total_s": 15678.686856031418, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 15678.686856031418, "timesteps_since_restore": 0, "iterations_since_restore": 65, "trial_id": "31acc_00000"}
{"alpha": 0.3467476963996887, "policy": {"shifts-mean": -0.07218229025602341, "shifts-std": 1.4232265949249268, "shifts-max": 3.803875684738159, "shifts-min": -3.04695200920105, "scales-mean": 0.4195713698863983, "scales-std": 0.15031999349594116, "scales-max": 0.7818704843521118, "scales-min": 0.0337977297604084, "entropy-mean": -6.121892929077148, "entropy-std": 3.606151580810547, "actions-mean": -0.049279484897851944, "actions-std": 0.7686285376548767, "actions-min": -0.9989266991615295, "actions-max": 0.9983708262443542}, "evaluation": {"episode-reward-mean": 3372.802734375, "episode-reward-min": 3372.802734375, "episode-reward-max": 3372.802734375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5715091091948482, "reward_run-last-mean": -0.4905164278989105, "reward_run-mean-mean": 3.681702397716576, "reward_run-median-mean": 0.14878561268204749, "reward_run-range-mean": 17.428842239797195, "reward_ctrl-first-mean": -0.2016822099685669, "reward_ctrl-last-mean": -0.4475834369659424, "reward_ctrl-mean-mean": -0.30889968551993374, "reward_ctrl-median-mean": -0.30225436687469487, "reward_ctrl-range-mean": 0.5352681338787079}}, "training": {"episode-reward-mean": 13483.662780039482, "episode-reward-min": 12950.108625225175, "episode-reward-max": 13854.44509782004, "episode-reward-std": 259.84477519040934, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5489540668638939, "reward_run-last-mean": 15.229150488378309, "reward_run-mean-mean": 13.831241934241822, "reward_run-median-mean": 14.765845687499024, "reward_run-range-mean": 17.65023614259242, "reward_ctrl-first-mean": -0.27928073406219484, "reward_ctrl-last-mean": -0.3743091940879822, "reward_ctrl-mean-mean": -0.3475791542023421, "reward_ctrl-median-mean": -0.34935181379318236, "reward_ctrl-range-mean": 0.4932013320922851}}, "update": {"Q_value-mean": 1071.7371826171875, "Q_loss-mean": 18.071083068847656, "policy_loss-mean": -1071.3736572265625, "alpha": 0.3407299220561981, "alpha_loss-mean": -0.0003734961792360991}, "times": {"epoch_before_hook": 2.9641989385709167e-05, "timestep_before_hook": 0.09217181694111787, "sample": 15.971616496390197, "train": 206.10089696315117, "timestep_after_hook": 0.04071514794486575, "training_paths": 0.08973556099226698, "evaluation_paths": 0.5160745430039242, "training_metrics": 0.0015612240240443498, "evaluation_metrics": 0.00041298099677078426, "epoch_after_hook": 1.5500118024647236e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 13895.21257474354, "last-path-return": 13713.894133019172, "episodes": 1660, "total-samples": 1660000}, "epoch": 65, "timestep": 25000, "total_timestep": 1650000, "num_train_steps": 1650000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 66, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-04-03", "timestamp": 1652825043, "time_this_iter_s": 223.26744079589844, "time_total_s": 15901.954296827316, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 15901.954296827316, "timesteps_since_restore": 0, "iterations_since_restore": 66, "trial_id": "31acc_00000"}
{"alpha": 0.36247602105140686, "policy": {"shifts-mean": -0.1306622177362442, "shifts-std": 1.370849609375, "shifts-max": 3.035984992980957, "shifts-min": -2.8681881427764893, "scales-mean": 0.4201176166534424, "scales-std": 0.15775007009506226, "scales-max": 0.9230781197547913, "scales-min": 0.034315235912799835, "entropy-mean": -5.948380947113037, "entropy-std": 3.557544469833374, "actions-mean": -0.06608020514249802, "actions-std": 0.7614593505859375, "actions-min": -0.9989266395568848, "actions-max": 0.9993125200271606}, "evaluation": {"episode-reward-mean": 13911.84375, "episode-reward-min": 13911.84375, "episode-reward-max": 13911.84375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8106936136988269, "reward_run-last-mean": 15.383603617344761, "reward_run-mean-mean": 14.248517359244502, "reward_run-median-mean": 15.18553890780936, "reward_run-range-mean": 17.801617732370524, "reward_ctrl-first-mean": -0.4520870685577393, "reward_ctrl-last-mean": -0.3279235124588013, "reward_ctrl-mean-mean": -0.33667452284097676, "reward_ctrl-median-mean": -0.34401611089706424, "reward_ctrl-range-mean": 0.4647648215293884}}, "training": {"episode-reward-mean": 13674.751444716338, "episode-reward-min": 13241.56711633239, "episode-reward-max": 13926.130376883299, "episode-reward-std": 181.3809954158315, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5793974790057315, "reward_run-last-mean": 14.91645057900655, "reward_run-mean-mean": 14.022988219393975, "reward_run-median-mean": 14.970873011081196, "reward_run-range-mean": 17.633046796152236, "reward_ctrl-first-mean": -0.2770956575870514, "reward_ctrl-last-mean": -0.33762813329696656, "reward_ctrl-mean-mean": -0.34823677467763425, "reward_ctrl-median-mean": -0.35191227078437803, "reward_ctrl-range-mean": 0.48097786903381357}}, "update": {"Q_value-mean": 1079.3045654296875, "Q_loss-mean": 19.895845413208008, "policy_loss-mean": -1078.9324951171875, "alpha": 0.35727575421333313, "alpha_loss-mean": -0.0004964402178302407}, "times": {"epoch_before_hook": 4.452597931958735e-05, "timestep_before_hook": 0.08649585966486484, "sample": 15.557343991356902, "train": 201.88957186901825, "timestep_after_hook": 0.03800572076579556, "training_paths": 1.4757080919807777, "evaluation_paths": 0.5042921569838654, "training_metrics": 0.001504182000644505, "evaluation_metrics": 0.0004035299934912473, "epoch_after_hook": 1.5049881767481565e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 13962.734149145923, "last-path-return": 13606.472691897972, "episodes": 1685, "total-samples": 1685000}, "epoch": 66, "timestep": 25000, "total_timestep": 1675000, "num_train_steps": 1675000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 67, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-07-43", "timestamp": 1652825263, "time_this_iter_s": 219.97728443145752, "time_total_s": 16121.931581258774, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 16121.931581258774, "timesteps_since_restore": 0, "iterations_since_restore": 67, "trial_id": "31acc_00000"}
{"alpha": 0.37217676639556885, "policy": {"shifts-mean": -0.151939257979393, "shifts-std": 1.419825553894043, "shifts-max": 4.176239490509033, "shifts-min": -2.8937931060791016, "scales-mean": 0.4285213053226471, "scales-std": 0.15589368343353271, "scales-max": 0.7891590595245361, "scales-min": 0.03324534371495247, "entropy-mean": -6.060308456420898, "entropy-std": 3.983675718307495, "actions-mean": -0.08823593705892563, "actions-std": 0.762126624584198, "actions-min": -0.9997195601463318, "actions-max": 0.9998834133148193}, "evaluation": {"episode-reward-mean": 14069.7998046875, "episode-reward-min": 14069.7998046875, "episode-reward-max": 14069.7998046875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.31704447556325815, "reward_run-last-mean": 15.113337193465668, "reward_run-mean-mean": 14.413459899079365, "reward_run-median-mean": 15.227812365832847, "reward_run-range-mean": 17.76581851158557, "reward_ctrl-first-mean": -0.37521910667419434, "reward_ctrl-last-mean": -0.4194419860839844, "reward_ctrl-mean-mean": -0.34365987956523897, "reward_ctrl-median-mean": -0.3430570363998413, "reward_ctrl-range-mean": 0.47630506753921514}}, "training": {"episode-reward-mean": 13913.868991781663, "episode-reward-min": 13626.577383278123, "episode-reward-max": 14186.514768902563, "episode-reward-std": 151.70145836103796, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4802722156318957, "reward_run-last-mean": 15.546520998021833, "reward_run-mean-mean": 14.263035249263833, "reward_run-median-mean": 15.136498797668764, "reward_run-range-mean": 17.64889292698527, "reward_ctrl-first-mean": -0.3493777561187744, "reward_ctrl-last-mean": -0.39613122105598453, "reward_ctrl-mean-mean": -0.3491662574821711, "reward_ctrl-median-mean": -0.35499470829963686, "reward_ctrl-range-mean": 0.48732065916061407}}, "update": {"Q_value-mean": 1085.5126953125, "Q_loss-mean": 21.608875274658203, "policy_loss-mean": -1085.12939453125, "alpha": 0.36792218685150146, "alpha_loss-mean": -0.0003148486139252782}, "times": {"epoch_before_hook": 3.676299820654094e-05, "timestep_before_hook": 0.08807088862522505, "sample": 15.369424824748421, "train": 203.8810804784589, "timestep_after_hook": 0.03814765514107421, "training_paths": 0.07629231599275954, "evaluation_paths": 0.49571101999026723, "training_metrics": 0.0015621909988112748, "evaluation_metrics": 0.00041444701491855085, "epoch_after_hook": 1.5969853848218918e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14186.514768902545, "last-path-return": 13965.827073023615, "episodes": 1710, "total-samples": 1710000}, "epoch": 67, "timestep": 25000, "total_timestep": 1700000, "num_train_steps": 1700000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 68, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-11-24", "timestamp": 1652825484, "time_this_iter_s": 220.39277362823486, "time_total_s": 16342.324354887009, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 16342.324354887009, "timesteps_since_restore": 0, "iterations_since_restore": 68, "trial_id": "31acc_00000"}
{"alpha": 0.3854404389858246, "policy": {"shifts-mean": -0.13084664940834045, "shifts-std": 1.4327952861785889, "shifts-max": 3.8679206371307373, "shifts-min": -2.8851003646850586, "scales-mean": 0.4199732840061188, "scales-std": 0.15841539204120636, "scales-max": 0.9191933274269104, "scales-min": 0.03243140131235123, "entropy-mean": -6.321292877197266, "entropy-std": 4.206544876098633, "actions-mean": -0.08771436661481857, "actions-std": 0.7692208886146545, "actions-min": -0.9987296462059021, "actions-max": 0.99970543384552}, "evaluation": {"episode-reward-mean": 13966.4228515625, "episode-reward-min": 13966.4228515625, "episode-reward-max": 13966.4228515625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7592498835846525, "reward_run-last-mean": 13.63483562175361, "reward_run-mean-mean": 14.327432006713844, "reward_run-median-mean": 15.202712392870694, "reward_run-range-mean": 17.879512992809758, "reward_ctrl-first-mean": -0.45591416358947756, "reward_ctrl-last-mean": -0.36009740829467773, "reward_ctrl-mean-mean": -0.361009303855896, "reward_ctrl-median-mean": -0.3649386644363404, "reward_ctrl-range-mean": 0.48607338666915895}}, "training": {"episode-reward-mean": 14070.976827947941, "episode-reward-min": 13630.871954689788, "episode-reward-max": 14363.8842595183, "episode-reward-std": 195.52937684893507, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5695177318479743, "reward_run-last-mean": 15.760909803171899, "reward_run-mean-mean": 14.416468691651072, "reward_run-median-mean": 15.297340137227906, "reward_run-range-mean": 17.831747768155832, "reward_ctrl-first-mean": -0.31774046659469607, "reward_ctrl-last-mean": -0.3270763838291168, "reward_ctrl-mean-mean": -0.34549186370313173, "reward_ctrl-median-mean": -0.34921648740768435, "reward_ctrl-range-mean": 0.46620982468128214}}, "update": {"Q_value-mean": 1089.5528564453125, "Q_loss-mean": 22.595672607421875, "policy_loss-mean": -1089.143798828125, "alpha": 0.3816249668598175, "alpha_loss-mean": -0.0004342030733823776}, "times": {"epoch_before_hook": 3.055098932236433e-05, "timestep_before_hook": 0.09302784880856052, "sample": 16.00332333231927, "train": 206.42001259076642, "timestep_after_hook": 0.04116289655212313, "training_paths": 0.21568417898379266, "evaluation_paths": 0.5004915749887004, "training_metrics": 0.001479967002524063, "evaluation_metrics": 0.00041028400301001966, "epoch_after_hook": 1.6329868230968714e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14363.884259518285, "last-path-return": 14183.78053875015, "episodes": 1735, "total-samples": 1735000}, "epoch": 68, "timestep": 25000, "total_timestep": 1725000, "num_train_steps": 1725000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 69, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-15-07", "timestamp": 1652825707, "time_this_iter_s": 223.7270770072937, "time_total_s": 16566.051431894302, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 16566.051431894302, "timesteps_since_restore": 0, "iterations_since_restore": 69, "trial_id": "31acc_00000"}
{"alpha": 0.39970725774765015, "policy": {"shifts-mean": -0.13130658864974976, "shifts-std": 1.3887304067611694, "shifts-max": 4.155475616455078, "shifts-min": -3.6716978549957275, "scales-mean": 0.42501160502433777, "scales-std": 0.15717092156410217, "scales-max": 0.9304330348968506, "scales-min": 0.029934849590063095, "entropy-mean": -5.985206604003906, "entropy-std": 3.6015689373016357, "actions-mean": -0.06430855393409729, "actions-std": 0.7667968273162842, "actions-min": -0.9993447661399841, "actions-max": 0.9995591640472412}, "evaluation": {"episode-reward-mean": 13849.2177734375, "episode-reward-min": 13849.2177734375, "episode-reward-max": 13849.2177734375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.594874570026947, "reward_run-last-mean": 16.04418238597873, "reward_run-mean-mean": 14.187031428669377, "reward_run-median-mean": 14.915038961771643, "reward_run-range-mean": 17.719993610047187, "reward_ctrl-first-mean": -0.2596757888793945, "reward_ctrl-last-mean": -0.2764354705810547, "reward_ctrl-mean-mean": -0.33781375600099567, "reward_ctrl-median-mean": -0.337084436416626, "reward_ctrl-range-mean": 0.45003350973129275}}, "training": {"episode-reward-mean": 14083.64584364236, "episode-reward-min": 13695.371943804124, "episode-reward-max": 14376.738728015162, "episode-reward-std": 203.5484366726941, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7389002381893871, "reward_run-last-mean": 15.923834667742994, "reward_run-mean-mean": 14.428110017715696, "reward_run-median-mean": 15.365030260082875, "reward_run-range-mean": 18.06151058767805, "reward_ctrl-first-mean": -0.36349005937576295, "reward_ctrl-last-mean": -0.31211479783058166, "reward_ctrl-mean-mean": -0.3444641740733385, "reward_ctrl-median-mean": -0.3462719941139222, "reward_ctrl-range-mean": 0.47335716009140005}}, "update": {"Q_value-mean": 1096.1048583984375, "Q_loss-mean": 23.616222381591797, "policy_loss-mean": -1095.6904296875, "alpha": 0.39050179719924927, "alpha_loss-mean": -0.00039854043279774487}, "times": {"epoch_before_hook": 3.539302269928157e-05, "timestep_before_hook": 0.08231646058266051, "sample": 14.902087852271507, "train": 199.8747730824398, "timestep_after_hook": 0.036031485098646954, "training_paths": 0.07535166500019841, "evaluation_paths": 0.5286477729969192, "training_metrics": 0.0014826940023340285, "evaluation_metrics": 0.0004058519843965769, "epoch_after_hook": 1.7049896996468306e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14376.738728015172, "last-path-return": 14291.263412052627, "episodes": 1760, "total-samples": 1760000}, "epoch": 69, "timestep": 25000, "total_timestep": 1750000, "num_train_steps": 1750000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 70, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-18-43", "timestamp": 1652825923, "time_this_iter_s": 215.90877199172974, "time_total_s": 16781.960203886032, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 16781.960203886032, "timesteps_since_restore": 0, "iterations_since_restore": 70, "trial_id": "31acc_00000"}
{"alpha": 0.3973671495914459, "policy": {"shifts-mean": -0.1885601282119751, "shifts-std": 1.3949885368347168, "shifts-max": 3.9195895195007324, "shifts-min": -2.886040210723877, "scales-mean": 0.42781588435173035, "scales-std": 0.16212180256843567, "scales-max": 0.908769965171814, "scales-min": 0.03573281690478325, "entropy-mean": -6.1824541091918945, "entropy-std": 3.701779842376709, "actions-mean": -0.11041788011789322, "actions-std": 0.7620305418968201, "actions-min": -0.9978931546211243, "actions-max": 0.9983739256858826}, "evaluation": {"episode-reward-mean": 14496.8330078125, "episode-reward-min": 14496.8330078125, "episode-reward-max": 14496.8330078125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5508245897365385, "reward_run-last-mean": 15.357972159140445, "reward_run-mean-mean": 14.843622673320482, "reward_run-median-mean": 15.711997843260406, "reward_run-range-mean": 18.139807312986648, "reward_ctrl-first-mean": -0.22835650444030764, "reward_ctrl-last-mean": -0.4146134376525879, "reward_ctrl-mean-mean": -0.34678893780708314, "reward_ctrl-median-mean": -0.34859853982925415, "reward_ctrl-range-mean": 0.4589343428611756}}, "training": {"episode-reward-mean": 14160.142381470254, "episode-reward-min": 13810.938062534515, "episode-reward-max": 14395.367400305962, "episode-reward-std": 163.64983227912222, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7988084995956621, "reward_run-last-mean": 16.007805014069618, "reward_run-mean-mean": 14.50154060855036, "reward_run-median-mean": 15.426562797619951, "reward_run-range-mean": 18.157694718570873, "reward_ctrl-first-mean": -0.3166507613658905, "reward_ctrl-last-mean": -0.3143822014331818, "reward_ctrl-mean-mean": -0.34139822708010675, "reward_ctrl-median-mean": -0.34395658850669864, "reward_ctrl-range-mean": 0.4631653219461441}}, "update": {"Q_value-mean": 1102.3394775390625, "Q_loss-mean": 24.794219970703125, "policy_loss-mean": -1101.9097900390625, "alpha": 0.40160393714904785, "alpha_loss-mean": 0.00010916729661403224}, "times": {"epoch_before_hook": 4.0551996789872646e-05, "timestep_before_hook": 0.08922342912410386, "sample": 15.757798344478942, "train": 204.5594213384029, "timestep_after_hook": 0.03954284996143542, "training_paths": 0.07415542000671849, "evaluation_paths": 0.49880173697602004, "training_metrics": 0.00150130401016213, "evaluation_metrics": 0.00041342401527799666, "epoch_after_hook": 1.52099528349936e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14395.36740030594, "last-path-return": 14226.648480223426, "episodes": 1785, "total-samples": 1785000}, "epoch": 70, "timestep": 25000, "total_timestep": 1775000, "num_train_steps": 1775000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 71, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-22-25", "timestamp": 1652826145, "time_this_iter_s": 221.46067214012146, "time_total_s": 17003.420876026154, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 17003.420876026154, "timesteps_since_restore": 0, "iterations_since_restore": 71, "trial_id": "31acc_00000"}
{"alpha": 0.4101131856441498, "policy": {"shifts-mean": -0.09336427599191666, "shifts-std": 1.3643808364868164, "shifts-max": 3.541159152984619, "shifts-min": -2.7661092281341553, "scales-mean": 0.4107765853404999, "scales-std": 0.16103696823120117, "scales-max": 0.8125638961791992, "scales-min": 0.02654324844479561, "entropy-mean": -5.818805694580078, "entropy-std": 3.4849133491516113, "actions-mean": -0.04934009909629822, "actions-std": 0.7507677674293518, "actions-min": -0.9985491633415222, "actions-max": 0.999477744102478}, "evaluation": {"episode-reward-mean": 14498.1015625, "episode-reward-min": 14498.1015625, "episode-reward-max": 14498.1015625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.3086373690476389, "reward_run-last-mean": 15.363509768487802, "reward_run-mean-mean": 14.844074333574131, "reward_run-median-mean": 15.730518565904958, "reward_run-range-mean": 17.912704694856583, "reward_ctrl-first-mean": -0.24537105560302735, "reward_ctrl-last-mean": -0.3855300903320313, "reward_ctrl-mean-mean": -0.3459722739934921, "reward_ctrl-median-mean": -0.34850429296493535, "reward_ctrl-range-mean": 0.4645359754562378}}, "training": {"episode-reward-mean": 14348.855308415446, "episode-reward-min": 14181.89100102214, "episode-reward-max": 14522.05760797787, "episode-reward-std": 85.16373594617279, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6281545794392057, "reward_run-last-mean": 16.241560308197904, "reward_run-mean-mean": 14.690636584946068, "reward_run-median-mean": 15.557956358310918, "reward_run-range-mean": 17.99865925368904, "reward_ctrl-first-mean": -0.27976920962333673, "reward_ctrl-last-mean": -0.34731734752655036, "reward_ctrl-mean-mean": -0.34178127653062346, "reward_ctrl-median-mean": -0.34331907629966735, "reward_ctrl-range-mean": 0.4721619045734406}}, "update": {"Q_value-mean": 1109.6951904296875, "Q_loss-mean": 25.26091957092285, "policy_loss-mean": -1109.2349853515625, "alpha": 0.4115925431251526, "alpha_loss-mean": -0.0003775799705181271}, "times": {"epoch_before_hook": 3.5931996535509825e-05, "timestep_before_hook": 0.09102274681208655, "sample": 15.9063408645452, "train": 204.7156586216588, "timestep_after_hook": 0.04011901034391485, "training_paths": 0.07770584599347785, "evaluation_paths": 0.5024293010064866, "training_metrics": 0.0014735099975951016, "evaluation_metrics": 0.00044832000276073813, "epoch_after_hook": 1.7519923858344555e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14522.057607977873, "last-path-return": 14409.725887492872, "episodes": 1810, "total-samples": 1810000}, "epoch": 71, "timestep": 25000, "total_timestep": 1800000, "num_train_steps": 1800000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 72, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-26-07", "timestamp": 1652826367, "time_this_iter_s": 221.77808594703674, "time_total_s": 17225.19896197319, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 17225.19896197319, "timesteps_since_restore": 0, "iterations_since_restore": 72, "trial_id": "31acc_00000"}
{"alpha": 0.4198102056980133, "policy": {"shifts-mean": -0.1153903380036354, "shifts-std": 1.3949552774429321, "shifts-max": 4.71818733215332, "shifts-min": -2.911332130432129, "scales-mean": 0.4239022731781006, "scales-std": 0.1635495126247406, "scales-max": 0.8942939043045044, "scales-min": 0.024652615189552307, "entropy-mean": -6.0304412841796875, "entropy-std": 3.8895833492279053, "actions-mean": -0.06349986791610718, "actions-std": 0.7631826400756836, "actions-min": -0.9994398355484009, "actions-max": 0.9994205236434937}, "evaluation": {"episode-reward-mean": 14009.3515625, "episode-reward-min": 14009.3515625, "episode-reward-max": 14009.3515625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6139024045782244, "reward_run-last-mean": 6.0822735199622, "reward_run-mean-mean": 14.36733241284603, "reward_run-median-mean": 15.533299259867022, "reward_run-range-mean": 18.021452607811543, "reward_ctrl-first-mean": -0.30164120197296146, "reward_ctrl-last-mean": -0.33347647190094, "reward_ctrl-mean-mean": -0.3579803280591965, "reward_ctrl-median-mean": -0.35612183809280396, "reward_ctrl-range-mean": 0.44746425151824953}}, "training": {"episode-reward-mean": 14323.247384084709, "episode-reward-min": 14022.681115758183, "episode-reward-max": 14581.651422643074, "episode-reward-std": 146.15766421894477, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6390611540513843, "reward_run-last-mean": 15.435929471103691, "reward_run-mean-mean": 14.66472831584955, "reward_run-median-mean": 15.58578087232965, "reward_run-range-mean": 18.170449315850284, "reward_ctrl-first-mean": -0.33631468534469605, "reward_ctrl-last-mean": -0.41297834396362304, "reward_ctrl-mean-mean": -0.3414809317648411, "reward_ctrl-median-mean": -0.3418467712402344, "reward_ctrl-range-mean": 0.4713131481409073}}, "update": {"Q_value-mean": 1115.8216552734375, "Q_loss-mean": 25.737770080566406, "policy_loss-mean": -1115.31787109375, "alpha": 0.4182625710964203, "alpha_loss-mean": -0.000312655494781211}, "times": {"epoch_before_hook": 3.270999877713621e-05, "timestep_before_hook": 0.08713775101932697, "sample": 15.430300068343058, "train": 203.05515399231808, "timestep_after_hook": 0.038422568613896146, "training_paths": 0.07781824801350012, "evaluation_paths": 0.535041597991949, "training_metrics": 0.0015398810210172087, "evaluation_metrics": 0.0004082990053575486, "epoch_after_hook": 1.5490222722291946e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14581.651422643074, "last-path-return": 14329.882666985975, "episodes": 1835, "total-samples": 1835000}, "epoch": 72, "timestep": 25000, "total_timestep": 1825000, "num_train_steps": 1825000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 73, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-29-47", "timestamp": 1652826587, "time_this_iter_s": 219.65660214424133, "time_total_s": 17444.85556411743, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 17444.85556411743, "timesteps_since_restore": 0, "iterations_since_restore": 73, "trial_id": "31acc_00000"}
{"alpha": 0.4177052974700928, "policy": {"shifts-mean": -0.11076746135950089, "shifts-std": 1.4208393096923828, "shifts-max": 3.9823081493377686, "shifts-min": -2.9462735652923584, "scales-mean": 0.4115827977657318, "scales-std": 0.165197491645813, "scales-max": 1.004197359085083, "scales-min": 0.019974403083324432, "entropy-mean": -6.838993072509766, "entropy-std": 3.883544921875, "actions-mean": -0.0672510489821434, "actions-std": 0.7669806480407715, "actions-min": -0.9991907477378845, "actions-max": 0.9994498491287231}, "evaluation": {"episode-reward-mean": 14397.966796875, "episode-reward-min": 14397.966796875, "episode-reward-max": 14397.966796875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6269937280974992, "reward_run-last-mean": 16.152989705565233, "reward_run-mean-mean": 14.732125328016023, "reward_run-median-mean": 15.699560631876182, "reward_run-range-mean": 18.27108122749621, "reward_ctrl-first-mean": -0.2523939609527588, "reward_ctrl-last-mean": -0.3449488878250122, "reward_ctrl-mean-mean": -0.33415848973989487, "reward_ctrl-median-mean": -0.3213160872459412, "reward_ctrl-range-mean": 0.44081434011459353}}, "training": {"episode-reward-mean": 14437.379164319176, "episode-reward-min": 14224.929423749714, "episode-reward-max": 14625.098034638022, "episode-reward-std": 107.07725488807225, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5332376375690112, "reward_run-last-mean": 16.257063801666845, "reward_run-mean-mean": 14.778065423242884, "reward_run-median-mean": 15.635883226508682, "reward_run-range-mean": 18.104213949699684, "reward_ctrl-first-mean": -0.31666335940361023, "reward_ctrl-last-mean": -0.3329134154319764, "reward_ctrl-mean-mean": -0.34068625892370935, "reward_ctrl-median-mean": -0.33989506363868716, "reward_ctrl-range-mean": 0.47063078731298447}}, "update": {"Q_value-mean": 1121.7772216796875, "Q_loss-mean": 25.475236892700195, "policy_loss-mean": -1121.23828125, "alpha": 0.4229048788547516, "alpha_loss-mean": 0.00013864772336091846}, "times": {"epoch_before_hook": 4.3180014472454786e-05, "timestep_before_hook": 0.08573156531201676, "sample": 15.422541207546601, "train": 202.08066071153735, "timestep_after_hook": 0.03813117818208411, "training_paths": 0.07920310299959965, "evaluation_paths": 0.5336401239910629, "training_metrics": 0.001557944982778281, "evaluation_metrics": 0.0004105509724467993, "epoch_after_hook": 1.7329875845462084e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14625.098034638031, "last-path-return": 14532.083721005321, "episodes": 1860, "total-samples": 1860000}, "epoch": 73, "timestep": 25000, "total_timestep": 1850000, "num_train_steps": 1850000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 74, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-33-25", "timestamp": 1652826805, "time_this_iter_s": 218.66969084739685, "time_total_s": 17663.52525496483, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 17663.52525496483, "timesteps_since_restore": 0, "iterations_since_restore": 74, "trial_id": "31acc_00000"}
{"alpha": 0.43462073802948, "policy": {"shifts-mean": -0.13213913142681122, "shifts-std": 1.3675328493118286, "shifts-max": 4.090792179107666, "shifts-min": -3.135220527648926, "scales-mean": 0.4244503676891327, "scales-std": 0.16541142761707306, "scales-max": 1.0140186548233032, "scales-min": 0.025112444534897804, "entropy-mean": -5.979467391967773, "entropy-std": 3.338888168334961, "actions-mean": -0.06599500775337219, "actions-std": 0.763602077960968, "actions-min": -0.9996559619903564, "actions-max": 0.9994542002677917}, "evaluation": {"episode-reward-mean": 14231.962890625, "episode-reward-min": 14231.962890625, "episode-reward-max": 14231.962890625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.506281842335784, "reward_run-last-mean": 15.122187140734695, "reward_run-mean-mean": 14.560219352685026, "reward_run-median-mean": 15.414833747339571, "reward_run-range-mean": 17.480534071797866, "reward_ctrl-first-mean": -0.28089759349823, "reward_ctrl-last-mean": -0.4684772491455078, "reward_ctrl-mean-mean": -0.3282563740253449, "reward_ctrl-median-mean": -0.3418009281158447, "reward_ctrl-range-mean": 0.4731015384197236}}, "training": {"episode-reward-mean": 14389.346341924047, "episode-reward-min": 14128.847245405777, "episode-reward-max": 14567.543161444975, "episode-reward-std": 133.919308641798, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6839294418519961, "reward_run-last-mean": 15.60694948715468, "reward_run-mean-mean": 14.72895013832984, "reward_run-median-mean": 15.623522359441466, "reward_run-range-mean": 18.161158346531366, "reward_ctrl-first-mean": -0.3477534115314484, "reward_ctrl-last-mean": -0.3517803204059601, "reward_ctrl-mean-mean": -0.33960379640579225, "reward_ctrl-median-mean": -0.3399083328247071, "reward_ctrl-range-mean": 0.4758584642410278}}, "update": {"Q_value-mean": 1127.7066650390625, "Q_loss-mean": 26.029315948486328, "policy_loss-mean": -1127.1204833984375, "alpha": 0.4290153980255127, "alpha_loss-mean": -0.0005314684240147471}, "times": {"epoch_before_hook": 3.372298670001328e-05, "timestep_before_hook": 0.08974045742070302, "sample": 15.712847639602842, "train": 203.97196319382056, "timestep_after_hook": 0.03894422040320933, "training_paths": 0.0772955979919061, "evaluation_paths": 0.5010617219959386, "training_metrics": 0.001536877010948956, "evaluation_metrics": 0.00040435700793750584, "epoch_after_hook": 1.6730045899748802e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14625.098034638031, "last-path-return": 14447.130601591321, "episodes": 1885, "total-samples": 1885000}, "epoch": 74, "timestep": 25000, "total_timestep": 1875000, "num_train_steps": 1875000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 75, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-37-06", "timestamp": 1652827026, "time_this_iter_s": 220.83341240882874, "time_total_s": 17884.358667373657, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 17884.358667373657, "timesteps_since_restore": 0, "iterations_since_restore": 75, "trial_id": "31acc_00000"}
{"alpha": 0.44134292006492615, "policy": {"shifts-mean": -0.10519712418317795, "shifts-std": 1.3347840309143066, "shifts-max": 3.1731958389282227, "shifts-min": -2.718085527420044, "scales-mean": 0.4182681143283844, "scales-std": 0.1634044647216797, "scales-max": 0.8651163578033447, "scales-min": 0.030988719314336777, "entropy-mean": -5.584604263305664, "entropy-std": 3.356687068939209, "actions-mean": -0.07353123277425766, "actions-std": 0.7463613152503967, "actions-min": -0.9987786412239075, "actions-max": 0.9992868900299072}, "evaluation": {"episode-reward-mean": 14371.154296875, "episode-reward-min": 14371.154296875, "episode-reward-max": 14371.154296875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5944795078937216, "reward_run-last-mean": 16.848743556561203, "reward_run-mean-mean": 14.703729398848521, "reward_run-median-mean": 15.552596709100044, "reward_run-range-mean": 17.98709413895054, "reward_ctrl-first-mean": -0.30956802368164066, "reward_ctrl-last-mean": -0.3065628528594971, "reward_ctrl-mean-mean": -0.33257451896667484, "reward_ctrl-median-mean": -0.33473274707794193, "reward_ctrl-range-mean": 0.4912600278854371}}, "training": {"episode-reward-mean": 14430.495463245315, "episode-reward-min": 14291.309355341295, "episode-reward-max": 14561.892921386108, "episode-reward-std": 92.5858086184473, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.574252847892913, "reward_run-last-mean": 16.136419785851785, "reward_run-mean-mean": 14.770282784159585, "reward_run-median-mean": 15.667879388944513, "reward_run-range-mean": 18.167906723933605, "reward_ctrl-first-mean": -0.2817979693412781, "reward_ctrl-last-mean": -0.3319323587417603, "reward_ctrl-mean-mean": -0.3397873209142685, "reward_ctrl-median-mean": -0.3395931684970856, "reward_ctrl-range-mean": 0.4705876970291138}}, "update": {"Q_value-mean": 1133.62158203125, "Q_loss-mean": 25.88945198059082, "policy_loss-mean": -1132.9970703125, "alpha": 0.43363645672798157, "alpha_loss-mean": -0.00015852434444241226}, "times": {"epoch_before_hook": 3.578999894671142e-05, "timestep_before_hook": 0.09068262984510511, "sample": 15.84813196741743, "train": 204.54701874652528, "timestep_after_hook": 0.03975618537515402, "training_paths": 0.07912091698381118, "evaluation_paths": 0.49818098900141194, "training_metrics": 0.0016171519819181412, "evaluation_metrics": 0.00041467099799774587, "epoch_after_hook": 1.5310070011764765e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14652.530984592675, "last-path-return": 14304.62469385065, "episodes": 1910, "total-samples": 1910000}, "epoch": 75, "timestep": 25000, "total_timestep": 1900000, "num_train_steps": 1900000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 76, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-40-48", "timestamp": 1652827248, "time_this_iter_s": 221.54979515075684, "time_total_s": 18105.908462524414, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 18105.908462524414, "timesteps_since_restore": 0, "iterations_since_restore": 76, "trial_id": "31acc_00000"}
{"alpha": 0.432888001203537, "policy": {"shifts-mean": -0.15605218708515167, "shifts-std": 1.3354902267456055, "shifts-max": 3.159273862838745, "shifts-min": -3.568054676055908, "scales-mean": 0.4184717833995819, "scales-std": 0.16406679153442383, "scales-max": 0.9699554443359375, "scales-min": 0.03148194029927254, "entropy-mean": -5.516724586486816, "entropy-std": 3.4047083854675293, "actions-mean": -0.08005725592374802, "actions-std": 0.7476136088371277, "actions-min": -0.9990420937538147, "actions-max": 0.9991366863250732}, "evaluation": {"episode-reward-mean": 14604.783203125, "episode-reward-min": 14604.783203125, "episode-reward-max": 14604.783203125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4789897878244631, "reward_run-last-mean": 15.975610643329219, "reward_run-mean-mean": 14.943940800007178, "reward_run-median-mean": 15.8180240205877, "reward_run-range-mean": 18.039139181074127, "reward_ctrl-first-mean": -0.2206270456314087, "reward_ctrl-last-mean": -0.40888981819152836, "reward_ctrl-mean-mean": -0.3391568366229534, "reward_ctrl-median-mean": -0.3459923505783081, "reward_ctrl-range-mean": 0.4694040656089783}}, "training": {"episode-reward-mean": 14397.900623501995, "episode-reward-min": 13940.42594870349, "episode-reward-max": 14596.350789554406, "episode-reward-std": 177.20058528889825, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7067237707454482, "reward_run-last-mean": 15.807458724336811, "reward_run-mean-mean": 14.738370234801327, "reward_run-median-mean": 15.690051931796447, "reward_run-range-mean": 18.281154062666232, "reward_ctrl-first-mean": -0.3381961297988892, "reward_ctrl-last-mean": -0.4372304010391236, "reward_ctrl-mean-mean": -0.34046961129933595, "reward_ctrl-median-mean": -0.3413016211986542, "reward_ctrl-range-mean": 0.4828122690320015}}, "update": {"Q_value-mean": 1139.7293701171875, "Q_loss-mean": 24.897035598754883, "policy_loss-mean": -1139.053466796875, "alpha": 0.43583089113235474, "alpha_loss-mean": 0.00030617835000157356}, "times": {"epoch_before_hook": 3.6308018025010824e-05, "timestep_before_hook": 0.08877044011023827, "sample": 16.034762513561873, "train": 204.2027780553035, "timestep_after_hook": 0.03966115094954148, "training_paths": 0.18672498501837254, "evaluation_paths": 0.5005609139916487, "training_metrics": 0.0014759660116396844, "evaluation_metrics": 0.00040434100083075464, "epoch_after_hook": 1.9430008251219988e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14652.530984592675, "last-path-return": 14375.26093884865, "episodes": 1935, "total-samples": 1935000}, "epoch": 76, "timestep": 25000, "total_timestep": 1925000, "num_train_steps": 1925000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 77, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-44-29", "timestamp": 1652827469, "time_this_iter_s": 221.49838995933533, "time_total_s": 18327.40685248375, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 18327.40685248375, "timesteps_since_restore": 0, "iterations_since_restore": 77, "trial_id": "31acc_00000"}
{"alpha": 0.4403012692928314, "policy": {"shifts-mean": -0.13849955797195435, "shifts-std": 1.3819687366485596, "shifts-max": 3.4643075466156006, "shifts-min": -2.9031667709350586, "scales-mean": 0.41134360432624817, "scales-std": 0.16100364923477173, "scales-max": 0.9943183660507202, "scales-min": 0.025495264679193497, "entropy-mean": -6.315415382385254, "entropy-std": 3.3815085887908936, "actions-mean": -0.08925756067037582, "actions-std": 0.7607371211051941, "actions-min": -0.9991210699081421, "actions-max": 0.9981914758682251}, "evaluation": {"episode-reward-mean": 14102.193359375, "episode-reward-min": 14102.193359375, "episode-reward-max": 14102.193359375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.9455658644252063, "reward_run-last-mean": 15.408879026274462, "reward_run-mean-mean": 14.44107011040403, "reward_run-median-mean": 15.61353429395183, "reward_run-range-mean": 18.42445943988155, "reward_ctrl-first-mean": -0.2172003746032715, "reward_ctrl-last-mean": -0.42691116333007817, "reward_ctrl-mean-mean": -0.33887616221904754, "reward_ctrl-median-mean": -0.3389538168907166, "reward_ctrl-range-mean": 0.46097152233123784}}, "training": {"episode-reward-mean": 14440.854365826523, "episode-reward-min": 14173.286398331722, "episode-reward-max": 14621.675794425688, "episode-reward-std": 124.26809426348952, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6154742446365631, "reward_run-last-mean": 15.901933222959315, "reward_run-mean-mean": 14.781109135698355, "reward_run-median-mean": 15.690017087008712, "reward_run-range-mean": 18.11759652484302, "reward_ctrl-first-mean": -0.293673495054245, "reward_ctrl-last-mean": -0.3624084877967834, "reward_ctrl-mean-mean": -0.34025476987183095, "reward_ctrl-median-mean": -0.3408719336986542, "reward_ctrl-range-mean": 0.47827757000923155}}, "update": {"Q_value-mean": 1146.6932373046875, "Q_loss-mean": 24.79155921936035, "policy_loss-mean": -1145.9910888671875, "alpha": 0.43614262342453003, "alpha_loss-mean": -0.0002233664272353053}, "times": {"epoch_before_hook": 3.198999911546707e-05, "timestep_before_hook": 0.08698113323771395, "sample": 15.669221097923582, "train": 202.3829093518434, "timestep_after_hook": 0.03825173174845986, "training_paths": 0.20168750401353464, "evaluation_paths": 0.5483530460041948, "training_metrics": 0.043099172005895525, "evaluation_metrics": 0.010369921015808359, "epoch_after_hook": 2.53098551183939e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14676.068519838269, "last-path-return": 14173.286398331707, "episodes": 1960, "total-samples": 1960000}, "epoch": 77, "timestep": 25000, "total_timestep": 1950000, "num_train_steps": 1950000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 78, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-48-09", "timestamp": 1652827689, "time_this_iter_s": 219.4165279865265, "time_total_s": 18546.823380470276, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 18546.823380470276, "timesteps_since_restore": 0, "iterations_since_restore": 78, "trial_id": "31acc_00000"}
{"alpha": 0.4416584372520447, "policy": {"shifts-mean": -0.11679613590240479, "shifts-std": 1.3768694400787354, "shifts-max": 3.590763568878174, "shifts-min": -2.8580076694488525, "scales-mean": 0.4177469313144684, "scales-std": 0.16229183971881866, "scales-max": 0.8941892981529236, "scales-min": 0.023531243205070496, "entropy-mean": -6.055787563323975, "entropy-std": 3.3841395378112793, "actions-mean": -0.055382270365953445, "actions-std": 0.7653635740280151, "actions-min": -0.9976843595504761, "actions-max": 0.9999068379402161}, "evaluation": {"episode-reward-mean": 14715.1201171875, "episode-reward-min": 14715.1201171875, "episode-reward-max": 14715.1201171875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.42872001674636145, "reward_run-last-mean": 16.21451362565267, "reward_run-mean-mean": 15.059828604258128, "reward_run-median-mean": 15.875395878790641, "reward_run-range-mean": 17.85332132347323, "reward_ctrl-first-mean": -0.23174128532409669, "reward_ctrl-last-mean": -0.36497623920440675, "reward_ctrl-mean-mean": -0.344707819890976, "reward_ctrl-median-mean": -0.3372589826583863, "reward_ctrl-range-mean": 0.45225595831871035}}, "training": {"episode-reward-mean": 14530.19747815419, "episode-reward-min": 14350.369077414656, "episode-reward-max": 14685.431686432334, "episode-reward-std": 97.44165247017578, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5368996792948197, "reward_run-last-mean": 16.02124624636258, "reward_run-mean-mean": 14.87132156570066, "reward_run-median-mean": 15.748348460206913, "reward_run-range-mean": 18.12501765872188, "reward_ctrl-first-mean": -0.3364211654663086, "reward_ctrl-last-mean": -0.35449945688247686, "reward_ctrl-mean-mean": -0.3411240875464678, "reward_ctrl-median-mean": -0.3417683327198029, "reward_ctrl-range-mean": 0.4693915975093842}}, "update": {"Q_value-mean": 1153.790771484375, "Q_loss-mean": 23.76439094543457, "policy_loss-mean": -1153.05419921875, "alpha": 0.4347601532936096, "alpha_loss-mean": -4.203367279842496e-05}, "times": {"epoch_before_hook": 3.609899431467056e-05, "timestep_before_hook": 0.08070278711966239, "sample": 14.575134838698432, "train": 198.52771409135312, "timestep_after_hook": 0.03489087539492175, "training_paths": 0.20147557600284927, "evaluation_paths": 0.49947186998906545, "training_metrics": 0.0014851920132059604, "evaluation_metrics": 0.0004063319938722998, "epoch_after_hook": 1.6750127542763948e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14712.381639055222, "last-path-return": 14527.386517983414, "episodes": 1985, "total-samples": 1985000}, "epoch": 78, "timestep": 25000, "total_timestep": 1975000, "num_train_steps": 1975000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 79, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-51-43", "timestamp": 1652827903, "time_this_iter_s": 214.32234406471252, "time_total_s": 18761.14572453499, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 18761.14572453499, "timesteps_since_restore": 0, "iterations_since_restore": 79, "trial_id": "31acc_00000"}
{"alpha": 0.4374571442604065, "policy": {"shifts-mean": -0.12741078436374664, "shifts-std": 1.3770477771759033, "shifts-max": 3.461142063140869, "shifts-min": -3.4612221717834473, "scales-mean": 0.419854074716568, "scales-std": 0.1620037704706192, "scales-max": 0.981705904006958, "scales-min": 0.02332383580505848, "entropy-mean": -5.924503803253174, "entropy-std": 3.415001392364502, "actions-mean": -0.07208061963319778, "actions-std": 0.7621456980705261, "actions-min": -0.9997482299804688, "actions-max": 0.9986419081687927}, "evaluation": {"episode-reward-mean": 14303.142578125, "episode-reward-min": 14303.142578125, "episode-reward-max": 14303.142578125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5856138592039279, "reward_run-last-mean": 16.7385557140301, "reward_run-mean-mean": 14.636559551553253, "reward_run-median-mean": 15.54751500316172, "reward_run-range-mean": 18.423972669810748, "reward_ctrl-first-mean": -0.3517175674438477, "reward_ctrl-last-mean": -0.13804794549942018, "reward_ctrl-mean-mean": -0.33341681300401693, "reward_ctrl-median-mean": -0.34513838291168214, "reward_ctrl-range-mean": 0.5063919246196747}}, "training": {"episode-reward-mean": 14510.971297672531, "episode-reward-min": 14261.13395191601, "episode-reward-max": 14642.782509616303, "episode-reward-std": 125.83184154597616, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5539103646209368, "reward_run-last-mean": 15.9441510341901, "reward_run-mean-mean": 14.85011476852848, "reward_run-median-mean": 15.713313172383621, "reward_run-range-mean": 18.111781632844682, "reward_ctrl-first-mean": -0.29504147291183475, "reward_ctrl-last-mean": -0.34517892003059386, "reward_ctrl-mean-mean": -0.3391434708559513, "reward_ctrl-median-mean": -0.3405708265304566, "reward_ctrl-range-mean": 0.4817192417383195}}, "update": {"Q_value-mean": 1161.0220947265625, "Q_loss-mean": 23.19668197631836, "policy_loss-mean": -1160.2264404296875, "alpha": 0.43476834893226624, "alpha_loss-mean": 0.00016729693743400276}, "times": {"epoch_before_hook": 3.146901144646108e-05, "timestep_before_hook": 0.07895296849892475, "sample": 14.415487372374628, "train": 197.3199376076227, "timestep_after_hook": 0.034020948311081156, "training_paths": 0.07823792300769128, "evaluation_paths": 0.6256322109838948, "training_metrics": 0.0014940770051907748, "evaluation_metrics": 0.00040742100100032985, "epoch_after_hook": 1.5490222722291946e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14715.401413105204, "last-path-return": 14625.952429454279, "episodes": 2010, "total-samples": 2010000}, "epoch": 79, "timestep": 25000, "total_timestep": 2000000, "num_train_steps": 2000000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 80, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-55-16", "timestamp": 1652828116, "time_this_iter_s": 212.9468457698822, "time_total_s": 18974.09257030487, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 18974.09257030487, "timesteps_since_restore": 0, "iterations_since_restore": 80, "trial_id": "31acc_00000"}
{"alpha": 0.4318750202655792, "policy": {"shifts-mean": -0.14847217500209808, "shifts-std": 1.3861838579177856, "shifts-max": 3.774954080581665, "shifts-min": -2.726907730102539, "scales-mean": 0.4137782156467438, "scales-std": 0.1601002961397171, "scales-max": 0.7919486165046692, "scales-min": 0.025159334763884544, "entropy-mean": -6.011463165283203, "entropy-std": 4.017935752868652, "actions-mean": -0.0914049968123436, "actions-std": 0.7558092474937439, "actions-min": -0.9990260601043701, "actions-max": 0.9996152520179749}, "evaluation": {"episode-reward-mean": 14801.677734375, "episode-reward-min": 14801.677734375, "episode-reward-max": 14801.677734375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8650678437928044, "reward_run-last-mean": 16.42934614285423, "reward_run-mean-mean": 15.145929109431144, "reward_run-median-mean": 15.988709549039868, "reward_run-range-mean": 18.842894597657203, "reward_ctrl-first-mean": -0.3333211898803711, "reward_ctrl-last-mean": -0.5567660808563233, "reward_ctrl-mean-mean": -0.34425155075192454, "reward_ctrl-median-mean": -0.3482801795005799, "reward_ctrl-range-mean": 0.4807583808898926}}, "training": {"episode-reward-mean": 13900.552847058807, "episode-reward-min": 8050.542780433508, "episode-reward-max": 14705.748328427255, "episode-reward-std": 1951.668469249243, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.40405836096788317, "reward_run-last-mean": 14.422921967467232, "reward_run-mean-mean": 14.252195852293259, "reward_run-median-mean": 15.215729104653866, "reward_run-range-mean": 18.107601390734224, "reward_ctrl-first-mean": -0.3366143548488617, "reward_ctrl-last-mean": -0.3980514311790467, "reward_ctrl-mean-mean": -0.35164300523445013, "reward_ctrl-median-mean": -0.35415733575820924, "reward_ctrl-range-mean": 0.47768737748265266}}, "update": {"Q_value-mean": 1167.774658203125, "Q_loss-mean": 23.099105834960938, "policy_loss-mean": -1166.9478759765625, "alpha": 0.43578967452049255, "alpha_loss-mean": 0.0002182796160923317}, "times": {"epoch_before_hook": 3.401999128982425e-05, "timestep_before_hook": 0.07877770680352114, "sample": 14.580644867703086, "train": 197.62368125127978, "timestep_after_hook": 0.03421178658027202, "training_paths": 0.07693454800755717, "evaluation_paths": 0.5004581660032272, "training_metrics": 0.001493788993684575, "evaluation_metrics": 0.00040560500929132104, "epoch_after_hook": 1.4920078683644533e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14715.401413105204, "last-path-return": 14493.577934780158, "episodes": 2035, "total-samples": 2035000}, "epoch": 80, "timestep": 25000, "total_timestep": 2025000, "num_train_steps": 2025000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 81, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-17_23-58-49", "timestamp": 1652828329, "time_this_iter_s": 213.29066920280457, "time_total_s": 19187.383239507675, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 19187.383239507675, "timesteps_since_restore": 0, "iterations_since_restore": 81, "trial_id": "31acc_00000"}
{"alpha": 0.4276622235774994, "policy": {"shifts-mean": -0.14896178245544434, "shifts-std": 1.3596179485321045, "shifts-max": 4.31387996673584, "shifts-min": -3.246067523956299, "scales-mean": 0.4209998548030853, "scales-std": 0.16720964014530182, "scales-max": 1.0397435426712036, "scales-min": 0.028697630390524864, "entropy-mean": -5.57573938369751, "entropy-std": 3.608753204345703, "actions-mean": -0.07103759795427322, "actions-std": 0.7550208568572998, "actions-min": -0.9998509883880615, "actions-max": 0.9999334812164307}, "evaluation": {"episode-reward-mean": 14662.9619140625, "episode-reward-min": 14662.9619140625, "episode-reward-max": 14662.9619140625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.272728989398837, "reward_run-last-mean": 15.401024674233668, "reward_run-mean-mean": 14.997073726711697, "reward_run-median-mean": 15.71640845159493, "reward_run-range-mean": 17.730978185716918, "reward_ctrl-first-mean": -0.17933260202407839, "reward_ctrl-last-mean": -0.3789769411087036, "reward_ctrl-mean-mean": -0.3341120217263699, "reward_ctrl-median-mean": -0.3379951238632203, "reward_ctrl-range-mean": 0.4618413388729096}}, "training": {"episode-reward-mean": 14581.717302732515, "episode-reward-min": 14357.534610671435, "episode-reward-max": 14741.96362108514, "episode-reward-std": 136.94481071251917, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6709526109168563, "reward_run-last-mean": 16.222644037068903, "reward_run-mean-mean": 14.922863061608723, "reward_run-median-mean": 15.79430208404969, "reward_run-range-mean": 18.27768409808425, "reward_ctrl-first-mean": -0.337686505317688, "reward_ctrl-last-mean": -0.29440958976745607, "reward_ctrl-mean-mean": -0.3411457588762045, "reward_ctrl-median-mean": -0.3432459890842438, "reward_ctrl-range-mean": 0.47668525159358976}}, "update": {"Q_value-mean": 1173.152587890625, "Q_loss-mean": 24.487085342407227, "policy_loss-mean": -1172.289794921875, "alpha": 0.4368884861469269, "alpha_loss-mean": 0.00023794014123268425}, "times": {"epoch_before_hook": 2.999801654368639e-05, "timestep_before_hook": 0.08024435688275844, "sample": 14.503629813785665, "train": 197.32603558327537, "timestep_after_hook": 0.03424161995644681, "training_paths": 0.07589897501748055, "evaluation_paths": 0.4947801759990398, "training_metrics": 0.0015297890058718622, "evaluation_metrics": 0.0004049290146213025, "epoch_after_hook": 1.5200057532638311e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14741.963621085146, "last-path-return": 14741.963621085146, "episodes": 2060, "total-samples": 2060000}, "epoch": 81, "timestep": 25000, "total_timestep": 2050000, "num_train_steps": 2050000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 82, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-02-22", "timestamp": 1652828542, "time_this_iter_s": 212.91270065307617, "time_total_s": 19400.29594016075, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 19400.29594016075, "timesteps_since_restore": 0, "iterations_since_restore": 82, "trial_id": "31acc_00000"}
{"alpha": 0.44034305214881897, "policy": {"shifts-mean": -0.07273128628730774, "shifts-std": 1.4370063543319702, "shifts-max": 3.7917892932891846, "shifts-min": -2.8616151809692383, "scales-mean": 0.43451571464538574, "scales-std": 0.16523972153663635, "scales-max": 1.2209936380386353, "scales-min": 0.03161940723657608, "entropy-mean": -6.273547172546387, "entropy-std": 3.8010947704315186, "actions-mean": -0.04816519096493721, "actions-std": 0.7779595851898193, "actions-min": -0.9986894726753235, "actions-max": 0.9999944567680359}, "evaluation": {"episode-reward-mean": 14266.3681640625, "episode-reward-min": 14266.3681640625, "episode-reward-max": 14266.3681640625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8406241769889063, "reward_run-last-mean": 17.364018894156743, "reward_run-mean-mean": 14.625691210984442, "reward_run-median-mean": 15.868050332884991, "reward_run-range-mean": 18.482009381310885, "reward_ctrl-first-mean": -0.37662594318389897, "reward_ctrl-last-mean": -0.18448314666748047, "reward_ctrl-mean-mean": -0.3593231342315674, "reward_ctrl-median-mean": -0.35994758605957033, "reward_ctrl-range-mean": 0.4786228179931641}}, "training": {"episode-reward-mean": 14554.399715426005, "episode-reward-min": 14359.536920152, "episode-reward-max": 14727.601348517646, "episode-reward-std": 111.3951837242266, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4760694715011253, "reward_run-last-mean": 15.933139747647147, "reward_run-mean-mean": 14.895104442184007, "reward_run-median-mean": 15.776168542827264, "reward_run-range-mean": 18.216023120830002, "reward_ctrl-first-mean": -0.25963874578475954, "reward_ctrl-last-mean": -0.38068579673767095, "reward_ctrl-mean-mean": -0.3407047267580033, "reward_ctrl-median-mean": -0.3431879448890686, "reward_ctrl-range-mean": 0.4747791802883148}}, "update": {"Q_value-mean": 1180.8885498046875, "Q_loss-mean": 23.00617027282715, "policy_loss-mean": -1180.00830078125, "alpha": 0.43024659156799316, "alpha_loss-mean": -0.00041820493061095476}, "times": {"epoch_before_hook": 3.375799860805273e-05, "timestep_before_hook": 0.0793371711333748, "sample": 14.560087357327575, "train": 197.7070440670068, "timestep_after_hook": 0.034117793053155765, "training_paths": 0.07785569000407122, "evaluation_paths": 0.4941135559929535, "training_metrics": 0.0015754949999973178, "evaluation_metrics": 0.0004060329811181873, "epoch_after_hook": 1.4589750207960606e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14741.963621085146, "last-path-return": 14727.601348517655, "episodes": 2085, "total-samples": 2085000}, "epoch": 82, "timestep": 25000, "total_timestep": 2075000, "num_train_steps": 2075000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 83, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-05-56", "timestamp": 1652828756, "time_this_iter_s": 213.34702610969543, "time_total_s": 19613.642966270447, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 19613.642966270447, "timesteps_since_restore": 0, "iterations_since_restore": 83, "trial_id": "31acc_00000"}
{"alpha": 0.42054036259651184, "policy": {"shifts-mean": -0.14148414134979248, "shifts-std": 1.3446180820465088, "shifts-max": 3.1448888778686523, "shifts-min": -3.090714454650879, "scales-mean": 0.40265917778015137, "scales-std": 0.17003434896469116, "scales-max": 0.9393225312232971, "scales-min": 0.023681635037064552, "entropy-mean": -5.91636848449707, "entropy-std": 3.8218207359313965, "actions-mean": -0.06838590651750565, "actions-std": 0.7515565156936646, "actions-min": -0.9991925954818726, "actions-max": 0.9988296627998352}, "evaluation": {"episode-reward-mean": 14715.857421875, "episode-reward-min": 14715.857421875, "episode-reward-max": 14715.857421875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7494146563150328, "reward_run-last-mean": 16.17956513775198, "reward_run-mean-mean": 15.060905695254165, "reward_run-median-mean": 15.988599900731657, "reward_run-range-mean": 18.226768394578478, "reward_ctrl-first-mean": -0.3986980438232422, "reward_ctrl-last-mean": -0.36430010795593265, "reward_ctrl-mean-mean": -0.3450482335567474, "reward_ctrl-median-mean": -0.3523072361946106, "reward_ctrl-range-mean": 0.479391098022461}}, "training": {"episode-reward-mean": 13395.266450247917, "episode-reward-min": 2825.854944284427, "episode-reward-max": 14767.110761458174, "episode-reward-std": 3526.6354255744895, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.43948965986835786, "reward_run-last-mean": 14.615175464998345, "reward_run-mean-mean": 13.735063033474239, "reward_run-median-mean": 14.276476595125573, "reward_run-range-mean": 18.2233280224144, "reward_ctrl-first-mean": -0.27912445306777955, "reward_ctrl-last-mean": -0.3222670483589173, "reward_ctrl-mean-mean": -0.3397965832263231, "reward_ctrl-median-mean": -0.34170670509338386, "reward_ctrl-range-mean": 0.4797499263286591}}, "update": {"Q_value-mean": 1188.6878662109375, "Q_loss-mean": 22.684200286865234, "policy_loss-mean": -1187.77685546875, "alpha": 0.4279356896877289, "alpha_loss-mean": 0.0006851440411992371}, "times": {"epoch_before_hook": 2.9371993150562048e-05, "timestep_before_hook": 0.08026035575312562, "sample": 14.47506961930776, "train": 197.74247153275064, "timestep_after_hook": 0.0343075665878132, "training_paths": 0.0746117550006602, "evaluation_paths": 0.49520686198957264, "training_metrics": 0.001537803007522598, "evaluation_metrics": 0.0004020890046376735, "epoch_after_hook": 1.6449776012450457e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14767.11076145816, "last-path-return": 14636.602736753135, "episodes": 2110, "total-samples": 2110000}, "epoch": 83, "timestep": 25000, "total_timestep": 2100000, "num_train_steps": 2100000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 84, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-09-29", "timestamp": 1652828969, "time_this_iter_s": 213.29732131958008, "time_total_s": 19826.940287590027, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 19826.940287590027, "timesteps_since_restore": 0, "iterations_since_restore": 84, "trial_id": "31acc_00000"}
{"alpha": 0.41998621821403503, "policy": {"shifts-mean": -0.09986745566129684, "shifts-std": 1.3660175800323486, "shifts-max": 3.7205517292022705, "shifts-min": -2.838819980621338, "scales-mean": 0.41552749276161194, "scales-std": 0.16669976711273193, "scales-max": 0.9726710319519043, "scales-min": 0.02595713920891285, "entropy-mean": -6.004846572875977, "entropy-std": 3.578007698059082, "actions-mean": -0.08445940166711807, "actions-std": 0.7616221904754639, "actions-min": -0.9990086555480957, "actions-max": 0.9991084337234497}, "evaluation": {"episode-reward-mean": 14732.3779296875, "episode-reward-min": 14732.3779296875, "episode-reward-max": 14732.3779296875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.06211481394282181, "reward_run-last-mean": 15.61265646990023, "reward_run-mean-mean": 15.075498790054898, "reward_run-median-mean": 15.940224930027256, "reward_run-range-mean": 17.754079841159495, "reward_ctrl-first-mean": -0.2831505537033081, "reward_ctrl-last-mean": -0.4593932628631592, "reward_ctrl-mean-mean": -0.34312100704908377, "reward_ctrl-median-mean": -0.34205149412155156, "reward_ctrl-range-mean": 0.4597933411598206}}, "training": {"episode-reward-mean": 14594.194950474277, "episode-reward-min": 14156.220188340496, "episode-reward-max": 14750.879438587805, "episode-reward-std": 161.7020819472968, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4540873994083029, "reward_run-last-mean": 16.15583221661973, "reward_run-mean-mean": 14.93648532181479, "reward_run-median-mean": 15.793999423494114, "reward_run-range-mean": 18.210592848268465, "reward_ctrl-first-mean": -0.29440473079681395, "reward_ctrl-last-mean": -0.3670282924175263, "reward_ctrl-mean-mean": -0.34229037134051327, "reward_ctrl-median-mean": -0.3457273542881012, "reward_ctrl-range-mean": 0.4594966101646424}}, "update": {"Q_value-mean": 1195.3482666015625, "Q_loss-mean": 23.338172912597656, "policy_loss-mean": -1194.4298095703125, "alpha": 0.42263710498809814, "alpha_loss-mean": 7.150783494580537e-05}, "times": {"epoch_before_hook": 3.152398858219385e-05, "timestep_before_hook": 0.07965302694356069, "sample": 14.527533294458408, "train": 198.4018123151618, "timestep_after_hook": 0.0344492505537346, "training_paths": 0.07880658400245011, "evaluation_paths": 0.49992282697348855, "training_metrics": 0.0016377270221710205, "evaluation_metrics": 0.000425701990025118, "epoch_after_hook": 1.6829872038215399e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14805.569782726467, "last-path-return": 14689.134910609066, "episodes": 2135, "total-samples": 2135000}, "epoch": 84, "timestep": 25000, "total_timestep": 2125000, "num_train_steps": 2125000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 85, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-13-03", "timestamp": 1652829183, "time_this_iter_s": 214.01726031303406, "time_total_s": 20040.95754790306, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 20040.95754790306, "timesteps_since_restore": 0, "iterations_since_restore": 85, "trial_id": "31acc_00000"}
{"alpha": 0.41716697812080383, "policy": {"shifts-mean": -0.1282961368560791, "shifts-std": 1.3608509302139282, "shifts-max": 3.7759711742401123, "shifts-min": -2.6053121089935303, "scales-mean": 0.41612136363983154, "scales-std": 0.1643408238887787, "scales-max": 0.8231271505355835, "scales-min": 0.022324560210108757, "entropy-mean": -5.7572021484375, "entropy-std": 3.367115020751953, "actions-mean": -0.07874421030282974, "actions-std": 0.7514839768409729, "actions-min": -0.998201310634613, "actions-max": 0.9997944831848145}, "evaluation": {"episode-reward-mean": 14682.3359375, "episode-reward-min": 14682.3359375, "episode-reward-max": 14682.3359375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.14864589897003344, "reward_run-last-mean": 17.08077003505423, "reward_run-mean-mean": 15.028252580806212, "reward_run-median-mean": 15.904875779961287, "reward_run-range-mean": 17.529833889752826, "reward_ctrl-first-mean": -0.1915748119354248, "reward_ctrl-last-mean": -0.3481021881103516, "reward_ctrl-mean-mean": -0.34591628049016004, "reward_ctrl-median-mean": -0.3556602120399476, "reward_ctrl-range-mean": 0.4535012722015381}}, "training": {"episode-reward-mean": 14680.633430152502, "episode-reward-min": 14335.157926752421, "episode-reward-max": 14880.164608243855, "episode-reward-std": 144.14149676540057, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6139510607398669, "reward_run-last-mean": 16.312725104045057, "reward_run-mean-mean": 15.02402630418953, "reward_run-median-mean": 15.850916933647369, "reward_run-range-mean": 18.305514115956132, "reward_ctrl-first-mean": -0.2685513889789582, "reward_ctrl-last-mean": -0.3761680769920349, "reward_ctrl-mean-mean": -0.3433928740370274, "reward_ctrl-median-mean": -0.3472521531581879, "reward_ctrl-range-mean": 0.4721596211194992}}, "update": {"Q_value-mean": 1203.3731689453125, "Q_loss-mean": 21.857177734375, "policy_loss-mean": -1202.42431640625, "alpha": 0.41965988278388977, "alpha_loss-mean": 0.00013916387979406863}, "times": {"epoch_before_hook": 3.463600296527147e-05, "timestep_before_hook": 0.07960977038601413, "sample": 14.52276482063462, "train": 197.8181445155351, "timestep_after_hook": 0.03447704442078248, "training_paths": 0.07890566700370982, "evaluation_paths": 0.49678135899011977, "training_metrics": 0.0015444330056197941, "evaluation_metrics": 0.0004571430035866797, "epoch_after_hook": 1.781998435035348e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14880.164608243871, "last-path-return": 14755.737023790673, "episodes": 2160, "total-samples": 2160000}, "epoch": 85, "timestep": 25000, "total_timestep": 2150000, "num_train_steps": 2150000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 86, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-16-37", "timestamp": 1652829397, "time_this_iter_s": 213.42674589157104, "time_total_s": 20254.384293794632, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 20254.384293794632, "timesteps_since_restore": 0, "iterations_since_restore": 86, "trial_id": "31acc_00000"}
{"alpha": 0.40963631868362427, "policy": {"shifts-mean": -0.08146503567695618, "shifts-std": 1.3788180351257324, "shifts-max": 3.1792666912078857, "shifts-min": -3.2170422077178955, "scales-mean": 0.40951910614967346, "scales-std": 0.1693343222141266, "scales-max": 0.8369747996330261, "scales-min": 0.02523604780435562, "entropy-mean": -5.879854202270508, "entropy-std": 3.7152068614959717, "actions-mean": -0.06004684790968895, "actions-std": 0.7542783617973328, "actions-min": -0.9988057613372803, "actions-max": 0.9982823729515076}, "evaluation": {"episode-reward-mean": 14823.494140625, "episode-reward-min": 14823.494140625, "episode-reward-max": 14823.494140625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.38609613997754033, "reward_run-last-mean": 16.04246892886522, "reward_run-mean-mean": 15.16760654306686, "reward_run-median-mean": 15.959933081817894, "reward_run-range-mean": 18.13038488520468, "reward_ctrl-first-mean": -0.13167208433151245, "reward_ctrl-last-mean": -0.2556422233581543, "reward_ctrl-mean-mean": -0.3441131606519222, "reward_ctrl-median-mean": -0.3392827987670899, "reward_ctrl-range-mean": 0.48736346364021305}}, "training": {"episode-reward-mean": 14723.16773065882, "episode-reward-min": 14479.274339906551, "episode-reward-max": 14878.073008905685, "episode-reward-std": 110.40924083271462, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.3470852803315081, "reward_run-last-mean": 16.329306947491887, "reward_run-mean-mean": 15.067603698559575, "reward_run-median-mean": 15.877292865000285, "reward_run-range-mean": 18.231452930599765, "reward_ctrl-first-mean": -0.27238277196884153, "reward_ctrl-last-mean": -0.34259479761123657, "reward_ctrl-mean-mean": -0.34443596790075304, "reward_ctrl-median-mean": -0.34843788623809824, "reward_ctrl-range-mean": 0.4770446985960007}}, "update": {"Q_value-mean": 1211.524169921875, "Q_loss-mean": 20.68079948425293, "policy_loss-mean": -1210.5467529296875, "alpha": 0.41340553760528564, "alpha_loss-mean": 0.0002472373889759183}, "times": {"epoch_before_hook": 4.333799006417394e-05, "timestep_before_hook": 0.08024618998751976, "sample": 14.579885583691066, "train": 197.9107782857318, "timestep_after_hook": 0.034686984261497855, "training_paths": 0.07589815399842337, "evaluation_paths": 0.4963506040221546, "training_metrics": 0.0015391220222227275, "evaluation_metrics": 0.00040981400525197387, "epoch_after_hook": 1.5900004655122757e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14880.164608243871, "last-path-return": 14878.073008905685, "episodes": 2185, "total-samples": 2185000}, "epoch": 86, "timestep": 25000, "total_timestep": 2175000, "num_train_steps": 2175000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 87, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-20-10", "timestamp": 1652829610, "time_this_iter_s": 213.5745358467102, "time_total_s": 20467.958829641342, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 20467.958829641342, "timesteps_since_restore": 0, "iterations_since_restore": 87, "trial_id": "31acc_00000"}
{"alpha": 0.3985052704811096, "policy": {"shifts-mean": -0.07494694739580154, "shifts-std": 1.3670685291290283, "shifts-max": 4.807919979095459, "shifts-min": -2.6301794052124023, "scales-mean": 0.4188230335712433, "scales-std": 0.16312213242053986, "scales-max": 0.9568442702293396, "scales-min": 0.024852033704519272, "entropy-mean": -5.739002227783203, "entropy-std": 3.8328216075897217, "actions-mean": -0.05208860710263252, "actions-std": 0.7558833360671997, "actions-min": -0.9967908263206482, "actions-max": 0.9998862147331238}, "evaluation": {"episode-reward-mean": 14711.5654296875, "episode-reward-min": 14711.5654296875, "episode-reward-max": 14711.5654296875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.44776199376689735, "reward_run-last-mean": 16.003093690610513, "reward_run-mean-mean": 15.06541864692371, "reward_run-median-mean": 15.925065421158706, "reward_run-range-mean": 18.620088322713233, "reward_ctrl-first-mean": -0.2421527147293091, "reward_ctrl-last-mean": -0.5159015655517578, "reward_ctrl-mean-mean": -0.3538530341565609, "reward_ctrl-median-mean": -0.35267112255096433, "reward_ctrl-range-mean": 0.47944334149360657}}, "training": {"episode-reward-mean": 14732.049517338219, "episode-reward-min": 14599.208409979376, "episode-reward-max": 14857.155991462583, "episode-reward-std": 84.55709567752521, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5759320603402923, "reward_run-last-mean": 16.073026737378086, "reward_run-mean-mean": 15.077045329674425, "reward_run-median-mean": 15.898437854859466, "reward_run-range-mean": 18.332930352925864, "reward_ctrl-first-mean": -0.3015681779384613, "reward_ctrl-last-mean": -0.36163218736648567, "reward_ctrl-mean-mean": -0.3449958123362064, "reward_ctrl-median-mean": -0.3477552556991578, "reward_ctrl-range-mean": 0.48710910856723794}}, "update": {"Q_value-mean": 1219.2840576171875, "Q_loss-mean": 19.201690673828125, "policy_loss-mean": -1218.27978515625, "alpha": 0.4089250862598419, "alpha_loss-mean": 0.0004457433824427426}, "times": {"epoch_before_hook": 3.313500201329589e-05, "timestep_before_hook": 0.08021488250233233, "sample": 14.55553284479538, "train": 197.66906639467925, "timestep_after_hook": 0.03463721668231301, "training_paths": 0.07655228700605221, "evaluation_paths": 0.527414816984674, "training_metrics": 0.001537921983981505, "evaluation_metrics": 0.0004117290081921965, "epoch_after_hook": 1.9849976524710655e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14880.164608243871, "last-path-return": 14667.277295806934, "episodes": 2210, "total-samples": 2210000}, "epoch": 87, "timestep": 25000, "total_timestep": 2200000, "num_train_steps": 2200000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 88, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-23-44", "timestamp": 1652829824, "time_this_iter_s": 213.33956837654114, "time_total_s": 20681.298398017883, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 20681.298398017883, "timesteps_since_restore": 0, "iterations_since_restore": 88, "trial_id": "31acc_00000"}
{"alpha": 0.3957633376121521, "policy": {"shifts-mean": -0.09379959851503372, "shifts-std": 1.3833842277526855, "shifts-max": 3.7069647312164307, "shifts-min": -3.180553913116455, "scales-mean": 0.41701623797416687, "scales-std": 0.16439278423786163, "scales-max": 0.8532155752182007, "scales-min": 0.023936809971928596, "entropy-mean": -6.1200270652771, "entropy-std": 4.03231954574585, "actions-mean": -0.08422105759382248, "actions-std": 0.7579125761985779, "actions-min": -0.9988089799880981, "actions-max": 0.9997521042823792}, "evaluation": {"episode-reward-mean": 14791.3369140625, "episode-reward-min": 14791.3369140625, "episode-reward-max": 14791.3369140625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5848325073691807, "reward_run-last-mean": 15.97668014253486, "reward_run-mean-mean": 15.144015067473315, "reward_run-median-mean": 16.113664080091326, "reward_run-range-mean": 18.311904832302215, "reward_ctrl-first-mean": -0.23701508045196534, "reward_ctrl-last-mean": -0.4928434848785401, "reward_ctrl-mean-mean": -0.3526775374233723, "reward_ctrl-median-mean": -0.34813232421875, "reward_ctrl-range-mean": 0.4807204961776734}}, "training": {"episode-reward-mean": 14650.462454009516, "episode-reward-min": 14246.479373281141, "episode-reward-max": 14875.278533380124, "episode-reward-std": 212.69157625193162, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6751382615890122, "reward_run-last-mean": 16.369718636241032, "reward_run-mean-mean": 14.99592739639328, "reward_run-median-mean": 15.87957928653995, "reward_run-range-mean": 18.328988877673932, "reward_ctrl-first-mean": -0.32704152584075935, "reward_ctrl-last-mean": -0.34783905506134033, "reward_ctrl-mean-mean": -0.3454649423837662, "reward_ctrl-median-mean": -0.34806082487106327, "reward_ctrl-range-mean": 0.47522706151008604}}, "update": {"Q_value-mean": 1226.3951416015625, "Q_loss-mean": 18.8892879486084, "policy_loss-mean": -1225.345458984375, "alpha": 0.40801408886909485, "alpha_loss-mean": 8.65623660502024e-05}, "times": {"epoch_before_hook": 3.5559991374611855e-05, "timestep_before_hook": 0.08000679008546285, "sample": 14.508328527736012, "train": 197.93536680011312, "timestep_after_hook": 0.03472978941863403, "training_paths": 0.075896141002886, "evaluation_paths": 0.591860718006501, "training_metrics": 0.0014718809979967773, "evaluation_metrics": 0.0004070839786436409, "epoch_after_hook": 1.715001417323947e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14880.164608243871, "last-path-return": 14587.376815013122, "episodes": 2235, "total-samples": 2235000}, "epoch": 88, "timestep": 25000, "total_timestep": 2225000, "num_train_steps": 2225000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 89, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-27-17", "timestamp": 1652830037, "time_this_iter_s": 213.6544132232666, "time_total_s": 20894.95281124115, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 20894.95281124115, "timesteps_since_restore": 0, "iterations_since_restore": 89, "trial_id": "31acc_00000"}
{"alpha": 0.39374449849128723, "policy": {"shifts-mean": -0.11527568101882935, "shifts-std": 1.36162269115448, "shifts-max": 3.57776141166687, "shifts-min": -2.617645740509033, "scales-mean": 0.40055274963378906, "scales-std": 0.1663697212934494, "scales-max": 1.0194932222366333, "scales-min": 0.031802479177713394, "entropy-mean": -5.805234909057617, "entropy-std": 3.685547351837158, "actions-mean": -0.06566555052995682, "actions-std": 0.7562971115112305, "actions-min": -0.9981209635734558, "actions-max": 0.999707818031311}, "evaluation": {"episode-reward-mean": 14808.419921875, "episode-reward-min": 14808.419921875, "episode-reward-max": 14808.419921875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4893301032610728, "reward_run-last-mean": 16.53317275073732, "reward_run-mean-mean": 15.151713895696947, "reward_run-median-mean": 15.87666214468726, "reward_run-range-mean": 18.40219162117027, "reward_ctrl-first-mean": -0.19108405113220217, "reward_ctrl-last-mean": -0.3865010976791382, "reward_ctrl-mean-mean": -0.3432941062808037, "reward_ctrl-median-mean": -0.3455120325088501, "reward_ctrl-range-mean": 0.46528960466384894}}, "training": {"episode-reward-mean": 14695.620277970107, "episode-reward-min": 14329.880806234713, "episode-reward-max": 14873.578692374615, "episode-reward-std": 139.99504414383358, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.43575663296534745, "reward_run-last-mean": 16.130505317259576, "reward_run-mean-mean": 15.041148358414143, "reward_run-median-mean": 15.91101808238227, "reward_run-range-mean": 18.253681779909655, "reward_ctrl-first-mean": -0.27456116437911987, "reward_ctrl-last-mean": -0.34517887234687805, "reward_ctrl-mean-mean": -0.3455280804440379, "reward_ctrl-median-mean": -0.3485885918140411, "reward_ctrl-range-mean": 0.4862851455807686}}, "update": {"Q_value-mean": 1233.1854248046875, "Q_loss-mean": 18.18297576904297, "policy_loss-mean": -1232.0897216796875, "alpha": 0.40440407395362854, "alpha_loss-mean": 0.00012414553202688694}, "times": {"epoch_before_hook": 4.065601387992501e-05, "timestep_before_hook": 0.07910723277018405, "sample": 14.512390748539474, "train": 197.70791442046175, "timestep_after_hook": 0.03478242494747974, "training_paths": 0.0785990220028907, "evaluation_paths": 0.5279657370119821, "training_metrics": 0.0015308820002246648, "evaluation_metrics": 0.00044039098429493606, "epoch_after_hook": 1.7669808585196733e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14908.037824964285, "last-path-return": 14707.632024473744, "episodes": 2260, "total-samples": 2260000}, "epoch": 89, "timestep": 25000, "total_timestep": 2250000, "num_train_steps": 2250000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 90, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-30-51", "timestamp": 1652830251, "time_this_iter_s": 213.33878922462463, "time_total_s": 21108.291600465775, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 21108.291600465775, "timesteps_since_restore": 0, "iterations_since_restore": 90, "trial_id": "31acc_00000"}
{"alpha": 0.3996393382549286, "policy": {"shifts-mean": -0.1541597992181778, "shifts-std": 1.311873435974121, "shifts-max": 2.9730982780456543, "shifts-min": -2.885861396789551, "scales-mean": 0.41176000237464905, "scales-std": 0.1695791482925415, "scales-max": 0.8029352426528931, "scales-min": 0.020054930821061134, "entropy-mean": -5.386902332305908, "entropy-std": 3.257838010787964, "actions-mean": -0.08713053911924362, "actions-std": 0.7389442920684814, "actions-min": -0.999045193195343, "actions-max": 0.9985275864601135}, "evaluation": {"episode-reward-mean": 14470.58984375, "episode-reward-min": 14470.58984375, "episode-reward-max": 14470.58984375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4639548496294568, "reward_run-last-mean": 17.191479993966823, "reward_run-mean-mean": 14.80899747009684, "reward_run-median-mean": 15.639957466509031, "reward_run-range-mean": 18.429363276384244, "reward_ctrl-first-mean": -0.25651257038116454, "reward_ctrl-last-mean": -0.404729175567627, "reward_ctrl-mean-mean": -0.33840801177024843, "reward_ctrl-median-mean": -0.3414965271949768, "reward_ctrl-range-mean": 0.4916201591491699}}, "training": {"episode-reward-mean": 14768.219672297293, "episode-reward-min": 14408.190825624943, "episode-reward-max": 14891.656072190162, "episode-reward-std": 137.3674365593852, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6131758716223261, "reward_run-last-mean": 16.740208069265236, "reward_run-mean-mean": 15.115953673856016, "reward_run-median-mean": 15.943006623096906, "reward_run-range-mean": 18.430476138028016, "reward_ctrl-first-mean": -0.3005510842800141, "reward_ctrl-last-mean": -0.30575598001480103, "reward_ctrl-mean-mean": -0.3477340015587211, "reward_ctrl-median-mean": -0.3502908289432526, "reward_ctrl-range-mean": 0.48452115088701253}}, "update": {"Q_value-mean": 1241.581787109375, "Q_loss-mean": 17.51010513305664, "policy_loss-mean": -1240.490478515625, "alpha": 0.39564305543899536, "alpha_loss-mean": -0.00018587974773254246}, "times": {"epoch_before_hook": 3.778599784709513e-05, "timestep_before_hook": 0.0788432024710346, "sample": 14.507317535899347, "train": 197.62834151583957, "timestep_after_hook": 0.034726095967926085, "training_paths": 0.18865710301906802, "evaluation_paths": 0.4978427210007794, "training_metrics": 0.0014763959916308522, "evaluation_metrics": 0.0004053330048918724, "epoch_after_hook": 1.8859864212572575e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14908.037824964285, "last-path-return": 14769.07667953646, "episodes": 2285, "total-samples": 2285000}, "epoch": 90, "timestep": 25000, "total_timestep": 2275000, "num_train_steps": 2275000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 91, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-34-24", "timestamp": 1652830464, "time_this_iter_s": 213.33316850662231, "time_total_s": 21321.624768972397, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 21321.624768972397, "timesteps_since_restore": 0, "iterations_since_restore": 91, "trial_id": "31acc_00000"}
{"alpha": 0.3933064341545105, "policy": {"shifts-mean": -0.07918866723775864, "shifts-std": 1.3831770420074463, "shifts-max": 3.406151533126831, "shifts-min": -3.0972743034362793, "scales-mean": 0.42386746406555176, "scales-std": 0.1678587794303894, "scales-max": 1.3442051410675049, "scales-min": 0.018070386722683907, "entropy-mean": -6.022902488708496, "entropy-std": 3.3810606002807617, "actions-mean": -0.04716235771775246, "actions-std": 0.7579578757286072, "actions-min": -0.9996420741081238, "actions-max": 0.9992337822914124}, "evaluation": {"episode-reward-mean": 14940.267578125, "episode-reward-min": 14940.267578125, "episode-reward-max": 14940.267578125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.33562785790873323, "reward_run-last-mean": 15.74638440445824, "reward_run-mean-mean": 15.284130518126746, "reward_run-median-mean": 16.05037637916041, "reward_run-range-mean": 18.223221250295246, "reward_ctrl-first-mean": -0.15387606620788574, "reward_ctrl-last-mean": -0.5317872524261474, "reward_ctrl-mean-mean": -0.34386204830408096, "reward_ctrl-median-mean": -0.34564627408981324, "reward_ctrl-range-mean": 0.43902842998504643}}, "training": {"episode-reward-mean": 14739.92170253773, "episode-reward-min": 14336.419785085334, "episode-reward-max": 14957.689317647968, "episode-reward-std": 206.42023108202477, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.48595179788658094, "reward_run-last-mean": 16.738557058097513, "reward_run-mean-mean": 15.089311248055889, "reward_run-median-mean": 15.938383721671215, "reward_run-range-mean": 18.41445387107062, "reward_ctrl-first-mean": -0.23211044251918794, "reward_ctrl-last-mean": -0.3072144711017609, "reward_ctrl-mean-mean": -0.3493895455181598, "reward_ctrl-median-mean": -0.3523296809196473, "reward_ctrl-range-mean": 0.4863317054510118}}, "update": {"Q_value-mean": 1250.1927490234375, "Q_loss-mean": 17.563316345214844, "policy_loss-mean": -1249.099609375, "alpha": 0.38861533999443054, "alpha_loss-mean": 0.0002239679015474394}, "times": {"epoch_before_hook": 3.0351016903296113e-05, "timestep_before_hook": 0.07758286883472465, "sample": 13.95118921075482, "train": 195.59488969884114, "timestep_after_hook": 0.03361939324531704, "training_paths": 0.16731375400559045, "evaluation_paths": 0.48943793901707977, "training_metrics": 0.0014550679770763963, "evaluation_metrics": 0.00040749998879618943, "epoch_after_hook": 1.5440164133906364e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14976.635367162433, "last-path-return": 14891.71380405783, "episodes": 2310, "total-samples": 2310000}, "epoch": 91, "timestep": 25000, "total_timestep": 2300000, "num_train_steps": 2300000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 92, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-37-55", "timestamp": 1652830675, "time_this_iter_s": 210.7033941745758, "time_total_s": 21532.328163146973, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 21532.328163146973, "timesteps_since_restore": 0, "iterations_since_restore": 92, "trial_id": "31acc_00000"}
{"alpha": 0.37381407618522644, "policy": {"shifts-mean": -0.13368399441242218, "shifts-std": 1.3470383882522583, "shifts-max": 3.085035800933838, "shifts-min": -4.420382022857666, "scales-mean": 0.420235276222229, "scales-std": 0.16977573931217194, "scales-max": 1.0551800727844238, "scales-min": 0.02788466215133667, "entropy-mean": -5.738386154174805, "entropy-std": 3.555365800857544, "actions-mean": -0.06785526871681213, "actions-std": 0.7500039339065552, "actions-min": -0.9999369382858276, "actions-max": 0.9981138110160828}, "evaluation": {"episode-reward-mean": 14918.7265625, "episode-reward-min": 14918.7265625, "episode-reward-max": 14918.7265625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5669136129773692, "reward_run-last-mean": 15.624229726297472, "reward_run-mean-mean": 15.26209319473795, "reward_run-median-mean": 15.974224503599999, "reward_run-range-mean": 18.649586447138358, "reward_ctrl-first-mean": -0.33934614658355716, "reward_ctrl-last-mean": -0.36743874549865724, "reward_ctrl-mean-mean": -0.34336776588559154, "reward_ctrl-median-mean": -0.3465705752372742, "reward_ctrl-range-mean": 0.4764732778072357}}, "training": {"episode-reward-mean": 14763.423436370733, "episode-reward-min": 14584.65986701828, "episode-reward-max": 14880.022506570554, "episode-reward-std": 87.97117339995563, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.413435396802754, "reward_run-last-mean": 16.530689138598746, "reward_run-mean-mean": 15.10910279417062, "reward_run-median-mean": 15.944245556185933, "reward_run-range-mean": 18.34694918176094, "reward_ctrl-first-mean": -0.2364169251918793, "reward_ctrl-last-mean": -0.34458212375640873, "reward_ctrl-mean-mean": -0.34567935779988773, "reward_ctrl-median-mean": -0.3502994191646576, "reward_ctrl-range-mean": 0.4793516588211061}}, "update": {"Q_value-mean": 1256.912841796875, "Q_loss-mean": 17.620094299316406, "policy_loss-mean": -1255.793212890625, "alpha": 0.3838675916194916, "alpha_loss-mean": 0.0007000666810199618}, "times": {"epoch_before_hook": 2.5815999833866954e-05, "timestep_before_hook": 0.07650232419837266, "sample": 13.25277781879413, "train": 192.54419402446365, "timestep_after_hook": 0.032584925880655646, "training_paths": 0.1641387410054449, "evaluation_paths": 0.5199803569994401, "training_metrics": 0.0015411550120916218, "evaluation_metrics": 0.0004023280052933842, "epoch_after_hook": 1.6030098777264357e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14976.635367162433, "last-path-return": 14770.14769089281, "episodes": 2335, "total-samples": 2335000}, "epoch": 92, "timestep": 25000, "total_timestep": 2325000, "num_train_steps": 2325000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 93, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-41-22", "timestamp": 1652830882, "time_this_iter_s": 206.97552394866943, "time_total_s": 21739.303687095642, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 21739.303687095642, "timesteps_since_restore": 0, "iterations_since_restore": 93, "trial_id": "31acc_00000"}
{"alpha": 0.37978455424308777, "policy": {"shifts-mean": -0.06310310959815979, "shifts-std": 1.370129108428955, "shifts-max": 3.5488014221191406, "shifts-min": -3.5399112701416016, "scales-mean": 0.4253608286380768, "scales-std": 0.1665831059217453, "scales-max": 0.9722644686698914, "scales-min": 0.03102572076022625, "entropy-mean": -6.142207145690918, "entropy-std": 3.8662760257720947, "actions-mean": -0.04492777958512306, "actions-std": 0.7673640847206116, "actions-min": -0.9979486465454102, "actions-max": 0.9993886947631836}, "evaluation": {"episode-reward-mean": 14494.935546875, "episode-reward-min": 14494.935546875, "episode-reward-max": 14494.935546875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6618695902310708, "reward_run-last-mean": 16.680226219500582, "reward_run-mean-mean": 14.851211974681018, "reward_run-median-mean": 15.838068163455432, "reward_run-range-mean": 18.409755685304752, "reward_ctrl-first-mean": -0.34893193244934084, "reward_ctrl-last-mean": -0.24462363719940186, "reward_ctrl-mean-mean": -0.3562771330356598, "reward_ctrl-median-mean": -0.3574384927749634, "reward_ctrl-range-mean": 0.49191035032272334}}, "training": {"episode-reward-mean": 14739.5365127108, "episode-reward-min": 14282.512433182708, "episode-reward-max": 14883.319445466943, "episode-reward-std": 161.59632069355126, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5529067282590356, "reward_run-last-mean": 15.81883423899626, "reward_run-mean-mean": 15.087069950011719, "reward_run-median-mean": 15.931758204259282, "reward_run-range-mean": 18.297042322436766, "reward_ctrl-first-mean": -0.2732872390747071, "reward_ctrl-last-mean": -0.3992066407203675, "reward_ctrl-mean-mean": -0.3475334373009205, "reward_ctrl-median-mean": -0.35112416625022896, "reward_ctrl-range-mean": 0.48084652543067935}}, "update": {"Q_value-mean": 1265.0791015625, "Q_loss-mean": 18.486787796020508, "policy_loss-mean": -1263.9635009765625, "alpha": 0.37785622477531433, "alpha_loss-mean": -0.00016843991761561483}, "times": {"epoch_before_hook": 2.576899714767933e-05, "timestep_before_hook": 0.07720269737183116, "sample": 13.242699519061716, "train": 192.19625362212537, "timestep_after_hook": 0.03266571680433117, "training_paths": 0.07431286899372935, "evaluation_paths": 0.48655986099038273, "training_metrics": 0.0014993660151958466, "evaluation_metrics": 0.00040373901720158756, "epoch_after_hook": 1.4090037439018488e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14996.245675129587, "last-path-return": 14883.319445466936, "episodes": 2360, "total-samples": 2360000}, "epoch": 93, "timestep": 25000, "total_timestep": 2350000, "num_train_steps": 2350000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 94, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-44-49", "timestamp": 1652831089, "time_this_iter_s": 206.49589896202087, "time_total_s": 21945.799586057663, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 21945.799586057663, "timesteps_since_restore": 0, "iterations_since_restore": 94, "trial_id": "31acc_00000"}
{"alpha": 0.3584900200366974, "policy": {"shifts-mean": -0.10304508358240128, "shifts-std": 1.3714570999145508, "shifts-max": 3.166379928588867, "shifts-min": -2.852933645248413, "scales-mean": 0.4104592800140381, "scales-std": 0.16566991806030273, "scales-max": 1.5608593225479126, "scales-min": 0.022956375032663345, "entropy-mean": -6.035633087158203, "entropy-std": 3.2781460285186768, "actions-mean": -0.061695944517850876, "actions-std": 0.7540570497512817, "actions-min": -0.9978103041648865, "actions-max": 0.9985104203224182}, "evaluation": {"episode-reward-mean": 14721.5986328125, "episode-reward-min": 14721.5986328125, "episode-reward-max": 14721.5986328125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8451709848347627, "reward_run-last-mean": 15.825287593820576, "reward_run-mean-mean": 15.071854445633164, "reward_run-median-mean": 15.950772342445134, "reward_run-range-mean": 18.46957151492588, "reward_ctrl-first-mean": -0.17530269622802735, "reward_ctrl-last-mean": -0.36300957202911377, "reward_ctrl-mean-mean": -0.35025594680309297, "reward_ctrl-median-mean": -0.3569934248924256, "reward_ctrl-range-mean": 0.47202903032302856}}, "training": {"episode-reward-mean": 14825.109509534752, "episode-reward-min": 14648.039174065712, "episode-reward-max": 14957.64797179119, "episode-reward-std": 92.40051159706422, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5700723366142982, "reward_run-last-mean": 16.321832609935655, "reward_run-mean-mean": 15.176181023126162, "reward_run-median-mean": 16.005810210617284, "reward_run-range-mean": 18.441591860507188, "reward_ctrl-first-mean": -0.34582543611526495, "reward_ctrl-last-mean": -0.4091861271858216, "reward_ctrl-mean-mean": -0.35107151359140876, "reward_ctrl-median-mean": -0.35369057893753053, "reward_ctrl-range-mean": 0.4681942129135132}}, "update": {"Q_value-mean": 1272.5648193359375, "Q_loss-mean": 16.06682586669922, "policy_loss-mean": -1271.438232421875, "alpha": 0.3699095845222473, "alpha_loss-mean": 0.0008085203007794917}, "times": {"epoch_before_hook": 2.3922999389469624e-05, "timestep_before_hook": 0.07726588740479201, "sample": 13.359136785933515, "train": 192.18937286394066, "timestep_after_hook": 0.032639510347507894, "training_paths": 0.16198185199755244, "evaluation_paths": 0.49377297001774423, "training_metrics": 0.0014776359894312918, "evaluation_metrics": 0.0004046829999424517, "epoch_after_hook": 1.5969853848218918e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 14996.245675129587, "last-path-return": 14810.111536051734, "episodes": 2385, "total-samples": 2385000}, "epoch": 94, "timestep": 25000, "total_timestep": 2375000, "num_train_steps": 2375000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 95, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-48-15", "timestamp": 1652831295, "time_this_iter_s": 206.7012677192688, "time_total_s": 22152.50085377693, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 22152.50085377693, "timesteps_since_restore": 0, "iterations_since_restore": 95, "trial_id": "31acc_00000"}
{"alpha": 0.37454572319984436, "policy": {"shifts-mean": -0.07423656433820724, "shifts-std": 1.3943266868591309, "shifts-max": 3.842909097671509, "shifts-min": -3.1161997318267822, "scales-mean": 0.4280184805393219, "scales-std": 0.16683857142925262, "scales-max": 1.0837010145187378, "scales-min": 0.03280069679021835, "entropy-mean": -6.042272567749023, "entropy-std": 3.6218101978302, "actions-mean": -0.060988426208496094, "actions-std": 0.7671230435371399, "actions-min": -0.9993280172348022, "actions-max": 0.9998891949653625}, "evaluation": {"episode-reward-mean": 15017.859375, "episode-reward-min": 15017.859375, "episode-reward-max": 15017.859375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.801552876624303, "reward_run-last-mean": 17.53254100274262, "reward_run-mean-mean": 15.373255695791144, "reward_run-median-mean": 16.112775991796866, "reward_run-range-mean": 18.74690914071218, "reward_ctrl-first-mean": -0.36820402145385744, "reward_ctrl-last-mean": -0.3011486053466797, "reward_ctrl-mean-mean": -0.3553950781583786, "reward_ctrl-median-mean": -0.3547836661338806, "reward_ctrl-range-mean": 0.48333989977836606}}, "training": {"episode-reward-mean": 14642.584789167213, "episode-reward-min": 14173.42634498546, "episode-reward-max": 14910.604446186186, "episode-reward-std": 240.65136657336285, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6015757722116786, "reward_run-last-mean": 16.235983099059695, "reward_run-mean-mean": 14.99370142920958, "reward_run-median-mean": 15.91800041753055, "reward_run-range-mean": 18.47060912625187, "reward_ctrl-first-mean": -0.2778801774978638, "reward_ctrl-last-mean": -0.35825330972671504, "reward_ctrl-mean-mean": -0.35111664004236454, "reward_ctrl-median-mean": -0.3545652401447296, "reward_ctrl-range-mean": 0.4853283855319024}}, "update": {"Q_value-mean": 1280.4388427734375, "Q_loss-mean": 15.70362377166748, "policy_loss-mean": -1279.272216796875, "alpha": 0.3687247633934021, "alpha_loss-mean": -0.0005246050423011184}, "times": {"epoch_before_hook": 2.584498724900186e-05, "timestep_before_hook": 0.07601476137642749, "sample": 13.208804186142515, "train": 192.41798193720751, "timestep_after_hook": 0.03260161684011109, "training_paths": 0.16421195899602026, "evaluation_paths": 0.49336983502143994, "training_metrics": 0.0015188420074991882, "evaluation_metrics": 0.00039912399370223284, "epoch_after_hook": 1.5380210243165493e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15012.498945047435, "last-path-return": 14632.013309245564, "episodes": 2410, "total-samples": 2410000}, "epoch": 95, "timestep": 25000, "total_timestep": 2400000, "num_train_steps": 2400000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 96, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-51-42", "timestamp": 1652831502, "time_this_iter_s": 206.7791349887848, "time_total_s": 22359.279988765717, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 22359.279988765717, "timesteps_since_restore": 0, "iterations_since_restore": 96, "trial_id": "31acc_00000"}
{"alpha": 0.37126678228378296, "policy": {"shifts-mean": -0.0725930705666542, "shifts-std": 1.3476927280426025, "shifts-max": 2.9781174659729004, "shifts-min": -2.7092435359954834, "scales-mean": 0.4127051830291748, "scales-std": 0.16571955382823944, "scales-max": 0.8815736770629883, "scales-min": 0.022047867998480797, "entropy-mean": -5.660909652709961, "entropy-std": 3.523646116256714, "actions-mean": -0.04661563038825989, "actions-std": 0.7553390860557556, "actions-min": -0.9981162548065186, "actions-max": 0.9991456270217896}, "evaluation": {"episode-reward-mean": 14726.2451171875, "episode-reward-min": 14726.2451171875, "episode-reward-max": 14726.2451171875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5965391514502006, "reward_run-last-mean": 15.900580534209894, "reward_run-mean-mean": 15.07456318568652, "reward_run-median-mean": 15.83970925168046, "reward_run-range-mean": 18.454867707382203, "reward_ctrl-first-mean": -0.20626745223999024, "reward_ctrl-last-mean": -0.28502516746520995, "reward_ctrl-mean-mean": -0.3483180840849876, "reward_ctrl-median-mean": -0.34909709692001345, "reward_ctrl-range-mean": 0.46995196342468265}}, "training": {"episode-reward-mean": 14825.638082504165, "episode-reward-min": 14682.272829372378, "episode-reward-max": 14959.57464489029, "episode-reward-std": 101.3076293476769, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6635439562506191, "reward_run-last-mean": 16.410324533145058, "reward_run-mean-mean": 15.177520025758042, "reward_run-median-mean": 16.012184797510102, "reward_run-range-mean": 18.623684623096718, "reward_ctrl-first-mean": -0.33047600984573366, "reward_ctrl-last-mean": -0.35073357105255126, "reward_ctrl-mean-mean": -0.3518819432538748, "reward_ctrl-median-mean": -0.3545122420787812, "reward_ctrl-range-mean": 0.4705405128002166}}, "update": {"Q_value-mean": 1286.5435791015625, "Q_loss-mean": 14.83983039855957, "policy_loss-mean": -1285.360107421875, "alpha": 0.3644042909145355, "alpha_loss-mean": 0.0001300620788242668}, "times": {"epoch_before_hook": 2.4900014977902174e-05, "timestep_before_hook": 0.07809619212639518, "sample": 13.165847453288734, "train": 192.27870821091346, "timestep_after_hook": 0.03259880922269076, "training_paths": 0.07337150198873132, "evaluation_paths": 0.48785009401035495, "training_metrics": 0.0015583870117552578, "evaluation_metrics": 0.0004204860015306622, "epoch_after_hook": 1.4849938452243805e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15022.176444896357, "last-path-return": 14783.67160675694, "episodes": 2435, "total-samples": 2435000}, "epoch": 96, "timestep": 25000, "total_timestep": 2425000, "num_train_steps": 2425000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 97, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-55-09", "timestamp": 1652831709, "time_this_iter_s": 206.50293016433716, "time_total_s": 22565.782918930054, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 22565.782918930054, "timesteps_since_restore": 0, "iterations_since_restore": 97, "trial_id": "31acc_00000"}
{"alpha": 0.3396385908126831, "policy": {"shifts-mean": -0.045381415635347366, "shifts-std": 1.384296178817749, "shifts-max": 3.350001573562622, "shifts-min": -3.344313144683838, "scales-mean": 0.41907739639282227, "scales-std": 0.16518926620483398, "scales-max": 0.8841490149497986, "scales-min": 0.02177482843399048, "entropy-mean": -5.731490612030029, "entropy-std": 3.544051170349121, "actions-mean": -0.030991286039352417, "actions-std": 0.7634024620056152, "actions-min": -0.9997767210006714, "actions-max": 0.9980388879776001}, "evaluation": {"episode-reward-mean": 14978.2109375, "episode-reward-min": 14978.2109375, "episode-reward-max": 14978.2109375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6699081222332073, "reward_run-last-mean": 16.14958693339986, "reward_run-mean-mean": 15.33269522061482, "reward_run-median-mean": 16.159173739745967, "reward_run-range-mean": 18.52734041677149, "reward_ctrl-first-mean": -0.30314991474151615, "reward_ctrl-last-mean": -0.47034692764282227, "reward_ctrl-mean-mean": -0.35448387211561205, "reward_ctrl-median-mean": -0.34780468940734866, "reward_ctrl-range-mean": 0.4420360565185547}}, "training": {"episode-reward-mean": 14843.041149079112, "episode-reward-min": 14242.780359138913, "episode-reward-max": 15048.575703377664, "episode-reward-std": 220.39283875386357, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6514316454496948, "reward_run-last-mean": 16.60752033273957, "reward_run-mean-mean": 15.195341560258774, "reward_run-median-mean": 16.060139338663745, "reward_run-range-mean": 18.580555196085566, "reward_ctrl-first-mean": -0.2966770553588868, "reward_ctrl-last-mean": -0.30828473925590516, "reward_ctrl-mean-mean": -0.35230041117966177, "reward_ctrl-median-mean": -0.35652557969093324, "reward_ctrl-range-mean": 0.48261844575405116}}, "update": {"Q_value-mean": 1293.2705078125, "Q_loss-mean": 14.61571216583252, "policy_loss-mean": -1292.0758056640625, "alpha": 0.3568842113018036, "alpha_loss-mean": 0.0011663002660498023}, "times": {"epoch_before_hook": 2.4526991182938218e-05, "timestep_before_hook": 0.07620500650955364, "sample": 13.151431678998051, "train": 192.3032570934738, "timestep_after_hook": 0.03265800653025508, "training_paths": 0.07288555699051358, "evaluation_paths": 0.49134093400789425, "training_metrics": 0.0015070659865159541, "evaluation_metrics": 0.00040264599374495447, "epoch_after_hook": 1.3799872249364853e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15048.575703377654, "last-path-return": 14996.115268532561, "episodes": 2460, "total-samples": 2460000}, "epoch": 97, "timestep": 25000, "total_timestep": 2450000, "num_train_steps": 2450000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 98, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_00-58-35", "timestamp": 1652831915, "time_this_iter_s": 206.51159167289734, "time_total_s": 22772.29451060295, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 22772.29451060295, "timesteps_since_restore": 0, "iterations_since_restore": 98, "trial_id": "31acc_00000"}
{"alpha": 0.3553146421909332, "policy": {"shifts-mean": -0.04364430904388428, "shifts-std": 1.3647334575653076, "shifts-max": 2.97506046295166, "shifts-min": -3.8765387535095215, "scales-mean": 0.41478899121284485, "scales-std": 0.16093206405639648, "scales-max": 1.1502821445465088, "scales-min": 0.023183923214673996, "entropy-mean": -6.004575252532959, "entropy-std": 3.43863582611084, "actions-mean": -0.03051925264298916, "actions-std": 0.7660796046257019, "actions-min": -0.9984333515167236, "actions-max": 0.9995369911193848}, "evaluation": {"episode-reward-mean": 14900.4951171875, "episode-reward-min": 14900.4951171875, "episode-reward-max": 14900.4951171875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7983951250510781, "reward_run-last-mean": 15.929342425113191, "reward_run-mean-mean": 15.25717147936413, "reward_run-median-mean": 16.08846027452728, "reward_run-range-mean": 18.603633589096567, "reward_ctrl-first-mean": -0.40633974075317386, "reward_ctrl-last-mean": -0.4541015148162842, "reward_ctrl-mean-mean": -0.35667698702812195, "reward_ctrl-median-mean": -0.3502393245697022, "reward_ctrl-range-mean": 0.4541617393493652}}, "training": {"episode-reward-mean": 14794.259400979365, "episode-reward-min": 14574.25182113725, "episode-reward-max": 15084.189589267571, "episode-reward-std": 175.71155312915315, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5658133095222816, "reward_run-last-mean": 16.203568758071697, "reward_run-mean-mean": 15.148017726754034, "reward_run-median-mean": 16.000329355176746, "reward_run-range-mean": 18.463273644546423, "reward_ctrl-first-mean": -0.2970793652534485, "reward_ctrl-last-mean": -0.32964959025382995, "reward_ctrl-mean-mean": -0.35375832577466965, "reward_ctrl-median-mean": -0.35675018310546874, "reward_ctrl-range-mean": 0.4796775746345521}}, "update": {"Q_value-mean": 1297.93212890625, "Q_loss-mean": 16.04684829711914, "policy_loss-mean": -1296.7420654296875, "alpha": 0.3533720374107361, "alpha_loss-mean": -0.0004934262251481414}, "times": {"epoch_before_hook": 2.3810978746041656e-05, "timestep_before_hook": 0.07610176483285613, "sample": 13.60808112763334, "train": 192.63997177773854, "timestep_after_hook": 0.03266782907303423, "training_paths": 0.2233424159931019, "evaluation_paths": 0.5202528469962999, "training_metrics": 0.02805436699418351, "evaluation_metrics": 0.02677464301814325, "epoch_after_hook": 2.082000719383359e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15091.58050983409, "last-path-return": 14941.715861245371, "episodes": 2485, "total-samples": 2485000}, "epoch": 98, "timestep": 25000, "total_timestep": 2475000, "num_train_steps": 2475000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 99, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-02-03", "timestamp": 1652832123, "time_this_iter_s": 207.5575394630432, "time_total_s": 22979.852050065994, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 22979.852050065994, "timesteps_since_restore": 0, "iterations_since_restore": 99, "trial_id": "31acc_00000"}
{"alpha": 0.34921887516975403, "policy": {"shifts-mean": -0.04303364455699921, "shifts-std": 1.4587199687957764, "shifts-max": 3.5458500385284424, "shifts-min": -3.1067395210266113, "scales-mean": 0.4122399389743805, "scales-std": 0.15640012919902802, "scales-max": 0.8529172539710999, "scales-min": 0.031175119802355766, "entropy-mean": -6.747691631317139, "entropy-std": 4.142734050750732, "actions-mean": -0.023960953578352928, "actions-std": 0.7762978076934814, "actions-min": -0.9984834790229797, "actions-max": 0.9991170763969421}, "evaluation": {"episode-reward-mean": 14517.7509765625, "episode-reward-min": 14517.7509765625, "episode-reward-max": 14517.7509765625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8102603339095826, "reward_run-last-mean": 15.375438519399722, "reward_run-mean-mean": 14.88087012849278, "reward_run-median-mean": 15.755747434006935, "reward_run-range-mean": 18.990486774151943, "reward_ctrl-first-mean": -0.4177111148834229, "reward_ctrl-last-mean": -0.30348169803619385, "reward_ctrl-mean-mean": -0.36311928273439414, "reward_ctrl-median-mean": -0.35896326303482057, "reward_ctrl-range-mean": 0.46847383975982665}}, "training": {"episode-reward-mean": 14894.043727063607, "episode-reward-min": 14646.593515626273, "episode-reward-max": 15107.803532567626, "episode-reward-std": 128.12307628220265, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5833345901085262, "reward_run-last-mean": 16.569487286981484, "reward_run-mean-mean": 15.24780955000586, "reward_run-median-mean": 16.0577119852681, "reward_run-range-mean": 18.630530360158826, "reward_ctrl-first-mean": -0.2958590292930603, "reward_ctrl-last-mean": -0.36864766836166385, "reward_ctrl-mean-mean": -0.353765822942257, "reward_ctrl-median-mean": -0.3564169716835022, "reward_ctrl-range-mean": 0.48533189415931705}}, "update": {"Q_value-mean": 1302.6728515625, "Q_loss-mean": 15.386009216308594, "policy_loss-mean": -1301.4610595703125, "alpha": 0.3480520248413086, "alpha_loss-mean": 0.00026794426958076656}, "times": {"epoch_before_hook": 2.7123023755848408e-05, "timestep_before_hook": 0.07687698022346012, "sample": 13.175385919807013, "train": 192.4547746197204, "timestep_after_hook": 0.032650090724928305, "training_paths": 0.1747412889963016, "evaluation_paths": 0.5197216369851958, "training_metrics": 0.0015272030141204596, "evaluation_metrics": 0.0004073790041729808, "epoch_after_hook": 1.535983756184578e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15107.803532567657, "last-path-return": 14785.987425892332, "episodes": 2510, "total-samples": 2510000}, "epoch": 99, "timestep": 25000, "total_timestep": 2500000, "num_train_steps": 2500000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 100, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-05-30", "timestamp": 1652832330, "time_this_iter_s": 206.81732821464539, "time_total_s": 23186.66937828064, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 23186.66937828064, "timesteps_since_restore": 0, "iterations_since_restore": 100, "trial_id": "31acc_00000"}
{"alpha": 0.34071382880210876, "policy": {"shifts-mean": -0.1322549283504486, "shifts-std": 1.3837867975234985, "shifts-max": 3.4275314807891846, "shifts-min": -4.327452182769775, "scales-mean": 0.41726136207580566, "scales-std": 0.1615796685218811, "scales-max": 1.0766841173171997, "scales-min": 0.019683539867401123, "entropy-mean": -6.165999412536621, "entropy-std": 3.752368450164795, "actions-mean": -0.09003183990716934, "actions-std": 0.7622592449188232, "actions-min": -0.9999160766601562, "actions-max": 0.9992928504943848}, "evaluation": {"episode-reward-mean": 14933.533203125, "episode-reward-min": 14933.533203125, "episode-reward-max": 14933.533203125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.786449238941484, "reward_run-last-mean": 16.483101973410612, "reward_run-mean-mean": 15.291865200167743, "reward_run-median-mean": 16.14654071548557, "reward_run-range-mean": 18.65429745219262, "reward_ctrl-first-mean": -0.4679586410522461, "reward_ctrl-last-mean": -0.2370408058166504, "reward_ctrl-mean-mean": -0.35833263211846356, "reward_ctrl-median-mean": -0.35669589042663574, "reward_ctrl-range-mean": 0.48556211590766907}}, "training": {"episode-reward-mean": 14518.72119066954, "episode-reward-min": 11072.356050913497, "episode-reward-max": 15060.635228401734, "episode-reward-std": 1154.1840273325488, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5482977542289269, "reward_run-last-mean": 14.62835676664804, "reward_run-mean-mean": 14.869268581013085, "reward_run-median-mean": 15.998497511677954, "reward_run-range-mean": 18.548381579896596, "reward_ctrl-first-mean": -0.28695774316787725, "reward_ctrl-last-mean": -0.3660105276107788, "reward_ctrl-mean-mean": -0.35054739034354687, "reward_ctrl-median-mean": -0.3555466687679291, "reward_ctrl-range-mean": 0.4914817467331886}}, "update": {"Q_value-mean": 1309.1497802734375, "Q_loss-mean": 14.941954612731934, "policy_loss-mean": -1307.9283447265625, "alpha": 0.34422898292541504, "alpha_loss-mean": 0.0003684028924908489}, "times": {"epoch_before_hook": 2.6074005290865898e-05, "timestep_before_hook": 0.07624912378378212, "sample": 13.24390344080166, "train": 192.7761149230064, "timestep_after_hook": 0.03268409211887047, "training_paths": 0.07298615900799632, "evaluation_paths": 0.488662582996767, "training_metrics": 0.0015257560007739812, "evaluation_metrics": 0.0004191060143057257, "epoch_after_hook": 1.5299883671104908e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15107.803532567657, "last-path-return": 14844.826755974105, "episodes": 2535, "total-samples": 2535000}, "epoch": 100, "timestep": 25000, "total_timestep": 2525000, "num_train_steps": 2525000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 101, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-08-57", "timestamp": 1652832537, "time_this_iter_s": 207.07410883903503, "time_total_s": 23393.743487119675, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 23393.743487119675, "timesteps_since_restore": 0, "iterations_since_restore": 101, "trial_id": "31acc_00000"}
{"alpha": 0.3378216326236725, "policy": {"shifts-mean": -0.10263802856206894, "shifts-std": 1.3851484060287476, "shifts-max": 3.4067580699920654, "shifts-min": -3.2220137119293213, "scales-mean": 0.42768537998199463, "scales-std": 0.15069669485092163, "scales-max": 0.868753969669342, "scales-min": 0.031879957765340805, "entropy-mean": -6.276163578033447, "entropy-std": 3.822688579559326, "actions-mean": -0.07338164001703262, "actions-std": 0.778800904750824, "actions-min": -0.9998904466629028, "actions-max": 0.999032735824585}, "evaluation": {"episode-reward-mean": 14944.26171875, "episode-reward-min": 14944.26171875, "episode-reward-max": 14944.26171875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.062145245885544265, "reward_run-last-mean": 16.88934526028561, "reward_run-mean-mean": 15.296674448184854, "reward_run-median-mean": 16.0845214598271, "reward_run-range-mean": 18.160830060692987, "reward_ctrl-first-mean": -0.19432096481323244, "reward_ctrl-last-mean": -0.3136260271072388, "reward_ctrl-mean-mean": -0.35241385281085974, "reward_ctrl-median-mean": -0.35357233285903933, "reward_ctrl-range-mean": 0.46986571550369266}}, "training": {"episode-reward-mean": 13420.154385534644, "episode-reward-min": 48.9228064810174, "episode-reward-max": 15117.626105862666, "episode-reward-std": 4459.092691051487, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6108455307050866, "reward_run-last-mean": 14.703424409484978, "reward_run-mean-mean": 13.76554557673228, "reward_run-median-mean": 14.495528701629956, "reward_run-range-mean": 17.80658016818468, "reward_ctrl-first-mean": -0.3118235874176025, "reward_ctrl-last-mean": -0.3550076723098755, "reward_ctrl-mean-mean": -0.3453911911976338, "reward_ctrl-median-mean": -0.3488785338401795, "reward_ctrl-range-mean": 0.4887014335393906}}, "update": {"Q_value-mean": 1315.569091796875, "Q_loss-mean": 14.200235366821289, "policy_loss-mean": -1314.3365478515625, "alpha": 0.33744630217552185, "alpha_loss-mean": 0.00015746447024866939}, "times": {"epoch_before_hook": 2.446299185976386e-05, "timestep_before_hook": 0.07765565026784316, "sample": 13.324988353677327, "train": 192.8238998730376, "timestep_after_hook": 0.03264643019065261, "training_paths": 0.073888482991606, "evaluation_paths": 0.4895079590205569, "training_metrics": 0.0015289730217773467, "evaluation_metrics": 0.0004135729977861047, "epoch_after_hook": 1.5260011423379183e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15117.626105862668, "last-path-return": 14754.932086761151, "episodes": 2560, "total-samples": 2560000}, "epoch": 101, "timestep": 25000, "total_timestep": 2550000, "num_train_steps": 2550000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 102, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-12-24", "timestamp": 1652832744, "time_this_iter_s": 207.20602178573608, "time_total_s": 23600.94950890541, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 23600.94950890541, "timesteps_since_restore": 0, "iterations_since_restore": 102, "trial_id": "31acc_00000"}
{"alpha": 0.34773749113082886, "policy": {"shifts-mean": -0.16144461929798126, "shifts-std": 1.4316617250442505, "shifts-max": 3.6347131729125977, "shifts-min": -3.5098588466644287, "scales-mean": 0.4099288880825043, "scales-std": 0.16180391609668732, "scales-max": 1.5466487407684326, "scales-min": 0.026944484561681747, "entropy-mean": -6.694042205810547, "entropy-std": 3.9446957111358643, "actions-mean": -0.09398367255926132, "actions-std": 0.76805579662323, "actions-min": -0.999015212059021, "actions-max": 0.9978329539299011}, "evaluation": {"episode-reward-mean": 14929.041015625, "episode-reward-min": 14929.041015625, "episode-reward-max": 14929.041015625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -1.0097402414999102, "reward_run-last-mean": 17.2206907466375, "reward_run-mean-mean": 15.282730098393325, "reward_run-median-mean": 16.076459643178822, "reward_run-range-mean": 18.81613617812604, "reward_ctrl-first-mean": -0.4382408142089844, "reward_ctrl-last-mean": -0.2880956411361694, "reward_ctrl-mean-mean": -0.35368975577354433, "reward_ctrl-median-mean": -0.35771998167037966, "reward_ctrl-range-mean": 0.48162405490875243}}, "training": {"episode-reward-mean": 14877.440136476896, "episode-reward-min": 14579.527292885628, "episode-reward-max": 15108.820197498299, "episode-reward-std": 175.74561942426652, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.521847153096975, "reward_run-last-mean": 16.29820514520975, "reward_run-mean-mean": 15.234338945835969, "reward_run-median-mean": 16.102189764347543, "reward_run-range-mean": 18.665172258107813, "reward_ctrl-first-mean": -0.28089936614036565, "reward_ctrl-last-mean": -0.39877512454986574, "reward_ctrl-mean-mean": -0.35689880935907364, "reward_ctrl-median-mean": -0.3586446487903595, "reward_ctrl-range-mean": 0.47654347658157353}}, "update": {"Q_value-mean": 1319.326416015625, "Q_loss-mean": 14.658051490783691, "policy_loss-mean": -1318.0577392578125, "alpha": 0.3389396071434021, "alpha_loss-mean": -0.00036002835258841515}, "times": {"epoch_before_hook": 2.5260000256821513e-05, "timestep_before_hook": 0.07718007787480019, "sample": 13.278457331151003, "train": 192.38842125041992, "timestep_after_hook": 0.03255425955285318, "training_paths": 0.07573301301454194, "evaluation_paths": 0.4882214269891847, "training_metrics": 0.0015078189899213612, "evaluation_metrics": 0.0004098209901712835, "epoch_after_hook": 1.5830155462026596e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15117.626105862668, "last-path-return": 14926.894926805302, "episodes": 2585, "total-samples": 2585000}, "epoch": 102, "timestep": 25000, "total_timestep": 2575000, "num_train_steps": 2575000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 103, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-15-51", "timestamp": 1652832951, "time_this_iter_s": 206.72332334518433, "time_total_s": 23807.672832250595, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 23807.672832250595, "timesteps_since_restore": 0, "iterations_since_restore": 103, "trial_id": "31acc_00000"}
{"alpha": 0.3328252136707306, "policy": {"shifts-mean": -0.057614367455244064, "shifts-std": 1.4026840925216675, "shifts-max": 2.939383029937744, "shifts-min": -6.107332706451416, "scales-mean": 0.4234185218811035, "scales-std": 0.16339746117591858, "scales-max": 1.5484459400177002, "scales-min": 0.03291163221001625, "entropy-mean": -5.979207992553711, "entropy-std": 3.6425108909606934, "actions-mean": -0.04259546101093292, "actions-std": 0.7682687044143677, "actions-min": -0.9999990463256836, "actions-max": 0.9962350726127625}, "evaluation": {"episode-reward-mean": 14073.2373046875, "episode-reward-min": 14073.2373046875, "episode-reward-max": 14073.2373046875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.2131839913256145, "reward_run-last-mean": 15.981098723243576, "reward_run-mean-mean": 14.431909118135213, "reward_run-median-mean": 15.958349899086102, "reward_run-range-mean": 18.512827296697616, "reward_ctrl-first-mean": -0.1368542790412903, "reward_ctrl-last-mean": -0.2851850986480713, "reward_ctrl-mean-mean": -0.3586725790977478, "reward_ctrl-median-mean": -0.3617703795433045, "reward_ctrl-range-mean": 0.4904668807983399}}, "training": {"episode-reward-mean": 14848.45811930263, "episode-reward-min": 14480.918021851881, "episode-reward-max": 15057.639004842167, "episode-reward-std": 175.17610727748166, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.425328550247564, "reward_run-last-mean": 16.45503974374583, "reward_run-mean-mean": 15.200720401135328, "reward_run-median-mean": 16.063013561952857, "reward_run-range-mean": 18.568483369098892, "reward_ctrl-first-mean": -0.2170454925298691, "reward_ctrl-last-mean": -0.33674546957015994, "reward_ctrl-mean-mean": -0.35226228183269503, "reward_ctrl-median-mean": -0.354895932674408, "reward_ctrl-range-mean": 0.4892386019229889}}, "update": {"Q_value-mean": 1321.1263427734375, "Q_loss-mean": 15.847479820251465, "policy_loss-mean": -1319.8695068359375, "alpha": 0.3358279764652252, "alpha_loss-mean": 0.0006436404655687511}, "times": {"epoch_before_hook": 2.4281005607917905e-05, "timestep_before_hook": 0.07586515537695959, "sample": 13.692427695175866, "train": 192.4231298348168, "timestep_after_hook": 0.03251529787667096, "training_paths": 0.0736707930045668, "evaluation_paths": 0.48727321400656365, "training_metrics": 0.001489908987423405, "evaluation_metrics": 0.00040932800038717687, "epoch_after_hook": 1.5069963410496712e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15189.010290151644, "last-path-return": 15039.955279736412, "episodes": 2610, "total-samples": 2610000}, "epoch": 103, "timestep": 25000, "total_timestep": 2600000, "num_train_steps": 2600000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 104, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-19-18", "timestamp": 1652833158, "time_this_iter_s": 207.16752099990845, "time_total_s": 24014.840353250504, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 24014.840353250504, "timesteps_since_restore": 0, "iterations_since_restore": 104, "trial_id": "31acc_00000"}
{"alpha": 0.3396456837654114, "policy": {"shifts-mean": -0.044095247983932495, "shifts-std": 1.3745681047439575, "shifts-max": 3.066800355911255, "shifts-min": -2.8827085494995117, "scales-mean": 0.41398775577545166, "scales-std": 0.15892156958580017, "scales-max": 1.221510887145996, "scales-min": 0.026182936504483223, "entropy-mean": -5.988302707672119, "entropy-std": 3.537158250808716, "actions-mean": -0.03157561272382736, "actions-std": 0.7646676301956177, "actions-min": -0.9989103674888611, "actions-max": 0.9985530376434326}, "evaluation": {"episode-reward-mean": 14737.4384765625, "episode-reward-min": 14737.4384765625, "episode-reward-max": 14737.4384765625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7507756801705341, "reward_run-last-mean": 16.516729049453716, "reward_run-mean-mean": 15.0860872655981, "reward_run-median-mean": 15.89815182468783, "reward_run-range-mean": 18.575974391422438, "reward_ctrl-first-mean": -0.3653669118881226, "reward_ctrl-last-mean": -0.44851136207580566, "reward_ctrl-mean-mean": -0.34864857524037357, "reward_ctrl-median-mean": -0.35751731395721437, "reward_ctrl-range-mean": 0.47504006028175355}}, "training": {"episode-reward-mean": 14805.788498889471, "episode-reward-min": 14365.860813167557, "episode-reward-max": 15072.071828508473, "episode-reward-std": 221.8437525891702, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5343879018198923, "reward_run-last-mean": 16.56933029451011, "reward_run-mean-mean": 15.162709661999608, "reward_run-median-mean": 16.013822024888853, "reward_run-range-mean": 18.643745379368927, "reward_ctrl-first-mean": -0.36167630910873416, "reward_ctrl-last-mean": -0.4077320790290832, "reward_ctrl-mean-mean": -0.35692116311013705, "reward_ctrl-median-mean": -0.36023028731346135, "reward_ctrl-range-mean": 0.4896512454748153}}, "update": {"Q_value-mean": 1323.41455078125, "Q_loss-mean": 15.267226219177246, "policy_loss-mean": -1322.1239013671875, "alpha": 0.3381953239440918, "alpha_loss-mean": -0.0002285814844071865}, "times": {"epoch_before_hook": 2.4693988962098956e-05, "timestep_before_hook": 0.07787298137554899, "sample": 14.356815987906884, "train": 192.12258434656542, "timestep_after_hook": 0.032485465839272365, "training_paths": 0.0736119509965647, "evaluation_paths": 0.5162533239927143, "training_metrics": 0.001580930984346196, "evaluation_metrics": 0.0004189040046185255, "epoch_after_hook": 1.4269899111241102e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15189.010290151644, "last-path-return": 14920.109179097686, "episodes": 2635, "total-samples": 2635000}, "epoch": 104, "timestep": 25000, "total_timestep": 2625000, "num_train_steps": 2625000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 105, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-22-46", "timestamp": 1652833366, "time_this_iter_s": 207.56177878379822, "time_total_s": 24222.4021320343, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 24222.4021320343, "timesteps_since_restore": 0, "iterations_since_restore": 105, "trial_id": "31acc_00000"}
{"alpha": 0.34200695157051086, "policy": {"shifts-mean": -0.06976739317178726, "shifts-std": 1.3803619146347046, "shifts-max": 2.8926827907562256, "shifts-min": -3.388547420501709, "scales-mean": 0.42725464701652527, "scales-std": 0.1649131029844284, "scales-max": 1.15939199924469, "scales-min": 0.030246373265981674, "entropy-mean": -5.969470977783203, "entropy-std": 3.181037187576294, "actions-mean": -0.05844927951693535, "actions-std": 0.7631102204322815, "actions-min": -0.9983587265014648, "actions-max": 0.999961793422699}, "evaluation": {"episode-reward-mean": 15072.63671875, "episode-reward-min": 15072.63671875, "episode-reward-max": 15072.63671875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.42268913961782206, "reward_run-last-mean": 15.682265488762823, "reward_run-mean-mean": 15.434336565492119, "reward_run-median-mean": 16.23685006693904, "reward_run-range-mean": 19.21367592766703, "reward_ctrl-first-mean": -0.2721766471862793, "reward_ctrl-last-mean": -0.3588423252105713, "reward_ctrl-mean-mean": -0.36170074177980427, "reward_ctrl-median-mean": -0.3585714340209961, "reward_ctrl-range-mean": 0.46442080736160285}}, "training": {"episode-reward-mean": 13449.37052745176, "episode-reward-min": 2900.9551902734543, "episode-reward-max": 15059.662913789925, "episode-reward-std": 3540.199861835088, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.505879538617092, "reward_run-last-mean": 14.393297245548752, "reward_run-mean-mean": 13.797872171183949, "reward_run-median-mean": 14.423824879511463, "reward_run-range-mean": 18.774834555495325, "reward_ctrl-first-mean": -0.2983307278156281, "reward_ctrl-last-mean": -0.38498428821563724, "reward_ctrl-mean-mean": -0.3485016437321901, "reward_ctrl-median-mean": -0.3509425592422486, "reward_ctrl-range-mean": 0.49717419207096103}}, "update": {"Q_value-mean": 1324.7781982421875, "Q_loss-mean": 15.694680213928223, "policy_loss-mean": -1323.466796875, "alpha": 0.338056355714798, "alpha_loss-mean": 1.764795342751313e-05}, "times": {"epoch_before_hook": 2.557001425884664e-05, "timestep_before_hook": 0.07715664035640657, "sample": 13.302224620449124, "train": 192.23587457739632, "timestep_after_hook": 0.03245347770280205, "training_paths": 0.07326210298924707, "evaluation_paths": 0.5187819310231134, "training_metrics": 0.0015477239794563502, "evaluation_metrics": 0.0004126239800825715, "epoch_after_hook": 1.6849953681230545e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15189.010290151644, "last-path-return": 15059.66291378994, "episodes": 2660, "total-samples": 2660000}, "epoch": 105, "timestep": 25000, "total_timestep": 2650000, "num_train_steps": 2650000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 106, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-26-13", "timestamp": 1652833573, "time_this_iter_s": 206.62278056144714, "time_total_s": 24429.02491259575, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 24429.02491259575, "timesteps_since_restore": 0, "iterations_since_restore": 106, "trial_id": "31acc_00000"}
{"alpha": 0.3496791422367096, "policy": {"shifts-mean": -0.14250917732715607, "shifts-std": 1.360769271850586, "shifts-max": 2.9942855834960938, "shifts-min": -3.4994750022888184, "scales-mean": 0.42434534430503845, "scales-std": 0.16164003312587738, "scales-max": 1.004791021347046, "scales-min": 0.03667643666267395, "entropy-mean": -5.718233585357666, "entropy-std": 3.4396729469299316, "actions-mean": -0.07279094308614731, "actions-std": 0.7601515650749207, "actions-min": -0.9994143843650818, "actions-max": 0.9994519948959351}, "evaluation": {"episode-reward-mean": 14631.6015625, "episode-reward-min": 14631.6015625, "episode-reward-max": 14631.6015625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.3183815403635354, "reward_run-last-mean": 17.439878850032073, "reward_run-mean-mean": 14.996875883358415, "reward_run-median-mean": 15.947220487092295, "reward_run-range-mean": 18.863149801616935, "reward_ctrl-first-mean": -0.18041160106658938, "reward_ctrl-last-mean": -0.1937542796134949, "reward_ctrl-mean-mean": -0.3652747615337372, "reward_ctrl-median-mean": -0.3638309001922608, "reward_ctrl-range-mean": 0.47995243072509763}}, "training": {"episode-reward-mean": 14774.788689488876, "episode-reward-min": 14266.875237334982, "episode-reward-max": 14967.617534047806, "episode-reward-std": 223.13761874096411, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4373520288859626, "reward_run-last-mean": 16.221513204108078, "reward_run-mean-mean": 15.129265001284883, "reward_run-median-mean": 16.04549352758491, "reward_run-range-mean": 18.38060023464133, "reward_ctrl-first-mean": -0.24889880746603016, "reward_ctrl-last-mean": -0.3774952733516693, "reward_ctrl-mean-mean": -0.3544763117960096, "reward_ctrl-median-mean": -0.3599473023414612, "reward_ctrl-range-mean": 0.4939892944693566}}, "update": {"Q_value-mean": 1324.5911865234375, "Q_loss-mean": 16.49983787536621, "policy_loss-mean": -1323.2230224609375, "alpha": 0.34225496649742126, "alpha_loss-mean": -0.00020596920512616634}, "times": {"epoch_before_hook": 2.955499803647399e-05, "timestep_before_hook": 0.07653121757903136, "sample": 13.20169767003972, "train": 192.311161909136, "timestep_after_hook": 0.032632923423079774, "training_paths": 0.07398449201718904, "evaluation_paths": 0.48857528500957415, "training_metrics": 0.0015956210263539106, "evaluation_metrics": 0.0004214979999233037, "epoch_after_hook": 1.8110149540007114e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15189.010290151644, "last-path-return": 14950.87984834766, "episodes": 2685, "total-samples": 2685000}, "epoch": 106, "timestep": 25000, "total_timestep": 2675000, "num_train_steps": 2675000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 107, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-29-40", "timestamp": 1652833780, "time_this_iter_s": 206.56731867790222, "time_total_s": 24635.59223127365, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 24635.59223127365, "timesteps_since_restore": 0, "iterations_since_restore": 107, "trial_id": "31acc_00000"}
{"alpha": 0.3468119502067566, "policy": {"shifts-mean": -0.056544214487075806, "shifts-std": 1.4171462059020996, "shifts-max": 5.2806830406188965, "shifts-min": -4.659436225891113, "scales-mean": 0.41960814595222473, "scales-std": 0.157815620303154, "scales-max": 0.8327357172966003, "scales-min": 0.013609941117465496, "entropy-mean": -6.183852195739746, "entropy-std": 4.134334564208984, "actions-mean": -0.0447741337120533, "actions-std": 0.7676759362220764, "actions-min": -0.9998840093612671, "actions-max": 0.9999026656150818}, "evaluation": {"episode-reward-mean": 15055.205078125, "episode-reward-min": 15055.205078125, "episode-reward-max": 15055.205078125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7061832357790961, "reward_run-last-mean": 17.245357971476096, "reward_run-mean-mean": 15.407043758951815, "reward_run-median-mean": 16.176159318924306, "reward_run-range-mean": 18.823387104357607, "reward_ctrl-first-mean": -0.33215098381042485, "reward_ctrl-last-mean": -0.2965425491333008, "reward_ctrl-mean-mean": -0.3518382827341556, "reward_ctrl-median-mean": -0.3531309962272644, "reward_ctrl-range-mean": 0.5050415813922882}}, "training": {"episode-reward-mean": 13551.402529501263, "episode-reward-min": 3152.936772975153, "episode-reward-max": 14995.178976947003, "episode-reward-std": 3478.5007638798197, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.344335676884987, "reward_run-last-mean": 13.986793202580316, "reward_run-mean-mean": 13.897833450748863, "reward_run-median-mean": 14.395713324374128, "reward_run-range-mean": 18.3305788923372, "reward_ctrl-first-mean": -0.24269261598587039, "reward_ctrl-last-mean": -0.30437595367431647, "reward_ctrl-mean-mean": -0.3464309212476015, "reward_ctrl-median-mean": -0.3491537785530091, "reward_ctrl-range-mean": 0.49261669397354124}}, "update": {"Q_value-mean": 1323.18896484375, "Q_loss-mean": 16.38972282409668, "policy_loss-mean": -1321.7784423828125, "alpha": 0.34672266244888306, "alpha_loss-mean": 0.0001397668820573017}, "times": {"epoch_before_hook": 2.4998997105285525e-05, "timestep_before_hook": 0.07692704460350797, "sample": 13.366294781822944, "train": 192.15319863893092, "timestep_after_hook": 0.03264605678850785, "training_paths": 0.07383713201852515, "evaluation_paths": 0.4879122350248508, "training_metrics": 0.0015217499749269336, "evaluation_metrics": 0.0004014620208181441, "epoch_after_hook": 1.6039994079619646e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15189.010290151644, "last-path-return": 14995.178976947016, "episodes": 2710, "total-samples": 2710000}, "epoch": 107, "timestep": 25000, "total_timestep": 2700000, "num_train_steps": 2700000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 108, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-33-07", "timestamp": 1652833987, "time_this_iter_s": 206.5742335319519, "time_total_s": 24842.166464805603, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 24842.166464805603, "timesteps_since_restore": 0, "iterations_since_restore": 108, "trial_id": "31acc_00000"}
{"alpha": 0.34280210733413696, "policy": {"shifts-mean": -0.07689765840768814, "shifts-std": 1.3703519105911255, "shifts-max": 3.429563522338867, "shifts-min": -2.85417103767395, "scales-mean": 0.4165695607662201, "scales-std": 0.16028407216072083, "scales-max": 0.9116851091384888, "scales-min": 0.0317099429666996, "entropy-mean": -6.100057125091553, "entropy-std": 3.785944700241089, "actions-mean": -0.05851415917277336, "actions-std": 0.7608988881111145, "actions-min": -0.9974260330200195, "actions-max": 0.9993106126785278}, "evaluation": {"episode-reward-mean": 15171.224609375, "episode-reward-min": 15171.224609375, "episode-reward-max": 15171.224609375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": 0.05347749128634047, "reward_run-last-mean": 16.84930916651865, "reward_run-mean-mean": 15.524340955242707, "reward_run-median-mean": 16.34660151034609, "reward_run-range-mean": 18.164411790879356, "reward_ctrl-first-mean": -0.35430493354797366, "reward_ctrl-last-mean": -0.28059256076812744, "reward_ctrl-mean-mean": -0.35311649268269535, "reward_ctrl-median-mean": -0.3562985539436341, "reward_ctrl-range-mean": 0.46798345446586614}}, "training": {"episode-reward-mean": 14679.369794543916, "episode-reward-min": 13195.118714763592, "episode-reward-max": 15091.222457792011, "episode-reward-std": 532.1419301631723, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.334314852799965, "reward_run-last-mean": 16.07679229899395, "reward_run-mean-mean": 15.033527636203107, "reward_run-median-mean": 16.041430727324766, "reward_run-range-mean": 18.73737785260492, "reward_ctrl-first-mean": -0.2714151000976563, "reward_ctrl-last-mean": -0.36288915157318125, "reward_ctrl-mean-mean": -0.3541578416591883, "reward_ctrl-median-mean": -0.35863064289093016, "reward_ctrl-range-mean": 0.486654726266861}}, "update": {"Q_value-mean": 1322.4525146484375, "Q_loss-mean": 16.396665573120117, "policy_loss-mean": -1321.066650390625, "alpha": 0.34137508273124695, "alpha_loss-mean": 0.00018249887216370553}, "times": {"epoch_before_hook": 2.6395980967208743e-05, "timestep_before_hook": 0.0761755520652514, "sample": 13.300278034934308, "train": 193.61228166733054, "timestep_after_hook": 0.032517542043933645, "training_paths": 0.07350053897243924, "evaluation_paths": 0.4876484540000092, "training_metrics": 0.0015215989842545241, "evaluation_metrics": 0.00040716599323786795, "epoch_after_hook": 1.4720135368406773e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15189.010290151644, "last-path-return": 15080.630817776397, "episodes": 2735, "total-samples": 2735000}, "epoch": 108, "timestep": 25000, "total_timestep": 2725000, "num_train_steps": 2725000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 109, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-36-35", "timestamp": 1652834195, "time_this_iter_s": 208.0542585849762, "time_total_s": 25050.22072339058, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 25050.22072339058, "timesteps_since_restore": 0, "iterations_since_restore": 109, "trial_id": "31acc_00000"}
{"alpha": 0.32414719462394714, "policy": {"shifts-mean": -0.012080262415111065, "shifts-std": 1.3747284412384033, "shifts-max": 3.2781641483306885, "shifts-min": -3.410428524017334, "scales-mean": 0.4188730716705322, "scales-std": 0.16309493780136108, "scales-max": 1.4120486974716187, "scales-min": 0.028002409264445305, "entropy-mean": -5.828539848327637, "entropy-std": 3.709681749343872, "actions-mean": -0.018800897523760796, "actions-std": 0.7667291164398193, "actions-min": -0.9988071322441101, "actions-max": 0.9993199110031128}, "evaluation": {"episode-reward-mean": 14302.357421875, "episode-reward-min": 14302.357421875, "episode-reward-max": 14302.357421875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.8228464345153194, "reward_run-last-mean": 16.07195847046114, "reward_run-mean-mean": 14.653371752628978, "reward_run-median-mean": 15.927770965902255, "reward_run-range-mean": 18.7034770620777, "reward_ctrl-first-mean": -0.42028470039367677, "reward_ctrl-last-mean": -0.30828375816345216, "reward_ctrl-mean-mean": -0.3510145224571228, "reward_ctrl-median-mean": -0.3499751091003418, "reward_ctrl-range-mean": 0.47718585729599}}, "training": {"episode-reward-mean": 14861.163678209496, "episode-reward-min": 12951.364505300517, "episode-reward-max": 15193.104132107714, "episode-reward-std": 640.0343126585136, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5374486207133088, "reward_run-last-mean": 15.1079030580986, "reward_run-mean-mean": 15.212820379186581, "reward_run-median-mean": 16.13774176046681, "reward_run-range-mean": 18.696105295953377, "reward_ctrl-first-mean": -0.321934711933136, "reward_ctrl-last-mean": -0.3242252063751221, "reward_ctrl-mean-mean": -0.351656700977087, "reward_ctrl-median-mean": -0.3560706007480622, "reward_ctrl-range-mean": 0.4831947946548462}}, "update": {"Q_value-mean": 1323.64404296875, "Q_loss-mean": 16.063312530517578, "policy_loss-mean": -1322.2313232421875, "alpha": 0.3440415561199188, "alpha_loss-mean": 0.0007214350625872612}, "times": {"epoch_before_hook": 2.484399010427296e-05, "timestep_before_hook": 0.07575908480794169, "sample": 13.26812285577762, "train": 192.38865526096197, "timestep_after_hook": 0.03251859432202764, "training_paths": 0.07391408400144428, "evaluation_paths": 0.4915031709824689, "training_metrics": 0.0015071420057211071, "evaluation_metrics": 0.00040271200123243034, "epoch_after_hook": 1.4980032574385405e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15193.104132107714, "last-path-return": 15137.979533772654, "episodes": 2760, "total-samples": 2760000}, "epoch": 109, "timestep": 25000, "total_timestep": 2750000, "num_train_steps": 2750000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 110, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-40-01", "timestamp": 1652834401, "time_this_iter_s": 206.71381211280823, "time_total_s": 25256.934535503387, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 25256.934535503387, "timesteps_since_restore": 0, "iterations_since_restore": 110, "trial_id": "31acc_00000"}
{"alpha": 0.3485279083251953, "policy": {"shifts-mean": -0.08130655437707901, "shifts-std": 1.3524657487869263, "shifts-max": 3.2334179878234863, "shifts-min": -3.120347261428833, "scales-mean": 0.4073265492916107, "scales-std": 0.1592695564031601, "scales-max": 0.8035759329795837, "scales-min": 0.02868424728512764, "entropy-mean": -5.884129047393799, "entropy-std": 3.7684450149536133, "actions-mean": -0.06325038522481918, "actions-std": 0.746965765953064, "actions-min": -0.9976425170898438, "actions-max": 0.9987512826919556}, "evaluation": {"episode-reward-mean": 14821.8740234375, "episode-reward-min": 14821.8740234375, "episode-reward-max": 14821.8740234375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6985954170791564, "reward_run-last-mean": 17.216739771308767, "reward_run-mean-mean": 15.175160592051554, "reward_run-median-mean": 16.045273032887337, "reward_run-range-mean": 18.638439230646608, "reward_ctrl-first-mean": -0.4319077014923096, "reward_ctrl-last-mean": -0.22577011585235596, "reward_ctrl-mean-mean": -0.3532874979317189, "reward_ctrl-median-mean": -0.35890032052993776, "reward_ctrl-range-mean": 0.4879289388656616}}, "training": {"episode-reward-mean": 13199.353133704915, "episode-reward-min": 3122.6185164284198, "episode-reward-max": 15068.924346401598, "episode-reward-std": 3711.850340377884, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.3214887012882805, "reward_run-last-mean": 12.916000996817502, "reward_run-mean-mean": 13.547356534631504, "reward_run-median-mean": 14.367902753620982, "reward_run-range-mean": 18.844034105631046, "reward_ctrl-first-mean": -0.3220941352844238, "reward_ctrl-last-mean": -0.291794114112854, "reward_ctrl-mean-mean": -0.34800340092659005, "reward_ctrl-median-mean": -0.35073366522789, "reward_ctrl-range-mean": 0.49516282945871354}}, "update": {"Q_value-mean": 1325.5899658203125, "Q_loss-mean": 17.021106719970703, "policy_loss-mean": -1324.2265625, "alpha": 0.33745139837265015, "alpha_loss-mean": -0.0008038980304263532}, "times": {"epoch_before_hook": 2.435100032016635e-05, "timestep_before_hook": 0.07658146557514556, "sample": 13.354752565996023, "train": 192.2910718731291, "timestep_after_hook": 0.03260563951334916, "training_paths": 0.07428963601705618, "evaluation_paths": 0.48870027798693627, "training_metrics": 0.0015173419960774481, "evaluation_metrics": 0.0004045109963044524, "epoch_after_hook": 1.4069955796003342e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15193.104132107714, "last-path-return": 14949.23538435209, "episodes": 2785, "total-samples": 2785000}, "epoch": 110, "timestep": 25000, "total_timestep": 2775000, "num_train_steps": 2775000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 111, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-43-28", "timestamp": 1652834608, "time_this_iter_s": 206.70165610313416, "time_total_s": 25463.63619160652, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 25463.63619160652, "timesteps_since_restore": 0, "iterations_since_restore": 111, "trial_id": "31acc_00000"}
{"alpha": 0.33869272470474243, "policy": {"shifts-mean": -0.11772904545068741, "shifts-std": 1.3915505409240723, "shifts-max": 3.489604949951172, "shifts-min": -2.8481974601745605, "scales-mean": 0.4161454439163208, "scales-std": 0.16246339678764343, "scales-max": 0.9673914313316345, "scales-min": 0.022778332233428955, "entropy-mean": -6.204641819000244, "entropy-std": 3.8160388469696045, "actions-mean": -0.058493632823228836, "actions-std": 0.7709643840789795, "actions-min": -0.9989190101623535, "actions-max": 0.9995461702346802}, "evaluation": {"episode-reward-mean": 15039.8310546875, "episode-reward-min": 15039.8310546875, "episode-reward-max": 15039.8310546875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5838518720864089, "reward_run-last-mean": 16.11907346656608, "reward_run-mean-mean": 15.38941262755908, "reward_run-median-mean": 16.178901771483822, "reward_run-range-mean": 18.623482001732093, "reward_ctrl-first-mean": -0.24655187129974365, "reward_ctrl-last-mean": -0.4919928550720215, "reward_ctrl-mean-mean": -0.34958138343095785, "reward_ctrl-median-mean": -0.3513204097747803, "reward_ctrl-range-mean": 0.4490174293518066}}, "training": {"episode-reward-mean": 14826.559134829498, "episode-reward-min": 13999.638065491396, "episode-reward-max": 15085.049957702606, "episode-reward-std": 303.91899343394033, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5670383871981076, "reward_run-last-mean": 16.829727001955916, "reward_run-mean-mean": 15.18243607754753, "reward_run-median-mean": 16.060200406635744, "reward_run-range-mean": 18.759054919177853, "reward_ctrl-first-mean": -0.3389913105964661, "reward_ctrl-last-mean": -0.35643561601638796, "reward_ctrl-mean-mean": -0.35587694271802905, "reward_ctrl-median-mean": -0.3604921543598175, "reward_ctrl-range-mean": 0.482018318772316}}, "update": {"Q_value-mean": 1323.4248046875, "Q_loss-mean": 18.914051055908203, "policy_loss-mean": -1322.0277099609375, "alpha": 0.34524568915367126, "alpha_loss-mean": 0.0003943839983548969}, "times": {"epoch_before_hook": 2.5635992642492056e-05, "timestep_before_hook": 0.07650175562594086, "sample": 13.288428543048212, "train": 192.26515108934836, "timestep_after_hook": 0.032609837187919766, "training_paths": 0.07368662298540585, "evaluation_paths": 0.4865889399952721, "training_metrics": 0.0016027019883040339, "evaluation_metrics": 0.00041142001282423735, "epoch_after_hook": 1.5620025806128979e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15193.104132107714, "last-path-return": 15085.0499577026, "episodes": 2810, "total-samples": 2810000}, "epoch": 111, "timestep": 25000, "total_timestep": 2800000, "num_train_steps": 2800000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 112, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-46-55", "timestamp": 1652834815, "time_this_iter_s": 206.60588479042053, "time_total_s": 25670.242076396942, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 25670.242076396942, "timesteps_since_restore": 0, "iterations_since_restore": 112, "trial_id": "31acc_00000"}
{"alpha": 0.3517308235168457, "policy": {"shifts-mean": -0.10369034856557846, "shifts-std": 1.3879376649856567, "shifts-max": 4.779796600341797, "shifts-min": -5.447135925292969, "scales-mean": 0.415872186422348, "scales-std": 0.17381569743156433, "scales-max": 2.003234624862671, "scales-min": 0.030079655349254608, "entropy-mean": -6.074521064758301, "entropy-std": 3.9608266353607178, "actions-mean": -0.06887224316596985, "actions-std": 0.762383759021759, "actions-min": -1.0, "actions-max": 0.9986187815666199}, "evaluation": {"episode-reward-mean": 15016.4833984375, "episode-reward-min": 15016.4833984375, "episode-reward-max": 15016.4833984375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.9804397402508849, "reward_run-last-mean": 17.290394476990514, "reward_run-mean-mean": 15.35709479302593, "reward_run-median-mean": 16.132146253501674, "reward_run-range-mean": 18.647263965814005, "reward_ctrl-first-mean": -0.4063309192657471, "reward_ctrl-last-mean": -0.2250915765762329, "reward_ctrl-mean-mean": -0.340610608458519, "reward_ctrl-median-mean": -0.3446236848831177, "reward_ctrl-range-mean": 0.48396126031875614}}, "training": {"episode-reward-mean": 14962.613406555069, "episode-reward-min": 14400.049682214336, "episode-reward-max": 15196.851220816705, "episode-reward-std": 210.40695871076207, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7640497696776041, "reward_run-last-mean": 16.492609972950504, "reward_run-mean-mean": 15.316283827126039, "reward_run-median-mean": 16.164649491893897, "reward_run-range-mean": 18.731150525866276, "reward_ctrl-first-mean": -0.3365364122390747, "reward_ctrl-last-mean": -0.3652901220321656, "reward_ctrl-mean-mean": -0.35367042057096965, "reward_ctrl-median-mean": -0.3571155095100403, "reward_ctrl-range-mean": 0.47150801658630365}}, "update": {"Q_value-mean": 1322.313232421875, "Q_loss-mean": 18.387327194213867, "policy_loss-mean": -1320.9041748046875, "alpha": 0.347161203622818, "alpha_loss-mean": -0.0004242369905114174}, "times": {"epoch_before_hook": 2.4038017727434635e-05, "timestep_before_hook": 0.07579129107762128, "sample": 13.195941068144748, "train": 192.63198581524193, "timestep_after_hook": 0.032724958640756086, "training_paths": 0.07395743802771904, "evaluation_paths": 0.4924113919842057, "training_metrics": 0.0016039449837990105, "evaluation_metrics": 0.00041055798646993935, "epoch_after_hook": 1.4200049918144941e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15196.851220816701, "last-path-return": 14963.890153308137, "episodes": 2835, "total-samples": 2835000}, "epoch": 112, "timestep": 25000, "total_timestep": 2825000, "num_train_steps": 2825000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 113, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-50-22", "timestamp": 1652835022, "time_this_iter_s": 206.88748574256897, "time_total_s": 25877.12956213951, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 25877.12956213951, "timesteps_since_restore": 0, "iterations_since_restore": 113, "trial_id": "31acc_00000"}
{"alpha": 0.34722450375556946, "policy": {"shifts-mean": -0.13042020797729492, "shifts-std": 1.356216549873352, "shifts-max": 4.162867546081543, "shifts-min": -2.765606164932251, "scales-mean": 0.41359278559684753, "scales-std": 0.16558438539505005, "scales-max": 1.0931980609893799, "scales-min": 0.030511435121297836, "entropy-mean": -5.803073883056641, "entropy-std": 3.7292747497558594, "actions-mean": -0.07921599596738815, "actions-std": 0.7561800479888916, "actions-min": -0.9978612065315247, "actions-max": 0.9999257922172546}, "evaluation": {"episode-reward-mean": 14868.8125, "episode-reward-min": 14868.8125, "episode-reward-max": 14868.8125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.38284123538793763, "reward_run-last-mean": 15.828289404896623, "reward_run-mean-mean": 15.22803098750667, "reward_run-median-mean": 16.142247358519057, "reward_run-range-mean": 18.246316481607817, "reward_ctrl-first-mean": -0.11908299922943116, "reward_ctrl-last-mean": -0.541520357131958, "reward_ctrl-mean-mean": -0.3592180978894233, "reward_ctrl-median-mean": -0.35921081304550173, "reward_ctrl-range-mean": 0.46853296756744384}}, "training": {"episode-reward-mean": 13667.682277404543, "episode-reward-min": 2071.6678646416494, "episode-reward-max": 15180.796671942699, "episode-reward-std": 3871.0865729225025, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5299136141587348, "reward_run-last-mean": 14.254714183459157, "reward_run-mean-mean": 14.01080125086295, "reward_run-median-mean": 14.558837007760602, "reward_run-range-mean": 18.555493850874576, "reward_ctrl-first-mean": -0.2987836837768555, "reward_ctrl-last-mean": -0.34436737060546874, "reward_ctrl-mean-mean": -0.34311897345840936, "reward_ctrl-median-mean": -0.3447191905975342, "reward_ctrl-range-mean": 0.4839397302269936}}, "update": {"Q_value-mean": 1322.7197265625, "Q_loss-mean": 18.027944564819336, "policy_loss-mean": -1321.3095703125, "alpha": 0.34546253085136414, "alpha_loss-mean": 0.00026788757531903684}, "times": {"epoch_before_hook": 2.4130975361913443e-05, "timestep_before_hook": 0.0768423706467729, "sample": 13.323601889103884, "train": 192.26681695663137, "timestep_after_hook": 0.032661696313880384, "training_paths": 0.16207206298713572, "evaluation_paths": 0.4894207500037737, "training_metrics": 0.001614554988918826, "evaluation_metrics": 0.00042060299892909825, "epoch_after_hook": 1.514999894425273e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15196.851220816701, "last-path-return": 14894.824383866904, "episodes": 2860, "total-samples": 2860000}, "epoch": 113, "timestep": 25000, "total_timestep": 2850000, "num_train_steps": 2850000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 114, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-53-49", "timestamp": 1652835229, "time_this_iter_s": 206.7352159023285, "time_total_s": 26083.86477804184, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 26083.86477804184, "timesteps_since_restore": 0, "iterations_since_restore": 114, "trial_id": "31acc_00000"}
{"alpha": 0.35210496187210083, "policy": {"shifts-mean": 0.01608344353735447, "shifts-std": 1.4135462045669556, "shifts-max": 3.2363762855529785, "shifts-min": -5.009181022644043, "scales-mean": 0.42942699790000916, "scales-std": 0.1580810397863388, "scales-max": 0.8872702121734619, "scales-min": 0.03219382464885712, "entropy-mean": -6.08607292175293, "entropy-std": 3.760627269744873, "actions-mean": -0.0027173261623829603, "actions-std": 0.7790273427963257, "actions-min": -0.9998742938041687, "actions-max": 0.9992924928665161}, "evaluation": {"episode-reward-mean": 15076.90625, "episode-reward-min": 15076.90625, "episode-reward-max": 15076.90625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.3797079152717703, "reward_run-last-mean": 17.482184052262255, "reward_run-mean-mean": 15.434270647747201, "reward_run-median-mean": 16.343276430812068, "reward_run-range-mean": 18.92391662765198, "reward_ctrl-first-mean": -0.15621819496154787, "reward_ctrl-last-mean": -0.2763553619384766, "reward_ctrl-mean-mean": -0.35736426782608033, "reward_ctrl-median-mean": -0.3496174573898316, "reward_ctrl-range-mean": 0.4677455306053162}}, "training": {"episode-reward-mean": 14353.331207094117, "episode-reward-min": 10292.291991960023, "episode-reward-max": 15138.76756055135, "episode-reward-std": 1401.8842877503141, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5067775800324104, "reward_run-last-mean": 14.494568076978794, "reward_run-mean-mean": 14.706091036082432, "reward_run-median-mean": 16.04792874578297, "reward_run-range-mean": 18.73691373908565, "reward_ctrl-first-mean": -0.3105127894878387, "reward_ctrl-last-mean": -0.319198341369629, "reward_ctrl-mean-mean": -0.3527598289883137, "reward_ctrl-median-mean": -0.3557400786876678, "reward_ctrl-range-mean": 0.48346040606498714}}, "update": {"Q_value-mean": 1320.9638671875, "Q_loss-mean": 18.958314895629883, "policy_loss-mean": -1319.5367431640625, "alpha": 0.3485243022441864, "alpha_loss-mean": -5.025663267588243e-05}, "times": {"epoch_before_hook": 2.527900505810976e-05, "timestep_before_hook": 0.0761346562358085, "sample": 13.162511911825277, "train": 192.18492995141423, "timestep_after_hook": 0.0326106124848593, "training_paths": 0.16290915000718087, "evaluation_paths": 0.4891413610021118, "training_metrics": 0.0014484839921351522, "evaluation_metrics": 0.0004018420004285872, "epoch_after_hook": 1.4849938452243805e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15196.851220816701, "last-path-return": 14951.626608672019, "episodes": 2885, "total-samples": 2885000}, "epoch": 114, "timestep": 25000, "total_timestep": 2875000, "num_train_steps": 2875000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 115, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_01-57-15", "timestamp": 1652835435, "time_this_iter_s": 206.4914426803589, "time_total_s": 26290.3562207222, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 26290.3562207222, "timesteps_since_restore": 0, "iterations_since_restore": 115, "trial_id": "31acc_00000"}
{"alpha": 0.3345533609390259, "policy": {"shifts-mean": -0.09037670493125916, "shifts-std": 1.3997695446014404, "shifts-max": 3.818093776702881, "shifts-min": -3.922344207763672, "scales-mean": 0.4135681688785553, "scales-std": 0.15773479640483856, "scales-max": 1.0528862476348877, "scales-min": 0.03394895792007446, "entropy-mean": -5.937935829162598, "entropy-std": 4.001102924346924, "actions-mean": -0.05521450936794281, "actions-std": 0.7644496560096741, "actions-min": -0.9996495246887207, "actions-max": 0.9996411204338074}, "evaluation": {"episode-reward-mean": 14358.90625, "episode-reward-min": 14358.90625, "episode-reward-max": 14358.90625, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.9890688068946532, "reward_run-last-mean": 15.630023133676332, "reward_run-mean-mean": 14.712627371268667, "reward_run-median-mean": 15.801281003683414, "reward_run-range-mean": 18.81488550632385, "reward_ctrl-first-mean": -0.23495373725891114, "reward_ctrl-last-mean": -0.3957845687866211, "reward_ctrl-mean-mean": -0.3537209704399109, "reward_ctrl-median-mean": -0.3530530214309693, "reward_ctrl-range-mean": 0.5125218868255615}}, "training": {"episode-reward-mean": 14740.56952314197, "episode-reward-min": 13836.97186191258, "episode-reward-max": 15070.589280024004, "episode-reward-std": 397.67033683304544, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.4951695834489264, "reward_run-last-mean": 16.19198514763525, "reward_run-mean-mean": 15.094853495584122, "reward_run-median-mean": 16.066153033951082, "reward_run-range-mean": 18.534699974867344, "reward_ctrl-first-mean": -0.3340460157394409, "reward_ctrl-last-mean": -0.3710925364494324, "reward_ctrl-mean-mean": -0.35428397244215015, "reward_ctrl-median-mean": -0.35771812677383424, "reward_ctrl-range-mean": 0.47665044903755194}}, "update": {"Q_value-mean": 1323.0343017578125, "Q_loss-mean": 20.113460540771484, "policy_loss-mean": -1321.6453857421875, "alpha": 0.34410423040390015, "alpha_loss-mean": 0.000725420075468719}, "times": {"epoch_before_hook": 3.068198566325009e-05, "timestep_before_hook": 0.07579442451242357, "sample": 13.30490560468752, "train": 192.19455988684786, "timestep_after_hook": 0.032446684286696836, "training_paths": 0.07531528698746115, "evaluation_paths": 0.4856404770107474, "training_metrics": 0.0015152739943005145, "evaluation_metrics": 0.00040237398934550583, "epoch_after_hook": 1.6060075722634792e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15232.460526326477, "last-path-return": 14955.365326454652, "episodes": 2910, "total-samples": 2910000}, "epoch": 115, "timestep": 25000, "total_timestep": 2900000, "num_train_steps": 2900000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 116, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_02-00-42", "timestamp": 1652835642, "time_this_iter_s": 206.55203008651733, "time_total_s": 26496.908250808716, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 26496.908250808716, "timesteps_since_restore": 0, "iterations_since_restore": 116, "trial_id": "31acc_00000"}
{"alpha": 0.3344019651412964, "policy": {"shifts-mean": -0.11914841085672379, "shifts-std": 1.344663381576538, "shifts-max": 2.77726149559021, "shifts-min": -3.0726544857025146, "scales-mean": 0.4015449583530426, "scales-std": 0.15981927514076233, "scales-max": 0.8254150152206421, "scales-min": 0.02839982882142067, "entropy-mean": -5.761006832122803, "entropy-std": 3.612032413482666, "actions-mean": -0.05691168084740639, "actions-std": 0.7525234818458557, "actions-min": -0.9990127682685852, "actions-max": 0.9985426068305969}, "evaluation": {"episode-reward-mean": 15109.7998046875, "episode-reward-min": 15109.7998046875, "episode-reward-max": 15109.7998046875, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5090001143301076, "reward_run-last-mean": 17.218001411538353, "reward_run-mean-mean": 15.44918142923785, "reward_run-median-mean": 16.157547826943528, "reward_run-range-mean": 18.266130272586693, "reward_ctrl-first-mean": -0.43283767700195314, "reward_ctrl-last-mean": -0.11245468854904175, "reward_ctrl-mean-mean": -0.3393811883211136, "reward_ctrl-median-mean": -0.33844747543334963, "reward_ctrl-range-mean": 0.4560606002807618}}, "training": {"episode-reward-mean": 14930.936842760071, "episode-reward-min": 14567.938356893981, "episode-reward-max": 15141.286716429993, "episode-reward-std": 179.2237696018694, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6144830666485112, "reward_run-last-mean": 16.412378954252517, "reward_run-mean-mean": 15.283572948389875, "reward_run-median-mean": 16.144529056704187, "reward_run-range-mean": 18.56115887487206, "reward_ctrl-first-mean": -0.2924098920822144, "reward_ctrl-last-mean": -0.35671584606170653, "reward_ctrl-mean-mean": -0.35263610562980174, "reward_ctrl-median-mean": -0.3561998903751374, "reward_ctrl-range-mean": 0.4833634829521179}}, "update": {"Q_value-mean": 1323.10986328125, "Q_loss-mean": 21.967166900634766, "policy_loss-mean": -1321.6944580078125, "alpha": 0.3487073481082916, "alpha_loss-mean": 1.6070194760686718e-05}, "times": {"epoch_before_hook": 2.4612003471702337e-05, "timestep_before_hook": 0.07614882191410288, "sample": 13.240752892830642, "train": 192.2339230705693, "timestep_after_hook": 0.03254014771664515, "training_paths": 0.07311187000595964, "evaluation_paths": 0.48579307200270705, "training_metrics": 0.0015311309834942222, "evaluation_metrics": 0.0004023670044261962, "epoch_after_hook": 1.5720142982900143e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15232.460526326477, "last-path-return": 15036.683060086923, "episodes": 2935, "total-samples": 2935000}, "epoch": 116, "timestep": 25000, "total_timestep": 2925000, "num_train_steps": 2925000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 117, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_02-04-08", "timestamp": 1652835848, "time_this_iter_s": 206.5259611606598, "time_total_s": 26703.434211969376, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 26703.434211969376, "timesteps_since_restore": 0, "iterations_since_restore": 117, "trial_id": "31acc_00000"}
{"alpha": 0.34423792362213135, "policy": {"shifts-mean": -0.031563788652420044, "shifts-std": 1.41343355178833, "shifts-max": 7.1221923828125, "shifts-min": -5.39150857925415, "scales-mean": 0.4124045670032501, "scales-std": 0.15802092850208282, "scales-max": 0.8656677603721619, "scales-min": 0.03497932106256485, "entropy-mean": -6.026514053344727, "entropy-std": 3.9434704780578613, "actions-mean": -0.03164111450314522, "actions-std": 0.7683982849121094, "actions-min": -0.9999756813049316, "actions-max": 0.9999996423721313}, "evaluation": {"episode-reward-mean": 14377.396484375, "episode-reward-min": 14377.396484375, "episode-reward-max": 14377.396484375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.42309339900824694, "reward_run-last-mean": 15.887299072951464, "reward_run-mean-mean": 14.727150900844515, "reward_run-median-mean": 15.826667841205335, "reward_run-range-mean": 18.185572272661684, "reward_ctrl-first-mean": -0.24439861774444582, "reward_ctrl-last-mean": -0.44486517906188966, "reward_ctrl-mean-mean": -0.3497545825600624, "reward_ctrl-median-mean": -0.3614867925643921, "reward_ctrl-range-mean": 0.48263162374496466}}, "training": {"episode-reward-mean": 14083.500166766147, "episode-reward-min": 6437.675420753198, "episode-reward-max": 15153.634765679837, "episode-reward-std": 2555.7155925530096, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5778356373034089, "reward_run-last-mean": 15.027549480330094, "reward_run-mean-mean": 14.432057575823766, "reward_run-median-mean": 14.747725613484008, "reward_run-range-mean": 18.803375263123613, "reward_ctrl-first-mean": -0.2988270604610443, "reward_ctrl-last-mean": -0.3281995177268982, "reward_ctrl-mean-mean": -0.34855740905761723, "reward_ctrl-median-mean": -0.3513153207302094, "reward_ctrl-range-mean": 0.4804124873876572}}, "update": {"Q_value-mean": 1322.786376953125, "Q_loss-mean": 22.002052307128906, "policy_loss-mean": -1321.3541259765625, "alpha": 0.34783828258514404, "alpha_loss-mean": -0.00024653912987560034}, "times": {"epoch_before_hook": 2.52070021815598e-05, "timestep_before_hook": 0.07563785812817514, "sample": 13.176546279108152, "train": 192.27941117875162, "timestep_after_hook": 0.03258755124988966, "training_paths": 0.1624750749906525, "evaluation_paths": 0.4878077610046603, "training_metrics": 0.0014766929962206632, "evaluation_metrics": 0.0004079759819433093, "epoch_after_hook": 1.5379919204860926e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15232.460526326477, "last-path-return": 14954.70659297416, "episodes": 2960, "total-samples": 2960000}, "epoch": 117, "timestep": 25000, "total_timestep": 2950000, "num_train_steps": 2950000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 118, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_02-07-35", "timestamp": 1652836055, "time_this_iter_s": 206.59766602516174, "time_total_s": 26910.031877994537, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 26910.031877994537, "timesteps_since_restore": 0, "iterations_since_restore": 118, "trial_id": "31acc_00000"}
{"alpha": 0.34862950444221497, "policy": {"shifts-mean": -0.052777379751205444, "shifts-std": 1.3917442560195923, "shifts-max": 7.565428256988525, "shifts-min": -4.906698226928711, "scales-mean": 0.40464887022972107, "scales-std": 0.15573076903820038, "scales-max": 1.1588168144226074, "scales-min": 0.013675177469849586, "entropy-mean": -6.0617218017578125, "entropy-std": 4.406188488006592, "actions-mean": -0.03182562068104744, "actions-std": 0.7635217905044556, "actions-min": -0.9999150037765503, "actions-max": 1.0}, "evaluation": {"episode-reward-mean": 14625.7470703125, "episode-reward-min": 14625.7470703125, "episode-reward-max": 14625.7470703125, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.7941545649149867, "reward_run-last-mean": 17.222352156177294, "reward_run-mean-mean": 14.96859437600337, "reward_run-median-mean": 15.861057938675458, "reward_run-range-mean": 18.742955387378213, "reward_ctrl-first-mean": -0.3971468210220337, "reward_ctrl-last-mean": -0.3322858572006226, "reward_ctrl-mean-mean": -0.3428470297694206, "reward_ctrl-median-mean": -0.3486976981163025, "reward_ctrl-range-mean": 0.5186675906181335}}, "training": {"episode-reward-mean": 14884.80367295493, "episode-reward-min": 14416.943848493118, "episode-reward-max": 15125.872682473022, "episode-reward-std": 245.1249491759678, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.5686959977543186, "reward_run-last-mean": 16.470537329803847, "reward_run-mean-mean": 15.240361903918275, "reward_run-median-mean": 16.095281374950133, "reward_run-range-mean": 18.79794880095712, "reward_ctrl-first-mean": -0.3324545383453369, "reward_ctrl-last-mean": -0.36626917839050294, "reward_ctrl-mean-mean": -0.3555582309633494, "reward_ctrl-median-mean": -0.3586556267738342, "reward_ctrl-range-mean": 0.47834403932094577}}, "update": {"Q_value-mean": 1321.5010986328125, "Q_loss-mean": 22.412050247192383, "policy_loss-mean": -1320.054931640625, "alpha": 0.35091620683670044, "alpha_loss-mean": 5.6524277169955894e-05}, "times": {"epoch_before_hook": 2.5721994461491704e-05, "timestep_before_hook": 0.07656006448087282, "sample": 13.414428868913092, "train": 192.4278435119195, "timestep_after_hook": 0.03248643811093643, "training_paths": 0.07435117900604382, "evaluation_paths": 0.5240943859971594, "training_metrics": 0.006172623980091885, "evaluation_metrics": 0.008153445000061765, "epoch_after_hook": 1.8700084183365107e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15232.460526326477, "last-path-return": 15090.977461201728, "episodes": 2985, "total-samples": 2985000}, "epoch": 118, "timestep": 25000, "total_timestep": 2975000, "num_train_steps": 2975000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 119, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_02-11-02", "timestamp": 1652836262, "time_this_iter_s": 206.95552277565002, "time_total_s": 27116.987400770187, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 27116.987400770187, "timesteps_since_restore": 0, "iterations_since_restore": 119, "trial_id": "31acc_00000"}
{"alpha": 0.34768936038017273, "policy": {"shifts-mean": 0.014624953269958496, "shifts-std": 1.3572572469711304, "shifts-max": 3.6187455654144287, "shifts-min": -3.6748318672180176, "scales-mean": 0.41251087188720703, "scales-std": 0.16532734036445618, "scales-max": 0.8445427417755127, "scales-min": 0.023808641359210014, "entropy-mean": -6.007743835449219, "entropy-std": 3.7272140979766846, "actions-mean": -0.0065599605441093445, "actions-std": 0.7654885053634644, "actions-min": -0.9990545511245728, "actions-max": 0.9994532465934753}, "evaluation": {"episode-reward-mean": 15037.59375, "episode-reward-min": 15037.59375, "episode-reward-max": 15037.59375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.901636802731503, "reward_run-last-mean": 17.366281163988333, "reward_run-mean-mean": 15.393971428460311, "reward_run-median-mean": 16.32974881918244, "reward_run-range-mean": 18.92029505791612, "reward_ctrl-first-mean": -0.32089996337890625, "reward_ctrl-last-mean": -0.2938960075378418, "reward_ctrl-mean-mean": -0.3563772949457169, "reward_ctrl-median-mean": -0.35338134765625007, "reward_ctrl-range-mean": 0.441618013381958}}, "training": {"episode-reward-mean": 14214.759418783622, "episode-reward-min": 8293.161208167816, "episode-reward-max": 15182.298062229598, "episode-reward-std": 1986.130780181625, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6205316460601776, "reward_run-last-mean": 14.760831890899567, "reward_run-mean-mean": 14.571117201489045, "reward_run-median-mean": 15.511190327807668, "reward_run-range-mean": 18.53039989996118, "reward_ctrl-first-mean": -0.2903135490417481, "reward_ctrl-last-mean": -0.33747656822204586, "reward_ctrl-mean-mean": -0.35635778270542623, "reward_ctrl-median-mean": -0.3600524139404297, "reward_ctrl-range-mean": 0.48695250809192664}}, "update": {"Q_value-mean": 1320.7296142578125, "Q_loss-mean": 22.666852951049805, "policy_loss-mean": -1319.3094482421875, "alpha": 0.3456360995769501, "alpha_loss-mean": 9.347370360046625e-05}, "times": {"epoch_before_hook": 2.5290995836257935e-05, "timestep_before_hook": 0.0761223591689486, "sample": 13.425991960742977, "train": 192.51948056017864, "timestep_after_hook": 0.03260063339257613, "training_paths": 0.07383893697988242, "evaluation_paths": 0.48442512200563215, "training_metrics": 0.0014970320044085383, "evaluation_metrics": 0.0004020220076199621, "epoch_after_hook": 1.4289980754256248e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15232.460526326477, "last-path-return": 14481.609763504412, "episodes": 3010, "total-samples": 3010000}, "epoch": 119, "timestep": 25000, "total_timestep": 3000000, "num_train_steps": 3000000, "done": false, "timesteps_total": null, "episodes_total": null, "training_iteration": 120, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_02-14-29", "timestamp": 1652836469, "time_this_iter_s": 206.9953854084015, "time_total_s": 27323.98278617859, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 27323.98278617859, "timesteps_since_restore": 0, "iterations_since_restore": 120, "trial_id": "31acc_00000"}
{"done": true, "alpha": 0.34768936038017273, "policy": {"shifts-mean": 0.014624953269958496, "shifts-std": 1.3572572469711304, "shifts-max": 3.6187455654144287, "shifts-min": -3.6748318672180176, "scales-mean": 0.41251087188720703, "scales-std": 0.16532734036445618, "scales-max": 0.8445427417755127, "scales-min": 0.023808641359210014, "entropy-mean": -6.007743835449219, "entropy-std": 3.7272140979766846, "actions-mean": -0.0065599605441093445, "actions-std": 0.7654885053634644, "actions-min": -0.9990545511245728, "actions-max": 0.9994532465934753}, "evaluation": {"episode-reward-mean": 15037.59375, "episode-reward-min": 15037.59375, "episode-reward-max": 15037.59375, "episode-reward-std": 0.0, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.901636802731503, "reward_run-last-mean": 17.366281163988333, "reward_run-mean-mean": 15.393971428460311, "reward_run-median-mean": 16.32974881918244, "reward_run-range-mean": 18.92029505791612, "reward_ctrl-first-mean": -0.32089996337890625, "reward_ctrl-last-mean": -0.2938960075378418, "reward_ctrl-mean-mean": -0.3563772949457169, "reward_ctrl-median-mean": -0.35338134765625007, "reward_ctrl-range-mean": 0.441618013381958}}, "training": {"episode-reward-mean": 14214.759418783622, "episode-reward-min": 8293.161208167816, "episode-reward-max": 15182.298062229598, "episode-reward-std": 1986.130780181625, "episode-length-mean": 1000.0, "episode-length-min": 1000, "episode-length-max": 1000, "episode-length-std": 0.0, "environment_infos": {"reward_run-first-mean": -0.6205316460601776, "reward_run-last-mean": 14.760831890899567, "reward_run-mean-mean": 14.571117201489045, "reward_run-median-mean": 15.511190327807668, "reward_run-range-mean": 18.53039989996118, "reward_ctrl-first-mean": -0.2903135490417481, "reward_ctrl-last-mean": -0.33747656822204586, "reward_ctrl-mean-mean": -0.35635778270542623, "reward_ctrl-median-mean": -0.3600524139404297, "reward_ctrl-range-mean": 0.48695250809192664}}, "update": {"Q_value-mean": 1320.7296142578125, "Q_loss-mean": 22.666852951049805, "policy_loss-mean": -1319.3094482421875, "alpha": 0.3456360995769501, "alpha_loss-mean": 9.347370360046625e-05}, "times": {"epoch_before_hook": 2.5290995836257935e-05, "timestep_before_hook": 0.0761223591689486, "sample": 13.425991960742977, "train": 192.51948056017864, "timestep_after_hook": 0.03260063339257613, "training_paths": 0.07383893697988242, "evaluation_paths": 0.48442512200563215, "training_metrics": 0.0014970320044085383, "evaluation_metrics": 0.0004020220076199621, "epoch_after_hook": 1.4289980754256248e-06}, "sampler": {"pool-size": 1000000, "max-path-return": 15232.460526326477, "last-path-return": 14481.609763504412, "episodes": 3010, "total-samples": 3010000}, "epoch": 119, "timestep": 25000, "total_timestep": 3000000, "num_train_steps": 3000000, "timesteps_total": null, "episodes_total": null, "training_iteration": 121, "experiment_id": "aa6a66a2866746f0a9d46236d60e4b5e", "date": "2022-05-18_02-14-29", "timestamp": 1652836469, "time_this_iter_s": 4.458427429199219e-05, "time_total_s": 27323.982830762863, "pid": 283289, "hostname": "cpu-q-259", "node_ip": "10.43.77.35", "config": {"git_sha": "43dc0887a60101b40e4f56d5bcaad101eb95546d master", "environment_params": {"training": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}, "evaluation": {"domain": "HalfCheetah", "task": "v2", "universe": "gym", "kwargs": {}}}, "policy_params": {"class_name": "FeedforwardGaussianPolicy", "config": {"hidden_layer_sizes": [256, 256], "squash": true, "observation_keys": null, "preprocessors": null}}, "exploration_policy_params": {"class_name": "ContinuousUniformPolicy", "config": {"observation_keys": null}}, "Q_params": {"class_name": "double_feedforward_Q_function", "config": {"hidden_layer_sizes": [256, 256], "observation_keys": null, "preprocessors": null}}, "algorithm_params": {"config": {"train_every_n_steps": 1, "n_train_repeat": 1, "eval_render_kwargs": {}, "eval_n_episodes": 1, "num_warmup_samples": 10000, "policy_lr": 0.0003, "Q_lr": 0.0003, "alpha_lr": 0.0003, "target_update_interval": 1, "tau": 0.005, "target_entropy": "auto", "discount": 0.99, "reward_scale": 1.0, "n_epochs": 120, "epoch_length": 25000, "min_pool_size": 1000, "batch_size": 256}, "class_name": "SAC"}, "replay_pool_params": {"class_name": "SimpleReplayPool", "config": {"max_size": 1000000}}, "sampler_params": {"class_name": "SimpleSampler", "config": {"max_path_length": 1000}}, "run_params": {"host_name": "cpu-q-259", "seed": 9479, "checkpoint_at_end": true, "checkpoint_frequency": 10, "checkpoint_replay_pool": false, "run_eagerly": null}, "restore": null}, "time_since_restore": 27323.982830762863, "timesteps_since_restore": 0, "iterations_since_restore": 121, "trial_id": "31acc_00000"}
